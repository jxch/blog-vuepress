[
  {
    "title": "Java 根据 Getter 方法获取字段及注解值",
    "path": "/blogs/bianmabiji/JavagenjuGetterfangfahuoquziduanjizhujiezhi.html",
    "url": "/blogs/bianmabiji/JavagenjuGetterfangfahuoquziduanjizhujiezhi.html",
    "content": "---\r\ntitle: Java 根据 Getter 方法获取字段及注解值\r\ndate: 2025/04/12\r\ntags:\r\n - Java\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```java\r\n@FunctionalInterface\r\npublic interface SIFunction<T, R> extends Function<T, R>, Serializable {}\r\n```\r\n\r\n```java\r\npublic class FieldUtil {\r\n\r\n    public static <T, R> String getFieldNameByGetter(SIFunction<T, R> func) {\r\n        try {\r\n            SerializedLambda serializedLambda = getSerializedLambda(func);\r\n            String getterMethodName = serializedLambda.getImplMethodName();\r\n            return methodToFieldName(getterMethodName);\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(\"获取字段名失败\", e);\r\n        }\r\n    }\r\n\r\n    private static SerializedLambda getSerializedLambda(Serializable lambda) throws Exception {\r\n        // 通过反射调用writeReplace方法获取SerializedLambda\r\n        Method writeReplace = lambda.getClass().getDeclaredMethod(\"writeReplace\");\r\n        writeReplace.setAccessible(true);\r\n        return (SerializedLambda) writeReplace.invoke(lambda);\r\n    }\r\n\r\n    private static String methodToFieldName(String getterMethodName) {\r\n        String fieldName;\r\n        if (getterMethodName.startsWith(\"get\")) {\r\n            fieldName = getterMethodName.substring(3);\r\n        } else if (getterMethodName.startsWith(\"is\")) {\r\n            fieldName = getterMethodName.substring(2);\r\n        } else {\r\n            throw new IllegalArgumentException(\"无效的getter方法名称: \" + getterMethodName);\r\n        }\r\n        // 将首字母转小写\r\n        return fieldName.substring(0, 1).toLowerCase(Locale.ROOT) + fieldName.substring(1);\r\n    }\r\n\r\n    public static <T, R> Field getFieldByGetter(SIFunction<T, R> getter, Class<T> clazz) {\r\n        try {\r\n            return clazz.getDeclaredField(getFieldNameByGetter(getter));\r\n        } catch (NoSuchFieldException e) {\r\n            throw new RuntimeException(\"字段不存在\", e);\r\n        }\r\n    }\r\n\r\n    public static <T, R, A extends Annotation> String getAnnotationValueByGetter(SIFunction<T, R> getter, Class<T> clazz, Class<A> annotationClass) {\r\n        try {\r\n            // 获取字段名\r\n            String fieldName = getFieldNameByGetter(getter);\r\n\r\n            // 获取字段对象\r\n            Field field = clazz.getDeclaredField(fieldName);\r\n\r\n            // 获取字段上的注解\r\n            A annotation = field.getAnnotation(annotationClass);\r\n\r\n            // 如果注解存在，返回其 value 属性值\r\n            if (annotation != null) {\r\n                // 使用反射获取注解的 value 属性值\r\n                Method valueMethod = annotationClass.getMethod(\"value\");\r\n                return (String) valueMethod.invoke(annotation);\r\n            } else {\r\n                throw new RuntimeException(\"字段没有指定的注解: \" + fieldName);\r\n            }\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(\"获取注解值失败\", e);\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Java 根据 Getter 方法获取字段及注解值"
    },
    "frontmatter": {
      "title": "Java 根据 Getter 方法获取字段及注解值",
      "date": "2025/04/12",
      "tags": [
        "Java"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Java 获取接口泛型类型",
    "path": "/blogs/bianmabiji/Javahuoqujiekoufanxingleixing.html",
    "url": "/blogs/bianmabiji/Javahuoqujiekoufanxingleixing.html",
    "content": "---\r\ntitle: Java 获取接口泛型类型\r\ndate: 2025/04/12\r\ntags:\r\n - Java\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```java\r\n    @SuppressWarnings(\"unchecked\")\r\n    public Class<S> getTypeClass() {\r\n        Class<?> clazz = this.getClass();\r\n        Type result = InterfaceUtils.findParameterizedType(clazz, ProjectTypeServiceGetter.class);\r\n        if (result != null) {\r\n            ParameterizedType pt = (ParameterizedType) result;\r\n            // 获取第一个泛型参数，它对应 S\r\n            Type sType = pt.getActualTypeArguments()[0];\r\n            if (sType instanceof Class) {\r\n                return (Class<S>) sType;\r\n            } else if (sType instanceof ParameterizedType) {\r\n                // 处理嵌套泛型情况\r\n                return (Class<S>) ((ParameterizedType) sType).getRawType();\r\n            }\r\n        }\r\n        throw new IllegalStateException(\"无法获取泛型类型 S 的 Class 对象\");\r\n    }\r\n```\r\n\r\n\r\n```java\r\npublic class InterfaceUtils {\r\n\r\n    /**\r\n     * 获取指定类实现的所有接口，包括父类实现的接口以及接口之间的继承关系。\r\n     *\r\n     * @param clazz 要查找接口的类\r\n     * @return 包含所有接口的集合\r\n     */\r\n    public static Set<Class<?>> getAllInterfaces(Class<?> clazz) {\r\n        Set<Class<?>> interfaces = new HashSet<>();\r\n        // 遍历类的继承层次结构\r\n        while (clazz != null) {\r\n            // 获取当前类直接实现的接口\r\n            Class<?>[] directInterfaces = clazz.getInterfaces();\r\n            for (Class<?> intf : directInterfaces) {\r\n                collectInterfaces(intf, interfaces);\r\n            }\r\n            clazz = clazz.getSuperclass();\r\n        }\r\n        return interfaces;\r\n    }\r\n\r\n    /**\r\n     * 递归地将接口及其扩展的接口加入到集合中。\r\n     *\r\n     * @param intf       当前的接口\r\n     * @param interfaces 用来保存所有接口的集合\r\n     */\r\n    private static void collectInterfaces(Class<?> intf, Set<Class<?>> interfaces) {\r\n        if (interfaces.add(intf)) {\r\n            // 获取接口可能扩展的其他接口\r\n            for (Class<?> superInterface : intf.getInterfaces()) {\r\n                collectInterfaces(superInterface, interfaces);\r\n            }\r\n        }\r\n    }\r\n\r\n    public static Type findParameterizedType(Type clazz, Class<?> targetType) {\r\n        if (clazz instanceof ParameterizedType) {\r\n            ParameterizedType pt = (ParameterizedType) clazz;\r\n            // 如果直接匹配目标接口\r\n            if (targetType.equals(pt.getRawType())) {\r\n                return pt;\r\n            }\r\n            // 检查该参数化类型的原始类型的接口\r\n            return findParameterizedType(pt.getRawType(), targetType);\r\n        } else if (clazz instanceof Class) {\r\n            Class<?> currentClass = (Class<?>) clazz;\r\n\r\n            // 检查当前类所有直接实现的接口\r\n            for (Type intf : currentClass.getGenericInterfaces()) {\r\n                Type result = findParameterizedType(intf, targetType);\r\n                if (result != null) {\r\n                    return result;\r\n                }\r\n            }\r\n            // 检查父类\r\n            Type superClass = currentClass.getGenericSuperclass();\r\n            if (superClass != null) {\r\n                return findParameterizedType(superClass, targetType);\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Java 获取接口泛型类型"
    },
    "frontmatter": {
      "title": "Java 获取接口泛型类型",
      "date": "2025/04/12",
      "tags": [
        "Java"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "MAVEN 上传到中心仓库",
    "path": "/blogs/bianmabiji/MAVENshangchuandaozhongxincangku.html",
    "url": "/blogs/bianmabiji/MAVENshangchuandaozhongxincangku.html",
    "content": "---\r\ntitle: MAVEN 上传到中心仓库\r\ndate: 2025/03/05\r\ntags:\r\n - MAVEN\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n1. 注册中心仓库账户：[central.sonatype.com](https://central.sonatype.com)\r\n2. 使用 GPG 生成密钥并上传到公钥服务器\r\n3. 配置 Maven 的 Setting.xml 文件\r\n4. pom.xml 文件模板\r\n5. 发布到中心仓库\r\n:::\r\n\r\n## 注册中心仓库账户 \r\n\r\n1. 注册中心仓库的账户：[central.sonatype.com](https://central.sonatype.com)\r\n2. 使用 Github 登录，可以自动获得命名空间 -> 有效的 groupId\r\n3. Generate User Token  ->  自动生成 maven setting.xml 的 server 配置项（修改 id 为 central）\r\n\r\n## GPG\r\n\r\n```powershell\r\n# 安装GPG\r\nwinget install GnuPG.Gpg4win\r\n\r\n# 生成密钥\r\ngpg --full-generate-key\r\n\r\n# 上传公钥到GPG公钥服务器\r\ngpg --keyserver pgp.mit.edu --send-keys <KEY_ID>\r\ngpg --keyserver keyserver.ubuntu.com --send-keys <KEY_ID>\r\n\r\n# 导出公钥\r\ngpg --armor --export <KEY_ID> > public_key_1.asc\r\n# 导出私钥\r\ngpg --armor --export-secret-keys <KEY_ID> > private_key_2.asc\r\n```\r\n\r\n## Maven Setting.xml\r\n\r\n```xml\r\n\t<servers>\r\n\t\t<server>\r\n\t\t\t<id>central</id>\r\n\t\t\t<username>${username}</username>\r\n\t\t\t<password>${token}</password>\r\n\t\t</server>\r\n    </servers>\r\n\r\n\t<profiles>\r\n\t\t<profile>\r\n\t\t\t<id>gpg-profile</id>\r\n\t\t\t<properties>\r\n\t\t\t\t<gpg.keyname> ${KEY_ID} </gpg.keyname>\r\n\t\t\t\t<gpg.passphrase><![CDATA[password]]></gpg.passphrase>\r\n\t\t\t</properties>\r\n\t\t</profile>\r\n\t</profiles>\r\n\t<activeProfiles>\r\n\t\t<activeProfile>gpg-profile</activeProfile>\r\n\t</activeProfiles>\r\n```\r\n\r\n## pom.xml\r\n\r\n```xml\r\n    <groupId>io.github.jxch</groupId>\r\n    <artifactId>capital-py4j-spring-boot-starter</artifactId>\r\n    <version>3.2.5-alpha.1</version>\r\n    <name>capital-py4j-spring-boot-starter</name>\r\n    <description>py4j本地执行引擎与springboot的无缝集成</description>\r\n    <url>https://github.com/jxch-capital/capital-py4j-spring-boot-starter</url>\r\n\r\n    <properties>\r\n        <maven.compiler.source>21</maven.compiler.source>\r\n        <maven.compiler.target>21</maven.compiler.target>\r\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\r\n        <lombok.version>1.18.32</lombok.version>\r\n        <hutool.version>5.8.27</hutool.version>\r\n        <maven-source-plugin.version>3.3.1</maven-source-plugin.version>\r\n        <maven-javadoc-plugin.version>3.6.3</maven-javadoc-plugin.version>\r\n        <maven-gpg-plugin.version>3.2.4</maven-gpg-plugin.version>\r\n        <maven-release-plugin.version>3.0.1</maven-release-plugin.version>\r\n        <central-publishing-maven-plugin.version>0.4.0</central-publishing-maven-plugin.version>\r\n    </properties>\r\n\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-source-plugin</artifactId>\r\n                <version>${maven-source-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>attach-sources</id>\r\n                        <goals>\r\n                            <goal>jar-no-fork</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-javadoc-plugin</artifactId>\r\n                <version>${maven-javadoc-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>attach-javadocs</id>\r\n                        <goals>\r\n                            <goal>jar</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.sonatype.central</groupId>\r\n                <artifactId>central-publishing-maven-plugin</artifactId>\r\n                <version>${central-publishing-maven-plugin.version}</version>\r\n                <extensions>true</extensions>\r\n                <configuration>\r\n                    <publishingServerId>central</publishingServerId>\r\n                    <tokenAuth>true</tokenAuth>\r\n                    <autoPublish>true</autoPublish>\r\n                    <waitUntil>published</waitUntil>\r\n                </configuration>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-release-plugin</artifactId>\r\n                <version>${maven-release-plugin.version}</version>\r\n                <configuration>\r\n                    <goals>deploy nexus-staging:release</goals>\r\n                    <autoVersionSubmodules>true</autoVersionSubmodules>\r\n                    <useReleaseProfile>false</useReleaseProfile>\r\n                    <releaseProfiles>release</releaseProfiles>\r\n                </configuration>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-gpg-plugin</artifactId>\r\n                <version>${maven-gpg-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>sign-artifacts</id>\r\n                        <phase>verify</phase>\r\n                        <goals>\r\n                            <goal>sign</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n\r\n    <licenses>\r\n        <license>\r\n            <name>The Apache Software License, Version 2.0</name>\r\n            <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>\r\n            <distribution>repo</distribution>\r\n        </license>\r\n    </licenses>\r\n\r\n    <scm>\r\n        <connection>scm:git:git://github.com/jxch-capital/capital-py4j-spring-boot-starter.git</connection>\r\n        <developerConnection>scm:git:ssh://github.com:jxch-capital/capital-py4j-spring-boot-starter.git</developerConnection>\r\n        <url>${developer_github_project_url}</url>\r\n    </scm>\r\n\r\n    <developers>\r\n        <developer>\r\n            <id>${developer_id}</id>\r\n            <name>${developer_name}</name>\r\n            <email>${developer_email}</email>\r\n            <url>${developer_github_url}</url>\r\n        </developer>\r\n    </developers>\r\n\r\n    <distributionManagement>\r\n        <snapshotRepository>\r\n            <id>central</id>\r\n            <url>https://s01.oss.sonatype.org/content/repositories/snapshots</url>\r\n        </snapshotRepository>\r\n        <repository>\r\n            <id>central</id>\r\n            <url>https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/</url>\r\n        </repository>\r\n    </distributionManagement>\r\n```\r\n\r\n## 发布\r\n\r\n```shell\r\nmvn deploy -f pom.xml\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MAVEN 上传到中心仓库",
      "lvl1": "注册中心仓库账户",
      "lvl2": "GPG",
      "lvl3": "Maven Setting.xml",
      "lvl4": "pom.xml",
      "lvl5": "发布"
    },
    "frontmatter": {
      "title": "MAVEN 上传到中心仓库",
      "date": "2025/03/05",
      "tags": [
        "MAVEN"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 实现 Chrome 环境隔离的多开方案",
    "path": "/blogs/bianmabiji/PowerShellshixianChromehuanjinggelideduokaifangan.html",
    "url": "/blogs/bianmabiji/PowerShellshixianChromehuanjinggelideduokaifangan.html",
    "content": "---\r\ntitle: PowerShell 实现 Chrome 环境隔离的多开方案\r\ndate: 2025/07/01\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n- 下载地址：[https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/chromej.ps1](https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/chromej.ps1)\r\n:::\r\n\r\n使用示例：\r\n```powershell\r\n    chromej.ps1 1 2 --disable-web-security --incognito\r\n        # 启动/多开 1、2 两个 profile，并传递原生参数\r\n\r\n    chromej.ps1 dev -a -u \"https://example.com\" --disable-gpu\r\n        # 激活已开的 dev profile，或未开则以指定网址和参数新开\r\n\r\n    chromej.ps1 1 -Delete -y\r\n        # 强制删除 1 号 profile 目录，无需确认\r\n\r\n    chromej.ps1 --disable-software-rasterizer -sc\r\n        # 启动 Chrome 并显示完整命令行\r\n\r\n    chromej.ps1 -s\r\n        # 静默启动 Chrome 本体\r\n\r\n    chromej.ps1 1 2 3 -Activate -ShowCmd -Silent\r\n        # 激活/多开 1、2、3，命令行输出，静默执行\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 实现 Chrome 环境隔离的多开方案"
    },
    "frontmatter": {
      "title": "PowerShell 实现 Chrome 环境隔离的多开方案",
      "date": "2025/07/01",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 实现图片大小压缩",
    "path": "/blogs/bianmabiji/PowerShellshixiantupiandaxiaoyasuo.html",
    "url": "/blogs/bianmabiji/PowerShellshixiantupiandaxiaoyasuo.html",
    "content": "---\r\ntitle: PowerShell 实现图片大小压缩\r\ndate: 2025/07/04\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n- 下载地址：[https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/imageQ.ps1](https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/imageQ.ps1)\r\n:::\r\n\r\n使用示例：\r\n```powershell\r\n    .\\imageQ.ps1 -Help\r\n    \r\n    .\\imageQ.ps1 -i .\\*.jpg\r\n    .\\imageQ.ps1 -i img1.jpg,img2.png -s 2MB\r\n    .\\imageQ.ps1 -i img1.jpg,img2.jpg -o out1.jpg,out2.jpg -q 90\r\n    .\\imageQ.ps1 -i .\\*.png -Silent\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 实现图片大小压缩"
    },
    "frontmatter": {
      "title": "PowerShell 实现图片大小压缩",
      "date": "2025/07/04",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 目录栈",
    "path": "/blogs/bianmabiji/PowerShellmuluzhan.html",
    "url": "/blogs/bianmabiji/PowerShellmuluzhan.html",
    "content": "---\r\ntitle: PowerShell 目录栈\r\ndate: 2025/04/23\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n如果只是在脚本里临时切换目录，使用 `Push-Location / Pop-Location` 更优雅\r\n:::\r\n\r\n```powershell\r\ntry {\r\n    Push-Location path/to/dir\r\n    # todo ...\r\n}\r\nfinally {\r\n    Pop-Location\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 目录栈"
    },
    "frontmatter": {
      "title": "PowerShell 目录栈",
      "date": "2025/04/23",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 设置定时任务",
    "path": "/blogs/bianmabiji/PowerShellshezhidingshirenwu.html",
    "url": "/blogs/bianmabiji/PowerShellshezhidingshirenwu.html",
    "content": "---\r\ntitle: PowerShell 设置定时任务\r\ndate: 2025/03/05\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n1. 注册任务\r\n2. 注销任务\r\n\r\n---\r\n\r\n[使用VBS保持PS脚本的静默执行](./VBS静默执行PS脚本.md)\r\n:::\r\n\r\n\r\n## 注册任务\r\n\r\n```powershell\r\n# 使用vbs脚本的好处是可以保持静默执行\r\n$Action = New-ScheduledTaskAction -Execute \"wscript.exe\" -Argument \"D:\\personal-folder\\app\\powershell\\wallpaper-kline.vbs\"\r\n\r\n# 设置开机执行一次\r\n$Trigger1 = New-ScheduledTaskTrigger -AtStartup\r\n# 设置每小时执行一次\r\n$Trigger2 = New-ScheduledTaskTrigger -Once -At (Get-Date).Date -RepetitionInterval (New-TimeSpan -Hours 1)\r\n\r\n# 注册任务\r\n$Settings = New-ScheduledTaskSettingsSet -AllowStartIfOnBatteries -DontStopIfGoingOnBatteries -StartWhenAvailable -RunOnlyIfNetworkAvailable\r\nRegister-ScheduledTask -Action $Action -Trigger $Trigger1,$Trigger2 -TaskName \"wallpaper-kline-task\" -Description \"wallpaper-kline.vbs\"  -Settings $Settings\r\n```\r\n\r\n## 注销任务\r\n\r\n```powershell\r\nUnregister-ScheduledTask -TaskName \"wallpaper-kline-task\" -Confirm:$false\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 设置定时任务",
      "lvl1": "注册任务",
      "lvl2": "注销任务"
    },
    "frontmatter": {
      "title": "PowerShell 设置定时任务",
      "date": "2025/03/05",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Python 导出最简项目依赖",
    "path": "/blogs/bianmabiji/PYdaochuzuijianxiangmuyilai.html",
    "url": "/blogs/bianmabiji/PYdaochuzuijianxiangmuyilai.html",
    "content": "---\r\ntitle: Python 导出最简项目依赖\r\ndate: 2025/03/05\r\ntags:\r\n - Python\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n使用 `pipreqs` 导出项目依赖\r\n:::\r\n\r\n## 导出依赖\r\n\r\n```shell\r\n# 安装 pipreqs\r\npip install pipreqs\r\n\r\n# 导出项目依赖到 requirements.txt\r\npipreqs ./ --encoding=utf-8\r\n\r\n# 覆盖 requirements.txt\r\npipreqs ./ --encoding=utf-8 --force\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Python 导出最简项目依赖",
      "lvl1": "导出依赖"
    },
    "frontmatter": {
      "title": "Python 导出最简项目依赖",
      "date": "2025/03/05",
      "tags": [
        "Python"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "shlink 部署及 openfeign 调用",
    "path": "/blogs/bianmabiji/shlinkbushujiopenfeigndiaoyong.html",
    "url": "/blogs/bianmabiji/shlinkbushujiopenfeigndiaoyong.html",
    "content": "---\r\ntitle: shlink 部署及 openfeign 调用\r\ndate: 2025/04/16\r\ntags:\r\n - shlink\r\n - openfeign\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## shlink 部署\r\n\r\n```yml\r\nservices:\r\n  shlink:\r\n    image: shlinkio/shlink:latest\r\n    ports:\r\n      - \"28881:8080\"\r\n    environment:\r\n      - SHLINK_SHORT_CODES_LENGTH=5\r\n      - INITIAL_API_KEY=cda4282f-27a5-4a93-bb8a-47234309628f\r\n      - DB_DRIVER=mysql\r\n      - DB_HOST=mysql_host\r\n      - DB_PORT=3306\r\n      - DB_NAME=shlink\r\n      - DB_USER=shlink\r\n      - DB_PASSWORD=662caa92-1f0e-40f5-9656-2147c76a4f73\r\n```\r\n\r\n## openfeign\r\n\r\n```java\r\n@FeignClient(name = CloudName.SHLINK, path = \"/rest/v3\",\r\n        fallbackFactory = ShlinkClientFallbackFactory.class,\r\n        configuration = ShlinkHeaderConfig.class)\r\npublic interface ShlinkClient {\r\n    @PostMapping(\"/short-urls\")\r\n    ShortUrlRes shortUrls(@RequestBody ShortUrlParam param);\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Builder\r\n@NoArgsConstructor\r\n@AllArgsConstructor\r\n@Accessors(chain = true)\r\npublic class ShortUrlParam {\r\n    private String longUrl;\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Builder\r\n@NoArgsConstructor\r\n@AllArgsConstructor\r\n@Accessors(chain = true)\r\npublic class ShortUrlRes {\r\n    private String shortUrl;\r\n    private String shortCode;\r\n    private String longUrl;\r\n    @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ssXXX\")\r\n    private Date dateCreated;\r\n    private String domain;\r\n    private String title;\r\n    private Boolean crawlable;\r\n    private Boolean forwardQuery;\r\n    private Boolean hasRedirectRules;\r\n}\r\n```\r\n\r\n```java\r\n@RequiredArgsConstructor\r\npublic class ShlinkHeaderConfig {\r\n    private final ShlinkConfig shlinkConfig;\r\n    @Bean\r\n    public RequestInterceptor requestInterceptor() {\r\n        return requestTemplate -> requestTemplate.header(\"X-Api-Key\", shlinkConfig.getApiKey());\r\n    }\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConfigurationProperties(prefix = \"app.shlink\")\r\npublic class ShlinkConfig {\r\n    private String apiKey;\r\n}\r\n```\r\n\r\n```yml\r\napp:\r\n  shlink:\r\n    api-key: cda4282f-27a5-4a93-bb8a-47234309628f\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "shlink 部署及 openfeign 调用",
      "lvl1": "shlink 部署",
      "lvl2": "openfeign"
    },
    "frontmatter": {
      "title": "shlink 部署及 openfeign 调用",
      "date": "2025/04/16",
      "tags": [
        "shlink",
        "openfeign"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 Starter 自定义环境变量",
    "path": "/blogs/bianmabiji/SpringBoot2Starterzidingyihuanjingbianliang.html",
    "url": "/blogs/bianmabiji/SpringBoot2Starterzidingyihuanjingbianliang.html",
    "content": "---\r\ntitle: SpringBoot2 Starter 自定义环境变量\r\ndate: 2025/04/12\r\ntags:\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```\r\nMETA-INF\r\n  - application-referenced.yml\r\n  - spring.factories\r\n```\r\n\r\nspring.factories\r\n```prop\r\norg.springframework.boot.env.EnvironmentPostProcessor=package.path.CommonEnvironmentPostProcessor\r\n```\r\n\r\n```java\r\npublic class CommonEnvironmentPostProcessor implements EnvironmentPostProcessor {\r\n    private static final String PROPERTY_SOURCE_NAME = CommonEnvironmentPostProcessor.class.getSimpleName();\r\n\r\n    @Override\r\n    public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) {\r\n        YamlPropertySourceLoader loader = new YamlPropertySourceLoader();\r\n        Resource resource = new ClassPathResource(\"META-INF/application-referenced.yml\");\r\n\r\n        if (resource.exists()) {\r\n            try {\r\n                PropertySource<?> yamlProps = loader.load(PROPERTY_SOURCE_NAME, resource).get(0);\r\n                environment.getPropertySources().addLast(yamlProps);  // 注意：使用 `.addLast()`，确保主项目配置优先\r\n            } catch (IOException e) {\r\n                throw new IllegalStateException(\"Failed to load YAML file: \" + resource.getFilename(), e);\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 Starter 自定义环境变量"
    },
    "frontmatter": {
      "title": "SpringBoot2 Starter 自定义环境变量",
      "date": "2025/04/12",
      "tags": [
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 实现 SpringCache 集成多个 CacheManager",
    "path": "/blogs/bianmabiji/SpringBoot2shixianSpringCachejichengduogeCacheManager.html",
    "url": "/blogs/bianmabiji/SpringBoot2shixianSpringCachejichengduogeCacheManager.html",
    "content": "---\r\ntitle: SpringBoot2 实现 SpringCache 集成多个 CacheManager\r\ndate: 2025/04/29\r\ntags:\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n- 通过 `CachingConfigurerSupport` 指定全局默认的主 `CacheManager`\r\n- `@Cacheable` 等 SpringCache 注解可以通过 `cacheManager` 属性指定自定义的 `CacheManager`\r\n:::\r\n\r\n```java\r\n@Configuration\r\n@EnableCaching\r\npublic class CacheConfig extends CachingConfigurerSupport {\r\n    private final CacheManager cacheManager;\r\n\r\n    public CacheConfig(@Qualifier(RedisCacheConfig.REDIS_CACHE_NAME) CacheManager cacheManager) {\r\n        this.cacheManager = cacheManager;\r\n    }\r\n\r\n    @Override\r\n    public CacheManager cacheManager() {\r\n        return cacheManager;\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConditionalOnClass(name = \"com.github.benmanes.caffeine.cache.Caffeine\")\r\npublic class LocalCacheConfig {\r\n    public static final String LOCAL_CACHE_MANAGER = \"caffeineCacheManager\";\r\n    @Value(\"${app.cache.ttl-seconds:3600}\")\r\n    private Long ttlSeconds;\r\n    @Value(\"${app.cache.maximum:5000}\")\r\n    private Integer maximum;\r\n\r\n    @Bean(LOCAL_CACHE_MANAGER)\r\n    public CaffeineCacheManager caffeineCacheManager() {\r\n        CaffeineCacheManager cacheManager = new CaffeineCacheManager();\r\n        cacheManager.setCaffeine(Caffeine.newBuilder()\r\n                .expireAfterWrite(ttlSeconds, TimeUnit.SECONDS)\r\n                .maximumSize(maximum));\r\n        return cacheManager;\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConditionalOnClass(name = \"org.springframework.data.redis.cache.RedisCacheManager\")\r\npublic class RedisCacheConfig {\r\n    public static final String REDIS_CACHE_NAME = \"cacheManager\";\r\n    @Value(\"${app.cache.ttl-seconds:3600}\")\r\n    private Long ttlSeconds;\r\n\r\n    @Bean\r\n    @ConditionalOnMissingBean(RedisCacheConfiguration.class)\r\n    public RedisCacheConfiguration redisCacheConfiguration() {\r\n        return RedisCacheConfiguration.defaultCacheConfig()\r\n                .entryTtl(Duration.ofSeconds(ttlSeconds))\r\n                .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()))\r\n                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));\r\n    }\r\n\r\n    @Primary\r\n    @Bean(REDIS_CACHE_NAME)\r\n    public CacheManager cacheManager(RedisConnectionFactory connectionFactory, RedisCacheConfiguration config) {\r\n        return RedisCacheManager.builder(connectionFactory)\r\n                .cacheDefaults(config)\r\n                .build();\r\n    }\r\n\r\n}\r\n```\r\n\r\n```yml\r\napp:\r\n  cache:\r\n    ttl-seconds: 3600\r\n    maximum: 5000\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 实现 SpringCache 集成多个 CacheManager"
    },
    "frontmatter": {
      "title": "SpringBoot2 实现 SpringCache 集成多个 CacheManager",
      "date": "2025/04/29",
      "tags": [
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
    "path": "/blogs/bianmabiji/SpringBoot2jichengZipkinheSleuthshixianlianluzhuizong.html",
    "url": "/blogs/bianmabiji/SpringBoot2jichengZipkinheSleuthshixianlianluzhuizong.html",
    "content": "---\r\ntitle: SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪\r\ndate: 2025/04/22\r\ntags:\r\n - SpringBoot\r\n - Zipkin\r\n - Sleuth\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>2.7.9</version>\r\n        <relativePath/>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-sleuth</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-sleuth-zipkin</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-openfeign</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-loadbalancer</artifactId>\r\n        </dependency>\r\n```\r\n\r\n## 配置\r\n\r\n:::tip\r\n- 关闭 sleuth 组件自动注入的链路日志信息：`spring.sleuth.default-logging-pattern-enabled: false`\r\n- logback 自定义链路日志：`%X{traceId:-} %X{spanId:-}`\r\n- logback 中自定义的默认就可以上传到 ELK，而 sleuth 默认输出的则默认上传不到 ELK\r\n- ELK 搭建见：[ELK 部署](../运维手册/ELK部署.md)\r\n:::\r\n\r\n```yml\r\nspring:\r\n  sleuth:\r\n    default-logging-pattern-enabled: false\r\n    jdbc:\r\n      datasource-proxy:\r\n        query:\r\n          enable-logging: true\r\n        slow-query:\r\n          enable-logging: true\r\n      p6spy:\r\n        enable-logging: true\r\n    sampler:\r\n      probability: 1.0\r\n      rate: 100\r\n  zipkin:\r\n    base-url: http://zipkin:port\r\n    sender:\r\n      type: web\r\n```\r\n\r\n## 标签\r\n\r\n:::info\r\n- 多环境公用一个Zipkin的时候，可以使用打标签的方式进行环境隔离\r\n- Zipkin 查询语句：`tagQuery=env=dev`\r\n:::\r\n\r\n```java\r\n@Configuration\r\npublic class ZipkinTracingConfig {\r\n    @Value(\"${spring.profiles.active:unknown}\")  // 读取当前环境\r\n    private String activeProfile;\r\n\r\n    @Bean\r\n    public SpanHandler spanHandler() {\r\n        return new SpanHandler() {\r\n            @Override\r\n            public boolean end(TraceContext context, MutableSpan span, Cause cause) {\r\n                span.tag(\"env\", activeProfile); // 给 Zipkin 添加环境信息\r\n                return true;\r\n            }\r\n        };\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
      "lvl1": "依赖",
      "lvl2": "配置",
      "lvl3": "标签"
    },
    "frontmatter": {
      "title": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
      "date": "2025/04/22",
      "tags": [
        "SpringBoot",
        "Zipkin",
        "Sleuth"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot3 集成 GraalVM 云原生",
    "path": "/blogs/bianmabiji/SpringBoot3jichengGraalVMyunyuansheng.html",
    "url": "/blogs/bianmabiji/SpringBoot3jichengGraalVMyunyuansheng.html",
    "content": "---\r\ntitle: SpringBoot3 集成 GraalVM 云原生\r\ndate: 2025/04/18\r\ntags:\r\n - GraalVM\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n:::info\r\nSpringBoot 版本必须在 3.4.4 之上\r\n:::\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>3.4.4</version>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n    <build>\r\n        <finalName>image-name</finalName>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.graalvm.buildtools</groupId>\r\n                <artifactId>native-maven-plugin</artifactId>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n                <version>3.4.4</version>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 构建发布\r\n\r\n```shell\r\nmvn clean -Pnative spring-boot:build-image -f pom.xml\r\ndocker tag image-name:{version} jxch/image-name:latest\r\ndocker push jxch/image-name:latest\r\n```\r\n\r\n## 兼容性\r\n\r\n### 反射声明配置\r\n\r\n需要声明哪些类被反射过（尤其是被JSON序列化的类）\r\n\r\n```java\r\n@Configuration\r\n@RegisterReflectionForBinding({\r\n        CPunchCardNormal.class, CPunchCardState.class, UserConfig.class, User.class\r\n})\r\npublic class NativeReflectionConfig {\r\n}\r\n```\r\n\r\n### 静态资源声明配置\r\n\r\n声明用到了哪些 resources 目录下的静态资源文件\r\n\r\n```java\r\n@Configuration\r\n@ImportRuntimeHints(NativeRuntimeHints.class)\r\npublic class NativeRuntimeHints implements RuntimeHintsRegistrar {\r\n    @Override\r\n    public void registerHints(RuntimeHints hints, ClassLoader classLoader) {\r\n        hints.resources().registerPattern(\"xxx.json\");\r\n    }\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot3 集成 GraalVM 云原生",
      "lvl1": "依赖",
      "lvl2": "构建发布",
      "lvl3": "兼容性"
    },
    "frontmatter": {
      "title": "SpringBoot3 集成 GraalVM 云原生",
      "date": "2025/04/18",
      "tags": [
        "GraalVM",
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 Dockerfile 健康检查",
    "path": "/blogs/bianmabiji/SpringBootjichengDockerfilejiankangjiancha.html",
    "url": "/blogs/bianmabiji/SpringBootjichengDockerfilejiankangjiancha.html",
    "content": "---\r\ntitle: SpringBoot 集成 Dockerfile 健康检查\r\ndate: 2025/04/23\r\ntags:\r\n - Docker\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n健康检查成功后，容器才视为启动成功，包括 docker swarm 的 update 也是这样，可以利用这个特性实现集群的不停机更新\r\n:::\r\n\r\n## HEALTHCHECK\r\n\r\n```dockerfile\r\nENV ACTUATOR_PORT=13011\r\nENV ACTUATOR_USER=admin\r\nENV ACTUATOR_PASS=123456\r\n\r\nHEALTHCHECK --interval=30s --timeout=10s --start-period=300s CMD curl -f -u $ACTUATOR_USER:$ACTUATOR_PASS http://127.0.0.1:$ACTUATOR_PORT/actuator/health || exit 1\r\n\r\nENTRYPOINT [...]\r\n```\r\n\r\n## 依赖\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-actuator</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-security</artifactId>\r\n        </dependency>\r\n```\r\n\r\n## 配置\r\n\r\n```yml\r\nmanagement:\r\n  server:\r\n    port: 13011\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: '*'\r\n\r\nspring:\r\n  security:\r\n    user:\r\n      name: admin\r\n      password: 123456\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 Dockerfile 健康检查",
      "lvl1": "HEALTHCHECK",
      "lvl2": "依赖",
      "lvl3": "配置"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 Dockerfile 健康检查",
      "date": "2025/04/23",
      "tags": [
        "Docker",
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
    "path": "/blogs/bianmabiji/VaadinjichengSpringBoot3jiGraalVMyunyuansheng.html",
    "url": "/blogs/bianmabiji/VaadinjichengSpringBoot3jiGraalVMyunyuansheng.html",
    "content": "---\r\ntitle: Vaadin 集成 SpringBoot3 及 GraalVM 云原生\r\ndate: 2025/04/18\r\ntags:\r\n - GraalVM\r\n - SpringBoot\r\n - Vaadin\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n:::info\r\n- SpringBoot 版本必须在 3.4.4 之上\r\n- Vaadin 版本必须在 24.7.2 之上\r\n:::\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>3.4.4</version>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.vaadin</groupId>\r\n            <artifactId>vaadin-spring-boot-starter</artifactId>\r\n            <version>24.7.2</version>\r\n        </dependency>\r\n```\r\n\r\n```xml\r\n    <build>\r\n        <finalName>image-name</finalName>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.graalvm.buildtools</groupId>\r\n                <artifactId>native-maven-plugin</artifactId>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n                <version>3.4.4</version>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>com.vaadin</groupId>\r\n                <artifactId>vaadin-maven-plugin</artifactId>\r\n                <version>24.7.2</version>\r\n                <executions>\r\n                    <execution>\r\n                        <goals>\r\n                            <goal>prepare-frontend</goal>\r\n                            <goal>build-frontend</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 兼容性\r\n\r\n:::info\r\nVaadin 组件中用到过的所有类都必须声明反射\r\n\r\n其他兼容性（静态资源、反射等）参见 [SpringBoot3集成GraalVM云原生](./SpringBoot3集成GraalVM云原生.md)\r\n:::\r\n\r\n## view\r\n\r\n```java\r\n@Route(\"clock\")\r\npublic class ClockView extends VerticalLayout {\r\n    public ClockView(){\r\n        // todo 在构造方法中编写这个页面（可以通过构造方法参数直接注入 SpringBean）\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
      "lvl1": "依赖",
      "lvl2": "兼容性",
      "lvl3": "view"
    },
    "frontmatter": {
      "title": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
      "date": "2025/04/18",
      "tags": [
        "GraalVM",
        "SpringBoot",
        "Vaadin"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "VBS 静默执行 PowerShell 脚本",
    "path": "/blogs/bianmabiji/VBSjingmozhixingPSjiaoben.html",
    "url": "/blogs/bianmabiji/VBSjingmozhixingPSjiaoben.html",
    "content": "---\r\ntitle: VBS 静默执行 PowerShell 脚本\r\ndate: 2025/03/05\r\ntags:\r\n - VBS\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 创建 VBS 脚本\r\n\r\n```powershell\r\nSet WshShell = CreateObject(\"WScript.Shell\")\r\nWshShell.Run \"powershell.exe -WindowStyle Hidden -File D:\\personal-folder\\app\\powershell\\wallpaper-kline.ps1\", 0\r\nSet WshShell = Nothing\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "VBS 静默执行 PowerShell 脚本",
      "lvl1": "创建 VBS 脚本"
    },
    "frontmatter": {
      "title": "VBS 静默执行 PowerShell 脚本",
      "date": "2025/03/05",
      "tags": [
        "VBS"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "AMD 架构上运行 ARM 架构的 Docker 容器",
    "path": "/blogs/yunweishouce/AMDjiagoushangyunxingARMjiagoudeDockerrongqi.html",
    "url": "/blogs/yunweishouce/AMDjiagoushangyunxingARMjiagoudeDockerrongqi.html",
    "content": "---\r\ntitle: AMD 架构上运行 ARM 架构的 Docker 容器\r\ndate: 2025/05/06\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n安装 QEMU binfmt 支持：\r\n```bash\r\ndocker run --privileged --rm tonistiigi/binfmt --install all\r\n```\r\n\r\n测试：\r\n```bash\r\ndocker run --rm --platform linux/arm64/v8 arm64v8/alpine uname -m\r\n```\r\n\r\n:::tip\r\n- QEMU 是一个开源的硬件虚拟化工具，可以在 x86_64 主机上模拟 ARM64（aarch64）环境，从而让 Docker 能“假装”自己是 ARM 机器，运行 ARM 容器镜像。\r\n- QEMU 虚拟化会大大降低运行速度（比真实 ARM 机子慢很多），只适合测试和编译。\r\n- 某些复杂场景（如需内核特性、特殊指令集等）可能不完全兼容。\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "AMD 架构上运行 ARM 架构的 Docker 容器"
    },
    "frontmatter": {
      "title": "AMD 架构上运行 ARM 架构的 Docker 容器",
      "date": "2025/05/06",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Cloudflared 防 DNS 污染",
    "path": "/blogs/yunweishouce/CloudflaredfangDNSwuran.html",
    "url": "/blogs/yunweishouce/CloudflaredfangDNSwuran.html",
    "content": "---\r\ntitle: Cloudflared 防 DNS 污染\r\ndate: 2025/06/29\r\ntags:\r\n - DNS\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n- 下载：[https://github.com/cloudflare/cloudflared/releases](https://github.com/cloudflare/cloudflared/releases)\r\n- 启动命令：`cloudflared proxy-dns`\r\n- win11 安装：`winget install Cloudflare.cloudflared`，然后把 `C:\\Program Files (x86)\\cloudflared` 设进环境变量 path\r\n- win11 开机自启\r\n  - NSSM方式参考：[WIN使用NSSM管理Service](./WIN使用NSSM管理Service.md)\r\n  - VBS方式：\r\n    - 启动脚本参考：[VBS静默执行PS脚本](../编码笔记/VBS静默执行PS脚本.md)\r\n    - 脚本放入 `win + r` 输入 `shell:startup` 回车后出现的文件夹中\r\n:::\r\n\r\n## 以 Ubuntu - arm64 为例\r\n\r\n### 安装\r\n```shell\r\n# 下载\r\nwget https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-arm64.deb\r\n\r\n# 安装\r\ndpkg -i cloudflared-linux-arm64.deb\r\n\r\n# 启动\r\ncloudflared proxy-dns\r\n```\r\n\r\n### 部署\r\n设为 service\r\n```shell\r\n# 查看路径\r\nwhich cloudflared\r\n# 编辑配置文件\r\nvi /etc/systemd/system/cloudflared-proxy-dns.service\r\n# 启动 service\r\nsystemctl daemon-reload\r\nsystemctl enable --now cloudflared-proxy-dns\r\nsystemctl status cloudflared-proxy-dns\r\n```\r\n\r\n`cloudflared-proxy-dns.service` 配置文件：\r\n\r\n```shell \r\n[Unit]\r\nDescription=cloudflared DNS over HTTPS Proxy\r\nAfter=network.target\r\n\r\n[Service]\r\nType=simple\r\nUser=nobody\r\nCapabilityBoundingSet=CAP_NET_BIND_SERVICE\r\nAmbientCapabilities=CAP_NET_BIND_SERVICE\r\nExecStart=/usr/local/bin/cloudflared proxy-dns\r\nRestart=on-failure\r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\n```\r\n\r\n### 应用\r\n\r\n```shell\r\n# 查看 nameserver 是不是 127.0.0.1，如果是则自动生效\r\ncat /etc/resolv.conf\r\n# 如果 nameserver 是 127.0.0.53 说明走的是本地的 systemd-resolved\r\n# 那么就需要修改 systemd-resolved 上游 DNS\r\n# 设置 DNS=127.0.0.1\r\nvi /etc/systemd/resolved.conf\r\n\r\nsystemctl restart systemd-resolved\r\nresolvectl status\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Cloudflared 防 DNS 污染",
      "lvl1": "以 Ubuntu - arm64 为例"
    },
    "frontmatter": {
      "title": "Cloudflared 防 DNS 污染",
      "date": "2025/06/29",
      "tags": [
        "DNS"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "dnsmasq 部署",
    "path": "/blogs/yunweishouce/dnsmasqbushu.html",
    "url": "/blogs/yunweishouce/dnsmasqbushu.html",
    "content": "---\r\ntitle: dnsmasq 部署\r\ndate: 2025/03/05\r\ntags:\r\n - dnsmasq\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n1. 使用 docker 部署，docker-compose.yml 文件\r\n2. 配置文件，dnsmasq.conf 文件\r\n:::\r\n\r\n## docker-compose.yml\r\n\r\n```yml\r\nservices:\r\n  dns-server:\r\n    image: jpillora/dnsmasq\r\n    container_name: dns-server\r\n    restart: unless-stopped\r\n    environment:\r\n      - TZ=Asia/Shanghai\r\n      - HTTP_USER=username\r\n      - HTTP_PASS=password\r\n    ports:\r\n      - \"53:53/udp\"\r\n      - \"5380:8080\"\r\n    volumes:\r\n      - \"./dns/dnsmasq.conf:/etc/dnsmasq.conf\"\r\n```\r\n\r\n## dnsmasq.conf\r\n\r\n```shell\r\n# 服务器上游DNS服务器地址\r\nresolv-file=/etc/resolv.conf\r\n# 默认缓存条数150，这里增加到1000\r\ncache-size=1000\r\n# 重启后清空缓存\r\nclear-on-reload\r\n\r\n# DNS 服务器\r\nserver=8.8.4.4\r\nserver=8.8.8.8\r\nserver=4.2.2.1\r\nserver=4.2.2.2\r\nserver=114.114.114.114\r\n\r\n# 自定义域名\r\naddress=/example.com/192.168.1.10\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "dnsmasq 部署",
      "lvl1": "docker-compose.yml",
      "lvl2": "dnsmasq.conf"
    },
    "frontmatter": {
      "title": "dnsmasq 部署",
      "date": "2025/03/05",
      "tags": [
        "dnsmasq"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker Registry2 镜像仓库清理",
    "path": "/blogs/yunweishouce/DockerRegistry2jingxiangcangkuqingli.html",
    "url": "/blogs/yunweishouce/DockerRegistry2jingxiangcangkuqingli.html",
    "content": "---\r\ntitle: Docker Registry2 镜像仓库清理\r\ndate: 2025/04/23\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::info\r\n1. 必须在配置文件中允许删除镜像：`/etc/docker/registry/config.yml`\r\n2. 手动删除镜像：`/var/lib/registry/docker/registry/v2/repositories/`\r\n3. 清理镜像：`registry garbage-collect /etc/docker/registry/config.yml`\r\n:::\r\n\r\n```yml\r\n# /etc/docker/registry/config.yml\r\nstorage:\r\n  delete:\r\n    enabled: true\r\n```\r\n\r\n```bash\r\ncd /var/lib/registry/docker/registry/v2/repositories/\r\nrm -rf ./<要删除的镜像>\r\n\r\nregistry garbage-collect /etc/docker/registry/config.yml\r\n```\r\n\r\n```bash\r\n# 检查清理效果\r\ndf -h\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker Registry2 镜像仓库清理"
    },
    "frontmatter": {
      "title": "Docker Registry2 镜像仓库清理",
      "date": "2025/04/23",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker Swarm 将服务部署到指定标签的节点上",
    "path": "/blogs/yunweishouce/DockerSwarmjiangfuwubushudaozhidingbiaoqiandejiedianshang.html",
    "url": "/blogs/yunweishouce/DockerSwarmjiangfuwubushudaozhidingbiaoqiandejiedianshang.html",
    "content": "---\r\ntitle: Docker Swarm 将服务部署到指定标签的节点上\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip \r\n1. 给节点打标签\r\n2. 给服务加约束\r\n:::\r\n\r\n```shell\r\n# 给节点打标签\r\ndocker node update --label-add memory=high NODE_ID\r\n\r\n# 给服务添加约束，他就会自动调度到特定标签的节点上\r\ndocker service update --constraint-add 'node.labels.memory == high' SERVICE_ID\r\n```\r\n\r\n```shell\r\n# 查看节点上的标签\r\ndocker node inspect <node_id> --format '{{json .Spec.Labels}}'\r\n```\r\n\r\n```shell\r\n# 使该节点不接受任务调度，但是仍然可以通过该节点的端口访问集群中的服务\r\ndocker node update --availability drain <node_id>\r\n```\r\n\r\n```yml\r\nservices:\r\n  app:\r\n    image: app-images\r\n    deploy:\r\n      placement:\r\n        constraints:\r\n          - node.labels.memory == high\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker Swarm 将服务部署到指定标签的节点上"
    },
    "frontmatter": {
      "title": "Docker Swarm 将服务部署到指定标签的节点上",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker 容器启动时提示内存太小",
    "path": "/blogs/yunweishouce/Dockerrongqiqidongshitishinacuntaixiao.html",
    "url": "/blogs/yunweishouce/Dockerrongqiqidongshitishinacuntaixiao.html",
    "content": "---\r\ntitle: Docker 容器启动时提示内存太小\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: danger 类似的报错信息\r\n`Maximum number of memory map areas per process (vm.max_map_count) 262144 is too low, recommended value: 1048575, you can change it with sysctl.`\r\n:::\r\n\r\n## 解决方案\r\n\r\n:::: code-group\r\n::: code-group-item LINUX\r\n```bash\r\nsysctl -w vm.max_map_count=1048575\r\n```\r\n:::\r\n::: code-group-item WINDOWS\r\n```powershell\r\nwsl -d docker-desktop sh -c \"sysctl -w vm.max_map_count=1048575\"\r\n```\r\n:::\r\n::::\r\n\r\n::: info \r\n1. 提示应该设置多少就设置多少\r\n2. 然后重启docker服务即可\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker 容器启动时提示内存太小",
      "lvl1": "解决方案"
    },
    "frontmatter": {
      "title": "Docker 容器启动时提示内存太小",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker 清理",
    "path": "/blogs/yunweishouce/Dockerqingli.html",
    "url": "/blogs/yunweishouce/Dockerqingli.html",
    "content": "---\r\ntitle: Docker 清理\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n通常可以直接使用 `docker system prune --all -f` 命令进行深度清理并且无需手动确认\r\n:::\r\n\r\n|命令|作用|\r\n|-|-|\r\n|`docker container prune`|容器清理|\r\n|`docker image prune`|镜像清理|\r\n|`docker volume prune`|数据卷清理|\r\n|`docker builder prune`|缓存清理|\r\n|`docker system prune`|一键清理|\r\n|`docker system prune -a`|深度清理|\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker 清理"
    },
    "frontmatter": {
      "title": "Docker 清理",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "ELK 部署",
    "path": "/blogs/yunweishouce/ELKbushu.html",
    "url": "/blogs/yunweishouce/ELKbushu.html",
    "content": "---\r\ntitle: ELK 部署\r\ndate: 2025/04/16\r\ntags:\r\n - elasticsearch\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## docker-compose.yml\r\n\r\n```yml\r\nservices:\r\n  elasticsearch: \r\n    image: elasticsearch:8.16.1\r\n    restart: always\r\n    environment:\r\n      - discovery.type=single-node \r\n      - xpack.security.enabled=true\r\n    volumes:\r\n      - /mnt/nexus3/es_data:/usr/share/elasticsearch/data \r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  kibana: \r\n    image: kibana:8.16.1 \r\n    ports:\r\n      - \"12563:5601\"\r\n    environment:\r\n      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\r\n      - XPACK_SECURITY_ENABLED=true\r\n      - ELASTICSEARCH_USERNAME=kibana_system\r\n      - ELASTICSEARCH_PASSWORD=\"3UGDvTkAmzhprC5*9PUw\"\r\n    depends_on:\r\n      - elasticsearch\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  zipkin:\r\n    image: bitnami/zipkin:3\r\n    ports:\r\n      - \"12411:9411\"\r\n    environment:\r\n      - STORAGE_TYPE=elasticsearch\r\n      - ES_HOSTS=elasticsearch:9200\r\n      - ES_USERNAME=elastic\r\n      - ES_PASSWORD=rC4hG9mR9DUC109=DeS8\r\n    depends_on:\r\n      - elasticsearch\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  logstash:\r\n    image: bitnami/logstash:8.17.0\r\n    ports: \r\n      - \"5044:8080\"\r\n    volumes:\r\n      - ./logstash.conf:/opt/bitnami/logstash/pipeline/logstash.conf\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n```\r\n\r\n## logstash.conf\r\n\r\n```config\r\ninput {\r\n  tcp {\r\n    port => 8080 \r\n    codec => json_lines \r\n  }\r\n}\r\n\r\n\r\noutput {\r\n  elasticsearch {\r\n    hosts => [\"http://elasticsearch:9200\"] \r\n    user => \"elastic\"\r\n    password => \"rC4hG9mR9DUC109=DeS8\"\r\n    index => \"logs-%{+YYYY.MM.dd}\"\r\n    ssl => false \r\n  }\r\n}\r\n```\r\n\r\n## 设置密码\r\n\r\n```bash\r\n# 进入 elasticsearch 容器内部\r\ndocker exec -it <elasticsearch> sh\r\n\r\n# 设置超级用户的密码，此用户名密码可以用在logstash、zipkin和kibana web ui的登录上\r\nbin/elasticsearch-reset-password -u elastic\r\n\r\n# 设置kibana用户的密码，此用户专用于kibana容器与elasticsearch容器的交互\r\nbin/elasticsearch-reset-password -u kibana_system\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "ELK 部署",
      "lvl1": "docker-compose.yml",
      "lvl2": "logstash.conf",
      "lvl3": "设置密码"
    },
    "frontmatter": {
      "title": "ELK 部署",
      "date": "2025/04/16",
      "tags": [
        "elasticsearch"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "HAProxy TCP 端口代理",
    "path": "/blogs/yunweishouce/HAProxy-TCPduankoudaili.html",
    "url": "/blogs/yunweishouce/HAProxy-TCPduankoudaili.html",
    "content": "---\r\ntitle: HAProxy TCP 端口代理\r\ndate: 2025/07/02\r\ntags:\r\n - proxy\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n\r\n## docker-compose.yml\r\n```yml\r\nversion: '3.8'\r\nservices: \r\n  haproxy: \r\n    image: haproxy:lts-alpine\r\n    privileged: true\r\n    ports:\r\n      - 1080:1080\r\n      - 3306:3306\r\n    volumes: \r\n      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg\r\n```\r\n\r\n## haproxy.cfg\r\n```properties\r\ndefaults\r\n    mode            tcp\r\n    log             global\r\n    option          tcplog\r\n    option          dontlognull\r\n    option http-server-close\r\n    option          redispatch\r\n    retries         3\r\n    timeout http-request 10s\r\n    timeout queue   1m\r\n    timeout connect 10s\r\n    timeout client  1m\r\n    timeout server  1m\r\n    timeout http-keep-alive 10s\r\n    timeout check   10s\r\n    maxconn         3000\r\nfrontend    mysql\r\n    bind        0.0.0.0:3306\r\n    mode        tcp\r\n    log         global\r\n    default_backend mysql_server\r\nbackend     mysql_server\r\n    balance roundrobin\r\n    server capital_mysql qbh.jiangxicheng.xyz:3306 check inter 5s rise 2 fall 3\r\nlisten stats\r\n    mode    http\r\n    bind    0.0.0.0:1080\r\n    stats   enable\r\n    stats   hide-version\r\n    stats uri /haproxyamdin?stats\r\n    stats realm Haproxy\\ Statistics\r\n    stats auth admin:admin\r\n    stats admin if TRUE\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "HAProxy TCP 端口代理",
      "lvl1": "docker-compose.yml",
      "lvl2": "haproxy.cfg"
    },
    "frontmatter": {
      "title": "HAProxy TCP 端口代理",
      "date": "2025/07/02",
      "tags": [
        "proxy"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "hexo 下载内部文件",
    "path": "/blogs/yunweishouce/hexo-xiazainabuwenjian.html",
    "url": "/blogs/yunweishouce/hexo-xiazainabuwenjian.html",
    "content": "---\r\ntitle: hexo 下载内部文件\r\ndate: 2025/07/02\r\ntags:\r\n - hexo\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n1. `_config.yml` 文件内修改属性 `post_asset_folder: true`\r\n2. 在 `source` 文件夹内创建下载目录 `download`\r\n3. 下载链接：`[xxxxxx](/download/xxxxxx)`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "hexo 下载内部文件"
    },
    "frontmatter": {
      "title": "hexo 下载内部文件",
      "date": "2025/07/02",
      "tags": [
        "hexo"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Jumpserver 部署",
    "path": "/blogs/yunweishouce/Jumpserverbushu.html",
    "url": "/blogs/yunweishouce/Jumpserverbushu.html",
    "content": "---\r\ntitle: Jumpserver 部署\r\ndate: 2025/06/16\r\ntags:\r\n - Jumpserver\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## docker compose\r\n\r\n```yml\r\nservices:\r\n  jumpserver: \r\n    image: jumpserver/jms_all\r\n    restart: unless-stopped\r\n    user: root\r\n    privileged: true\r\n    ports:\r\n      - \"10880:80\"\r\n    environment:\r\n      SECRET_KEY: \"uuid\"\r\n      BOOTSTRAP_TOKEN: \"uuid\"\r\n      LOG_LEVEL: \"ERROR\"\r\n      DB_ENGINE: mysql\r\n      DB_HOST: \"\"\r\n      DB_PORT: \"3306\"\r\n      DB_USER: \"root\"\r\n      DB_PASSWORD: \"\"\r\n      DB_NAME: \"jumpserver\"\r\n      REDIS_HOST: \"\"\r\n      REDIS_PORT: \"\"\r\n      REDIS_PASSWORD: \"\"\r\n      DOMAINS: host:port\r\n    volumes:\r\n      - /mnt/nexus3/jumpserver:/opt/jumpserver/data\r\n```\r\n\r\n:::tip\r\n- [Docker Hub - Jumpserver/jms_all](https://hub.docker.com/r/jumpserver/jms_all)\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Jumpserver 部署",
      "lvl1": "docker compose"
    },
    "frontmatter": {
      "title": "Jumpserver 部署",
      "date": "2025/06/16",
      "tags": [
        "Jumpserver"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 关闭 iptables 防火墙",
    "path": "/blogs/yunweishouce/Linuxguanbiiptablesfanghuoqiang.html",
    "url": "/blogs/yunweishouce/Linuxguanbiiptablesfanghuoqiang.html",
    "content": "---\r\ntitle: Linux 关闭 iptables 防火墙\r\ndate: 2025/03/11\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 允许所有流量\r\n\r\n```shell\r\niptables -P FORWARD ACCEPT \r\niptables -P OUTPUT ACCEPT \r\niptables -P INPUT ACCEPT\r\niptables -F \r\n```\r\n\r\n::: warning\r\n该方式会在重启后失效\r\n:::\r\n\r\n## 自动生效\r\n\r\n```shell\r\napt install iptables-persistent\r\n\r\nnetfilter-persistent save\r\n\r\n# 重启后验证\r\niptables -L -v\r\n```\r\n\r\n::: tip\r\n适用于 Debian/Ubuntu 系统\r\n:::\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 关闭 iptables 防火墙",
      "lvl1": "允许所有流量",
      "lvl2": "自动生效"
    },
    "frontmatter": {
      "title": "Linux 关闭 iptables 防火墙",
      "date": "2025/03/11",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 开启 BBR",
    "path": "/blogs/yunweishouce/LinuxkaiqiBBR.html",
    "url": "/blogs/yunweishouce/LinuxkaiqiBBR.html",
    "content": "---\r\ntitle: Linux 开启 BBR\r\ndate: 2025/03/05\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 开启 BBR\r\n\r\n```bash\r\necho \"net.core.default_qdisc=fq\" >> /etc/sysctl.conf\r\necho \"net.ipv4.tcp_congestion_control=bbr\" >> /etc/sysctl.conf\r\n\r\n# 生效\r\nsysctl -p\r\n\r\n# 查看内核是否已开启BBR\r\nsysctl net.ipv4.tcp_available_congestion_control\r\n\r\n# 查看BBR是否启动\r\nlsmod | grep bbr\r\n```\r\n\r\n::: warning 内核版本\r\n1. Linux 内核版本 4.9 以上才可以开启\r\n2. 查看版本是否符合要求：`uname -r` \r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 开启 BBR",
      "lvl1": "开启 BBR"
    },
    "frontmatter": {
      "title": "Linux 开启 BBR",
      "date": "2025/03/05",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 添加 Swap 交换空间",
    "path": "/blogs/yunweishouce/LinuxtianjiaSwapjiaohuankongjian.html",
    "url": "/blogs/yunweishouce/LinuxtianjiaSwapjiaohuankongjian.html",
    "content": "---\r\ntitle: Linux 添加 Swap 交换空间\r\ndate: 2025/03/07\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 添加交换空间\r\n\r\n```bash\r\nmkdir /swap\r\n\r\n# 创建交换空间文件\r\nfallocate -l 2G /swap/swapfile1\r\n# 或者使用 dd 命令\r\ndd if=/dev/zero of=/swap/swapfile1 bs=1024 count=2097152\r\n\r\n# 启用并挂载交换空间\r\nchmod 600 /swap/swapfile1\r\nmkswap /swap/swapfile1\r\nswapon /swap/swapfile1\r\necho \"/swap/swapfile1 swap swap defaults 0 0\" | sudo tee -a /etc/fstab\r\n\r\n# 查看是否挂载成功\r\nswapon --show\r\nfree -h\r\n```\r\n\r\n## 删除交换空间\r\n```bash\r\n# 卸载交换空间\r\nswapoff -v /swap/swapfile1\r\n\r\n# 删除挂载交换空间的配置\r\nvi /etc/fstab\r\nrm /swap/swapfile1\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 添加 Swap 交换空间",
      "lvl1": "添加交换空间",
      "lvl2": "删除交换空间"
    },
    "frontmatter": {
      "title": "Linux 添加 Swap 交换空间",
      "date": "2025/03/07",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MySQL 僵尸锁",
    "path": "/blogs/yunweishouce/MySQLjiangshisuo.html",
    "url": "/blogs/yunweishouce/MySQLjiangshisuo.html",
    "content": "---\r\ntitle: MySQL 僵尸锁\r\ndate: 2025/05/10\r\ntags:\r\n - MySQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 僵尸锁\r\n\r\n```sql\r\nSELECT * FROM performance_schema.data_locks;\r\n```\r\n\r\n存在锁，而查不到\r\n\r\n```sql\r\nSELECT\r\n    THREAD_ID,\r\n    PROCESSLIST_ID,\r\n    NAME,\r\n    TYPE\r\nFROM performance_schema.threads\r\nWHERE THREAD_ID IN (5468414, 5468475);\r\n```\r\n\r\n是一个假死的长事务导致的   \r\n \r\n```sql\r\nselect * from information_schema.INNODB_TRX;\r\n```\r\n\r\n但是查不到这个事务的线程id  \r\n \r\n```sql\r\nSELECT\r\n    trx_id,\r\n    trx_state,\r\n    trx_mysql_thread_id,\r\n    trx_started,\r\n    trx_query\r\nFROM information_schema.INNODB_TRX\r\nWHERE trx_id = 65772512;\r\n```\r\n\r\n也无法回滚事务\r\n\r\n```sql\r\nXA RECOVER;\r\nXA ROLLBACK '10.0.6.112.tm17458036649580053510.0.6.112.tm238';\r\n```\r\n\r\n## 回滚事务\r\n\r\n:::info\r\n根据16进制xid中不同的位数，直接回滚那个造成僵尸锁的事务\r\n:::\r\n\r\n```sql\r\nXA RECOVER CONVERT XID;\r\nXA ROLLBACK X'31302E302E362E3131322E746D313734353830333636343935383030353335', X'31302E302E362E3131322E746D323338', 1096044365;\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MySQL 僵尸锁",
      "lvl1": "僵尸锁",
      "lvl2": "回滚事务"
    },
    "frontmatter": {
      "title": "MySQL 僵尸锁",
      "date": "2025/05/10",
      "tags": [
        "MySQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
    "path": "/blogs/yunweishouce/MYSQLzengliangbinlogdenixianghuifangzhibinlog2sql.html",
    "url": "/blogs/yunweishouce/MYSQLzengliangbinlogdenixianghuifangzhibinlog2sql.html",
    "content": "---\r\ntitle: MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】\r\ndate: 2025/06/28\r\ntags:\r\n - MYSQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 下载工具 `binlog2sql`: `git clone https://github.com/danfengcao/binlog2sql.git`\r\n2. 初始化依赖环境\r\n3. 校验 mysql binlog 功能：其他实例的binlog在本地实例中的应用\r\n4. 生成逆向sql：兼容性问题（字符集问题）\r\n:::\r\n\r\n## binlog2sql\r\n\r\n```shell\r\n# 下载\r\ngit clone https://github.com/danfengcao/binlog2sql.git\r\n# 依赖环境（conda 为例）\r\nconda create -n binlog2sql_env python=3.9 -y\r\nconda activate binlog2sql_env\r\n\r\npip install -r requirements.txt\r\npip install mysqlclient\r\npip install pymysql\r\npip install requests\r\npip install python-dateutil\r\n\r\n# 验证\r\ncd .\\binlog2sql\\\r\npython binlog2sql.py --help\r\n```\r\n\r\n## binlog\r\n:::warning\r\n- 如果你的binlog文件来自其他实例，记得提前把binlog文件放入mysql的数据文件夹下（`/var/lib/mysql`），并修改`mysql-bin.index`文件\r\n- 查看binlog：`SHOW BINARY LOGS;`\r\n- 查看数据库字符集：`SHOW CREATE DATABASE matcheasy_new;`\r\n- 查看数据库表字符集：`SHOW FULL COLUMNS FROM matcheasy_new.i_resume;`\r\n:::\r\n\r\n以本地环境（docker mysql）为例（把线上实例的binlog放在本地实例上回放测试）\r\n\r\n```yml\r\nservices:\r\n  mysql:\r\n    image: mysql:8.0\r\n    environment:\r\n      MYSQL_ROOT_PASSWORD: password\r\n      MYSQL_USER: root_user\r\n      MYSQL_PASSWORD: password\r\n    ports:\r\n      - \"33306:3306\"\r\n    command:\r\n      --default-authentication-plugin=mysql_native_password\r\n      --character-set-server=utf8mb4\r\n      --collation-server=utf8mb4_unicode_ci\r\n      --binlog-format=ROW\r\n      --server-id=1\r\n      --log-bin=mysql-bin\r\n      --local-infile=1\r\n      --log-bin-trust-function-creators=1\r\n      --gtid-mode=ON\r\n      --enforce-gtid-consistency=ON\r\n    volumes:\r\n      - ./mysql_data:/var/lib/mysql\r\n```\r\n\r\n```sql\r\n-- 启动实例后给用户赋权\r\nGRANT ALL PRIVILEGES ON *.* TO 'root_user'@'%';\r\nFLUSH PRIVILEGES;\r\n```\r\n\r\n:::tip\r\n- 基础数据准备参考：[MYSQL数据导出导入](./MYSQL数据导出导入.md)\r\n- mysql版本以8.0为例，binlog以开启gtid为例\r\n- 源实例字符集以 utf8mb3 为例（注意我的docker compose文件中字符集指定的是 utf8mb4 ，因为它和 utf8mb3 可能会有兼容性问题，且本工具对 utf8mb3 也有兼容性问题，方便进行演示，实际场景中请保证两实例字符集一致）\r\n:::\r\n\r\n## 生成逆向sql\r\n\r\n:::info\r\n- 本工具可以直接连线上的mysql，包括阿里云什么的，就不用折腾两个实例了，这里只是对这种特殊需求的演示\r\n:::\r\n\r\n```shell\r\npython ..\\binlog2sql\\binlog2sql.py \\\r\n    --start-file=mysql-bin.001030 \\\r\n    --stop-file=mysql-bin.001039 \\\r\n    --host=127.0.0.1 --port=33306 \\\r\n    --user=root_user \\\r\n    --password='password' \\\r\n    --database=test_database \\\r\n    --flashback \\\r\n        > rollback.sql\r\n```\r\n\r\n:::danger utf8mb3字符集兼容性问题报错\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 150, in <module>\r\n    binlog2sql.process_binlog()\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 105, in process_binlog\r\n    for row in binlog_event.rows:\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 428, in rows\r\n    self._fetch_rows()\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 423, in _fetch_rows\r\n    self.__rows.append(self._fetch_one_row())\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 476, in _fetch_one_row\r\n    row[\"values\"] = self._read_column_data(self.columns_present_bitmap)\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 132, in _read_column_data\r\n    values[name] = self.__read_string(1, column)\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 220, in __read_string\r\n    string = string.decode(charset_to_encoding(column.character_set_name))\r\nLookupError: unknown encoding: utf8mb3\r\n```\r\n\r\n解决方案：因为本工具引用的pymysql版本太老，无法识别utf8mb3，所以需要手动修改pymysql包下的`charset.py`\r\n```py\r\ndef charset_to_encoding(name):\r\n    \"\"\"Convert MySQL's charset name to Python's codec name\"\"\"\r\n    if name == 'utf8mb4':\r\n        return 'utf8'\r\n    if name == 'utf8mb3':\r\n        return 'utf8'\r\n    return name\r\n```\r\n:::\r\n\r\n:::danger 字符解码报错\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 150, in <module>\r\n    binlog2sql.process_binlog()\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 121, in process_binlog\r\n    self.print_rollback_sql(filename=tmp_file)\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 129, in print_rollback_sql\r\n    for line in reversed_lines(f_tmp):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql_util.py\", line 249, in reversed_lines\r\n    block = block.decode(\"utf-8\")\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x83 in position 0: invalid start byte\r\n```\r\n\r\n解决方案：因为两实例字符集不同，或实例修改字符集导致的历史数据问题，总之解析binlog时发现存在无法解析的字符编码，所以需要手动修改工具中的解码逻辑，修改`binlog2sql_util.py`文件，这样非法字符就会被`�`代替，等回放完需要去sql文件中手动修改非法字符\r\n```py\r\nblock = block.decode(\"utf-8\")\r\n# 改为\r\nblock = block.decode(\"utf-8\", errors=\"replace\")\r\n```\r\n- 字符编码的报错没有好的办法彻底避免\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
      "lvl1": "binlog2sql",
      "lvl2": "binlog",
      "lvl3": "生成逆向sql"
    },
    "frontmatter": {
      "title": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
      "date": "2025/06/28",
      "tags": [
        "MYSQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MYSQL 数据导出导入",
    "path": "/blogs/yunweishouce/MYSQLshujudaochudaoru.html",
    "url": "/blogs/yunweishouce/MYSQLshujudaochudaoru.html",
    "content": "---\r\ntitle: MYSQL 数据导出导入\r\ndate: 2025/03/05\r\ntags:\r\n - MYSQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n1. 安装 mysqlsh\r\n2. 导出数据\r\n3. 导入数据（需要开启性能模式）\r\n:::\r\n\r\n## 安装 mysqlsh\r\n\r\n```shell\r\nwinget install Oracle.MySQLShell\r\nmysqlsh\r\n```\r\n\r\n## 导出\r\n\r\n```js\r\n\\connect username@host\r\n\\js\r\nutil.dumpTables(\"asktrue_exam\", [\"project_exam_student_result\"], \"E:\\\\DB\\\\asktrue\")\r\nutil.dumpSchemas([\"staffcloud_crm\", \"staffcloud_oa\"], \"E:\\\\DB\\\\staffcloud\");\r\n\r\n// 移除 definer，比如创建该库的用户名\r\nutil.dumpSchemas([\"staffcloud_crm\", \"staffcloud_oa\"], \"E:\\\\DB\\\\staffcloud\", {compatibility:[\"strip_definers\"]});\r\n```\r\n\r\n## 导入\r\n\r\n```js\r\n\\connect username@host\r\n\\js\r\nutil.loadDump(\"E:\\\\DB\\\\asktrue\\\\project_exam_student_result\", {threads: 4});\r\n\r\n// 指定导入另一个 schema\r\nutil.loadDump(\"E:\\\\DB-BACK\\\\matcheasy_new_gray_20250630_0100_2\", {schema: \"matcheasy_new\"})\r\n```\r\n\r\n::: info 需要开启性能模式\r\n开启性能模式：`performance_schema=ON`\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MYSQL 数据导出导入",
      "lvl1": "安装 mysqlsh",
      "lvl2": "导出",
      "lvl3": "导入"
    },
    "frontmatter": {
      "title": "MYSQL 数据导出导入",
      "date": "2025/03/05",
      "tags": [
        "MYSQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
    "path": "/blogs/yunweishouce/prometheusjiagrafanajichengcadvisorhenode-exportershixianjiankongwulijihedockerrongqidexingnenzhibiao.html",
    "url": "/blogs/yunweishouce/prometheusjiagrafanajichengcadvisorhenode-exportershixianjiankongwulijihedockerrongqidexingnenzhibiao.html",
    "content": "---\r\ntitle: prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标\r\ndate: 2025/04/29\r\ntags:\r\n - prometheus\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 部署采集器\r\n\r\n:::tip\r\n- node-exporter 采集物理机指标\r\n- cadvisor 采集各个 Docker 容器的指标\r\n:::\r\n\r\n```yml\r\nservices:\r\n  node-exporter:\r\n    image: prom/node-exporter:latest\r\n    deploy:\r\n      mode: global\r\n      restart_policy:\r\n        condition: any\r\n    ports:\r\n      - 9100:9100\r\n    pid: host\r\n    volumes:\r\n      - /:/host:ro,rslave\r\n    command:\r\n      - --path.rootfs=/host\r\n    labels:\r\n      - \"monitoring=enabled\"\r\n\r\n  cadvisor:\r\n    image: cadvisor/cadvisor:latest\r\n    deploy:\r\n      mode: global\r\n      restart_policy:\r\n        condition: any\r\n    ports: \r\n      - 8080:8080\r\n    volumes:\r\n      - /:/rootfs:ro\r\n      - /var/run:/var/run:rw\r\n      - /sys:/sys:ro\r\n      - /var/lib/docker/:/var/lib/docker:ro\r\n    labels:\r\n      - \"monitoring=enabled\"\r\n```\r\n\r\n## 自动更新采集端点\r\n\r\n:::tip\r\n- 需要整理所有的端点供 prometheus 采集信息\r\n- 保存到 file_sd 文件夹下的 json 文件中，这样 prometheus 就可以自动解析了\r\n:::\r\n\r\n```bash\r\n#!/bin/bash\r\n\r\nEXPORTER_PORTS=(9100 8080)\r\nPROM_FILE_SD_DIR=\"/etc/prometheus/file_sd\"\r\nmkdir -p $PROM_FILE_SD_DIR\r\n\r\n# 只选 Ready 状态节点\r\nNODES=$(docker node ls --format '{{.Hostname}} {{.Status}}' | awk '$2 == \"Ready\" {print $1}')\r\n\r\nfor PORT in \"${EXPORTER_PORTS[@]}\"; do\r\n  JSON_FILE=\"$PROM_FILE_SD_DIR/exporter_${PORT}.json\"\r\n  echo \"[\" > $JSON_FILE\r\n  SEP=\"\"\r\n  for HOST in $NODES; do\r\n    IP=$(docker node inspect \"$HOST\" --format '{{ index .Spec.Labels \"exporter_ip\" }}')\r\n    if [[ -n \"$IP\" ]]; then\r\n      echo \"${SEP}{\\\"targets\\\":[\\\"$IP:$PORT\\\"],\\\"labels\\\":{\\\"node\\\":\\\"$HOST\\\"}}\" >> $JSON_FILE\r\n      SEP=\",\"\r\n    fi\r\n  done\r\n  echo \"]\" >> $JSON_FILE\r\ndone\r\n```\r\n\r\n## prometheus\r\n\r\n```yml\r\n# prometheus.yml\r\n\r\nglobal:\r\n  scrape_interval: 15s\r\n\r\nscrape_configs:\r\n  - job_name: 'node-exporter'\r\n    file_sd_configs:\r\n      - files:\r\n          - /etc/prometheus/file_sd/exporter_9100.json\r\n\r\n  - job_name: 'cadvisor'\r\n    file_sd_configs:\r\n      - files:\r\n          - /etc/prometheus/file_sd/exporter_8080.json\r\n```\r\n\r\n```yml\r\nservices:\r\n  prometheus:\r\n    image: prom/prometheus:latest\r\n    container_name: prometheus\r\n    restart: always\r\n    volumes:\r\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro\r\n      - /etc/prometheus/file_sd:/etc/prometheus/file_sd:ro\r\n    ports:\r\n      - \"9090:9090\"\r\n    command:\r\n      - \"--config.file=/etc/prometheus/prometheus.yml\"\r\n      - \"--web.enable-lifecycle\"\r\n```\r\n\r\n## grafana\r\n\r\n:::tip\r\n- node-exporter 模板：11074、1860、405\r\n- cadvisor 模板：14282\r\n:::\r\n\r\n```yml\r\nservices:\r\n  grafana:\r\n    image: grafana/grafana-oss:latest\r\n    container_name: grafana\r\n    user: root\r\n    ports:\r\n      - \"9300:3000\"\r\n    volumes:\r\n      - ./data/grafana_data:/var/lib/grafana\r\n    environment:\r\n      - GF_SECURITY_ADMIN_USER=admin\r\n      - GF_SECURITY_ADMIN_PASSWORD=admin\r\n    restart: always\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
      "lvl1": "部署采集器",
      "lvl2": "自动更新采集端点",
      "lvl3": "prometheus",
      "lvl4": "grafana"
    },
    "frontmatter": {
      "title": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
      "date": "2025/04/29",
      "tags": [
        "prometheus"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 SpringBootAdmin",
    "path": "/blogs/yunweishouce/SpringBootjichengSpringBootAdmin.html",
    "url": "/blogs/yunweishouce/SpringBootjichengSpringBootAdmin.html",
    "content": "---\r\ntitle: SpringBoot 集成 SpringBootAdmin\r\ndate: 2025/05/15\r\ntags:\r\n - SpringBoot\r\n - SpringBootAdmin\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 部署 SpringBootAdminServer\r\n2. 集成 SpringBootAdminClient\r\n3. 按不同环境修改 SpringBootAdminClient 注册的实例名称\r\n:::\r\n\r\n## 部署 SpringBootAdminServer\r\n\r\n```java\r\n@EnableAdminServer\r\n@SpringBootApplication\r\npublic class AdminServerApplication {\r\n    public static void main(String[] args) {\r\n        SpringApplication.run(AdminServerApplication.class, args);\r\n    }\r\n}\r\n```\r\n\r\n:::info\r\n- 开启 `httpBasic` 来允许 `curl` 使用用户名密码的方式访问 `/actuator`\r\n:::\r\n\r\n```java\r\n@Configuration\r\n@EnableWebSecurity\r\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\r\n    @Override\r\n    protected void configure(HttpSecurity http) throws Exception {\r\n        http\r\n                .authorizeRequests()\r\n                .anyRequest().authenticated()\r\n                .and()\r\n                .formLogin()\r\n                .and()\r\n                .httpBasic()\r\n                .and()\r\n                .logout()\r\n                .and()\r\n                .csrf().disable();\r\n    }\r\n}\r\n```\r\n\r\n:::info\r\n- 可以集成注册中心（如 Nacos）实现服务的自动发现\r\n- SpringBootAdmin2 可以通过 `ignored-services` 属性忽略注册中心的某些服务\r\n- SpringBootAdmin3 可以通过 `metadata-filter` 属性通过元数据来选择注册中心中的某些服务\r\n:::\r\n\r\n```yml\r\nserver:\r\n  port: 8111\r\n\r\nspring:\r\n  application:\r\n    name: SPRING-BOOT-ADMIN-SERVER\r\n  security:\r\n    user:\r\n      name: admin\r\n      password: password\r\n  cloud:\r\n    nacos:\r\n      server-addr: nacos-server-addr\r\n      discovery:\r\n        username: nacos\r\n        password: password\r\n        group: DEFAULT_GROUP\r\n        namespace: public\r\n  boot:\r\n    admin:\r\n      discovery:\r\n        ignored-services: shlink,snowflake\r\n      client:\r\n        url: http://localhost:${server.port}\r\n        username: ${spring.security.user.name}\r\n        password: ${spring.security.user.password}\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            environment: ${spring.profiles.active}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n\r\nmanagement:\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: '*'\r\n      base-path: /actuator\r\n  endpoint:\r\n    health:\r\n      show-details: always\r\n    shutdown:\r\n      enabled: true\r\n```\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>2.7.9</version>\r\n        <relativePath/>\r\n    </parent>\r\n\r\n   <dependencies>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-server</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-server-ui</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-client</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.alibaba.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-actuator</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-security</artifactId>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n## 集成 SpringBootAdminClient\r\n\r\n:::info\r\n- 通过 `spring.boot.admin.client.instance.metadata` 来自定义要注册的元数据\r\n- 通过 `spring.boot.admin.client.instance.metadata.user` 来定义访问 `/actuator` 所需的用户名密码\r\n- 通过 `spring.boot.admin.client.username` 来定义 SpringBootAdminServer 所需的用户名\r\n- 通过 `spring.boot.admin.client.password` 来定义 SpringBootAdminServer 所需的密码\r\n:::\r\n\r\n```yml\r\nspring:\r\n  boot:\r\n    admin:\r\n      client:\r\n        url: http://asktrue.cn:8111\r\n        username: admin\r\n        password: password\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            application: ${spring.application.name}\r\n            environment: ${spring.profiles.active}\r\n            ip: ${spring.cloud.client.ip-address}\r\n            port: ${server.port}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-client</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n```\r\n\r\n## 按不同环境修改 SpringBootAdminClient 注册的实例名称\r\n\r\n:::info\r\n- 只能通过代码修改 `spring.boot.admin.client.instance.name` 属性来修改实例名称\r\n:::error\r\n- 直接在 `application.yml` 中修改 `spring.boot.admin.client.instance.name` 属性是无效的\r\n:::\r\n:::\r\n\r\n```java\r\n@Configuration\r\npublic class SBANameConfig implements ApplicationListener<ApplicationReadyEvent> {\r\n    @Value(\"${spring.application.name}\")\r\n    private String appName;\r\n    @Value(\"${spring.profiles.active:default}\")\r\n    private String active;\r\n\r\n    @PostConstruct\r\n    public void setAdminClientNameProperty() {\r\n        // 设置 System Property 让 SBA client 用自定义 name\r\n        System.setProperty(\"spring.boot.admin.client.instance.name\", appName + \"-[\" + active + \"]\");\r\n    }\r\n    @Override\r\n    public void onApplicationEvent(ApplicationReadyEvent event) {\r\n        // 这里也可以设置，保证启动后仍然有效\r\n        System.setProperty(\"spring.boot.admin.client.instance.name\", appName + \"-[\" + active + \"]\");\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 SpringBootAdmin",
      "lvl1": "部署 SpringBootAdminServer",
      "lvl2": "集成 SpringBootAdminClient",
      "lvl3": "按不同环境修改 SpringBootAdminClient 注册的实例名称"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 SpringBootAdmin",
      "date": "2025/05/15",
      "tags": [
        "SpringBoot",
        "SpringBootAdmin"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
    "path": "/blogs/yunweishouce/SpringBootjichengSpringBootAdminheArthasshixianyuanchengzhenduan.html",
    "url": "/blogs/yunweishouce/SpringBootjichengSpringBootAdminheArthasshixianyuanchengzhenduan.html",
    "content": "---\r\ntitle: SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断\r\ndate: 2025/05/15\r\ntags:\r\n - SpringBoot\r\n - SpringBootAdmin\r\n - Arthas\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 部署 arthas-tunnel-server\r\n2. SpringBoot 集成 arthas-spring-boot-starter\r\n3. 将 agent-id 注册到 SpringBootAdmin\r\n:::\r\n\r\n## 部署 arthas-tunnel-server\r\n\r\n:::tip\r\n- DockerHub 地址：https://hub.docker.com/repository/docker/jxch/arthas-tunnel-server/general\r\n- GitHub 地址：https://github.com/jxch-docker/docker-build/tree/main/arthas/tunnel\r\n:::\r\n\r\n```yml\r\nservices:\r\n  tunnel-server:\r\n    image: jxch/arthas-tunnel-server:4.0.5\r\n    ports:\r\n      - \"7777:7777\"\r\n      - \"10777:8080\"\r\n    environment:\r\n      - ARTHAS_TOKEN=token\r\n      - PASSWORD=password\r\n```\r\n\r\n## 集成 arthas-spring-boot-starter\r\n\r\n:::info\r\n- tunnelWeb 并非 arthas-spring-boot-starter 提供的字段，我的目的是把这个入口注册到 SpringBootAdminServer，这样就可以在 SBA Server 上直接进入远程诊断了\r\n- tunnelToken 是 arthas-spring-boot-starter 提供的字段，但并没有显示的 Java 属性，这个字段是必填的\r\n- tunnelServer 必须用 ws 地址\r\n:::\r\n\r\n```yml\r\narthas:\r\n  tunnelWeb: http://arthas-tunnel-server-ip-address:10777/\r\n  tunnelServer: ws://arthas-tunnel-server-ip-address:7777/ws\r\n  tunnelToken: ARTHAS_TOKEN\r\n  app-name: ${spring.application.name}\r\n  agent-id: ${spring.application.name}-${spring.cloud.client.ip-address:${server.address:127.0.0.1}}-${server.port}\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>com.taobao.arthas</groupId>\r\n            <artifactId>arthas-spring-boot-starter</artifactId>\r\n            <version>4.0.5</version>\r\n        </dependency>\r\n```\r\n\r\n## 集成 SpringBootAdminClient 并注册 agent-id\r\n\r\n:::info\r\n- 参考：[SpringBoot 集成 SpringBootAdmin](./SpringBoot集成SpringBootAdmin.md)\r\n- 把 agent-id 等信息通过元数据注册到 SpringBootAdminServer\r\n- 这样就可以在 SpringBootAdminServer 的 web 面板中直接进入远程诊断了\r\n:::\r\n\r\n```yml\r\nspring:\r\n  boot:\r\n    admin:\r\n      client:\r\n        url: http://asktrue.cn:8111\r\n        username: admin\r\n        password: password\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            application: ${spring.application.name}\r\n            environment: ${spring.profiles.active}\r\n            arthas-tunnel-server: ${arthas.tunnelWeb}\r\n            arthas-agent-id: ${arthas.agent-id}\r\n            ip: ${spring.cloud.client.ip-address}\r\n            port: ${server.port}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
      "lvl1": "部署 arthas-tunnel-server",
      "lvl2": "集成 arthas-spring-boot-starter",
      "lvl3": "集成 SpringBootAdminClient 并注册 agent-id"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
      "date": "2025/05/15",
      "tags": [
        "SpringBoot",
        "SpringBootAdmin",
        "Arthas"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "SQL优化-MYSQL8的JSON索引列",
    "path": "/blogs/yunweishouce/SQLyouhua-MYSQL8deJSONsuoyinlie.html",
    "url": "/blogs/yunweishouce/SQLyouhua-MYSQL8deJSONsuoyinlie.html",
    "content": "---\r\ntitle: SQL优化-MYSQL8的JSON索引列\r\ndate: 2026/01/14\r\ntags:\r\n - MYSQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n- 问题场景：存在CSV列的 `left join xxx on find_in_set` 式查询，导致全表扫描极慢，但又不想重构表结构建立关联表\r\n- 解决方案：使用MySQL8新特性，json属性。使用触发器把csv列数据同步写到json列，并创建索引\r\n:::\r\n\r\n## 新建json列\r\n\r\n```sql\r\nALTER TABLE crm_contract\r\n  ADD COLUMN order_id_json JSON NULL COMMENT '[索引列，只读] 订单ID(JSON数字数组)，由order_id(逗号串)同步';\r\n```\r\n\r\n## 回填历史数据\r\n\r\n```sql\r\nUPDATE crm_contract\r\nSET order_id_json =\r\n        CASE\r\n            WHEN order_id IS NULL OR order_id = '' THEN JSON_ARRAY()\r\n            ELSE CAST(CONCAT('[', REPLACE(order_id, ' ', ''), ']') AS JSON)\r\n        END;\r\n```\r\n\r\n## 建立 Multi-Valued 索引 \r\n\r\n```sql\r\nCREATE INDEX idx_crm_contract_order_id_mvi\r\nON crm_contract ((CAST(order_id_json AS UNSIGNED ARRAY)));\r\n```\r\n\r\n## 新增 insert/update 触发器\r\n\r\n```sql\r\nDELIMITER $$\r\n\r\nCREATE TRIGGER trg_crm_contract_bi_order_id_json\r\nBEFORE INSERT ON crm_contract\r\nFOR EACH ROW\r\nBEGIN\r\n  IF NEW.order_id IS NULL OR NEW.order_id = '' THEN\r\n    SET NEW.order_id_json = JSON_ARRAY();\r\n  ELSE\r\n    SET NEW.order_id_json =\r\n      CAST(CONCAT('[', REPLACE(NEW.order_id, ' ', ''), ']') AS JSON);\r\n  END IF;\r\nEND$$\r\n\r\nCREATE TRIGGER trg_crm_contract_bu_order_id_json\r\nBEFORE UPDATE ON crm_contract\r\nFOR EACH ROW\r\nBEGIN\r\n  IF (NEW.order_id <> OLD.order_id) OR (NEW.order_id IS NULL XOR OLD.order_id IS NULL) THEN\r\n    IF NEW.order_id IS NULL OR NEW.order_id = '' THEN\r\n      SET NEW.order_id_json = JSON_ARRAY();\r\n    ELSE\r\n      SET NEW.order_id_json =\r\n        CAST(CONCAT('[', REPLACE(NEW.order_id, ' ', ''), ']') AS JSON);\r\n    END IF;\r\n  END IF;\r\nEND$$\r\n\r\nDELIMITER ;\r\n```\r\n\r\n## 查询方式\r\n\r\n```sql\r\nSELECT * FROM crm_contract\r\nWHERE 537 MEMBER OF (order_id_json);\r\n```\r\n\r\n```sql\r\nSELECT * FROM crm_contract\r\nWHERE JSON_CONTAINS(order_id_json, CAST(537 AS JSON));\r\n```\r\n\r\n## left join json_table\r\n\r\n```sql\r\n    LEFT JOIN JSON_TABLE(contract.order_id_json, '$[*]' COLUMNS (oid BIGINT PATH '$') ) jt ON TRUE\r\n    LEFT JOIN crm_order o ON o.order_id = jt.oid\r\n```\r\n\r\n:::warn\r\n- `JSON_TABLE` 的方式，会导致展开成多行，需要注意\r\n- `JSON_TABLE` 本省不会走索引，只是把json数组在运行时展开成一个派生表\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SQL优化-MYSQL8的JSON索引列",
      "lvl1": "新建json列",
      "lvl2": "回填历史数据",
      "lvl3": "建立 Multi-Valued 索引",
      "lvl4": "新增 insert/update 触发器",
      "lvl5": "查询方式",
      "lvl6": "left join json_table"
    },
    "frontmatter": {
      "title": "SQL优化-MYSQL8的JSON索引列",
      "date": "2026/01/14",
      "tags": [
        "MYSQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "V2fly Shadowsocks 等翻墙服务部署",
    "path": "/blogs/yunweishouce/v2fly_shadowsocksdengfanqiangfuwubushu.html",
    "url": "/blogs/yunweishouce/v2fly_shadowsocksdengfanqiangfuwubushu.html",
    "content": "---\r\ntitle: V2fly Shadowsocks 等翻墙服务部署\r\ndate: 2025/03/08\r\ntags:\r\n - proxy\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: info\r\n替换一下各配置文件中的 uuid 就可以了\r\n:::\r\n\r\n## docker swarm 部署\r\n\r\n```yml\r\nservices:\r\n  shadowsocks: \r\n    image: shadowsocks/shadowsocks-libev \r\n    restart: unless-stopped\r\n    ports: \r\n      - 12346:12346\r\n      - 12346:12346/udp \r\n    configs: \r\n      - source: shadowsocks_config\r\n        target: /etc/shadowsocks-libev/config.json \r\n    environment:\r\n      - DNS_ADDRS=8.8.8.8,8.8.4.4\r\n    command: ss-server -c /etc/shadowsocks-libev/config.json \r\n  v2fly:\r\n    image: v2fly/v2fly-core\r\n    restart: unless-stopped\r\n    ports:\r\n      - 12345:12345\r\n    configs: \r\n      - source: v2fly_config\r\n        target: /etc/v2ray/config.json\r\n    entrypoint: [\"v2ray\", \"run\",  \"-c\", \"/etc/v2ray/config.json\"]\r\n\r\n\r\nconfigs:\r\n  shadowsocks_config:\r\n    file: /root/server/config/shadowsocks/config.json \r\n  v2fly_config:\r\n    file: /root/server/config/v2fly/config.json\r\n```\r\n\r\n## shadowsocks config.json\r\n\r\n```json\r\n{\r\n    \"server\":\"0.0.0.0\",\r\n    \"server_port\":12346,\r\n    \"password\":\"uuid\",\r\n    \"timeout\":3000,\r\n    \"method\":\"aes-256-gcm\",\r\n    \"fast_open\":false,\r\n    \"mode\":\"tcp_and_udp\"\r\n}\r\n\r\n```\r\n\r\n## v2fly config.json\r\n\r\n```json\r\n{\r\n    \"log\": {\r\n        \"access\": \"/var/log/v2ray/access.log\",\r\n        \"error\": \"/var/log/v2ray/error.log\",\r\n        \"loglevel\": \"warning\"\r\n    },\r\n    \"inbound\": {\r\n        \"port\": 12345,\r\n        \"protocol\": \"vmess\",\r\n        \"settings\": {\r\n            \"clients\": [\r\n                {\r\n                    \"id\": \"uuid\",\r\n                    \"level\": 1,\r\n                    \"alterId\": 0\r\n                }\r\n            ]\r\n        }\r\n    },\r\n    \"outbound\": {\r\n        \"protocol\": \"freedom\",\r\n        \"settings\": {}\r\n    },\r\n    \"inboundDetour\": [],\r\n    \"outboundDetour\": [\r\n        {\r\n            \"protocol\": \"blackhole\",\r\n            \"settings\": {},\r\n            \"tag\": \"blocked\"\r\n        }\r\n    ],\r\n    \"routing\": {\r\n        \"strategy\": \"rules\",\r\n        \"settings\": {\r\n            \"rules\": [\r\n                {\r\n                    \"type\": \"field\",\r\n                    \"ip\": [\r\n                        \"0.0.0.0/8\",\r\n                        \"10.0.0.0/8\",\r\n                        \"100.64.0.0/10\",\r\n                        \"127.0.0.0/8\",\r\n                        \"169.254.0.0/16\",\r\n                        \"172.16.0.0/12\",\r\n                        \"192.0.0.0/24\",\r\n                        \"192.0.2.0/24\",\r\n                        \"192.168.0.0/16\",\r\n                        \"198.18.0.0/15\",\r\n                        \"198.51.100.0/24\",\r\n                        \"203.0.113.0/24\",\r\n                        \"::1/128\",\r\n                        \"fc00::/7\",\r\n                        \"fe80::/10\"\r\n                    ],\r\n                    \"outboundTag\": \"blocked\"\r\n                }\r\n            ]\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "V2fly Shadowsocks 等翻墙服务部署",
      "lvl1": "docker swarm 部署",
      "lvl2": "shadowsocks config.json",
      "lvl3": "v2fly config.json"
    },
    "frontmatter": {
      "title": "V2fly Shadowsocks 等翻墙服务部署",
      "date": "2025/03/08",
      "tags": [
        "proxy"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 使用 Diskpart 永久固定 USB 盘符",
    "path": "/blogs/yunweishouce/WINshiyongDiskpartyongjiugudingUSBpanfu.html",
    "url": "/blogs/yunweishouce/WINshiyongDiskpartyongjiugudingUSBpanfu.html",
    "content": "---\r\ntitle: Windows 使用 Diskpart 永久固定 USB 盘符\r\ndate: 2025/03/05\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip Diskpart\r\n先执行 Diskpart 命令，进入 Diskpart 命令窗\r\n:::\r\n\r\n```powershell\r\n# 列出所有的硬盘\r\nlist volume\r\n\r\n# 选择需要操作的硬盘\r\nselect volume 6\r\n\r\n# 手动设置盘符\r\nassign letter=U\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 使用 Diskpart 永久固定 USB 盘符"
    },
    "frontmatter": {
      "title": "Windows 使用 Diskpart 永久固定 USB 盘符",
      "date": "2025/03/05",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 使用 NSSM 管理 Service",
    "path": "/blogs/yunweishouce/WINshiyongNSSMguanliService.html",
    "url": "/blogs/yunweishouce/WINshiyongNSSMguanliService.html",
    "content": "---\r\ntitle: Windows 使用 NSSM 管理 Service\r\ndate: 2025/06/29\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n- 安装：`winget install NSSM.NSSM`\r\n- 安装服务：`nssm install cloudflared-dns`\r\n  - 在弹出的对话框中\r\n    - Application path 添应用的绝对路径\r\n    - Startup dir 添 `win + r` 输入 `shell:startup` 回车后弹出的文件夹路径\r\n    - Arguments 填应用的启动参数\r\n    - 最后点击 Install service\r\n- 启动服务：`net start cloudflared-dns` 或 `Start-Service cloudflared-dns`\r\n- 检查服务状态： `Get-Service cloudflared-dns`\r\n- 修改服务参数：`nssm edit cloudflared-dns`\r\n- 卸载服务：`nssm remove cloudflared-dns confirm`\r\n\r\n:::info\r\n- 需要以管理员权限运行\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 使用 NSSM 管理 Service"
    },
    "frontmatter": {
      "title": "Windows 使用 NSSM 管理 Service",
      "date": "2025/06/29",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "WIN 安装 ANDROID 安卓子系统",
    "path": "/blogs/yunweishouce/WINanzhuangANDROIDanzhuozixitong.html",
    "url": "/blogs/yunweishouce/WINanzhuangANDROIDanzhuozixitong.html",
    "content": "---\r\ntitle: WIN 安装 ANDROID 安卓子系统\r\ndate: 2025/06/19\r\ntags:\r\n - Windows\r\n - Android\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n1. 打开链接 [https://store.rg-adguard.net/](https://store.rg-adguard.net/)\r\n2. 输入 `https://www.microsoft.com/store/productid/9p3395vx91nr`\r\n3. 选择 `slow`，点击 `√`\r\n4. `MicrosoftCorporationII.WindowsSubsystemForAndroid_1.8.32837.0_neutral_~_8wekyb3d8bbwe.msixbundle`，右键这个链接，复制链接地址，新建标签页，打开这个链接，开始下载\r\n5. 进入管理员模式 PS\r\n6. `Add-AppxPackage \"D:\\xicheng_jiang\\下载\\浏览器\\MicrosoftCorporationII.WindowsSubsystemForAndroid_1.8.32837.0_neutral___8wekyb3d8bbwe.Msixbundle\"`\r\n\r\n\r\n:::danger 安装过程中报错\r\n- 若报错则以同样的方式安装 `Microsoft.UI.Xaml.2.6_2.62112.3002.0_x64__8wekyb3d8bbwe.appx`，然后重试\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "WIN 安装 ANDROID 安卓子系统"
    },
    "frontmatter": {
      "title": "WIN 安装 ANDROID 安卓子系统",
      "date": "2025/06/19",
      "tags": [
        "Windows",
        "Android"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
    "path": "/blogs/yunweishouce/WINshezhiRoutezailianjieVPNdetongshibaochiduihulianwangdezhengchangfangwen.html",
    "url": "/blogs/yunweishouce/WINshezhiRoutezailianjieVPNdetongshibaochiduihulianwangdezhengchangfangwen.html",
    "content": "---\r\ntitle: Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问\r\ndate: 2025/03/08\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 操作方法\r\n\r\n1. `win+R` 输入 `ncpa.cpl`，按回车\r\n2. 右键需要操作的 VPN 设备，点击`属性`\r\n3. 点击`网络`选项卡，双击 `TCP/IPv4`，点击`高级`\r\n4. 取消勾选：`在远程网络上使用默认网关`\r\n5. 连接VPN\r\n6. 管理员模式打开 `powershell` 或 `cmd`\r\n7. 输入命令 `ipconfig /all` 回车，查看需要操作的VPN（如PPP连接）的IP地址，如`192.168.33.19`\r\n8. 添加永久静态路由：`route add 172.16.0.0 mask 255.255.0.0  192.168.33.19 -p` \r\n   - 将 `172.16.0.0` 网段，子网掩码为 `255.255.0.0` 的所有流量通过 `192.168.33.19` 接口访问，而 `192.168.33.19` 正是该VPN的接口\r\n\r\n::: info\r\n该方法的原理是，仅让特定网段的流量走VPN，其他流量依然走本地默认路由\r\n:::\r\n\r\n## Powershell 脚本\r\n\r\n```powershell\r\n# auto-vpn-route.ps1\r\n\r\nparam([String]$vpn, [String]$ip, [String]$mask)\r\n\r\n$vpn_ipv4 = (Get-NetIPAddress | Where-Object {$_.InterfaceAlias -eq $vpn}).IPAddress\r\n\r\nWrite-Host \"vpn: $vpn; vpn-ipv4: $vpn_ipv4\"\r\nIf([String]::IsNullOrEmpty($vpn_ipv4)) {\r\n    Write-Warning \"请连接 VPN：$vpn\"\r\n} Else {\r\n    Write-Host \"route delete $ip\" -ForegroundColor DarkGray\r\n    route delete $ip\r\n    Write-Host \"route add $ip mask $mask $vpn_ipv4\" -ForegroundColor DarkGray\r\n    route add $ip mask $mask $vpn_ipv4\r\n\r\n    If([String]::IsNullOrEmpty((route print | Select-String -Pattern \"\\s0.0.0.0\" | Select-String $vpn_ipv4))) {\r\n        Write-Host \"操作完成！可使用 route print | select-string $ip 查询路由表是否修改。\"\r\n    } Else {\r\n        Write-Host \"route delete $ip\" -ForegroundColor DarkGray\r\n        route delete $ip\r\n        Write-Warning \"请去控制面板关闭 $vpn 网卡的默认网关功能\" \r\n        Write-Warning \"参见：ncpa.cpl -> $vpn -> 属性 -> 网络 -> (TCP/IPv4) -> 高级 -> 在远程网络上使用默认网关\" \r\n        Write-Warning \"重新连接 $vpn\"\r\n    }\r\n}\r\n```\r\n\r\n```powershell\r\n.\\auto-vpn-route.ps1 -vpn 云开发 -ip 172.0.0.0 -mask 255.0.0.0\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
      "lvl1": "操作方法",
      "lvl2": "Powershell 脚本"
    },
    "frontmatter": {
      "title": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
      "date": "2025/03/08",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "JAVA 架构师学习笔记",
    "path": "/docs/architect/architect.html",
    "url": "/docs/architect/architect.html",
    "content": "---\r\ntitle: JAVA 架构师学习笔记\r\ndate: 2025/03/04\r\n---\r\n\r\n## 学习路径\r\n\r\n- 并发编程\r\n- 设计模式\r\n- JAVA反射、流式编程、编码规范\r\n- Spring、SpringBoot（核心启动流程、常见扩展点）\r\n- SpringCloud（微服务、分布式）\r\n- MySQL、MybatisPlus\r\n- 中间件（Redis、Sharding-Sphere、Zookeeper、RabbitMQ、Kafka、RocketMQ、Dubbo）\r\n- 网络编程（Netty）\r\n- JVM（内存模型、垃圾回收、GraalVM）\r\n- 性能调优（数据库、JVM、Tomcat）\r\n- MonoDB、ElasticSearch\r\n- clickhouse、Neo4j\r\n- Docker+K8S\r\n- 架构设计（DDD）\r\n- webflux\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JAVA 架构师学习笔记",
      "lvl1": "学习路径"
    },
    "frontmatter": {
      "title": "JAVA 架构师学习笔记",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "读书笔记",
    "path": "/docs/book/book.html",
    "url": "/docs/book/book.html",
    "content": "---\r\ntitle: 读书笔记\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "读书笔记"
    },
    "frontmatter": {
      "title": "读书笔记",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "日记",
    "path": "/docs/diary/diary.html",
    "url": "/docs/diary/diary.html",
    "content": "---\r\ntitle: 日记\r\npassword: b593bf97f44387eb6fdc629acef2d138\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "日记"
    },
    "frontmatter": {
      "title": "日记",
      "password": "b593bf97f44387eb6fdc629acef2d138",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "计算机技术栈",
    "path": "/docs/it/it.html",
    "url": "/docs/it/it.html",
    "content": "---\r\ntitle: 计算机技术栈\r\ndate: 2025/03/08\r\n---\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "计算机技术栈"
    },
    "frontmatter": {
      "title": "计算机技术栈",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "感谢打赏",
    "path": "/docs/others/donate.html",
    "url": "/docs/others/donate.html",
    "content": "---\r\ntitle: 感谢打赏\r\ndate: 2025/03/05\r\n---\r\n\r\n<div style=\"display: flex; justify-content: space-around; flex-wrap: wrap;\">\r\n    <img src=\"@source/docs/others/static/收款码-支付宝.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n    <img src=\"@source/docs/others/static/收款码-微信.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n    <img src=\"@source/docs/others/static/收款码-QQ.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n</div>\r\n\r\n::: info \r\n加入群聊一起交流哦！如有错误的地方，欢迎指正！\r\n\r\n<ul>\r\n    <li><a target=\"_blank\" href=\"http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=_8OK2fsmwKYXliSoqszUCHZ_RnMmcZsm&authKey=KEju9D76HcqTr3vuFLbdkamaqpGVYcvfo%2F%2BlLd04GucOwH0XnMZjeg0a0WUJ7OwQ&noverify=0&group_code=961215331\">架构师：961215331</a></li>\r\n    <li><a target=\"_blank\" href=\"http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=1CRaLYPuesGlWXEPQmqwmi2UsTgXebSz&authKey=EReo0mUHRG9%2FGdYsRLClzizP%2BcRIzQCVIIHjfMLUmX%2FpoV4RIoAnQBktkimpKqdD&noverify=0&group_code=966469984\">操盘手：966469984</a></li>\r\n</ul>\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "感谢打赏"
    },
    "frontmatter": {
      "title": "感谢打赏",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "诗集",
    "path": "/docs/poetry/poetry.html",
    "url": "/docs/poetry/poetry.html",
    "content": "---\r\ntitle: 诗集\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "诗集"
    },
    "frontmatter": {
      "title": "诗集",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "交易笔记",
    "path": "/docs/trading_journal/trading_journal.html",
    "url": "/docs/trading_journal/trading_journal.html",
    "content": "---\r\ntitle: 交易笔记\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "交易笔记"
    },
    "frontmatter": {
      "title": "交易笔记",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "操盘手学习笔记",
    "path": "/docs/trader/trader.html",
    "url": "/docs/trader/trader.html",
    "content": "---\r\ntitle: 操盘手学习笔记\r\ndate: 2025/03/05\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "操盘手学习笔记"
    },
    "frontmatter": {
      "title": "操盘手学习笔记",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-1",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-1.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-1.html",
    "content": "---\r\ntitle: 格言联璧-名句-1\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n> \r\n> <font color=\"orange\">静坐常思己过，闲谈莫论人非</font><br>\r\n> 怒是猛虎，欲是深渊<br>\r\n> <font color=\"orange\">鱼离水则身枯，心离书则神索</font><br>\r\n> <font color=\"orange\">修己以清心为要，涉世以慎言为先</font><br>\r\n> 谦，美德也，过谦者怀诈。默，懿行也，过默者藏奸<br>\r\n> <font color=\"orange\">天欲祸人，先以微福骄之；天欲福人，先以微祸儆之</font><br>\r\n> 日日行不怕千万里，常常做不怕千万事<br>\r\n> 对失意人，莫谈得意事。处得意日，莫忘失意时<br>\r\n> <font color=\"orange\">以情恕人，以理律己</font><br>\r\n> <font color=\"orange\">恶莫大于纵己之欲，祸莫大于言人之非</font><br>\r\n> 此生不学一可惜，此日闲过二可惜，此身一败三可惜<br>\r\n> 人之谤我也，与其能辩，不如能容；人之侮我也，与其能防，不如能化<br>\r\n> <font color=\"orange\">提得起，放得下，算得到，做得完，看得破，撇得开</font><br>\r\n> <font color=\"orange\">是非窝里，人用口，我用耳；热闹场中，人向前，我落后</font><br>\r\n> <font color=\"orange\">事有机缘，不先不后，刚刚凑巧。命若蹭蹬，走来走去，步步踏空</font><br>\r\n> 胆欲大，心欲小；智欲圆，行欲方<br>\r\n> <font color=\"orange\">事当快意时须转，言到快意时须住</font><br>\r\n> 不自重者取辱，不自畏者招祸，不自满者受益，不自是者博闻<br>\r\n> 读书即未成名，究竟人高品雅。修德不期获报，自然梦稳心安<br>\r\n> 以恕己之心恕人，则全交。以责人之心责己，则寡过<br>\r\n> 世人以七尺为性命，君子以性命为七尺<br>\r\n> 在古人之后议古人之失，则易；处古人之位为古人之事，则难<br>\r\n> 读未见书，如得良友；见已读书，如逢故人<br>\r\n> 事不可做尽，言不可道尽，势不可倚尽，福不可享尽<br>\r\n> <font color=\"orange\">不可吃尽，不可穿尽，不可说尽；又要洞得，又要做得，又要耐得</font><br>\r\n> <font color=\"orange\">有才而性缓，定属大才。有智而气和，斯为大智</font><br>\r\n> 何思何虑，居心当如止水；勿取勿忘，为学当如流水<br>\r\n> 案上不可多书，心中不可少书<br>\r\n> 辱人以不堪，必反辱；伤人以已甚，必反伤<br>\r\n> 无事时埋藏着许多小人，多事时识破了许多君子<br>\r\n> 不自反者，看不出一身病痛；不耐烦者，做不成一件事业<br>\r\n> 无心者公，无我者明<br>\r\n> 论人当节取其长，曲谅其短；做事必先审其害，后计其利<br>\r\n> 人好刚，我以柔胜之；人用术，我以诚感之；人使气，我以理屈之<br>\r\n> 盛喜中勿许人物，盛怒中勿答人书<br>\r\n> 不可不存时时可死之心，不可不行步步求生之事<br>\r\n> 见事贵乎理明，处事贵乎心公<br>\r\n> 气忌盛，心忌满，才忌露<br>\r\n> <font color=\"orange\">一念疏忽，是错起头。一念决裂，是错到底</font><br>\r\n> <font color=\"orange\">龙吟虎啸，凤翥鸾翔，大丈夫之气象</font><br>\r\n> <font color=\"orange\">缓事宜急干，敏则有功；急事宜缓办，忙则多错</font><br>\r\n> 直道事人，虚衷御物<br>\r\n> 小人乐闻君子之过，君子耻闻小人之恶<br>\r\n> <font color=\"orange\">不近人情，举足尽是危机；不体物情，一生俱成梦境</font><br>\r\n> <font color=\"orange\">心慎杂欲，则有余灵；目慎杂观，则有余明</font><br>\r\n> 眼界要阔，遍历名山大川；度量要宏，熟读五经诸史<br>\r\n> 步步占先者，必有人以挤之。事事争胜者，必有人以挫之<br>\r\n> <font color=\"orange\">顽石之中良玉隐焉，寒灰之中星火寓焉</font><br>\r\n> <font color=\"orange\">下手处是自强不息，成就处是至诚无息</font><br>\r\n> <font color=\"orange\">自责之外，无胜人之术。自强之外，无上人之术</font><br>\r\n>\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-1"
    },
    "frontmatter": {
      "title": "格言联璧-名句-1",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-2",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-2.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-2.html",
    "content": "---\r\ntitle: 格言联璧-名句-2\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 穷寇不可追也，遁辞不可攻也，贫民不可威也<br>\r\n> 见人不是，诸恶之根，见己不是，万善之门<br>\r\n> 热闹荣华之境，一过辄生凄凉。清真冷淡之为，历久愈有意味<br>\r\n> 古今来许多世家，无非积德。天地间第一人品，还是读书<br>\r\n> 善用威者不轻怒，善用恩者不妄施<br>\r\n> 事到手，且莫急，便要缓缓想；想到时，切莫缓，便要急急行<br>\r\n> 静以修身，俭以养德。入则笃行，出则友贤<br>\r\n> 作本色人，说根心话，干近情事<br>\r\n> <font color=\"orange\">知足常足，终身不辱；知止常止，终身不耻</font><br>\r\n> 怒如火，不遏则燎原；欲如水，不遏则滔天<br>\r\n> 不让古人，是谓有志；不让今人，是谓无量<br>\r\n> 读书为身上之用，而人以为纸上之用<br>\r\n> 执法如山，守身如玉，爱民如子，去蠹如仇<br>\r\n> 小人专望受人恩，受过辄忘；君子不轻受人恩，受则必报<br>\r\n> 书有未曾经我读，事无不可对人言<br>\r\n> 至乐无如读书，至要莫如教子<br>\r\n> <font color=\"orange\">福莫大于无祸，祸莫大于邀福</font><br>\r\n> 大智兴邦，不过集众思；大愚误国，只为好自用<br>\r\n> <font color=\"orange\">任难任之事，要有力而无气；处难处之人，要有知而无言</font><br>\r\n> 待小人宜宽，防小人宜严<br>\r\n> 无欲之谓圣，寡欲之谓贤，多欲之谓凡，徇欲之谓狂<br>\r\n> <font color=\"orange\">律己宜带秋气，处世须带春风</font><br>\r\n> 有真才者，必不矜才。有实学者，必不夸学<br>\r\n> 天下之势，以渐而成；天下之事，以积而居<br>\r\n> <font color=\"orange\">强不知以为知，此乃大愚；本无事而生事，是谓薄福</font><br>\r\n> 处逆境心，须用开拓法。处顺境心，要用收敛法<br>\r\n> 物忌全胜，事忌全美，人忌全盛<br>\r\n> 一时劝人以言，百世劝人以书<br>\r\n> <font color=\"orange\">有作用者，器宇定是不凡。有智慧者，才情决然不露</font><br>\r\n> 以虚养心，以德养身，以仁养天下万物，以道养天下万世<br>\r\n> <font color=\"orange\">心不欲杂，杂则神荡而不收；心不欲劳，劳则神疲而不入</font><br>\r\n> 对愁人勿乐，对哭人勿笑，对失意人勿矜<br>\r\n> 寡欲故静，有主则虚<br>\r\n> 必有容，德乃大；必有忍，事乃济<br>\r\n> 聪明者，戒太察。刚强者，戒太暴。温良者，戒无断<br>\r\n> 喜来时一检点，怒来时一检点，怠惰时一检点，放肆时一检点<br>\r\n> <font color=\"orange\">毋以小嫌疏至戚，毋以新怨忘旧恩</font><br>\r\n> 倚势欺人，势尽而为人欺；恃财侮人，财散而受人侮<br>\r\n> 彼之理是，我之理非，我让之；彼之理非，我之理是，我容之<br>\r\n> <font color=\"orange\">大着肚皮容物，立定脚跟做人</font><br>\r\n> <font color=\"orange\">闻恶不可遽怒，恐为谗人泄忿；闻善不可就亲，恐引奸人进身</font><br>\r\n> 炎凉之态，富贵其于贫贱；嫉妒之心，骨肉其于外人<br>\r\n> <font color=\"orange\">待人三自反，处世两如何</font><br>\r\n> 涵养冲虚，便是身世学问。省除烦恼，何等心性安和<br>\r\n> <font color=\"orange\">公生明，诚生明，从容生明</font><br>\r\n> 居安虑危，处治思乱<br>\r\n> 丈夫之高华，只在于道德气节。鄙夫之炫耀，但求诸服饰起居<br>\r\n> 古之君子病其无能也，学之；今之君子耻其无能也，讳之<br>\r\n> 身在天地后，心在天地前；身在万物中，心在万物上<br>\r\n> <font color=\"orange\">世事让三分，天空地阔。心田培一点，子种孙收</font><br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-2"
    },
    "frontmatter": {
      "title": "格言联璧-名句-2",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-3",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-3.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-3.html",
    "content": "---\r\ntitle: 格言联璧-名句-3\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> <font color=\"orange\">处事须留余地，责善切戒尽言</font><br>\r\n> 以耐事了天下之多事，以无心息天下之争心<br>\r\n> 读书贵能疑，疑乃可以启信。读书在有渐，渐乃克底有成<br>\r\n> 只是心不放肆，便无过差。只是心不怠忽，便无逸志<br>\r\n> 临事须替别人想，论人先将自己想<br>\r\n> <font color=\"orange\">以镜自照见形容，以心自照见吉凶</font><br>\r\n> 人性中不曾缺一物，人性上不可添一物<br>\r\n> 看书求理，须令自家胸中点头。与人谈理，须令人家胸中点头<br>\r\n> <font color=\"orange\">不为过三字，昧却多少良心；没奈何三字，抹却多少体面</font><br>\r\n> 静能制动，沈能制浮。宽能制褊，缓能制急<br>\r\n> 观天地生物气象，学圣贤克己工夫<br>\r\n> 贫贱是苦境，能善处者自乐；富贵是乐境，不善处者更苦<br>\r\n> 谈人之善，泽于膏沐；暴人之恶，痛于戈矛<br>\r\n> 人未己知，不可急求其知；人未己合，不可急与之合<br>\r\n> 勿施小惠伤大体，毋借公道遂私情<br>\r\n> 心志要苦，意趣要乐。气度要宏，言动要谨<br>\r\n> 勤能补拙，俭以养廉<br>\r\n> 尽前行者地步窄，向后看者眼界宽<br>\r\n> 阿谀取容，男子耻为妾妇之道。本真不凿，大人不失赤子之心<br>\r\n> 穷达有命，吉凶见人<br>\r\n> 省费医贫，恬退医躁，独卧医淫，随缘医愁，读书医俗<br>\r\n> 以鲜花视美色，则孽障自消；以流水听弦歌，则性灵何害<br>\r\n> 当厄之施甘于时雨，伤心之语毒于阴冰<br>\r\n> 能容小人是大人，能培薄德是厚德<br>\r\n> <font color=\"orange\">居处必先精勤，乃能闲暇。凡事务求停妥，然后逍遥</font><br>\r\n> <font color=\"orange\">毋毁众人之名，以成一己之善。毋没天下之理，以护一己之过</font><br>\r\n> <font color=\"orange\">实处着脚，稳处下手</font><br>\r\n> 兄弟争财，父遗不尽不止；妻妾争宠，夫命不死不休<br>\r\n> 盖世功劳，当不得一个“矜”字。弥天罪恶，当不得一个“悔”字<br>\r\n> 古之学者得一善言，附于其身；今之学者得一善言，务以悦人<br>\r\n> 万理澄彻，则一心愈精而愈谨。一心凝聚，则万理愈通而愈流<br>\r\n> 语言间尽可积德，妻子间亦是修身<br>\r\n> 吉凶祸福，是天主张。毁誉予夺，是人主张。主身行己，是我主张<br>\r\n> 位尊身危，财多命殆<br>\r\n> <font color=\"orange\">天下无不是的父母，世间最难得者兄弟</font><br>\r\n> 读书者不贱，力田者不饥。积德者不倾，择交者不败<br>\r\n> 天德只是个无我，王道只是个爱人<br>\r\n> <font color=\"orange\">真圣贤决非迂腐，真豪杰断不粗疏</font><br>\r\n> 防欲如挽逆水之舟，才歇手便下流。力行如缘无枝之树，才住脚便下坠<br>\r\n> 以仁义存心，以勤俭作家，以忍让接物<br>\r\n> <font color=\"orange\">恩怕先益后损，威怕先松后紧</font><br>\r\n> 无事时戒一“偷”字，有事时戒一“乱”字<br>\r\n> 律身惟廉为宜，处世以退为尚<br>\r\n> 俭则约，约则百善俱兴；侈则肆，肆则百恶俱纵<br>\r\n> <font color=\"orange\">欲理会七尺，先理会方寸；欲理会六合，先理会一腔</font><br>\r\n> 径路窄处，留一步与人行；滋味浓处，减三分让人嗜<br>\r\n> 飘风不可以调宫商，巧妇不可以主中馈，词章之士不可以治国家<br>\r\n> <font color=\"orange\">人褊急，我受之以宽宏；人险仄，我待之以坦荡</font><br>\r\n> 工于论人者，察己常阔疏；狃于讦直者，发言多弊病<br>\r\n> <font color=\"orange\">不蹈无人之室，不入有事之门，不处藏物之所</font><br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-3"
    },
    "frontmatter": {
      "title": "格言联璧-名句-3",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-4",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-4.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-4.html",
    "content": "---\r\ntitle: 格言联璧-名句-4\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 敬守此心，则心定；敛抑其气，则气平<br>\r\n> 富以能施为德，贫以无求为德，贵以下人为德，贱以忘势为德<br>\r\n> <font color=\"orange\">要得富贵福泽，天主张由不得我。要做贤人君子，我主张由不得天</font><br>\r\n> <font color=\"orange\">爱惜精神，留他日担当宇宙。蹉跎岁月，尽此身污秽乾坤</font><br>\r\n> 为善最乐，读书便佳<br>\r\n> <font color=\"orange\">富贵家不肯从宽，必遭横祸；聪明人不肯学厚，必殀天年</font><br>\r\n> <font color=\"orange\">海阔从鱼跃，天空任鸟飞</font><br>\r\n> 事以典故为据，故当博洽，不然臆说杜撰也<br>\r\n> 敬为千圣授受真源，慎乃百年提撕紧钥<br>\r\n> 祸到休愁，也要会救；福来休喜，也要会受<br>\r\n> 庙堂之上，以养正气为先；海宇之内，以养元气为本<br>\r\n> <font color=\"orange\">凡为外所胜者，皆内不足；凡为邪所夺者，皆正不足</font><br>\r\n> 只一事不留心，便有一事不得其理；只一物不留心，便有一物不得其所<br>\r\n> 古之从仕者养人，今之从仕者养己<br>\r\n> 未用兵时，全要虚心用人；既用兵时，全要实心活人<br>\r\n> <font color=\"orange\">治家严家乃和，居乡恕乡乃睦</font><br>\r\n> <font color=\"orange\">直不犯祸，和不害义</font><br>\r\n> 困辱非忧，取困辱为忧。荣利非乐，忘荣利为乐<br>\r\n> 接人要和中有介，处事要精中有果，认理要正中有道通<br>\r\n> 意粗性躁，一事无成。心平气和，千祥骈集<br>\r\n> <font color=\"orange\">喜闻人过，不若喜闻己过；乐道己善，何如乐道人善</font><br>\r\n> <font color=\"orange\">在事者，当置身利害之外；建言者，当设身利害之中</font><br>\r\n> 人属寒微，要思矜礼他，着不得一毫傲睨的气象<br>\r\n> 果决人似忙，心中常有余闲。因循人似闲，人中常有余忙<br>\r\n> 俗语近于市，纤语近于娼，诨语近于优<br>\r\n> <font color=\"orange\">岂能尽如人意，但求不愧我心</font><br>\r\n> 能改过，则天地不怒。能安分，则鬼神无权<br>\r\n> 居官先厚民风，处事先求大体<br>\r\n> 事属暖昧，要思回护他，着不得一点攻讦的念头<br>\r\n> 名誉自屈辱中彰，德量自隐忍中大<br>\r\n> <font color=\"orange\">荆棘满野，而望收嘉禾者愚；私念满胸，而欲求福应者悖</font><br>\r\n> 心术不可得罪于天地，言行要留好样与儿孙<br>\r\n> 肆傲者纳侮，诲过者长恶，贪利者害己，纵欲者戕生<br>\r\n> <font color=\"orange\">作恶事须防鬼神知，干好事莫怕旁人笑</font><br>\r\n> 作德日休，是谓福地；居易俟命，是谓洞天<br>\r\n> 藏书可以邀友，积德可以邀天<br>\r\n> <font color=\"orange\">于福作罪，其罪非轻；于苦作福，其福最大</font><br>\r\n> 洁己方能不失己，爱民所重在亲民<br>\r\n> 供人欣赏，侪风月于烟花，是曰亵天<br>\r\n> <font color=\"orange\">宇宙内事，乃己分内事；己分内事，乃宇宙内事</font><br>\r\n> 舍事功更无学问。求性道不外文章<br>\r\n> 事事难上难，举足常虞失坠；件件想一想，浑身都是过差<br>\r\n> 怒宜实力消融，过要细心检点<br>\r\n> 经济出自学问，经济方有本源；心性见之事功，心性方为圆满<br>\r\n> 逞我机锋，借诗书以戏谑，是名侮圣<br>\r\n> 罪莫大于亵天，恶莫大于无耻；苛刻心术之恶，过莫大于深险<br>\r\n> 衣垢不湔，器缺不补，对人犹有惭色<br>\r\n> <font color=\"orange\">盛者衰之始，福者祸之基</font><br>\r\n> 国家立法，不可不严。有司行法，不可不恕<br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-4"
    },
    "frontmatter": {
      "title": "格言联璧-名句-4",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-5",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-5.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-5.html",
    "content": "---\r\ntitle: 格言联璧-名句-5\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 古之名望相近则相得，今之名望相近则相妒<br>\r\n> 孝莫辞劳，转眼便为人父母；善因望报，回头但看尔儿孙<br>\r\n> 理欲交争，肺腑成为吴越。物我一体，参商终是兄弟<br>\r\n> 政令之所重者人才，国家之所重者元气<br>\r\n> 父母所欲为者，我继述之；父母所重念者，我亲厚之<br>\r\n> 兄弟和其中自乐，子孙贤此外何求<br>\r\n> 造物所忌，曰刻曰巧；万类相感，以诚以忠<br>\r\n> 入瑶树琼林中皆宝，有谦德仁心者为祥<br>\r\n> 行垢不湔，德缺不补，对天岂无愧心<br>\r\n> 内不欺己，外不欺人<br>\r\n> 何思何虑，居心当如止水；勿取勿忘，为学当如流水<br>\r\n> 存养宜冲粹，近春温；省察宜谨严，近秋肃<br>\r\n> 惩忿如摧山，窒欲如填壑；惩忿如救火，窒欲如防水<br>\r\n> 奢者富不足，俭者贫有余。奢者心常贫，贫者心常富<br>\r\n> 蚕茧蛛丝，蚁封蚓结，儿女子之经营<br>\r\n> 慎言动于妻子仆隶之间，检身人于食息起居之际<br>\r\n> 宽厚者，毋使人有所恃；精明者，不使人有所容<br>\r\n> 富儿因求宦倾赀，污吏以黩货失职<br>\r\n> 问消息于蓍龟，疑团空结；祈福祉于奥灶，奢想徒劳<br>\r\n> 圣贤学问是一套，行王道必本天德；后世学问是两截，不修己只管治人<br>\r\n> 理以心得为精，故当沈潜，不然耳边口头尔<br>\r\n> <font color=\"orange\">信不足则多言</font><br>\r\n> <font color=\"orange\">立党羽，不如昭信义</font><br>\r\n> 孝子百世之宗，仁人天下之命<br>\r\n> 圣人敛福，君子考祥；作德日休，为善最乐<br>\r\n> 听断之官，成心必不可有；任事之官，成算必不可无<br>\r\n> 做大官底是一样家数，做好人底是一样家数<br>\r\n> 知足常乐，能忍自安<br>\r\n> 休诿罪于气化，一切责之人事。休过望于世间，一切求之我身<br>\r\n> 亲兄弟析箸，璧合翻作瓜分。士大夫爱钱，书香化为铜臭<br>\r\n> <font color=\"orange\">一能胜千，君子不可无此小心。吾何畏彼，丈夫不可无此大志</font><br>\r\n> 安莫安于知足，危莫危于多言<br>\r\n> 人之心胸，多欲则窄，寡欲则宽<br>\r\n> <font color=\"orange\">惟有主，则天地万物自我而立；必无私，斯上下四旁咸得其平</font><br>\r\n> 茹素虽佛氏教也，好生非上天意乎<br>\r\n> 志之所趋，无远勿届，穷山距海，不能限也<br>\r\n> 对痴人莫说梦话，防所误也；见短人莫说矮话，避所忌也<br>\r\n> 有违言为信，践言为非信者<br>\r\n> 情爱过义，子孙之灾也<br>\r\n> 勤俭治家之本，忠孝齐家之本，谨慎保家之本，诗书起家之本，积善传家之本<br>\r\n> 饱肥甘衣轻暖，不知节者损福<br>\r\n> 广积聚骄富贵，不知止者杀身<br>\r\n> <font color=\"orange\">戒久睡，久睡倦神</font><br>\r\n> 慨夏畦之劳劳，秋毫无补；悯冬烘之贸贸，春恩广覃<br>\r\n> 四海和平之福，只是随缘。一生牵惹之劳，总因好事<br>\r\n> 口不妄言，君子所以存诚<br>\r\n> 志之所向，无坚不入，锐兵固甲，不能御也<br>\r\n> 天下无不可化之人，但恐诚心未至；天下无不可为之事，只怕立志不坚<br>\r\n> ",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-5"
    },
    "frontmatter": {
      "title": "格言联璧-名句-5",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "JAVA并发-设计模式",
    "path": "/docs/architect/concurrent/JAVAbingfa-shejimoshi.html",
    "url": "/docs/architect/concurrent/JAVAbingfa-shejimoshi.html",
    "content": "---\r\ntitle: JAVA并发-设计模式\r\ndate: 2025/04/22\r\n---\r\n\r\n- 终止线程的设计模式\r\n\t- Two-phase Termination（两阶段终止）模式：终止标志位\r\n- 避免共享的设计模式\r\n\t- Immutability模式：只读\r\n\t- Copy-on-Write模式：写时复制\r\n\t- Thread-Specific Storage 模式：线程本地存储 ThreadLocal\r\n- 多线程版本的 if 模式\r\n\t- Guarded Suspension 模式（Guarded Wait 模式、Spin Lock 模式）：一个线程需要等待另外的线程完成后继续下一步操作\r\n\t- Balking 模式：一个线程发现另一个线程已经做了某一件相同的事，那么本线程就无需再做了，直接结束返回\r\n- 多线程分工模式\r\n\t- Thread-Per-Message 模式：为每个任务分配一个独立的线程\r\n\t- Worker Thread 模式：线程池\r\n\t- 生产者-消费者模式：核心是一个任务队列\r\n\t\t- 过饱问题：生产者生产的速度大于消费者消费的速度\r\n\t\t\t- 消费者每天能处理的量比生产者生产的少：消费者加机器\r\n\t\t\t- 消费者每天能处理的量比生产者生产的多：适当的加大队列\r\n\t\t\t- 系统高峰期生产者速度太快：生产者限流\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JAVA并发-设计模式"
    },
    "frontmatter": {
      "title": "JAVA并发-设计模式",
      "date": "2025/04/22"
    },
    "type": "content"
  },
  {
    "title": "JVM-内存模型",
    "path": "/docs/architect/jvm/JVM-nacunmoxing.html",
    "url": "/docs/architect/jvm/JVM-nacunmoxing.html",
    "content": "---\r\ntitle: JVM-内存模型\r\ndate: 2025/03/04\r\n---\r\n\r\n::: tip 介绍\r\n1. JVM 内存模型\r\n2. JVM 内存核心参数\r\n3. 存调优案例\r\n:::\r\n\r\n## JVM 内存模型\r\n\r\n![JVM 内存模型](static/JVM-内存模型-内存模型.png)\r\n\r\n## JVM 内存核心参数\r\n\r\n![JVM 核心参数](static/JVM-内存模型-核心参数.png)\r\n\r\n- 关于元空间的JVM参数有两个：`-XX:MetaspaceSize=N` 和 `-XX:MaxMetaspaceSize=N`\r\n\t- `-XX:MaxMetaspaceSize` ： 设置元空间最大值， 默认是 -1， 即不限制， 或者说只受限于本地内存大小\r\n\t- `-XX:MetaspaceSize`： 指定元空间触发Fullgc的初始阈值(元空间无固定初始大小)， 以字节为单位，默认是21M，达到该值就会触发full gc进行类型卸载\r\n\t\t- 同时收集器会对该值进行调整： 如果释放了大量的空间， 就适当降低该值； 如果释放了很少的空间， 那么在不超过 `-XX:MaxMetaspaceSize`（如果设置了的话） 的情况下， 适当提高该值\r\n\t\t- 这个跟早期jdk版本的 `-XX:PermSize` 参数意思不一样，`-XX:PermSize` 代表永久代的初始容量\r\n\t- 由于调整元空间的大小需要Full GC，这是非常昂贵的操作，如果应用在启动的时候发生大量Full GC，通常都是由于永久代或元空间发生了大小调整，基于这种情况，一般建议在JVM参数中将 MetaspaceSize 和 MaxMetaspaceSize 设置成一样的值，并设置得比初始值要大，对于 8G 物理内存的机器来说，一般我会将这两个值都设置为 256M\r\n- `-Xss` 设置越小，说明一个线程栈里能分配的栈帧就越少，但是对 JVM 整体来说能开启的线程数会更多\r\n- 尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收\r\n\r\n## 内存调优案例\r\n\r\n![JVM 内存调优案例](static/JVM-内存模型-案例.png)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JVM-内存模型",
      "lvl1": "JVM 内存模型",
      "lvl2": "JVM 内存核心参数",
      "lvl3": "内存调优案例"
    },
    "frontmatter": {
      "title": "JVM-内存模型",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "JVM-常量池",
    "path": "/docs/architect/jvm/JVM-changliangchi.html",
    "url": "/docs/architect/jvm/JVM-changliangchi.html",
    "content": "---\r\ntitle: JVM-常量池\r\ndate: 2025/03/04\r\n---\r\n\r\n::: tip 介绍\r\n1. Class 常量池与运行时常量池\r\n2. 字符串常量池\r\n3. 八种基本类型的包装类和对象池\r\n:::\r\n\r\n## Class 常量池与运行时常量池\r\n\r\n- Class 常量池与运行时常量池（`javap -v Xxx.class` -> Constant pool）：常量池中主要存放字面量和符号引用\r\n\t- Class常量池可以理解为是Class文件中的资源仓库\r\n\t\t- Class文件中除了包含类的版本、字段、方法、接口等描述信息外， 还有一项信息就是常量池(constant pool table)，用于存放编译期生成的各种字面量(Literal)和符号引用(Symbolic References)\r\n\t- 字面量：就是指由字母、数字等构成的字符串或者数值常量\r\n\t\t- 字面量只可以右值出现，所谓右值是指等号右边的值，如：int a=1 这里的a为左值，1为右值\r\n\t- 符号引用：是编译原理中的概念，是相对于直接引用来说的\r\n\t\t- 主要包括了三类常量：类和接口的全限定名；字段的名称和描述符；方法的名称和描述符\r\n\t- 运行时常量池：这些常量池现在是静态信息，只有到运行时被加载到内存后，这些符号才有对应的内存地址信息，这些常量池一旦被装入内存就变成运行时常量池\r\n\t\t- 例如，compute()这个符号引用在运行时就会被转变为compute()方法具体代码在内存中的 地址，主要通过对象头里的类型指针去转换直接引用\r\n\r\n## 字符串常量池\r\n- 字符串常量池\r\n\t- 设计思想\r\n\t\t- 字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价，作为最基础的数据类型，大量频繁的创建字符串，极大程度地影响程序的性能\r\n\t\t- JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化\r\n\t\t\t- 为字符串开辟一个字符串常量池，类似于缓存区\r\n\t\t\t- 创建字符串常量时，首先查询字符串常量池是否存在该字符串\r\n\t\t\t- 存在该字符串，返回引用实例，不存在，实例化该字符串并放入池中\r\n\t- 三种字符串操作\r\n\t\t- 直接赋值字符串（指向常量池中的引用）：`String s = \"jxch\";`\r\n\t\t\t- 这种方式创建的字符串对象，只会在常量池中\r\n\t\t\t- 创建对象s的时候，JVM会先去常量池中通过 equals(key) 方法，判断是否有相同的对象\r\n\t\t\t\t- 如果有，则直接返回该对象在常量池中的引用\r\n\t\t\t\t- 如果没有，则会在常量池中创建一个新对象，再返回引用\r\n\t\t- `String s = new String(\"jxch\");` （指向内存中的对象引用）\r\n\t\t\t- 这种方式会保证字符串常量池和堆中都有这个对象，没有就创建，最后返回堆内存中的对象引用\r\n\t\t\t- 先检查字符串常量池中是否存在字符串\r\n\t\t\t\t- 不存在，先在字符串常量池里创建一个字符串对象；再去内存中创建一个字符串对象\r\n\t\t\t\t- 存在的话，就直接去堆内存中创建一个字符串对象\r\n\t\t\t- 最后，将内存中的引用返回\r\n\t\t- `intern` 方法是一个 native 的方法\r\n\t\t\t- 如果池已经包含一个等于此String对象的字符串（equals(oject)），则返回池中的字符串\r\n\t\t\t- 否则，将intern返回的引用指向当前字符串\r\n\t\t\t\t- 在 JDK 1.7 (及以上版本) 中，由于字符串池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象（字符串不存在时不再需要重新创建实例，可以直接指向堆上的实例）\r\n\t\t\t\t- jdk1.6版本需要将字符串复制到字符串常量池里\r\n\t- 常量池的位置\r\n\t\t- Jdk1.6及之前： 有永久代, 运行时常量池在永久代，运行时常量池包含字符串常量池\r\n\t\t- Jdk1.7：有永久代，但已经逐步“去永久代”，字符串常量池从永久代里的运行时常量池分离到堆里\r\n\t\t- Jdk1.8及之后： 无永久代，运行时常量池在元空间，字符串常量池里依然在堆里\r\n\t- 设计原理：类似 HashTable ，本质上是字符串对象的引用\r\n\r\n## 八种基本类型的包装类和对象池\r\n- 八种基本类型的包装类和对象池\r\n\t- java中基本类型的包装类的大部分都实现了常量池技术 (严格来说应该叫对象池，在堆上)\r\n\t- Byte,Short,Integer,Long,Character,Boolean （另外两种浮点数类型的包装类则没有实现对象池）\r\n\t- Byte,Short,Integer,Long,Character这5种整型的包装类也只是在对应值小于等于127时才可使用对象池\r\n\t\t- 即对象不负责创建和管理大于127的这些类的对象\r\n\t\t- 一般这种比较小的数用到的概率相对较大\r\n\r\n\r\n## 字符串常量池示例\r\n\r\n```java\r\nString s1 = new String(\"he\") + new String(\"llo\");\r\nString s2 = s1.intern();\r\n \r\nSystem.out.println(s1 == s2);\r\n// 在 JDK 1.6 下输出是 false，创建了 6 个对象\r\n// 在 JDK 1.7 及以上的版本输出是 true，创建了 5 个对象 \r\n// 当然我们这里没有考虑GC，但这些对象确实存在或存在过\r\n```\r\n\r\n![字符串常量池-JDK1.7+](static/JVM-常量池-字符串常量池-JDK1.7+.png)\r\n\r\n\r\n![字符串常量池-JDK1.6](static/JVM-常量池-字符串常量池-JDK1.6.png)\r\n\r\n```java\r\nString s0=\"zhuge\"; \r\nString s1=\"zhuge\"; \r\nString s2=\"zhu\" + \"ge\";\r\nSystem.out.println( s0==s1 ); //true \r\nSystem.out.println( s0==s2 ); //true\r\n\r\nString s0=\"zhuge\";\r\nString s1=new String(\"zhuge\");\r\nString s2=\"zhu\" + new String(\"ge\");\r\nSystem.out.println( s0==s1 ); // false \r\nSystem.out.println( s0==s2 )； // false \r\nSystem.out.println( s1==s2 ); // false\r\n\r\nString a = \"a1\";\r\nString b = \"a\" + 1;\r\nSystem.out.println(a == b); // true\r\nString a = \"atrue\";\r\nString b = \"a\" + \"true\";\r\nSystem.out.println(a == b); // true\r\nString a = \"a3.4\";\r\nString b = \"a\" + 3.4;\r\nSystem.out.println(a == b); // true\r\n\r\nString a = \"ab\"; \r\nString bb = \"b\"; \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // false 由于在字符串的\"+\"连接中，有字符串引用存在，而引用的值在程序编译期是无法确定的\r\n\r\nString a = \"ab\";\r\nfinal String bb = \"b\"; \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // true 对于final修饰的变量，它在编译时被解析为常量值的一个本地拷贝存储到自己的常量池中或嵌入到它的字节码流中\r\n\r\nprivate static String getBB() { return \"b\"; }\r\nString a = \"ab\";\r\nfinal String bb = getBB(); \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // false JVM对于字符串引用bb，它的值在编译期无法确定，只能在程序运行期调用方法后，将方法的返回值和\"a\"来动态连接并分配地址为b\r\n\r\nString str1 = new StringBuilder(\"ja\").append(\"va\").toString();\r\nSystem.out.println(str1 == str1.intern()); //false java是关键字，在JVM初始化的相关类里肯定早就放进字符串常量池了\r\n```\r\n\r\n::: info 注意\r\nString是不可变的\r\n:::\r\n\r\n```java\r\nString s = \"a\" + \"b\" + \"c\"; //就等价于String s = \"abc\";\r\nString a = \"a\";\r\nString b = \"b\";\r\nString c = \"c\";\r\nString s1 = a + b + c;\r\n\r\n// `s1` 这个就不一样了，可以通过观察其 `JVM` 指令码发现 `s1` 的 `+` 操作会变成如下操作\r\nStringBuilder temp = new StringBuilder(); \r\ntemp.append(a).append(b).append(c);\r\nString s = temp.toString();\r\n```\r\n\r\n## 包装类对象池示例\r\n\r\n```java\r\n //5种整形的包装类Byte,Short,Integer,Long,Character的对象，\r\n //在值小于127时可以使用对象池\r\n Integer i1 = 127; //这种调用底层实际是执行的Integer.valueOf(127)，里面用到了IntegerCache对象池 \r\n Integer i2 = 127;\r\n System.out.println(i1 == i2);//输出true\r\n \r\n //值大于127时，不会从对象池中取对象\r\n Integer i3 = 128;\r\n Integer i4 = 128;\r\n System.out.println(i3 == i4);//输出false\r\n \r\n //用new关键词新生成对象不会使用对象池\r\n Integer i5 = new Integer(127);\r\n Integer i6 = new Integer(127);\r\n System.out.println(i5 == i6);//输出false\r\n \r\n //Boolean类也实现了对象池技术\r\n Boolean bool1 = true;\r\n Boolean bool2 = true;\r\n System.out.println(bool1 == bool2);//输出true\r\n \r\n //浮点类型的包装类没有实现对象池技术\r\n Double d1 = 1.0;\r\n Double d2 = 1.0;\r\n System.out.println(d1 == d2);//输出false\r\n```\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JVM-常量池",
      "lvl1": "Class 常量池与运行时常量池",
      "lvl2": "字符串常量池",
      "lvl3": "八种基本类型的包装类和对象池",
      "lvl4": "字符串常量池示例",
      "lvl5": "包装类对象池示例"
    },
    "frontmatter": {
      "title": "JVM-常量池",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "1.基础",
    "path": "/docs/architect/kafka/Kafka-1.jichu.html",
    "url": "/docs/architect/kafka/Kafka-1.jichu.html",
    "content": "---\r\ntitle: 1.基础\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 核心组件\r\n- 配置文件\r\n- 基础命令\r\n- Topic\r\n- Kafka集群\r\n- Java客户端 & SpringBoot支持\r\n:::\r\n\r\n---\r\n## 核心组件\r\n\r\n\r\n| 名称            | 解释                                                                                                           |\r\n| ------------- | ------------------------------------------------------------------------------------------------------------ |\r\n| Broker        | 消息中间件处理节点，一个Kafka节点就是一个broker，一<br>个或者多个Broker可以组成一个Kafka集群                                                  |\r\n| Topic         | Kafka根据topic对消息进行归类，发布到Kafka集群的每条<br>消息都需要指定一个topic                                                          |\r\n| Producer      | 消息生产者，向Broker发送消息的客户端                                                                                        |\r\n| Consumer      | 消息消费者，从Broker读取消息的客户端                                                                                        |\r\n| ConsumerGroup | 每个Consumer属于一个特定的Consumer Group，一条消<br>息可以被多个不同的Consumer Group消费，但是一个<br>Consumer Group中只能有一个Consumer能够消费该消息 |\r\n| Partition     | 物理上的概念，一个topic可以分为多个partition，每个<br>partition内部消息是有序的                                                        |\r\n\r\n![核心组件](static/Kafka-基础-1.png)\r\n\r\n---\r\n## 配置文件\r\n\r\n- 配置：`server.properties`\r\n```properties\r\n#broker.id属性在kafka集群中必须要是唯一\r\nbroker.id=0\r\n#kafka部署的机器ip和提供服务的端口号\r\nlisteners=PLAINTEXT://192.168.65.60:9092\r\n#kafka的消息存储文件\r\nlog.dir=/usr/local/data/kafka‐logs\r\n#kafka连接zookeeper的地址\r\nzookeeper.connect=192.168.65.60:2181\r\n```\r\n- 默认配置\r\n\r\n| Property                   | Default                       | Description                                                                                                                                                      |\r\n| -------------------------- | ----------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |\r\n| broker.id                  | 0                             | 每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为<br>broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯<br>一的即可                                                                             |\r\n| log.dirs                   | /tmp/kafka-logs               | kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间<br>只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最<br>少partitions的路径下进行                                                                  |\r\n| listeners                  | PLAINTEXT://192.168.65.60:909 | server接受客户端连接的端口，ip配置kafka本机ip即可                                                                                                                                 |\r\n| zookeeper.connect          | localhost:2181                | zooKeeper连接字符串的格式为：hostname:port，此处hostname和<br>port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果<br>是集群，连接方式为 hostname1:port1, hostname2:port2, <br>hostname3:port3 |\r\n| log.retention.hours        | 168                           | 每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样                                                                                                                              |\r\n| num.partitions             | 1                             | 创建topic的默认分区数                                                                                                                                                    |\r\n| default.replication.factor | 1                             | 自动创建topic的默认副本数量，建议设置为大于等于2                                                                                                                                      |\r\n| min.insync.replicas        | 1                             | 当producer设置acks为-1时，min.insync.replicas指定replicas的最小<br>数目（必须确认每一个repica的写数据都是成功的），如果这个数目没<br>有达到，producer发送消息会产生异常                                              |\r\n| delete.topic.enable        | false                         | 是否允许删除主题                                                                                                                                                         |\r\n\r\n---\r\n## 基础命令\r\n\r\n- 启动：`kafka‐server‐start.sh ‐daemon server.properties`\r\n\t- ­`-daemon` 表示以后台进程运行，否则ssh客户端退出后，就会停止服务\r\n\t- 在启动kafka时会使用linux主机名关联的ip地址，所以需要把主机名和linux的ip映射配置到本地host里，用 `vim /etc/hosts`\r\n- 停止：`kafka‐server‐stop.sh`\r\n- 创建主题：当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创建\r\n\t- `kafka‐topics.sh ‐‐create ‐‐zookeeper 192.168.65.60:2181 ‐‐replication‐factor 1 ‐‐partitions 1 ‐‐topic test`\r\n\t- `kafka‐topics.sh ‐‐create ‐‐zookeeper 192.168.65.60:2181 ‐‐replication‐factor 1 ‐‐partitions 2 ‐‐topic test`\r\n\t- `kafka‐topics.sh ‐‐list ‐‐zookeeper 192.168.65.60:2181`\r\n- 查看Topic：`kafka‐topics.sh ‐‐describe ‐‐zookeeper 192.168.65.60:2181 ‐‐topic test`\r\n\t- 第一行是所有分区的概要信息，之后的每一行表示每一个pa",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础",
      "lvl1": "核心组件",
      "lvl2": "配置文件",
      "lvl3": "基础命令",
      "lvl4": "Topic",
      "lvl5": "Kafka集群",
      "lvl6": "Java客户端",
      "lvl7": "SpringBoot支持"
    },
    "frontmatter": {
      "title": "1.基础",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 4
  },
  {
    "title": "1.基础",
    "path": "/docs/architect/kafka/Kafka-1.jichu.html",
    "url": "/docs/architect/kafka/Kafka-1.jichu.html",
    "content": "rtition的信息\r\n\t- leader节点负责给定partition的所有读写请求\r\n\t- replicas 表示某个partition 在哪几个 broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出\r\n\t- isr 是replicas的一个子集，它只列出当前还存活着的，并且已同步备份了该partition的节点。leader的选举也是从ISR(in-sync replica)中进行的\r\n- 增加Topic的分区数量（目前不支持减少分区）：`kafka‐topics.sh ‐alter ‐‐partitions 3 ‐‐zookeeper 192.168.65.60:2181 ‐‐topic test`\r\n- 删除主题：`kafka‐topics.sh ‐‐delete ‐‐topic test ‐‐zookeeper 192.168.65.60:2181`\r\n- 发送消息：`kafka‐console‐producer.sh ‐‐broker‐list 192.168.65.60:9092 ‐‐topic test`\r\n- 消费消息：默认是消费最新的消息\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐topic test`\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐from‐beginning ‐‐topic test`\r\n- 消费多主题：`kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐whitelist \"test|test‐2\"`\r\n- 单播消费：只需让消费者在同一个消费组里即可\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐consumer‐property group.id=testGroup ‐‐topic test`\r\n- 多播消费：只要保证这些消费者属于不同的消费组即可\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐consumer‐property group.id=testGroup‐2 ‐‐topic test`\r\n- 生产消费集群消息\r\n\t- `kafka‐console‐producer.sh ‐‐broker‐list 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094 ‐‐topic my‐replicated‐topic`\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094 ‐‐from‐beginning ‐‐topic my‐replicated‐topic`\r\n- 查看消费组名：`kafka‐consumer‐groups.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐list`\r\n- 查看消费组的消费偏移量：`kafka‐consumer‐groups.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐describe ‐‐group testGroup`\r\n\t- current-offset：当前消费组的已消费偏移量\r\n\t- log-end-offset：主题对应分区消息的结束偏移量(HW)\r\n\t- lag：当前消费组未消费的消息数\r\n---\r\n## Topic\r\n\r\n- 同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件\r\n\t- ![Topic](static/Kafka-基础-2.png)\r\n\t- Partition是一个有序的message序列，这些message按顺序添加到一个叫做commit log的文件中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message\r\n\t- 每个partition，都对应一个commit log文件。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的\r\n\t- kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响\r\n\t- 每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的。在kafka中，消费offset由consumer自己来维护；一般情况下我们按照顺序逐条消费commit log中的消息，当然可以通过指定offset来重复消费某些消息，或者跳过某些消息\r\n\t- 这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset\r\n- 对Topic下数据进行分区存储\r\n\t- commit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据\r\n\t- 提高并行度\r\n---\r\n## Kafka集群\r\n\r\n- kafka集群：一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量，只需要多启动几个broker实例即可\r\n\t- kafka将很多集群关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便\r\n- 集群消费\r\n\t- log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka集群支持配置一个partition备份的数量\r\n\t- 针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用\r\n\t- leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)。如果这个leader失效了，其中的一个follower将会自动的变成新的leader\r\n- Producers：生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round­-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多\r\n- Consumers：consumer group\r\n\t- queue 模式：consumer 位于同一个 consumer group 下\r\n\t- publish-subscribe 模式：consumer 有自己唯一的 consumer group\r\n\t- ![consumer group](static/Kafka-基础-3.png)\r\n- 消费顺序：一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序\r\n\t- Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性\r\n\t- 如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础",
      "lvl1": "核心组件",
      "lvl2": "配置文件",
      "lvl3": "基础命令",
      "lvl4": "Topic",
      "lvl5": "Kafka集群",
      "lvl6": "Java客户端",
      "lvl7": "SpringBoot支持"
    },
    "frontmatter": {
      "title": "1.基础",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 4
  },
  {
    "title": "1.基础",
    "path": "/docs/architect/kafka/Kafka-1.jichu.html",
    "url": "/docs/architect/kafka/Kafka-1.jichu.html",
    "content": "消费很少用\r\n\t- consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息\r\n---\r\n## Java客户端\r\n\r\n- 绑定Kafka服务器\r\n```java\r\nProperties props = new Properties();\r\nprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094\");\r\n// 生产者\r\nProducer<String, String> producer = new KafkaProducer<String, String>(props);\r\n// 消费者\r\nKafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);\r\n```\r\n- 生产者配置\r\n```java\r\n/* \r\n * 发出消息持久化机制参数\r\n * acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息\r\n * acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入，就可以继续发送下一条消息\r\n *          如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失\r\n * acks=‐1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志\r\n *                这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置\r\n */\r\nprops.put(ProducerConfig.ACKS_CONFIG, \"1\");\r\n// 发送失败重试次数，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，需要接收者做好消息接收的幂等性处理\r\nprops.put(ProducerConfig.RETRIES_CONFIG, 3);\r\n// 重试间隔设置，默认重试间隔100ms\r\nprops.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);\r\n// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB\r\nprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);\r\n// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去\r\nprops.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);\r\n/* \r\n * batch最大的延迟发送时间\r\n * 默认值是0：意思就是消息必须立即被发送，但这样会影响性能\r\n * 一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去\r\n * 如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长\r\n * \r\n *  消息 -> 本地缓冲区（32M）-> batch（16k）-> 发送（10ms batch不满也发送）\r\n */\r\nprops.put(ProducerConfig.LINGER_MS_CONFIG, 10);\r\n// 把发送的key和value从字符串序列化为字节数组\r\nprops.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\r\nprops.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\r\n```\r\n- 生产者发送消息：指定分区；不指定分区；同步；异步\r\n```java\r\n// 指定发送分区\r\nvar producerRecord = new ProducerRecord<String, String>(TOPIC_NAME, 0, key_json, value_json);\r\n// 未指定发送分区，具体发送的分区计算公式：hash(key) % partitionNum\r\nvar producerRecord = new ProducerRecord<String, String>(TOPIC_NAME, key_json, value_json);\r\n// 等待消息发送成功的同步阻塞方法\r\nRecordMetadata metadata = producer.send(producerRecord).get();\r\n// 异步回调方式发送消息\r\nproducer.send(producerRecord, new Callback() {\r\n\tpublic void onCompletion(RecordMetadata metadata, Exception exception) {\r\n\t\t// 处理异常\r\n\t}\r\n});\r\n// 关闭\r\nproducer.close();\r\n```\r\n- 消费配置\r\n```java\r\n// 消费分组名\r\nprops.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);\r\n// 是否自动提交offset，默认就是true\r\nprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\r\n// 自动提交offset的间隔时间\r\nprops.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\r\n/* \r\n * 当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费\r\n * latest(默认) ：只消费自己启动之后发送到主题的消息\r\n * earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于 consumer.seekToBeginning(每次都从头开始消费)\r\n */\r\nprops.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\r\n// consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，这个时间可以稍微短一点\r\nprops.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);\r\n// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒\r\nprops.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);\r\n// 一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点\r\nprops.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);\r\n// 如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费\r\nprops.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);\r\n// 把发送的key和value从字符串序列化为字节数组\r\nprops.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\nprops.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\n```\r\n- 消费者接收消息（topic）：指定分区；回溯（从头，指定offset）；拉取集合\r\n```java\r\n// 订阅Topic\r\nconsumer.subscribe(Arrays.asList(TOPIC_NAME));\r\n// 消费指定分区\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\n//",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础",
      "lvl1": "核心组件",
      "lvl2": "配置文件",
      "lvl3": "基础命令",
      "lvl4": "Topic",
      "lvl5": "Kafka集群",
      "lvl6": "Java客户端",
      "lvl7": "SpringBoot支持"
    },
    "frontmatter": {
      "title": "1.基础",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 4
  },
  {
    "title": "1.基础",
    "path": "/docs/architect/kafka/Kafka-1.jichu.html",
    "url": "/docs/architect/kafka/Kafka-1.jichu.html",
    "content": " 回溯消费（从头消费 - seekToBeginning）\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\nconsumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\n// 指定offset消费\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\nconsumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);\r\n// 从指定时间点开始消费 - 1小时前\r\nList<PartitionInfo> topicPartitions = consumer.partitionsFor(TOPIC_NAME);\r\nlong fetchDataTime = new Date().getTime() ‐ 1000 * 60 * 60;\r\nMap<TopicPartition, Long> map = new HashMap<>();\r\nfor (PartitionInfo par : topicPartitions) {\r\n\tmap.put(new TopicPartition(topicName, par.partition()), fetchDataTime);\r\n}\r\n// 遍历 value.offset(); 获取offset，然后指定offset消费\r\nMap<TopicPartition, OffsetAndTimestamp> parMap = consumer.offsetsForTimes(map);\r\n// 拉取消息集合\r\nConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\r\n```\r\n- 消费提交（offset）：同步；异步\r\n```java\r\n// 手动同步提交offset，当前线程会阻塞直到offset提交成功，一般使用同步提交，因为提交之后一般也没有什么逻辑代码了\r\nconsumer.commitSync();\r\n// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑\r\nconsumer.commitAsync(new OffsetCommitCallback() {\r\n\t@Override\r\n\tpublic void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception ex) {\r\n\t\t// 处理异常\r\n\t}\r\n});\r\n```\r\n---\r\n## SpringBoot支持\r\n\r\n- springboot配置application.yml\r\n```yml\r\nspring:\r\n\tkafka:\r\n\t\tbootstrap‐servers: 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094\r\n\t\tproducer:\r\n\t\t\tretries: 3\r\n\t\t\tbatch‐size: 16384\r\n\t\t\tbuffer‐memory: 33554432\r\n\t\t\tacks: 1\r\n\t\t\tkey‐serializer: org.apache.kafka.common.serialization.StringSerializer\r\n\t\t\tvalue‐serializer: org.apache.kafka.common.serialization.StringSerializer\r\n\t\tconsumer:\r\n\t\t\tgroup‐id: default‐group\r\n\t\t\tenable‐auto‐commit: false\r\n\t\t\tauto‐offset‐reset: earliest\r\n\t\t\tkey‐deserializer: xxx.StringDeserializer\r\n\t\t\tvalue‐deserializer: xxx.StringDeserializer\r\n\t\t\tlistener:\r\n\t\t\t\tack‐mode: manual_immediate\r\n```\r\n- ack‐mode\r\n\t- RECORD：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交\r\n\t- BATCH：当每一批poll()的数据被消费者监听器处理之后提交\r\n\t- TIME：当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交\r\n\t- COUNT：当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交\r\n\t- TIME | COUNT：有一个条件满足时提交\r\n\t- MANUAL：当每一批poll()的数据被消费者监听器处理之后, 手动调用Acknowledgment.acknowledge()后提交\r\n\t- MANUAL_IMMEDIATE：手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种（一次提交一条消息）\r\n- 生产者\r\n```java\r\n@Autowired\r\nprivate KafkaTemplate<String, String> kafkaTemplate;\r\nkafkaTemplate.send(TOPIC_NAME, 0, \"key\", \"this is a msg\");\r\n```\r\n- 消费者\r\n```java\r\n@KafkaListener(topics = \"my‐replicated‐topic\",groupId = \"zhugeGroup\")\r\npublic void listenZhugeGroup(ConsumerRecord<String, String> record, Acknowledgment ack) {\r\n\tString value = record.value();\r\n\tack.acknowledge();  //手动提交offset\r\n}\r\n\r\n// 配置多个消费组（再写一个消费组处理同一个topic）\r\n@KafkaListener(topics = \"my‐replicated‐topic\",groupId = \"tulingGroup\")\r\n\r\n// 配置多个topic，concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数\r\n@KafkaListener(groupId = \"testGroup\", topicPartitions = {\r\n\t@TopicPartition(topic = \"topic1\", partitions = {\"0\", \"1\"}),\r\n\t@TopicPartition(topic = \"topic2\", partitions = \"0\",\r\n\t\tpartitionOffsets = @PartitionOffset(partition = \"1\", initialOffset = \"100\"))\r\n},concurrency = \"6\")\r\n```\r\n---\r\n- Kafka事务\r\n```java\r\nProperties props = new Properties();\r\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\r\nprops.put(\"transactional.id\", \"my‐transactional‐id\");\r\nProducer<String, String> producer = new KafkaProducer<>(props, new StringSerializer(), new StringSerializer());\r\nproducer.initTransactions();      // 初始化事务\r\ntry {\r\n\tproducer.beginTransaction();  // 开启事务\r\n\tproducer.send(/*...*/);       // 发到不同的主题的不同分区\r\n\tproducer.commitTransaction(); // 提交事务\r\n} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {\r\n\tproducer.close();\r\n} catch (KafkaException e) {\r\n\tproducer.abortTransaction();  // 回滚事务\r\n}\r\nproducer.close();\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础",
      "lvl1": "核心组件",
      "lvl2": "配置文件",
      "lvl3": "基础命令",
      "lvl4": "Topic",
      "lvl5": "Kafka集群",
      "lvl6": "Java客户端",
      "lvl7": "SpringBoot支持"
    },
    "frontmatter": {
      "title": "1.基础",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 4,
    "contentParts": 4
  },
  {
    "title": "2.代码模板",
    "path": "/docs/architect/kafka/Kafka-2.daimamoban.html",
    "url": "/docs/architect/kafka/Kafka-2.daimamoban.html",
    "content": "---\r\ntitle: 2.代码模板\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 配置：`server.properties`\r\n- 绑定Kafka服务器\r\n- 生产者配置\r\n- 生产者发送消息\r\n- 消费配置\r\n- 消费者接收消息\r\n- 消费提交\r\n- springboot 集成\r\n    - ack‐mode\r\n    - 生产者 & 消费者\r\n- Kafka事务\r\n:::\r\n\r\n---\r\n\r\n## 配置：`server.properties`\r\n\r\n- 配置：`server.properties`\r\n```properties\r\n#broker.id属性在kafka集群中必须要是唯一\r\nbroker.id=0\r\n#kafka部署的机器ip和提供服务的端口号\r\nlisteners=PLAINTEXT://192.168.65.60:9092\r\n#kafka的消息存储文件\r\nlog.dir=/usr/local/data/kafka‐logs\r\n#kafka连接zookeeper的地址\r\nzookeeper.connect=192.168.65.60:2181\r\n```\r\n\r\n## 绑定Kafka服务器\r\n\r\n- 绑定Kafka服务器\r\n```java\r\nProperties props = new Properties();\r\nprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094\");\r\n// 生产者\r\nProducer<String, String> producer = new KafkaProducer<String, String>(props);\r\n// 消费者\r\nKafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);\r\n```\r\n\r\n## 生产者配置\r\n\r\n- 生产者配置\r\n```java\r\n/* \r\n * 发出消息持久化机制参数\r\n * acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息\r\n * acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入，就可以继续发送下一条消息\r\n *          如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失\r\n * acks=‐1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志\r\n *                这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置\r\n */\r\nprops.put(ProducerConfig.ACKS_CONFIG, \"1\");\r\n// 发送失败重试次数，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，需要接收者做好消息接收的幂等性处理\r\nprops.put(ProducerConfig.RETRIES_CONFIG, 3);\r\n// 重试间隔设置，默认重试间隔100ms\r\nprops.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);\r\n// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB\r\nprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);\r\n// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去\r\nprops.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);\r\n/* \r\n * batch最大的延迟发送时间\r\n * 默认值是0：意思就是消息必须立即被发送，但这样会影响性能\r\n * 一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去\r\n * 如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长\r\n * \r\n *  消息 -> 本地缓冲区（32M）-> batch（16k）-> 发送（10ms batch不满也发送）\r\n */\r\nprops.put(ProducerConfig.LINGER_MS_CONFIG, 10);\r\n// 把发送的key和value从字符串序列化为字节数组\r\nprops.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\r\nprops.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\r\n```\r\n\r\n## 生产者发送消息\r\n\r\n- 生产者发送消息：指定分区；不指定分区；同步；异步\r\n```java\r\n// 指定发送分区\r\nvar producerRecord = new ProducerRecord<String, String>(TOPIC_NAME, 0, key_json, value_json);\r\n// 未指定发送分区，具体发送的分区计算公式：hash(key) % partitionNum\r\nvar producerRecord = new ProducerRecord<String, String>(TOPIC_NAME, key_json, value_json);\r\n// 等待消息发送成功的同步阻塞方法\r\nRecordMetadata metadata = producer.send(producerRecord).get();\r\n// 异步回调方式发送消息\r\nproducer.send(producerRecord, new Callback() {\r\n\tpublic void onCompletion(RecordMetadata metadata, Exception exception) {\r\n\t\t// 处理异常\r\n\t}\r\n});\r\n// 关闭\r\nproducer.close();\r\n```\r\n\r\n## 消费配置\r\n\r\n- 消费配置\r\n```java\r\n// 消费分组名\r\nprops.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);\r\n// 是否自动提交offset，默认就是true\r\nprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\r\n// 自动提交offset的间隔时间\r\nprops.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\r\n/* \r\n * 当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费\r\n * latest(默认) ：只消费自己启动之后发送到主题的消息\r\n * earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于 consumer.seekToBeginning(每次都从头开始消费)\r\n */\r\nprops.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\r\n// consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，这个时间可以稍微短一点\r\nprops.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);\r\n// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒\r\nprops.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);\r\n// 一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点\r\nprops.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);\r\n// 如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consume",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.代码模板",
      "lvl1": "配置：server.properties",
      "lvl2": "绑定Kafka服务器",
      "lvl3": "生产者配置",
      "lvl4": "生产者发送消息",
      "lvl5": "消费配置",
      "lvl6": "消费者接收消息",
      "lvl7": "消费提交",
      "lvl8": "springboot 集成",
      "lvl9": "Kafka事务"
    },
    "frontmatter": {
      "title": "2.代码模板",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "2.代码模板",
    "path": "/docs/architect/kafka/Kafka-2.daimamoban.html",
    "url": "/docs/architect/kafka/Kafka-2.daimamoban.html",
    "content": "r消费\r\nprops.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);\r\n// 把发送的key和value从字符串序列化为字节数组\r\nprops.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\nprops.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\n```\r\n\r\n## 消费者接收消息\r\n\r\n- 消费者接收消息（topic）：指定分区；回溯（从头，指定offset）；拉取集合\r\n```java\r\n// 订阅Topic\r\nconsumer.subscribe(Arrays.asList(TOPIC_NAME));\r\n// 消费指定分区\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\n// 回溯消费（从头消费 - seekToBeginning）\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\nconsumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\n// 指定offset消费\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\nconsumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);\r\n// 从指定时间点开始消费 - 1小时前\r\nList<PartitionInfo> topicPartitions = consumer.partitionsFor(TOPIC_NAME);\r\nlong fetchDataTime = new Date().getTime() ‐ 1000 * 60 * 60;\r\nMap<TopicPartition, Long> map = new HashMap<>();\r\nfor (PartitionInfo par : topicPartitions) {\r\n\tmap.put(new TopicPartition(topicName, par.partition()), fetchDataTime);\r\n}\r\n// 遍历 value.offset(); 获取offset，然后指定offset消费\r\nMap<TopicPartition, OffsetAndTimestamp> parMap = consumer.offsetsForTimes(map);\r\n// 拉取消息集合\r\nConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\r\n```\r\n\r\n## 消费提交\r\n\r\n- 消费提交（offset）：同步；异步\r\n```java\r\n// 手动同步提交offset，当前线程会阻塞直到offset提交成功，一般使用同步提交，因为提交之后一般也没有什么逻辑代码了\r\nconsumer.commitSync();\r\n// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑\r\nconsumer.commitAsync(new OffsetCommitCallback() {\r\n\t@Override\r\n\tpublic void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception ex) {\r\n\t\t// 处理异常\r\n\t}\r\n});\r\n```\r\n---\r\n\r\n## springboot 集成\r\n\r\n- springboot配置application.yml\r\n```yml\r\nspring:\r\n\tkafka:\r\n\t\tbootstrap‐servers: 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094\r\n\t\tproducer:\r\n\t\t\tretries: 3\r\n\t\t\tbatch‐size: 16384\r\n\t\t\tbuffer‐memory: 33554432\r\n\t\t\tacks: 1\r\n\t\t\tkey‐serializer: org.apache.kafka.common.serialization.StringSerializer\r\n\t\t\tvalue‐serializer: org.apache.kafka.common.serialization.StringSerializer\r\n\t\tconsumer:\r\n\t\t\tgroup‐id: default‐group\r\n\t\t\tenable‐auto‐commit: false\r\n\t\t\tauto‐offset‐reset: earliest\r\n\t\t\tkey‐deserializer: xxx.StringDeserializer\r\n\t\t\tvalue‐deserializer: xxx.StringDeserializer\r\n\t\t\tlistener:\r\n\t\t\t\tack‐mode: manual_immediate\r\n```\r\n\r\n### ack‐mode\r\n\r\n- ack‐mode\r\n\t- RECORD：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交\r\n\t- BATCH：当每一批poll()的数据被消费者监听器处理之后提交\r\n\t- TIME：当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交\r\n\t- COUNT：当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交\r\n\t- TIME | COUNT：有一个条件满足时提交\r\n\t- MANUAL：当每一批poll()的数据被消费者监听器处理之后, 手动调用Acknowledgment.acknowledge()后提交\r\n\t- MANUAL_IMMEDIATE：手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种（一次提交一条消息）\r\n\r\n### 生产者 & 消费者\r\n\r\n- 生产者\r\n```java\r\n@Autowired\r\nprivate KafkaTemplate<String, String> kafkaTemplate;\r\nkafkaTemplate.send(TOPIC_NAME, 0, \"key\", \"this is a msg\");\r\n```\r\n- 消费者\r\n```java\r\n@KafkaListener(topics = \"my‐replicated‐topic\",groupId = \"zhugeGroup\")\r\npublic void listenZhugeGroup(ConsumerRecord<String, String> record, Acknowledgment ack) {\r\n\tString value = record.value();\r\n\tack.acknowledge();  //手动提交offset\r\n}\r\n\r\n// 配置多个消费组（再写一个消费组处理同一个topic）\r\n@KafkaListener(topics = \"my‐replicated‐topic\",groupId = \"tulingGroup\")\r\n\r\n// 配置多个topic，concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数\r\n@KafkaListener(groupId = \"testGroup\", topicPartitions = {\r\n\t@TopicPartition(topic = \"topic1\", partitions = {\"0\", \"1\"}),\r\n\t@TopicPartition(topic = \"topic2\", partitions = \"0\",\r\n\t\tpartitionOffsets = @PartitionOffset(partition = \"1\", initialOffset = \"100\"))\r\n},concurrency = \"6\")\r\n```\r\n---\r\n\r\n## Kafka事务\r\n\r\n- Kafka事务\r\n```java\r\nProperties props = new Properties();\r\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\r\nprops.put(\"transactional.id\", \"my‐transactional‐id\");\r\nProducer<String, String> producer = new KafkaProducer<>(props, new StringSerializer(), new StringSerializer());\r\n\r\n// 初始化事务\r\nproducer.initTransactions();\r\ntry {\r\n\t// 开启事务\r\n\tproducer.beginTransaction();\r\n\t// 发到不同的主题的不同分区\r\n\tproducer.send(/*...*/);\r\n\r\n\t// 提交事务\r\n\tproducer.commitTransaction();\r\n} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {\r\n\tproducer.close();\r\n} catch (KafkaException e) {\r\n\t// 回滚事务\r\n\tproducer.abortTransaction();\r\n}\r\n// 关闭\r\nproducer.close();\r\n```\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.代码模板",
      "lvl1": "配置：server.properties",
      "lvl2": "绑定Kafka服务器",
      "lvl3": "生产者配置",
      "lvl4": "生产者发送消息",
      "lvl5": "消费配置",
      "lvl6": "消费者接收消息",
      "lvl7": "消费提交",
      "lvl8": "springboot 集成",
      "lvl9": "Kafka事务"
    },
    "frontmatter": {
      "title": "2.代码模板",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "3.设计原理",
    "path": "/docs/architect/kafka/Kafka-3.shejiyuanli.html",
    "url": "/docs/architect/kafka/Kafka-3.shejiyuanli.html",
    "content": "---\r\ntitle: 3.设计原理\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- Controller\r\n- Leader - Partition\r\n- Rebalance\r\n- 消息发布机制\r\n- HW与LEO\r\n- 日志分段\r\n- zookeeper\r\n:::\r\n\r\n---\r\n## Controller\r\n\r\n- Kafka核心总控制器Controller：在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态\r\n\t- 当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本\r\n\t- 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息\r\n\t- 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到\r\n- Controller选举机制\r\n\t- zookeeper临时节点的创建来选举controller：在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller\r\n\t- controller重新选举：当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker成为新的controller\r\n- 具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下\r\n\t- 监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker增减的变化\r\n\t- 监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作\r\n\t- 从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic所对应的Zookeeper中的/brokers/topics/\\[topic\\]节点添加PartitionModificationsListener，用来监听topic中的分区分配变化\r\n\t- 更新集群的元数据信息，同步到其他普通的broker节点中\r\n---\r\n## Leader - Partition\r\n\r\n- Partition副本选举Leader机制\r\n\t- controller感知到分区leader所在的broker挂了（controller监听了很多zk节点可以感知到broker存活）\r\n\t- controller会从ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR列表，可能是同步数据最多的副本)\r\n\t- 如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多\r\n- 副本进入ISR列表有两个条件\r\n\t- 必须能与zookeeper保持会话以及跟leader副本网络连通\r\n\t- 副本能复制leader上的所有写操作，并且不能落后太多\r\n\t\t- 与leader副本同步滞后的副本，是由 replica.lag.time.max.ms 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表\r\n- 消费者消费消息的offset记录机制\r\n\t- 每个consumer会定期将自己消费分区的offset提交给kafka内部topic：\\_\\_consumer_offsets\r\n\t\t- 提交过去的时候，key是consumerGroupId+topic+分区号，value就是当前offset的值\r\n\t\t- kafka会定期清理topic里的消息，最后就保留最新的那条数据\r\n\t- 因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发\r\n---\r\n## Rebalance\r\n\r\n- Rebalance分区分配策略（partition.assignment.strategy）：range（默认）、round-robin、sticky\r\n\t- range：按照分区序号排序，比如分区0~3给一个consumer，分区4~6给一个consumer，分区7~9给一个consumer\r\n\t- round-robin：轮询分配，比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer\r\n\t- sticky：与round-robin类似，但是在rebalance的时候，需要保证如下两个原则（当两者发生冲突时，第一个目标优先于第二个目标）\r\n\t\t- 分区的分配要尽可能均匀\r\n\t\t- 分区的分配尽可能与上次分配的保持相同\r\n- Rebalance机制：如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。比如consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他\r\n\t- rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进行rebanlance\r\n\t- rebalance过程中，消费者无法从kafka消费消息，这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生\r\n- 触发消费者rebalance\r\n\t- 消费组里的consumer增加或减少了\r\n\t- 动态给topic增加了分区\r\n\t- 消费组订阅了更多的topic\r\n- Rebalance过程：当有消费者加入消费组时，消费者、消费组及组协调器之间会经历以下几个阶段\r\n\t1. 选择组协调器（GroupCoordinator）：每个consumer group都会选择一个broker作为自己的组协调器coordinator，负责监控这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance\r\n\t\t- consumer group中的每个consumer启动时会向kafka集群中的某个节点发送FindCoordinatorRequest请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接\r\n\t\t- 组协调器选择方式：通过如下公式可以选出consumer消费的offset要提交到__consumer_offsets的哪个分区，这个分区le",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.设计原理",
      "lvl1": "Controller",
      "lvl2": "Leader - Partition",
      "lvl3": "Rebalance",
      "lvl4": "消息发布机制",
      "lvl5": "HW与LEO",
      "lvl6": "日志分段"
    },
    "frontmatter": {
      "title": "3.设计原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "3.设计原理",
    "path": "/docs/architect/kafka/Kafka-3.shejiyuanli.html",
    "url": "/docs/architect/kafka/Kafka-3.shejiyuanli.html",
    "content": "ader对应的broker就是这个consumer group的coordinator。说白了，leader分区所在的节点就是GroupCoordinator\r\n\t1. 加入消费组（JOIN GROUP），选择消费组协调器\r\n\t\t1. 在成功找到消费组所对应的 GroupCoordinator 之后就进入加入消费组的阶段，在此阶段的消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求，并处理响应。\r\n\t\t2. 然后GroupCoordinator 从一个consumer group中选择第一个加入group（第一个与GroupCoordinator连接的consumer）的consumer作为leader(消费组协调器)\r\n\t\t3. 把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案\r\n\t2. SYNC GROUP\r\n\t\t1. consumer leader通过给GroupCoordinator发送SyncGroupRequest\r\n\t\t2. 接着GroupCoordinator就把分区方案下发给各个consumer，他们会根据指定分区的leader broker进行网络连接以及消息消费\r\n\r\n![Rebalance](static/Kafka-设计原理-1.png)\r\n\r\n---\r\n## 消息发布机制\r\n\r\n- producer发布消息机制\r\n\t- 写入方式：producer 采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）\r\n\t- 消息路由：producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition\r\n\t\t1. 指定了 patition，则直接使用\r\n\t\t2. 指定 patition 但指定 key，通过对 key 的 value 进行 hash 选出一个 patition \r\n\t\t3. patition 和 key 都未指定，使用轮询选出一个 patition\r\n\t- 写入流程\r\n\t\t1. producer 先从 zookeeper 的 \"/brokers/.../state\" 节点找到该 partition 的 leader \r\n\t\t2. producer 将消息发送给该 leader \r\n\t\t3. leader 将消息写入本地 log \r\n\t\t4. followers 从 leader pull 消息，写入本地 log 后向leader 发送 ACK\r\n\t\t5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK\r\n\r\n![消息发布机制](static/Kafka-设计原理-2.png)\r\n\r\n---\r\n## HW与LEO\r\n\r\n- HW：HW俗称高水位，HighWatermark的缩写，取一个partition对应的ISR中最小的LEO(log-end-offset)作为HW，consumer最多只能消费到HW所在的位置。\r\n\t- 每个replica都有HW，leader和follower各自负责更新自己的HW的状态。\r\n\t- 对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，消息才能被consumer消费。\r\n\t- 这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。\r\n\t- 对于来自内部broker的读取请求，没有HW的限制\r\n- 当producer生产消息至broker后，ISR以及HW和LEO的流转过程\r\n\t- ![HW](static/Kafka-设计原理-3.png)\r\n- Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制，很好的均衡了确保数据不丢失以及吞吐率\r\n- 当 acks=1\r\n\t- ![acks=1](static/Kafka-设计原理-4.png)\r\n\r\n---\r\n## 日志分段\r\n\r\n- 日志分段存储：Kafka 一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，消息在分区内是分段(segment)存储，每个段的消息都存储在不一样的log文件里，这种特性方便old segment file快速被删除，kafka规定了一个段位的 log 文件最大为 1G，做这个限制目的是为了方便把 log 文件加载到内存去操作\r\n\t- 00000000000000000000.index：部分消息的offset索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件\r\n\t\t- 如果要定位消息的offset会先在这个文件里快速定位，再去log文件里找具体消息\r\n\t- 00000000000000000000.log：消息存储文件，主要存offset和消息体\r\n\t- 00000000000000000000.timeindex：息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件\r\n\t\t- 如果需要按照时间来定位消息的offset，会先在这个文件里查找\r\n\t- 文件名00000000000000000000就是表了这个日志段文件里包含的起始 Offset\r\n- log.segment.bytes：限定了每个日志段文件的大小，最大就是 1GB\r\n\t- 一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做log rolling，正在被写入的那个日志段文件，叫做 active log segment。\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.设计原理",
      "lvl1": "Controller",
      "lvl2": "Leader - Partition",
      "lvl3": "Rebalance",
      "lvl4": "消息发布机制",
      "lvl5": "HW与LEO",
      "lvl6": "日志分段"
    },
    "frontmatter": {
      "title": "3.设计原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "4.优化",
    "path": "/docs/architect/kafka/Kafka-4.youhua.html",
    "url": "/docs/architect/kafka/Kafka-4.youhua.html",
    "content": "---\r\ntitle: 4.优化\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 环境规划\r\n- 线上问题\r\n- Kafka事务\r\n- Kafka高性能原因\r\n:::\r\n\r\n---\r\n## 环境规划\r\n\r\n- Kafka可视化管理工具：kafka-manager\r\n- 线上环境规划\r\n\t- ![环境规划](static/Kafka-优化-1.png)\r\n- JVM参数设置：bin/kafka-start-server.sh 中的jvm设置\r\n\t- `export KAFKA_HEAP_OPTS=\"‐Xmx16G ‐Xms16G ‐Xmn10G ‐XX:MetaspaceSize=256M ‐XX:+UseG1GC ‐XX:MaxGCPauseMillis=50 ‐XX:G1HeapRegionSize=16M\"`\r\n\t- 这种大内存的情况一般都要用G1垃圾收集器，因为年轻代内存比较大，用G1可以设置GC最大停顿时间，不至于一次minor gc就花费太长时间，当然，因为像kafka，rocketmq，es这些中间件，写数据到磁盘会用到操作系统的page cache，所以JVM内存不宜分配过大，需要给操作系统的缓存留出几个G\r\n---\r\n## 线上问题\r\n\r\n- 消息丢失\r\n\t- 发送端：acks 设置\r\n\t- 消费端：如果消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但是此时你consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了\r\n- 重复消费：一般消费端都是要做消费幂等处理的\r\n\t- 发送端：发送消息如果配置了重试机制，比如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息\r\n\t- 消费端：如果消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理\r\n- 消息乱序\r\n\t- 如果发送端配置了重试机制，kafka不会等之前那条消息完全发送成功才去发送下一条消息，这样可能会出现，发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了\r\n\t\t- 是否一定要配置重试要根据业务情况而定。也可以用同步发送的模式去发消息，当然acks不能设置为0\r\n\t- kafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但是这种性能比较低\r\n\t\t- 可以在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列(可以搞多个)，一个内存队列开启一个线程顺序处理消息\r\n- 消息积压\r\n\t- 线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致broker积压大量未消费消息\r\n\t\t- 如果积压了上百万未消费消息需要紧急处理，可以修改消费端程序，让其将收到的消息快速转发到其他topic(可以设置很多分区)，然后再启动多个消费者同时消费新主题的不同分区\r\n\t- 由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息\r\n\t\t- 可以将这些消费不成功的消息转发到其它队列里去(类似死信队列)，后面再慢慢分析死信队列里的消息处理问题\r\n- 延时队列：消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费\r\n\t- 发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中（topic_1s，topic_5s，topic_10s，...topic_2h，这个一般不能支持任意时间段的延时）\r\n\t- 通过定时器进行轮训消费这些topic，查看消息是否到期，如果到期就把这个消息发送到具体业务处理的topic中\r\n\t- 队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，如果到了就转发，如果还没到这一次定时任务就可以提前结束了\r\n- 消息回溯：对之前已消费的消息重新消费\r\n\t- 如果某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费\r\n\t- 可以指定从多久之前的消息回溯消费，这种可以用consumer的offsetsForTimes、seek等方法指定从某个offset偏移的消息开始消费\r\n- 分区数与吞吐量：一般情况分区数跟集群机器数量相当就差不多了\r\n\t- `kafka‐producer‐perf‐test.sh ‐‐topic test ‐‐num‐records 1000000 ‐‐record‐size 1024 ‐‐throughput ‐1 ‐‐producer‐props bootstrap.servers=192.168.65.60:9092 acks=1`\r\n\t- 往test里发送一百万消息，每条设置1KB，throughput 用来进行限流控制，当设定的值小于 0 时不限流，当设定的值大于 0 时，当发送的吞吐量大于该值时就会被阻塞一段时间\r\n\t- 如果分区数设置过大，比如设置10000，可能会设置不成功，后台会报错\"java.io.IOException : Too many open files\"\r\n\t\t- `ulimit -n 65535` 调大文件描述符\r\n- 消息传递保障\r\n\t- at most once（消费者最多收到一次消息，0-1次）：acks = 0 可以实现\r\n\t- at least once（消费者至少收到一次消息，1-多次）：ack = all 可以实现\r\n\t- exactly once（消费者刚好收到一次消息）：at least once 加上消费者幂等性可以实现，还可以用kafka生产者的幂等性来实现\r\n\t\t- kafka生产者的幂等性：因为发送端重试导致的消息重复发送问题，kafka的幂等性可以保证重复发送的消息只接收一次\r\n\t\t\t- 只需在生产者加上参数 `props.put(\"enable.idempotence\", true)` 即可，默认是 false 不开启\r\n\t\t\t- 具体实现原理是，kafka每次发送消息会生成PID和Sequence Number，并将这两个属性一起发送给broker，broker会将PID和Sequence Number跟消息绑定一起存起来，下次如果生产者重发相同消息，broker会检查PID和Sequence Number，如果相同不会再接收\r\n\t\t\t\t- PID：每个新的 Producer 在初始化的时候会被分配一个唯一的 PID，这个PID 对用户完全是透明的。生产者如果重启则会生成新的PID\r\n\t\t\t\t- Sequence Number：对于每个 PID，该 Producer 发送到每个 Partition 的数据都有对应的序列号，这些序列号是从0开始单调递增的\r\n\t\t\t- 但是它只保证了生产者的幂等性，没保证消费者的幂等性，所以保险起见还是要再消费端考虑幂等性的问题\r\n---\r\n## Kafka事务\r\n\r\n- kafka的事务：保障一次发送多条消息的事务一致性（流式计算场景）\r\n\t- Kafka的事务不同于Rocketmq，Rocketmq是保障本地事务(比如数据库)与mq消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性(要么同时成功要么同时失败)\r\n\t- 一般在kafka的流式计算场景用得多一点，比如，kafka需要对一个topic里的消息做不同的流式计算处理，处理完分别发到不同的topic里，这些topic分别被不同的下游系统消费(比如hbase，redis，es等)，这种我们肯定希望系统发送到多个topic的数据保持事务一致性。Kafka要实现类似Rocketmq的分布式事务需要额外开发功能\r\n```java\r\nProperties props = new Properties();\r\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\r\nprops.put(\"transactional.id\", \"my‐transactional‐id\");\r\nProducer<String, String> producer = new KafkaProducer<>(props, new StringSerializer(), new StringSerializer());\r\n\r\n// 初始化事务\r\nproducer.initTransactions();\r\ntry {\r\n\t// 开启事务\r\n\tproducer.beginTransaction();\r\n\t// 发到不同的主题的不同分区\r\n\tproducer.send(/*...*/);\r\n\r\n\t// 提交事务\r\n\tproducer.commitTransaction();\r\n} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {\r\n\tproducer.close();\r\n} catch (KafkaException e) {\r\n\t// 回滚事务\r\n\tproducer.abortTransaction();\r\n}\r\n// 关闭\r\nproducer.close();\r\n```\r\n---\r\n## Kafka高性能原因\r\n\r\n- kafka高性能的原因\r\n\t- 磁盘顺序读写：kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾，不会写入文件中的某个位置(随机写)保证了磁盘顺序写\r\n\t- 读写数据的批量batch处理以及压缩传输\r\n\t- 数据传输的零拷贝\r\n\t\t- ![零拷贝](static/Kafka-优化-2.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.优化",
      "lvl1": "环境规划",
      "lvl2": "线上问题",
      "lvl3": "Kafka事务",
      "lvl4": "Kafka高性能原因"
    },
    "frontmatter": {
      "title": "4.优化",
      "date": "2025/07/03"
    },
    "type": "content"
  },
  {
    "title": "1.生态",
    "path": "/docs/architect/hadoop/Hadoop-1.shengtai.html",
    "url": "/docs/architect/hadoop/Hadoop-1.shengtai.html",
    "content": "---\r\ntitle: 1.生态\r\ndate: 2025/07/01\r\n---\r\n\r\n## Hadoop 背景\r\n\r\n其实最先被这些问题困惑的并不是电商，而是 google，他需面对的挑战一点也不会比电商小\r\n* 大量的网页怎么存储\r\n* 面对的数据和计算难题\r\n\r\n2003，2004 年 Google\r\n* GFS\r\n* MapReduce\r\n\r\n为了解决上面的两大难题，google 提出了自己的简介方案，当然这解决方案是闭源的，另外\r\n还提出了两篇论文，为大量数据的存储与计算问题提供了思路。\r\n\r\n---\r\n\r\n## Hadoop 生态\r\n[Hadoop 是 apache 下面的一套开源软件平台](http://hadoop.apache.org/)\r\n\r\nHadoop 的功能：利用服务器的集群，根据用户的业务逻辑对海里信息进行处理（存储与计算）\r\nHadoop 的核心组件:\r\n* HDFS(分布式文件系统)\r\n* MAPREDUCE(分布式运行系统)\r\n* YARN(运算资源调度系统)\r\n以上就是 hadoop 最核心的部分，可是随着时间的推移，hadoop 已经不只是这些技术了，它慢慢进化成了一个生态圈\r\n\r\n![Hadoop 生态](static/生态.png)\r\n\r\n---\r\n\r\n## Hadoop 起源\r\n* Hadoop 最初是由 Apache Lucene 项目的创始人 Doug Cutting 开发的文本搜索库。Hadoop 源自始于 2002 年的 Apache Nutch 项目——一个开源的网络搜索引擎并且也是 Lucene 项目的一部分\r\n* 2004 年 Nutch 项目也模仿 GFS 开发了自己的分布式文件系统 NDFS（Nutch Distributed File System），也就是 HDFS 的前身\r\n* 2005 年，Nutch 开源实现了谷歌的 MapReduce\r\n* 2006 年 2 月，Nutch 中的 NDFS 和 MapReduce 开始独立出来，成为 Lucene 项目的一个子项目，称为 Hadoop，同时，Doug Cutting 加盟雅虎\r\n* 2008 年 1 月，HADOOP 成为 Apache 顶级项目，迎来了它的快速发展期。\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.生态",
      "lvl1": "Hadoop 背景",
      "lvl2": "Hadoop 生态",
      "lvl3": "Hadoop 起源"
    },
    "frontmatter": {
      "title": "1.生态",
      "date": "2025/07/01"
    },
    "type": "content"
  },
  {
    "title": "10. YARN 资源调度器",
    "path": "/docs/architect/hadoop/Hadoop-10-YARNziyuandiaoduqi.html",
    "url": "/docs/architect/hadoop/Hadoop-10-YARNziyuandiaoduqi.html",
    "content": "---\r\ntitle: 10. YARN 资源调度器\r\ndate: 2025/07/02\r\n---\r\n\r\n配置 ([官方文档](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml)):\r\n`yarn.resourcemanager.scheduler.class` 默认: `org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler`\r\n\r\n---\r\n\r\n![YARN 资源调度器](static/YARN-QUEUE.png)\r\n\r\n1. FIFO 队列缺点: 大任务会耗时太长会导致小任务得不到及时的执行\r\n2. 分为大小任务两个队列，小任务在大任务执行时也能得到及时执行\r\n    * 缺点：如果只有大任务或只有小任务，会浪费掉一部分内存资源维护另一个用不到的队列\r\n    * Apache Hadoop 原生默认的队列类型\r\n3. 公平队列：在大任务执行过程中，如果加入了小任务，那么大任务会让出部分资源给小任务执行\r\n    * 缺点：小任务需要等待大任务让出资源，得不到及时执行\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "10. YARN 资源调度器"
    },
    "frontmatter": {
      "title": "10. YARN 资源调度器",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "11.优化",
    "path": "/docs/architect/hadoop/Hadoop-11-youhua.html",
    "url": "/docs/architect/hadoop/Hadoop-11-youhua.html",
    "content": "---\r\ntitle: 11.优化\r\ndate: 2025/07/02\r\n---\r\n\r\n## 参数调优\r\n**以下参数是在用户自己的 mr 应用程序中配置就可以生效**\r\n1. `mapreduce.map.memory.mb`: 一个 Map Task 可使用的资源上限（单位:MB），默认为 1024。如果 Map Task 实际使用的资源量超过该值，则会被强制杀死。\r\n2. `mapreduce.reduce.memory.mb`: 一个 Reduce Task 可使用的资源上限（单位:MB），默认为 1024。如果 Reduce Task 实际使用的资源量超过该值，则会被强制杀死。\r\n3. `mapreduce.map.cpu.vcores`: 每个 Map task 可使用的最多 cpu core 数目, 默认值: 1\r\n4. `mapreduce.reduce.cpu.vcores`: 每个 Reduce task 可使用的最多 cpu core 数目, 默认值: 1\r\n5. `mapreduce.map.java.opts`: Map Task 的 JVM 参数，你可以在此配置默认的 java heap size 等参数, e.g. \"-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc\" （@taskid@ 会被 Hadoop 框架自动换为相应的 taskid）, 默认值: \"\"\r\n6. `mapreduce.reduce.java.opts`: Reduce Task 的 JVM 参数，你可以在此配置默认的 java heap size 等参数, e.g. \"-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc\", 默认值: \"\"\r\n\r\n**应该在 yarn 启动之前就配置在服务器的配置文件中才能生效**\r\n1. `yarn.scheduler.minimum-allocation-mb`: 1024 给应用程序 container 分配的最小内存\r\n2. `yarn.scheduler.maximum-allocation-mb`: 8192 给应用程序 container 分配的最大内存\r\n3. `yarn.scheduler.minimum-allocation-vcores`: 1 最小核数\r\n4. `yarn.scheduler.maximum-allocation-vcores`: 32 最大核数\r\n5. `yarn.nodemanager.resource.memory-mb`: 8192 nodemanager resource 内存大小\r\n\r\n**shuffle 性能优化的关键参数，应在 yarn 启动之前就配置好**\r\n1. `mapreduce.task.io.sort.mb`: 100  shuffle 的环形缓冲区大小，默认 100m\r\n2. `mapreduce.map.sort.spill.percent`: 0.8  环形缓冲区溢出的阈值，默认 80%\r\n\r\n**可靠性相关**\r\n1. `mapreduce.map.speculative`: 是否为 Map Task 打开推测执行机制，默认为 false \r\n2. `mapreduce.reduce.speculative`: 是否为 Reduce Task 打开推测执行机制，默认为 false\r\n3. `mapreduce.job.user.classpath.first` & `mapreduce.task.classpath.user.precedence`：当同一个 class 同时出现在用户 jar 包和 hadoop jar 中时，优先使用哪个 jar 包中的 class，默认为 false，表示优先使用 hadoop jar 中的 class\r\n4. `mapreduce.input.fileinputformat.split.minsize`: FileInputFormat 做切片时的最小切片大小，\r\n5. `mapreduce.input.fileinputformat.split.maxsize`: FileInputFormat 做切片时的最大切片大小 (切片的默认大小就等于 blocksize，即 134217728)\r\n\r\n推测执行机制就是同时执行两台机器，选最先出结果的机器的结果，杀死另一台机器的任务，防止出现其中一台机器计算速度太慢的情况\r\n\r\n**压缩**\r\n* 如果是 IO 密集形任务，可以考虑开启压缩\r\n\r\n## 代码优化\r\n1. 输出的时候不要频繁创建对象\r\n```java\r\nfor(String word: words) {\r\n    context.write(new Text(word),new IntWritable(1));\r\n}\r\n// 改为\r\nText text = new Text(\"\");\r\nIntWritable count = new IntWritable(1);\r\nfor(String word: words) {\r\n    context.write(text.set(word), count);\r\n}\r\n```\r\n2. 尽量使用Combiner机制，减轻Reduce的压力: `job.setCombinerClass(XXReducer.class);`\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "11.优化",
      "lvl1": "参数调优",
      "lvl2": "代码优化"
    },
    "frontmatter": {
      "title": "11.优化",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "11.1. 数据压缩",
    "path": "/docs/architect/hadoop/Hadoop-11.1.shujuyasuo.html",
    "url": "/docs/architect/hadoop/Hadoop-11.1.shujuyasuo.html",
    "content": "---\r\ntitle: 11.1. 数据压缩\r\ndate: 2025/07/02\r\n---\r\n\r\n## 原则\r\nMapReduce 支持压缩，通过压缩算法对 mapper 或者 reducer 的最终数据结果进行压缩\r\n* 好处：减少了磁盘 io，提高了 MR 获取数据的速度，节省了磁盘空间\r\n* 坏处：压缩需要增加 cpu 的运算负担\r\n\r\n原则:\r\n* 运算密集的 job，少用压缩，尤其是中间数据\r\n* Io 密集的 job，可以用压缩，尤其是最终归档数据\r\n\r\n[官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Data_Compression)\r\n\r\n---\r\n\r\n## Mapper 输出压缩\r\n配置文档:\r\n* `mapreduce.map.output.compress=false`\r\n* `mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec`\r\n\r\n在代码中进行配置:\r\n```java\r\nconf.setBoolean(Job.MAP_OUTPUT_COMPRESS, true);\r\nconf.setClass(Job.MAP_OUTPUT_COMPRESS_CODEC, GzipCodec.class, CompressionCodec.class);\r\n```\r\n\r\n## Reduce 输出压缩\r\n配置文档:\r\n* `mapreduce.output.fileoutputformat.compress=false `\r\n* `mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec `\r\n* `mapreduce.output.fileoutputformat.compress.type=RECORD`\r\n\r\n在代码中进行配置:\r\n```java\r\nJob job = Job.getInstance(conf);\r\nFileOutputFormat.setCompressOutput(job, true);\r\nFileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);\r\n```\r\n\r\n---\r\n\r\n![支持的压缩类型](static/Compression.jpg)\r\n\r\n不建议使用配置文档的方式，不灵活，可以使用代码进行配置\r\n[配置文件官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "11.1. 数据压缩",
      "lvl1": "原则",
      "lvl2": "Mapper 输出压缩",
      "lvl3": "Reduce 输出压缩"
    },
    "frontmatter": {
      "title": "11.1. 数据压缩",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12. Hive 特点",
    "path": "/docs/architect/hadoop/Hadoop-12-Hive-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-12-Hive-tedian.html",
    "content": "---\r\ntitle: 12. Hive 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n\r\n## Hive 简介\r\nHive 是属于 Hadoop 的数据仓库工具，可以让使用者将结构化数据映射成一张张数据库的表，让用户能通过 SQL 来查询数据。用户出 SQL 命令给 hive，<font color=\"orange\">hive 把 SQL 语句转换成 MapReduce 查询分析存储在 hdfs 上的数据</font>。\r\n\r\n优点:\r\n* 直接使用 MapReuce 实现复杂查询比较复杂，而 Hive 提供 SQL 的语法，提高了开发的便捷程度\r\n* 直接使用 SQL 查询，减少了人员的学习成本，哪怕是数据库操作人员能很快上手\r\n* HIVE 提供很好的扩展性，方便用户增加功能\r\n\r\n## Hive 与传统数据库对比\r\n![Hive 与传统数据库对比](static/Hive-SQL-Compare.png)\r\n\r\n* **查询语言**: 由于 SQL 被广泛的应用在数据仓库中，因此，专门针对 Hive 的特性设计了类 SQL 的查询语言 HQL。熟悉 SQL 开发的开发者可以很方便的使用 Hive 进行开发。\r\n* **数据存储位置**: Hive 是建立在 Hadoop 之上的，所有 Hive 的数据都是存储在 HDFS 中的。而数据库则可以将数据保存在块设备或者本地文件系统中。\r\n* **数据格式**: Hive 中没有定义专门的数据格式，数据格式可以由用户指定，用户定义数据格式需要指定三个属性：**列分隔符**（通常为空格、”\\t”、”\\x001″）、**行分隔符**（”\\n”）以及**读取文件数据的方法**（Hive 中默认有三个文件格式 `TextFile`，`SequenceFile` 以及 `RCFile`）。由于在加载数据的过程中，不需要从用户数据格式到 Hive 定义的数据格式的转换，因此，**Hive 在加载的过程中不会对数据本身进行任何修改**，而只是将数据内容复制或者移动到相应的 HDFS 目录中。而在数据库中，不同的数据库有不同的存储引擎，定义了自己的数据格式。所有数据都会按照一定的组织存储，因此，数据库加载数据的过程会比较耗时。\r\n* **数据更新**: 由于 Hive 是针对数据仓库应用设计的，而数据仓库的内容是**读多写少**的。因此，**Hive 中不支持对数据的改写和添加**，所有的数据都是在加载的时候中确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO ... VALUES 添加数据，使用 UPDATE ... SET 修改数据。\r\n* **索引**: 之前已经说过，Hive 在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些 Key 建立索引。Hive 要访问数据中满足条件的特定值时，需要**暴力扫描整个数据**，因此访问延迟较高。由于 `MapReduce` 的引入， Hive 可以**并行访问数据**，因此即使没有索引，**对于大数据量的访问，Hive 仍然可以体现出优势**。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 **Hive 不适合在线数据查询**。\r\n* **执行**: Hive 中大多数查询的执行是通过 Hadoop 提供的 `MapReduce` 来实现的（类似 select * from tbl 的查询不需要 MapReduce）。而数据库通常有自己的执行引擎。\r\n* **执行延迟**: 之前提到，Hive 在查询数据的时候，**由于没有索引，需要扫描整个表，因此延迟较高**。另外一个导致 Hive 执行延迟高的因素是 MapReduce 框架。由于 **MapReduce 本身具有较高的延迟**，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，**当数据规模大到超过数据库的处理能力的时候，Hive 的并行计算显然能体现出优势**。\r\n* **可扩展性**: 由于 Hive 是建立在 Hadoop 之上的，因此 **Hive 的可扩展性是和 Hadoop 的可扩展性是一致的**。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle 在理论上的扩展能力也只有 100 台左右。\r\n* **数据规模**: 由于 Hive 建立在集群上并可以利用 MapReduce 进行并行计算，因此可以支持**很大规模的数据**；对应的，数据库可以支持的数据规模较小。\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12. Hive 特点",
      "lvl1": "Hive 简介",
      "lvl2": "Hive 与传统数据库对比"
    },
    "frontmatter": {
      "title": "12. Hive 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.1. Hive 窗口函数",
    "path": "/docs/architect/hadoop/Hadoop-12.1.Hivechuangkouhanshu.html",
    "url": "/docs/architect/hadoop/Hadoop-12.1.Hivechuangkouhanshu.html",
    "content": "---\r\ntitle: 12.1. Hive 窗口函数\r\ndate: 2025/07/02\r\n---\r\n\r\n```sql\r\nCREATE TABLE window_demo(cookieid STRING, createtime STRING, pv INT)\r\nROW FORMAT DELIMITED\r\nFIELDS TERMINATED BY ',';\r\n\r\nload data local inpath '/testdata/window' into table window_demo;\r\n```\r\n\r\n## SUM\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime) AS pv1, -- 默认为从起点到当前行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS pv2, --从起点到当前行，结果同 pv1\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS pv3, --当前行+往前 3 行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING) AS pv4, --当前行+往前 3 行+往后 1 行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS pv5 --当前行+往后所有行\r\nFROM test1;\r\n```\r\n\r\n* 如果不指定 `ROWS BETWEEN`, 默认统计窗口为从起点到当前行\r\n* 如果不指定 `ORDER BY`, 不仅分区内没有排序, 则将分组内所有值累加\r\n* `max()` 函数无论有没有 `order by` 都是计算整个分区的最大值\r\n\r\n关键是理解 `ROWS BETWEEN` 含义, 也叫做 window 子句：\r\n* `PRECEDING`：往前\r\n* `FOLLOWING`：往后\r\n* `CURRENT ROW`：当前行\r\n* `UNBOUNDED`：无边界\r\n* `UNBOUNDED PRECEDING`：表示从最前面的起点开始 \r\n* `UNBOUNDED FOLLOWING`：表示到最后面的终点\r\n\r\n## NTILE\r\n`NTILE(n)`，用于将分组数据按照顺序切分成 n 片，返回当前切片值，`NTILE` 不支持 `ROWS BETWEEN`\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nNTILE(2) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile1, --分组内将数据分成 2 片\r\nNTILE(3) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile2, --分组内将数据分成 3 片\r\nNTILE(4) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile3 --将所有数据分成 4 片\r\nFROM window_demo;\r\n```\r\n\r\n## ROW_NUMBER\r\n`ROW_NUMBER()` 从 1 开始，按照顺序，生成分组内记录的序列\r\n`ROW_NUMBER()` 的应用场景非常多，比如获取分组内排序第一的记录\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY pv desc) AS rn\r\nFROM window_demo;\r\n```\r\n\r\n## RANK DENSE_RANK\r\n`RANK()` 生成数据项在分组中的排名，排名相等会在名次中留下空位\r\n`DENSE_RANK()` 生成数据项在分组中的排名，排名相等会在名次中不会留下空位\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nRANK() OVER(PARTITION BY cookieid ORDER BY pv desc) AS rank1, \r\nDENSE_RANK() OVER(PARTITION BY cookieid ORDER BY pv desc) AS d_rank2, \r\nROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY pv DESC) AS rn3\r\nFROM window_demo\r\n```\r\n\r\n## CUME_DIST\r\n`cume_dist` 返回 小于等于 当前值的行数/分组内总行数\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nround(CUME_DIST() OVER(ORDER BY pv),2) AS cd1, \r\nround(CUME_DIST() OVER(PARTITION BY cookieid ORDER BY pv),2) AS cd2\r\nFROM window_demo;\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.1. Hive 窗口函数",
      "lvl1": "SUM",
      "lvl2": "NTILE",
      "lvl3": "ROW_NUMBER",
      "lvl4": "RANK DENSE_RANK",
      "lvl5": "CUME_DIST"
    },
    "frontmatter": {
      "title": "12.1. Hive 窗口函数",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.2. Hive 常用命令 dd 与 dmll",
    "path": "/docs/architect/hadoop/Hadoop-12.2.Hivechangyongminglingddyudmll.html",
    "url": "/docs/architect/hadoop/Hadoop-12.2.Hivechangyongminglingddyudmll.html",
    "content": "---\r\ntitle: 12.2. Hive 常用命令 dd 与 dmll\r\ndate: 2025/07/02\r\n---\r\n\r\n## 创建表\r\n```sql\r\nCREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name\r\n    [(col_name data_type [COMMENT col_comment], ...)]\r\n    [COMMENT table_comment]\r\n    [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]\r\n    [CLUSTERED BY (col_name, col_name, ...)\r\n    [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]\r\n    [ROW FORMAT row_format]\r\n    [STORED AS file_format]\r\n    [LOCATION hdfs_path]\r\n```\r\n\r\n### 创建内部表\r\n删除表的时候数据也会被删除\r\n\r\n```sql\r\ncreate table if not exists mytable(sid int ,sname string) \r\nrow format delimited\r\nfields terminated by ',' stored as textfile;\r\n\r\nshow tables;\r\n```\r\n\r\n上传数据: `hdfs dfs -put a /user/hive/warehouse/test.db/mytable/`\r\n`select * from mytable`\r\n\r\n### 创建外部表\r\n删除表的时候数据不会被删除\r\n\r\n```sql\r\ncreate external table mytable_ext(sid int ,sname string)\r\nrow format delimited\r\nfields terminated by ',' location '/dbdata'\r\n\r\nshow tables;\r\nselect * from mytable_ext;\r\n```\r\n\r\n### 创建分区表\r\n```sql\r\ncreate table person_p(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited fields\r\nterminated by ','stored as textfile;\r\n\r\nload data local inpath '/testdata/a' into table person_p partition(sex='nan');\r\nload data local inpath '/testdata/a' into table person_p partition(sex='nv');\r\n\r\nshow tables;\r\nselect * from person_p;\r\n```\r\n\r\n### 创建动态分区表\r\n```sql\r\nset hive.exec.dynamic.partition.mode=nonstrict;\r\n\r\ncreate table person_p2(sid int ,sname string) partitioned by(sex string) row format delimited\r\nfields terminated by ','stored as textfile;\r\n\r\ninsert into person_p2 partition(sex) select sid,sname,sex from person_p;\r\n\r\nshow tables;\r\nselect * from person_p2;\r\n```\r\n\r\n## 修改表\r\n```sql\r\nALTER TABLE table_name ADD [IF NOT EXISTS] partition_spec [ LOCATION 'location1' ] partition_spec [ LOCATION 'location2' ] ...\r\npartition_spec:\r\n: PARTITION (partition_col = partition_col_value, partition_col = partiton_col_value, ...)\r\n\r\nALTER TABLE table_name DROP partition_spec, partition_spec,...\r\n```\r\n\r\n### 增加分区\r\n```sql\r\ncreate table person_p3(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited\r\nfields terminated by ','stored as textfile;\r\n\r\nalter table person_p3 add partition(sex='1') partition(sex='2');\r\n\r\nload data local inpath '/testdata/a' into table person_p3 partition(sex='1');\r\nload data local inpath '/testdata/a' into table person_p3 partition(sex='2');\r\n\r\nshow tables;\r\nselect * from person_p3;\r\n```\r\n\r\n### 删除分区\r\n```sql\r\nalter table person_p3 drop partition(sex='2')\r\n```\r\n\r\n###  重命名表\r\n```sql\r\nALTER TABLE person_p3 RENAME TO person_p4;\r\n```\r\n\r\n### 新增列\r\nADD 是代表新增一字段，字段位置在所有列后面(partition 列前)，REPLACE 则是表示替换表中所有字段。\r\n```sql\r\nALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...\r\n```\r\n\r\n```sql\r\ncreate table person_p5(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited\r\nfields terminated by \r\n\r\nAlter table person_p5 add COLUMNS (age int);\r\ndesc person_p5;\r\n\r\nAlter table person_p5 REPLACE COLUMNS (age2 int);\r\ndesc person_p5;\r\n```\r\n\r\n### 修改列\r\n```sql\r\nALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type\r\n[COMMENT col_comment] [FIRST|AFTER column_name]\r\n```\r\n\r\n```sql\r\nalter table person_p5 change column age2 age2 string;\r\n\r\ndesc person_p5;\r\n```\r\n\r\n## 显示命令\r\n```sql\r\nshow tablese;\r\nshow databasese;\r\nshow partitions table_namee;\r\nshow functionse;\r\ndesc extended table_name;\r\ndesc formatted table_name;\r\n```\r\n\r\n## Load 操作\r\n```sql\r\nLOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO\r\nTABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]\r\n```\r\n\r\n## Insert\r\n```sql\r\nINSERT INTO TABLE VALUES(XX,YY,ZZ);\r\n\r\nINSERT OVERWRITE [INTO] TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)]\r\nselect_statement1 \r\n```\r\n\r\n## SELECT\r\n```sql\r\nSELECT [ALL | DISTINCT] select_expr, select_expr, ... FROM table_reference\r\n[WHERE where_condition]\r\n[GROUP BY col_list [HAVING condition]]\r\n[CLUSTER BY col_list\r\n| [DISTRIBUTE BY col_list] [SORT BY| ORDER BY col_list]\r\n]\r\n[LIMIT number]\r\n```\r\n\r\n1. `order by` 会对输入做全局排序，因此只有一个 reducer，会导致当输入规模较大时，需要较长的计算时间。\r\n2. `sort by` 不是全局排序，其在数据进入 reducer 前完成排序。因此，如果用 `sort by` 进行排序，并且设置 `mapred.reduce.tasks>1`，则 `sort by` 只保证每个 reducer 的输出有序，**不保证全局有序**。\r\n3. `distribute by`(字段) 根据指定的字段将数据分到不同的 reducer，且分发算法是 **hash 散列**。\r\n4. `Cluster by`(字段) 除了具有 `Distribute by` 的功能外，还会对该字段进行**排序**。\r\n\r\n因此，如果分桶和 sort 字段是同一个时，此时，`cluster by = distribute by + sort by`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.2. Hive 常用命令 dd 与 dmll",
      "lvl1": "创建表",
      "lvl2": "修改表",
      "lvl3": "显示命令",
      "lvl4": "Load 操作",
      "lvl5": "Insert",
      "lvl6": "SELECT"
    },
    "frontmatter": {
      "title": "12.2. Hive 常用命令 dd 与 dmll",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.3. Hive 分桶",
    "path": "/docs/architect/hadoop/Hadoop-12.3.Hivefentong.html",
    "url": "/docs/architect/hadoop/Hadoop-12.3.Hivefentong.html",
    "content": "---\r\ntitle: 12.3. Hive 分桶\r\ndate: 2025/07/02\r\n---\r\n\r\n## 创建桶表\r\n```sql\r\nset hive.enforce.bucketing=true;\r\nset mapreduce.job.reduces=4;\r\n\r\ndrop table person_buck;\r\n\r\ncreate table person_buck(sid int ,sname string)\r\npartitioned by(sex string)\r\nclustered by(sid)\r\nsorted by(sid DESC)\r\ninto 4 buckets\r\nrow format delimited\r\nfields terminated by ',';\r\n\r\ninsert into person_buck partition(sex) select sid,sname,sex from person_p;\r\n```\r\n\r\n## 桶表抽样查询\r\n```sql\r\nselect * from table_name tablesample(bucket X out of Y on field);\r\n\r\nselect * from person_buck tablesample(bucket 1 out of 2 on sid);\r\n```\r\n\r\n* X 表示从哪个桶中开始抽取\r\n* Y 表示相隔多少个桶再次抽取\r\n    * Y 必须为分桶数量的倍数或者因子，比如分桶数为 6，Y 为 6，则表示只从桶中抽取 1 个 bucket 的数据；若 Y 为 3，则表示从桶中抽取 6/3 (2)个 bucket 的数据\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.3. Hive 分桶",
      "lvl1": "创建桶表",
      "lvl2": "桶表抽样查询"
    },
    "frontmatter": {
      "title": "12.3. Hive 分桶",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
    "path": "/docs/architect/hadoop/Hadoop-12.4.HiveDemodaxiaoxiezhuanhuanUDFzidingyihanshu.html",
    "url": "/docs/architect/hadoop/Hadoop-12.4.HiveDemodaxiaoxiezhuanhuanUDFzidingyihanshu.html",
    "content": "---\r\ntitle: 12.4. Hive Demo 大小写转换 UDF 自定义函数\r\ndate: 2025/07/02\r\n---\r\n\r\n## pom.xml\r\n```xml\r\n<dependency>\r\n    <groupId>org.apache.hive</groupId>\r\n    <artifactId>hive-exec</artifactId>\r\n</dependency>\r\n```\r\n\r\n## Lower.java\r\n```java\r\npublic final class Lower extends UDF {\r\n    public Text evaluate(final Text s){\r\n        if(s==null){return null;}\r\n        return new Text(s.toString().toLowerCase());\r\n    }\r\n}\r\n```\r\n\r\n## 测试\r\n将代码打成 jar 包上传到服务器\r\n\r\n```sql\r\nadd JAR /path/to/udf.jar\r\n\r\ncreate temporary function tolowercase as 'cn.enjoy.hive.Lower'\r\n\r\nselect tolowercase(\"AAA\");\r\nselect sid,tolowercase(sname),sex from person_p;\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
      "lvl1": "pom.xml",
      "lvl2": "Lower.java",
      "lvl3": "测试"
    },
    "frontmatter": {
      "title": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.5.1. Hive 不支援 10 验证类型",
    "path": "/docs/architect/hadoop/Hadoop-12.5.1.Hivebuzhiyuan10yanzhengleixing.html",
    "url": "/docs/architect/hadoop/Hadoop-12.5.1.Hivebuzhiyuan10yanzhengleixing.html",
    "content": "---\r\ntitle: 12.5.1. Hive 不支援 10 验证类型\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger\r\n- 报错：PSQLException: 不支援 10 验证类型。请核对您已经组态 pg_hba.conf 文件包含客户端的IP位址或网路区段，以及驱动程序所支援的验证架构模式已被支援\r\n:::\r\n\r\n原因：驱动不兼容（需要更新驱动版本）\r\n\r\n1. 去官网或者使用Maven下载新的驱动jar包\r\n2. 添加到 hive/lib 目录中\r\n3. 将目录中旧的驱动jar包移出 hive/lib 目录\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.5.1. Hive 不支援 10 验证类型"
    },
    "frontmatter": {
      "title": "12.5.1. Hive 不支援 10 验证类型",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.5.2. Hive WstxParsingException",
    "path": "/docs/architect/hadoop/Hadoop-12.5.2.HiveWstxParsingException.html",
    "url": "/docs/architect/hadoop/Hadoop-12.5.2.HiveWstxParsingException.html",
    "content": "---\r\ntitle: 12.5.2. Hive WstxParsingException\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger\r\n- Hive-WstxParsingException: Illegal character entity: expansion character\r\n:::\r\n\r\n`hive-site.xml` 文件第 3215 行左右有一个特殊字符 (`&#8;`)，删掉它:\r\n\r\n```xml\r\n214      <description>\r\n3215       Ensures commands with OVERWRITE (such as INSERT OVERWRITE) acquire Exclusive      locks for&#8;transactional tables.  This ensures that inserts (w/o overwrite) runni     ng concurrently\r\n3216       are not hidden by the INSERT OVERWRITE.\r\n3217     </description>\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.5.2. Hive WstxParsingException"
    },
    "frontmatter": {
      "title": "12.5.2. Hive WstxParsingException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13. HBase 特点",
    "path": "/docs/architect/hadoop/Hadoop-13-HBase-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-13-HBase-tedian.html",
    "content": "---\r\ntitle: 13. HBase 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n## HBase 列式数据库简介\r\nHBase 是一个开源的非关系型分布式数据库（NoSql） 原型是 Google 的 BigTable 论文，受到了该论文思想的启发，目前作为Hadoop 的子项目来开发维护。它介于 nosql 和 RDBMS 之间，仅能通过主键(row key)和主键的 range 来检索数据，可通过 hive 支持来实现多表 join 等复杂操作。\r\n\r\n## HBase 特点\r\n\r\n* **海量存储**: Hbase 适合存储 PB 级别的海量数据，在 PB 级别的数据以及采用廉价 PC 存储的情况下，能在几十到百毫秒内返回数据。这与 Hbase 的极易扩展性息息相关。正式因为 Hbase 良好的扩展性，才为海量数据的存储提供了便利。\r\n* **列式存储**: 这里的列式存储其实说的是列族（ColumnFamily）存储，Hbase 是根据列族来存储数据的。列族下面可以有非常多的列，列族在创建表的时候就必须指定。\r\n* **极易扩展**: Hbase 的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer）的扩展，一个是基于存储的扩展（HDFS）。通过横向添加RegionSever 的机器，进行水平扩展，提升 Hbase 上层的处理能力，提升 Hbsae 服务更多 Region 的能力。\r\n* **高并发**: 由于目前大部分使用 Hbase 的架构，都是采用的廉价 PC，因此单个 IO 的延迟其实并不小，一般在几十到上百 ms 之间。这里说的高并发，主要是在并发的情况下，Hbase 的单个 IO 延迟下降并不多。能获得高并发、低延迟的服务。\r\n* **稀疏**: 稀疏主要是针对 Hbase 列的灵活性，在列族中，你可以指定任意多的列，在列数据为空的情况下，是不会占用存储空间的。\r\n\r\n适用场景:\r\n* 持久化存储大量数据（TB、PB）\r\n* 对扩展伸缩性有要求\r\n* 需要良好的随机读写性能\r\n* 简单的业务 KV 查询(不支持复杂的查询比如表关联等)\r\n* 能够同时处理结构化和非结构化的数据\r\n* 订单流水、交易记录、需要记录历史版本的数据等\r\n\r\n不适用场景:\r\n* 几千、几百万那种还不如使用 RDBMS\r\n* 需要类型列\r\n* 需要跨行事务，目前 HBase 只支持单行事务\r\n* SQL 查询\r\n\r\n## HBase 数据模型\r\n<table>\r\n    <tr>\r\n        <th>Row Key</th>\r\n        <th>Time Stamp</th>\r\n        <th>CF1</th>\r\n        <th>CF2</th>\r\n        <th>CF3</th>\r\n    </tr>\r\n    <tr>\r\n        <td rowspan=\"3\">rk00001</td>\r\n        <td>t1</td>\r\n        <td></td>\r\n        <td>CF2:q1=val1</td>\r\n        <td>CF3:q2=val2</td>\r\n    </tr>\r\n    <tr>\r\n        <td>t2</td>\r\n        <td></td>\r\n        <td></td>\r\n        <td></td>\r\n    </tr>\r\n    <tr>\r\n        <td>t3</td>\r\n        <td>CF1:q3=val3</td>\r\n        <td></td>\r\n        <td></td>\r\n    </tr>\r\n</table>\r\n\r\n* ROW KEY\r\n    * 决定一行数据\r\n    * 按照字典顺序排序的\r\n    * ROW KEY 只能存储 64k 的字节数据\r\n* Column Family 列族 & qualifier 列\r\n    * HBase 表中的每个列都归属于某个列族，列族必须作为表模式(schema)定义的一部分预先给出。`create 'test', 'course'`\r\n    * 列名以列族作为前缀， 每个“列族”都可以有多个列成员(column) ； 如 `course:math`,`course:english`, 新的列族成员（列）可以随后按需、动态加入；\r\n    * 权限控制、存储以及调优都是在列族层面进行的；\r\n    * HBase 把同一列族里面的数据存储在同一目录下，由几个文件保存\r\n* Timestamp 时间戳\r\n    * 在HBase 每个 cell 存储单元对同一份数据有多个版本，根据唯一的时间戳来区分每个版本之间的差异，不同版本的数据按照时间倒序排序，最新的数据版本排在最前面\r\n    * 时间戳的类型是 64 位整型\r\n    * 时间戳可以由HBase(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间\r\n    * 时间戳也可以由客户显式赋值\r\n* Cell 单元格\r\n    * 由行和列的坐标交叉决定\r\n    * 单元格是有版本的\r\n    * 单元格的内容是未解析的字节数组\r\n    * 由`{rowkey，column(=<family> +<qualifier>)，version}`唯一确定的单元\r\n    * Cell 中的数据是没有类型的，全部是二进制字节码形式存储\r\n\r\n## HBase 架构\r\n![HBase 架构](static/HBase.png)\r\n\r\n* **Client**: 包含了访问 Hbase 的接口，另外 Client 还维护了对应的 cache 来加速 HBase 的访问，比如 cache 的.META.元数据的信息\r\n* **Zookeeper**: HBase 通过 Zookeeper 来做 master 的高可用、RegionServer 的监控、元数据的入口以及集群配置的维护等工作\r\n    * 通过 Zoopkeeper 来保证集群中只有1个 master 在运行，如果 master 异常，会通过竞争机制\r\n    * 产生新的 master 提供服务\r\n    * 通过 Zoopkeeper 来监控 RegionServer 的状态，当 RegionSevrer 有异常的时候，通过回调的形式通知 Master RegionServer 上下线的信息\r\n    * 通过 Zoopkeeper 存储元数据的统一入口地址\r\n* **HMaster**: \r\n    * 为 RegionServer 分配 Region\r\n    * 维护整个集群的负载均衡\r\n    * 维护集群的元数据信息\r\n    * 发现失效的 Region，并将失效的 Region 分配到正常的 RegionServer 上\r\n    * 当 RegionSever 失效的时候，协调对应 Hlog 的拆分\r\n* **HregionServer**: 直接对接用户的读写请求，是真正的“干活”的节点\r\n    * 管理 master 为其分配的 Region\r\n    * 处理来自客户端的读写请求\r\n    * 负责和底层 HDFS 的交互，存储数据到 HDFS\r\n    * 负责 Region 变大以后的拆分\r\n    * 负责 Storefile 的合并工作\r\n* **HDFS**: 为 Hbase 提供最终的底层数据存储服务，同时为 HBase 提供高可用（Hlog 存储在 HDFS）的支持\r\n    * 提供元数据和表数据的底层分布式存储服务\r\n    * 数据多副本，保证的高可靠和高可用性\r\n\r\n## HBase 中的角色\r\n\r\n* **HMaster**\r\n    * 监控 RegionServer\r\n    * 处理 RegionServer 故障转移\r\n    * 处理元数据的变更\r\n    * 处理 region 的分配或转移\r\n    * 在空闲时间进行数据的负载均衡\r\n    * 通过 Zookeeper 发布自己的位置给客户端\r\n* **RegionServer**\r\n    * 负责存储 HBase 的实际数据\r\n    * 处理分配给它的 Region\r\n    * 刷新缓存到 HDFS\r\n    * 维护 Hlog\r\n    * 执行压缩\r\n    * 负责处理 Region 分片\r\n* **Write-Ahead logs (WAL)**\r\n    * HBase 的修改记录，当对 HBase 读写数据的时候，数据不是直接写进磁盘，它会在内存中保留一段时间（时间以及数据量阈值可以设定）。但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入内存中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。\r\n* **Region**\r\n    * Hbase 表的分片，HBase 表会根据 RowKey 值被切分成不同的 region 存储在 RegionServer 中，在一个 RegionServer 中可以有多个不同的 region\r\n* **Store**\r\n    * HFile 存储在 Store 中，一个 Store 对应 HBase 表中的一个列族(列簇， ColumnFamily)\r\n* **MemStore**\r\n    * 顾名思义，就是内存存储，位于内存中，用来保存当前的数据操作，所以当数据保存在 WAL 中之后，RegsionServer 会在内存中存储键值对\r\n* **HFile**\r\n    * 这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。StoreFile 是以 HFile 的形式存储在 HDFS 的\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13. HBase 特点",
      "lvl1": "HBase 列式数据库简介",
      "lvl2": "HBase 特点",
      "lvl3": "HBase 数据模型",
      "lvl4": "HBase 架构",
      "lvl5": "HBase 中的角色"
    },
    "frontmatter": {
      "title": "13. HBase 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.1. HBase 常用命令",
    "path": "/docs/architect/hadoop/Hadoop-13.1.HBasechangyongmingling.html",
    "url": "/docs/architect/hadoop/Hadoop-13.1.HBasechangyongmingling.html",
    "content": "---\r\ntitle: 13.1. HBase 常用命令\r\ndate: 2025/07/02\r\n---\r\n\r\n`hbase shell` 进入shell\r\n`help` 命令查看帮助文档\r\n`list` 命令查看数据库中的表\r\n\r\n## 创建表\r\n创建 person 表，包含 info, data 两个列族\r\n然后查看表结构\r\n```sql\r\ncreate 'person', 'info', 'data'\r\ndescribe 'person'\r\n```\r\n\r\n## 插入数据\r\n```sql\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加name 列标示符，值为zhangsan\r\nput 'person', 'rk0001', 'info:name', 'zhangsan'\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加gender 列标示符，值为female\r\nput 'person', 'rk0001', 'info:gender', 'female'\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加age 列标示符，值为20\r\nput 'person', 'rk0001', 'info:age', 20\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族data 中添加pic 列标示符，值为picture\r\nput 'person', 'rk0001', 'data:pic', 'picture'\r\n```\r\n\r\n## 查询数据\r\n`get` 适用于获取单个记录或少量记录的场景，`scan` 适用于获取大量记录的场景\r\n```sql\r\n-- 获取person 表中row key 为rk0001 的所有信息\r\nget 'person', 'rk0001'\r\n\r\n-- 获取person 表中row key 为rk0001，info 列族的所有信息\r\nget 'person', 'rk0001', 'info'\r\n\r\n-- 获取person 表中row key 为rk0001，info 列族的name、age 列标示符的信息\r\nget 'person', 'rk0001', 'info:name', 'info:age'\r\n\r\n-- 获取person 表中row key 为rk0001，info、data 列族的信息\r\nget 'person', 'rk0001', 'info', 'data'\r\n\r\nget 'person', 'rk0001', {COLUMN => ['info', 'data']}\r\nget 'person', 'rk0001', {COLUMN => ['info:name', 'data:pic']}\r\n\r\n-- 获取person 表中row key 为rk0001，列族为info，版本号最新5 个的信息\r\nget 'person', 'rk0001', {COLUMN => 'info', VERSIONS => 5}\r\n\r\nget 'person', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5}\r\nget 'person', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5, TIMERANGE => [1567491377530,1567491377590]}\r\n\r\n-- 获取person 表中row key 为rk0001，cell 的值为zhangsan 的信息\r\nget 'person', 'rk0001', {FILTER => \"ValueFilter(=, 'binary:zhangsan')\"}\r\n\r\n-- 获取person 表中row key 为rk0001，列标示符中含有a 的信息\r\nget 'person', 'rk0001', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\r\n\r\nput 'person', 'rk0002', 'info:name', 'fanbingbing'\r\nput 'person', 'rk0002', 'info:gender', 'female'\r\nput 'person', 'rk0002', 'info:nationality', '中国'\r\nget 'person', 'rk0002', {FILTER => \"ValueFilter(=, 'binary:中国')\"}\r\n\r\n-- 查询person 表中的所有信息\r\nscan 'person'\r\n\r\n-- 查询person 表中列族为info 的信息\r\nscan 'person', {COLUMNS => 'info'}\r\n\r\n-- 查询person 表中列族为info 和data 的信息\r\nscan 'person', {COLUMNS => ['info', 'data']}\r\nscan 'person', {COLUMNS => ['info:name', 'data:pic']}\r\n\r\n-- 查询person 表中列族为info、列标示符为name 的信息\r\nscan 'person', {COLUMNS => 'info:name'}\r\n\r\n-- 查询person 表中列族为info、列标示符为name 的信息,并且版本最新的5 个\r\nscan 'person', {COLUMNS => 'info:name', VERSIONS => 5}\r\n\r\n-- 查询person 表中列族为info 和data 且列标示符中含有a 字符的信息\r\nscan 'person', {COLUMNS => ['info', 'data'], FILTER => \"(QualifierFilter(=,'substring:a'))\"}\r\n\r\n-- 查询person 表中列族为info，rk 范围是[rk0001, rk0003)的数据\r\nscan 'person', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}\r\n\r\n-- 查询person 表中row key 以rk 字符开头的\r\nscan 'person',{FILTER=>\"PrefixFilter('rk')\"}\r\n\r\n-- 查询person 表中指定范围的数据\r\nscan 'person', {TIMERANGE => [1392368783980, 1392380169184]}\r\n```\r\n\r\n## 删除数据\r\n```sql\r\n-- 删除person 表row key 为rk0001，列标示符为info:name 的数据\r\ndelete 'person', 'rk0001', 'info:name'\r\n\r\n-- 删除person 表row key 为rk0001，列标示符为info:name，timestamp 为1392383705316 的数据\r\ndelete 'person', 'rk0001', 'info:name', 1392383705316\r\n\r\n-- 清空person 表中的数据\r\ntruncate 'person'\r\n```\r\n\r\n## 修改表结构\r\n```sql\r\n-- 首先停用person 表\r\ndisable 'person'\r\n\r\n-- 添加两个列族f1 和f2\r\nalter 'person', NAME => 'f1'\r\nalter 'person', NAME => 'f2'\r\n\r\n-- 删除一个列族\r\nalter 'person', NAME => 'f1', METHOD => 'delete'\r\nalter 'person', 'delete' => 'f1'\r\n\r\n-- 添加列族f1 同时删除列族f2\r\nalter 'person', {NAME => 'f1'}, {NAME => 'f2', METHOD => 'delete'}\r\n\r\n-- 将person 表的f1 列族版本号改为5\r\nalter 'person', NAME => 'info', VERSIONS => 5\r\n\r\n-- 启用表\r\nenable 'person'\r\n```\r\n\r\n## 删除表\r\n```sql\r\ndisable 'person'\r\ndrop 'person'\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.1. HBase 常用命令",
      "lvl1": "创建表",
      "lvl2": "插入数据",
      "lvl3": "查询数据",
      "lvl4": "删除数据",
      "lvl5": "修改表结构",
      "lvl6": "删除表"
    },
    "frontmatter": {
      "title": "13.1. HBase 常用命令",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.2. HBase 优化",
    "path": "/docs/architect/hadoop/Hadoop-13.2.HBaseyouhua.html",
    "url": "/docs/architect/hadoop/Hadoop-13.2.HBaseyouhua.html",
    "content": "---\r\ntitle: 13.2. HBase 优化\r\ndate: 2025/07/02\r\n---\r\n\r\n* [13.3. HBase 设计优化 rowkey](./Hadoop-13.3.HBase设计优化rowkey.md)\r\n* 代码优化\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setInMemory(true)` 将表放到 RegionServer 的缓存中，**保证在读取的时候被 cache 命中**\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setMaxVersions(int maxVersions)` **设置表中数据的最大版本**，如果只需要保存最新版本的数据，那么可以设置 `setMaxVersions(1)`\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setTimeToLive(int timeToLive)` **设置表中数据的存储生命期，过期数据将自动被删除**，例如如果只需要存储最近两天的数据，那么可以设置 `setTimeToLive(2 * 24 * 60 * 60)`\r\n* `hdfs-site.xml`: **HDFS 副本数的调整**\r\n    * `dfs.replication`: 如果数据量巨大，且不是非常之重要，可以调整为2~3，如果数据非常之重要，可以调整为3~5\r\n    * `dfs.datanode.max.transfer.threads`: HBase 一般都会同一时间操作大量的文件，根据集群的数量和规模以及数据动作，设置为 4096 或者更高。默认值：4096\r\n* `mapred-site.xml`: **优化数据的写入效率, 减少写入时间 (压缩)**\r\n    * `mapreduce.map.output.compress`: 修改为 `true`\r\n    * `mapreduce.map.output.compress.codec`: 修改为 `org.apache.hadoop.io.compress.GzipCodec` 或者其他压缩方式\r\n* `hbase-site.xml`\r\n    * `hbase.regionserver.handler.count`: 默认值为 30，用于指定 **RPC 监听的数量**，可以根据客户端的请求数进行调整，读写请求较多时，增加此值\r\n    * `hbase.hregion.max.filesize`: 默认值10737418240(10GB)，如果需要运行 HBase 的 MR 任务，可以减小此值，因为**一个 region 对应一个 map 任务**，如果单个 region 过大，会导致 map 任务执行时间过长。该值的意思就是，如果 HFile 的大小达到这个数值，则这个 region 会被切分为两个 Hfile\r\n    * `hbase.client.write.buffer`: 用于指定 HBase 客户端缓存，**增大该值可以减少 RPC 调用次数，但是会消耗更多内存**。一般我们需要设定一定的缓存大小，以达到减少 RPC 次数的目的\r\n    * `hbase.client.scanner.caching`: 用于指定 `scan.next` 方法**获取的默认行数，值越大，消耗内存越大**\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.2. HBase 优化"
    },
    "frontmatter": {
      "title": "13.2. HBase 优化",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.3. HBase 设计优化 rowkey",
    "path": "/docs/architect/hadoop/Hadoop-13.3.HBaseshejiyouhuarowkey.html",
    "url": "/docs/architect/hadoop/Hadoop-13.3.HBaseshejiyouhuarowkey.html",
    "content": "---\r\ntitle: 13.3. HBase 设计优化 rowkey\r\ndate: 2025/07/02\r\n---\r\n\r\n## 性能上考虑\r\n一条数据的唯一标识就是 rowkey，而这行数据最终存储到哪一个分区里面，取决于分区({% post_link architect/Hadoop/HBase-预分区 %})，如果从性能上考虑 rowkey 优化，应该考虑的是让数据均匀的分布在所有的 region 中，**防止数据的倾斜**。\r\n\r\n设计方案:\r\n1. 使用**随机数**, **hash** 等\r\n2. **字符串反转** 10001, 10002 反转成为 10001, 20001\r\n3. **拼接字符串** XX0001 -> 1000XX0001\r\n\r\n## 业务上考虑\r\n\r\n### 列族数目\r\n一个列族和一个 Store 对于，如果经常需要跨列族查询，对应就是需要从多个 Store 中取数据，这样对性能开销挺大，建议**创建表的时候不要太多列族，一般 2-3 个为主**。**基本信息**放到一个列族，**扩展信息**放到一个列族，如果还有另外的**不常用的附件信息**放到第三个列族。\r\n\r\n### 行键设置\r\n\r\n**根据查询要求设置 key**:\r\n* 手机号-日期: \r\n    * `18229955555-20190919`\r\n    * `18229955555-20190920`\r\n* 日期-姓名缩写-类别: 姓名缩写长度需要保持一致 (填充和截断)\r\n    * `20150230-lisi-category`\r\n    * `20150230-zs__-category`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.3. HBase 设计优化 rowkey",
      "lvl1": "性能上考虑",
      "lvl2": "业务上考虑"
    },
    "frontmatter": {
      "title": "13.3. HBase 设计优化 rowkey",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.4. HBase 预分区",
    "path": "/docs/architect/hadoop/Hadoop-13.4.HBaseyufenqu.html",
    "url": "/docs/architect/hadoop/Hadoop-13.4.HBaseyufenqu.html",
    "content": "---\r\ntitle: 13.4. HBase 预分区\r\ndate: 2025/07/02\r\n---\r\n\r\n在默认情况下，在使用 hbase 创建表的时候会自动创建一个 region 分区，所有 hbase 的客户端的数据都写到这个 region 分区里面，一直到 region 足够大的时候才进行切分。每一个 region 维护着 startRow 与 endRowKey，如果加入的数据符合某个 region 维护的 rowKey范围，则该数据交给这个 region 维护, 根据这个特性，我们可以根据以后要插入 hbase 的数据进行一个预估，**将数据大致估算好，提前进行分区，用于提升 hbase 的性能**。\r\n\r\n可以在 `http://hadoop01:16010/`(主节点) 查看分区情况\r\n\r\n## 预分区\r\n* 手动预分区: `create 'p1','info','partition1',SPLITS => ['1000','2000','3000','4000']`\r\n* 16进制分区: `create 'p2','info','partition2',{NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'}`\r\n* 代码分区: 创建表的时候指定分区\r\n    ```java\r\n    public class SplitReginTest {\r\n        private Configuration conf = null;\r\n        private Connection conn = null;\r\n\r\n        @Before\r\n        public void init() throws Exception {\r\n            conf = HBaseConfiguration.create();\r\n            conf.set(\"hbase.zookeeper.quorum\",\"hadoop01:2181,hadoop02:2182,hadoop03:2183\");\r\n            conn = ConnectionFactory.createConnection(conf);\r\n        }\r\n\r\n        @Test\r\n        public void testCreateTable() throws Exception {\r\n            Admin admin = conn.getAdmin();\r\n\r\n            HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(\"split_p\"));\r\n            HColumnDescriptor hcd1 = new HColumnDescriptor(\"base_info\");\r\n            htd.addFamily(hcd1);\r\n\r\n            byte[][] splitKeys = new byte[4][];\r\n            splitKeys[0] = Bytes.toBytes(\"1000\");\r\n            splitKeys[1] = Bytes.toBytes(\"2000\");\r\n            splitKeys[2] = Bytes.toBytes(\"3000\");\r\n            splitKeys[3] = Bytes.toBytes(\"4000\");\r\n\r\n            admin.createTable(htd,splitKeys);\r\n\r\n            admin.close();\r\n            conn.close();\r\n        }\r\n    }\r\n    ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.4. HBase 预分区",
      "lvl1": "预分区"
    },
    "frontmatter": {
      "title": "13.4. HBase 预分区",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.5.1. HBase Demo Java API 常用操作",
    "path": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "url": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "content": "---\r\ntitle: 13.5.1. HBase Demo Java API 常用操作\r\ndate: 2025/07/02\r\n---\r\n\r\n## pom.xml\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.apache.hbase</groupId>\r\n            <artifactId>hbase-server</artifactId>\r\n            <version>2.5.4</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hbase</groupId>\r\n            <artifactId>hbase-client</artifactId>\r\n            <version>2.5.4</version>\r\n        </dependency>\r\n```\r\n\r\n## 获得连接\r\n```java\r\nprivate Configuration conf = null;\r\nprivate Connection conn = null;\r\n\r\n    @Before\r\n    public void init() throws Exception {\r\n        conf = HBaseConfiguration.create();\r\n        conf.set(\"hbase.zookeeper.quorum\", \"hadoop01:2181,hadoop02:2182,hadoop03:2183\");\r\n        conn = ConnectionFactory.createConnection(conf);\r\n    }\r\n```\r\n\r\n## 建表\r\n```java\r\n    @Test\r\n    public void testCreateTable() throws Exception {\r\n        // 获取一个表管理器\r\n        Admin admin = conn.getAdmin();\r\n\r\n        // 构造一个表描述器，并指定表名\r\n        HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 构造一个列族描述器，并指定列族名\r\n        HColumnDescriptor hcd1 = new HColumnDescriptor(\"base_info\");\r\n        // 构造第二个列族描述器，并指定列族名\r\n        HColumnDescriptor hcd2 = new HColumnDescriptor(\"extra_info\");\r\n\r\n        // 将列族描述器添加到表描述器中\r\n        htd.addFamily(hcd1).addFamily(hcd2);\r\n        admin.createTable(htd);\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 删除表\r\n```java\r\n    @Test\r\n    public void testDrop() throws Exception {\r\n        Admin admin = conn.getAdmin();\r\n\r\n        admin.disableTable(TableName.valueOf(\"t_person_info\"));\r\n        admin.deleteTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 修改表结构\r\n```java\r\n    @Test\r\n    public void testModify() throws Exception {\r\n        Admin admin = conn.getAdmin();\r\n\r\n        // 修改已有的ColumnFamily\r\n        HTableDescriptor table = admin.getTableDescriptor(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 添加新的ColumnFamily\r\n        table.addFamily(new HColumnDescriptor(\"other_info\"));\r\n        admin.modifyTable(TableName.valueOf(\"t_person_info\"), table);\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 插入/修改数据\r\n```java\r\n    @Test\r\n    public void testPut() throws Exception {\r\n        Table table = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        ArrayList<Put> puts = new ArrayList<Put>();\r\n        // 构建一个put 对象（kv），指定其行键\r\n        Put put01 = new Put(Bytes.toBytes(\"user001\"));\r\n        put01.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhangsan\"));\r\n        Put put02 = new Put(\"user001\".getBytes());\r\n        put02.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"password\"),Bytes.toBytes(\"123456\"));\r\n        Put put03 = new Put(\"user002\".getBytes());\r\n        put03.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"lisi\"));\r\n        put03.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put04 = new Put(\"zhang_sh_01\".getBytes());\r\n        put04.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang01\"));\r\n        put04.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put05 = new Put(\"zhang_sh_02\".getBytes());\r\n        put05.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang02\"));\r\n        put05.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put06 = new Put(\"liu_sh_01\".getBytes());\r\n        put06.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"liu01\"));\r\n        put06.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put07 = new Put(\"zhang_bj_01\".getBytes());\r\n        put07.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang03\"));\r\n        put07.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put08 = new Put(\"zhang_bj_01\".getBytes());\r\n        put08.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang04\"));\r\n        put08.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n\r\n        puts.add(put01);\r\n        puts.add(put02);\r\n        puts.add(put03);\r\n        puts.add(put04);\r\n        puts.add(put05);\r\n        puts.add(put06);\r\n        puts.add(put07);\r\n        puts.add(put08);\r\n        table.put(puts);\r\n\r\n        table.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## get 查询\r\n```java\r\n    @Test\r\n    public void testGet() throws Exception {\r\n        Table table = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 构造一个get 查询参数对象，指定要get 的是哪一行\r\n        Get get = new Get(\"user001\".getBytes());\r\n        Result result = table.get(get);\r\n\r\n        CellScanner cellScanner = result.cellScanner();\r\n        while (cellScanner.advance()) {\r\n            Cell current = cellScanner.current();\r\n            byte[] familyArray = current.getFamilyArray();\r\n            byte[] qualifierArray = current.getQualifierArray();\r\n            byte[] valueArray = current.getValueArray();\r\n            System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n            System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n            System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n        }\r\n\r\n        table.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 删除表中数据\r\n```java\r\n    @Test\r\n    public void testDel() throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.5.1. HBase Demo Java API 常用操作",
      "lvl1": "pom.xml",
      "lvl2": "获得连接",
      "lvl3": "建表",
      "lvl4": "删除表",
      "lvl5": "修改表结构",
      "lvl6": "插入/修改数据",
      "lvl7": "get 查询",
      "lvl8": "删除表中数据",
      "lvl9": "scan 查询",
      "lvl10": "过滤查询"
    },
    "frontmatter": {
      "title": "13.5.1. HBase Demo Java API 常用操作",
      "date": "2025/07/02"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "13.5.1. HBase Demo Java API 常用操作",
    "path": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "url": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "content": "(\"t_person_info\"));\r\n\r\n        Delete delete = new Delete(\"user001\".getBytes());\r\n        delete.addColumn(\"base_info\".getBytes(), \"password\".getBytes());\r\n\r\n        t_person_info.delete(delete);\r\n\r\n        t_person_info.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## scan 查询\r\n```java\r\n    @Test\r\n    public void testScan() throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n        Scan scan = new Scan(Bytes.toBytes(\"liu_sh_01\"), Bytes.toBytes(\"zhang_bj_01\" + \"\\000\"));\r\n        ResultScanner scanner = t_person_info.getScanner(scan);\r\n        Iterator<Result> iter = scanner.iterator();\r\n        while (iter.hasNext()) {\r\n            Result result = iter.next();\r\n            CellScanner cellScanner = result.cellScanner();\r\n            while (cellScanner.advance()) {\r\n                Cell current = cellScanner.current();\r\n                byte[] familyArray = current.getFamilyArray();\r\n                byte[] valueArray = current.getValueArray();\r\n                byte[] qualifierArray = current.getQualifierArray();\r\n                byte[] rowArray = current.getRowArray();\r\n                System.out.println(new String(rowArray, current.getRowOffset(),current.getRowLength()));\r\n                System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n                System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n                System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n            }\r\n            System.out.println(\"-----------------------\");\r\n        }\r\n    }\r\n```\r\n\r\n## 过滤查询\r\n```java\r\n    @Test\r\n    public void testFilter() throws Exception {\r\n        // 针对行键的前缀过滤器\r\n        Filter pf = new PrefixFilter(Bytes.toBytes(\"liu\"));\r\n        testScan(pf);\r\n\r\n        // 行过滤器\r\n        RowFilter rf1 = new RowFilter(CompareOp.LESS, new BinaryComparator(Bytes.toBytes(\"user002\")));\r\n        RowFilter rf2 = new RowFilter(CompareOp.EQUAL, new SubstringComparator(\"00\"));\r\n        testScan(rf1);\r\n        System.out.println(\"**********\");\r\n        testScan(rf2);\r\n\r\n        // 针对指定一个列的 value 来过滤\r\n        SingleColumnValueFilter scvf = new SingleColumnValueFilter(\"base_info\".getBytes(),\"password\".getBytes(), CompareOp.EQUAL, \"123456\".getBytes());\r\n        scvf.setFilterIfMissing(true); // 如果指定的列缺失，则也过滤掉\r\n        testScan(scvf);\r\n\r\n        ByteArrayComparable comparator1 = new RegexStringComparator(\"^zhang\");\r\n        ByteArrayComparable comparator2 = new SubstringComparator(\"ang\");\r\n        SingleColumnValueFilter scvf = new SingleColumnValueFilter(\"base_info\".getBytes(),\r\n        \"username\".getBytes(), CompareOp.EQUAL, comparator2);\r\n        testScan(scvf);\r\n\r\n        // 针对列族名的过滤器返回结果中只会包含满足条件的列族中的数据\r\n        FamilyFilter ff1 = new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(\"inf\")));\r\n        FamilyFilter ff2 = new FamilyFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"base\")));\r\n        testScan(ff1);\r\n\r\n        // 针对列名的过滤器返回结果中只会包含满足条件的列的数据\r\n        QualifierFilter qf = new QualifierFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(\"password\")));\r\n        QualifierFilter qf2 = new QualifierFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"us\")));\r\n        testScan(qf);\r\n\r\n        // 跟 SingleColumnValueFilter 结果不同，只返回符合条件的该column\r\n        ColumnPrefixFilter cf = new ColumnPrefixFilter(\"passw\".getBytes());\r\n        testScan(cf);\r\n\r\n        byte[][] prefixes = new byte[][]{ Bytes.toBytes(\"username\"),Bytes.toBytes(\"password\") };\r\n        MultipleColumnPrefixFilter mcf = new MultipleColumnPrefixFilter(prefixes);\r\n        testScan(mcf);\r\n\r\n        FamilyFilter ff2 = new FamilyFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"base\")));\r\n        ColumnPrefixFilter cf = new ColumnPrefixFilter(\"passw\".getBytes());\r\n        FilterList filterList = new FilterList(Operator.MUST_PASS_ALL);\r\n        filterList.addFilter(ff2);\r\n        filterList.addFilter(cf);\r\n        testScan(filterList);\r\n    }\r\n```\r\n\r\n```java\r\n    private void testScan(Filter filter) throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n        Scan scan = new Scan();\r\n        scan.setFilter(filter);\r\n        ResultScanner scanner = t_person_info.getScanner(scan);\r\n        Iterator<Result> iter = scanner.iterator();\r\n        while (iter.hasNext()) {\r\n            Result result = iter.next();\r\n            CellScanner cellScanner = result.cellScanner();\r\n            while (cellScanner.advance()) {\r\n                Cell current = cellScanner.current();\r\n                byte[] familyArray = current.getFamilyArray();\r\n                byte[] valueArray = current.getValueArray();\r\n                byte[] qualifierArray = current.getQualifierArray();\r\n                byte[] rowArray = current.getRowArray();\r\n                System.out.println(new String(rowArray, current.getRowOffset(),current.getRowLength()));\r\n                System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n                System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n                System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n            }\r\n            System.out.println(\"-----------------------\");\r\n        }\r\n    }\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.5.1. HBase Demo Java API 常用操作",
      "lvl1": "pom.xml",
      "lvl2": "获得连接",
      "lvl3": "建表",
      "lvl4": "删除表",
      "lvl5": "修改表结构",
      "lvl6": "插入/修改数据",
      "lvl7": "get 查询",
      "lvl8": "删除表中数据",
      "lvl9": "scan 查询",
      "lvl10": "过滤查询"
    },
    "frontmatter": {
      "title": "13.5.1. HBase Demo Java API 常用操作",
      "date": "2025/07/02"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "13.6.1. HBase ServerNotRunningYetException",
    "path": "/docs/architect/hadoop/Hadoop-13.6.1.HBaseServerNotRunningYetException.html",
    "url": "/docs/architect/hadoop/Hadoop-13.6.1.HBaseServerNotRunningYetException.html",
    "content": "---\r\ntitle: 13.6.1. HBase ServerNotRunningYetException\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger ServerNotRunningYetException\r\n- HBase ServerNotRunningYetException: Server is not running yet\r\n:::\r\n\r\n`hbase-site.xml` 中添加:\r\n```xml\r\n  <property>\r\n    <name>hbase.wal.provider</name>\r\n    <value>filesystem</value>\r\n  </property>\r\n```\r\n\r\n重启 HBase 即可\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.6.1. HBase ServerNotRunningYetException"
    },
    "frontmatter": {
      "title": "13.6.1. HBase ServerNotRunningYetException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.6.2. HBase No Hbase Master Found",
    "path": "/docs/architect/hadoop/Hadoop-13.6.2.HBaseNoHbaseMasterFound.html",
    "url": "/docs/architect/hadoop/Hadoop-13.6.2.HBaseNoHbaseMasterFound.html",
    "content": "---\r\ntitle: 13.6.2. HBase No Hbase Master Found\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger\r\n- HBase-stop-hbase.sh: no hbase master found\r\n:::\r\n\r\n1. `hbase-env.sh` 中添加: `export HBASE_PID_DIR=/var/hbase/pids`\r\n2. `jps` 查看 hbase 相关的 pid, 然后 `kill -9` 结束进程\r\n3. `start-hbase.sh` 启动 hbase\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.6.2. HBase No Hbase Master Found"
    },
    "frontmatter": {
      "title": "13.6.2. HBase No Hbase Master Found",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14. Sqoop 特点",
    "path": "/docs/architect/hadoop/Hadoop-14-Sqoop-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-14-Sqoop-tedian.html",
    "content": "---\r\ntitle: 14. Sqoop 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n## Sqoop 简介\r\nSqoop 是 apache 旗下的工具，用于实现结构型数据（如关系数据库）和 Hadoop 之间进行数据迁移的工具, 可以讲关系型数据库中的数据导入到 Hadoop 的 HDFS 中，同样也完全可以把 HDFS 的数据导入到关系型数据库里面\r\n* 导入数据：MySQL, Oracle 导入数据到 Hadoop 的 HDFS, HIVE, HBASE 等数据存储系统\r\n* 导出数据：从 Hadoop 的文件系统中导出数据到关系数据库\r\n\r\n![Sqoop](static/sqoop.png)\r\n\r\n## Sqoop 原理\r\nSqoop 把导入或导出命令翻译成 `mapreduce` 代码来实现, 在翻译出的 `mapreduce` 中，其实只是对 `inputformat` 和 `outputformat` 进行了定制\r\n\r\n---\r\n\r\n<font color=\"red\">该项目已于 2021-06 终止, 并移入 Apache Attic</font>\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14. Sqoop 特点",
      "lvl1": "Sqoop 简介",
      "lvl2": "Sqoop 原理"
    },
    "frontmatter": {
      "title": "14. Sqoop 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.1. Sqoop 导入数据到 HBase",
    "path": "/docs/architect/hadoop/Hadoop-14.1.SqoopdaorushujudaoHBase.html",
    "url": "/docs/architect/hadoop/Hadoop-14.1.SqoopdaorushujudaoHBase.html",
    "content": "---\r\ntitle: 14.1. Sqoop 导入数据到 HBase\r\ndate: 2025/07/02\r\n---\r\n\r\n1. 创建 HBase 表: `create 'hbase_person','info'`\r\n2. 导入数据到 HBase\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --columns \"pid,name,sex\" \\\r\n        --column-family \"info\" \\\r\n        --hbase-create-table \\\r\n        --hbase-row-key \"pid\" \\\r\n        --hbase-table \"hbase_person\" \\\r\n        --num-mappers 1 \\\r\n        --split-by pid\r\n    ```\r\n3. `scan 'hbase_person'`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.1. Sqoop 导入数据到 HBase"
    },
    "frontmatter": {
      "title": "14.1. Sqoop 导入数据到 HBase",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.2. Sqoop Hive 与 Mysql 互导",
    "path": "/docs/architect/hadoop/Hadoop-14.2.SqoopHiveyuMysqlhudao.html",
    "url": "/docs/architect/hadoop/Hadoop-14.2.SqoopHiveyuMysqlhudao.html",
    "content": "---\r\ntitle: 14.2. Sqoop Hive 与 Mysql 互导\r\ndate: 2025/07/02\r\n---\r\n\r\n* 导入数据到 HIVE\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --num-mappers 1 \\\r\n        --hive-import \\\r\n        --fields-terminated-by \",\" \\\r\n        --hive-overwrite \\\r\n        --hive-table person_hive\r\n    ```\r\n* hive/hdfs 导入数据到 mysql\r\n    ```bash\r\n    sqoop export \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person2 \\\r\n        --export-dir /user/hive/warehouse/person_hive \\\r\n        --m 1\r\n    ```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.2. Sqoop Hive 与 Mysql 互导"
    },
    "frontmatter": {
      "title": "14.2. Sqoop Hive 与 Mysql 互导",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.3. Sqoop Mysql 导入 HDFS",
    "path": "/docs/architect/hadoop/Hadoop-14.3.SqoopMysqldaoruHDFS.html",
    "url": "/docs/architect/hadoop/Hadoop-14.3.SqoopMysqldaoruHDFS.html",
    "content": "---\r\ntitle: 14.3. Sqoop Mysql 导入 HDFS\r\ndate: 2025/07/02\r\n---\r\n\r\n1. Mysql 测试数据\r\n    ```sql\r\n    create database sqooptest;\r\n    Use sqooptest\r\n    create table person(pid int primary key auto_increment, name varchar(20), sex varchar(20));\r\n    insert into person(name, sex) values('james', 'Male');\r\n    insert into person(name, sex) values('lison', 'Female');\r\n    ```\r\n2. 全量导入\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\"\r\n\r\n    hadoop fs -cat /user/person/part-m-00000\r\n    ```\r\n3. 带查询条件导入: `$CONDITIONS` 不能省略, 要链接 sqoop 默认的条件\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\" \\\r\n        --query 'select name,sex from person where pid <=1 and $CONDITIONS;'\r\n\r\n    hadoop fs -cat /user/person/part-m-00000\r\n    ```\r\n4. 导入特定列\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\" \\\r\n        --columns pid,sex \\\r\n        --table person\r\n    ```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.3. Sqoop Mysql 导入 HDFS"
    },
    "frontmatter": {
      "title": "14.3. Sqoop Mysql 导入 HDFS",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.1. Demo 单词统计",
    "path": "/docs/architect/hadoop/Hadoop-15.1.Demodancitongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.1.Demodancitongji.html",
    "content": "---\r\ntitle: 15.1. Demo 单词统计\r\ndate: 2025/07/02\r\n---\r\n\r\n导入 `hadoop` 和 `hadoop.mapreduce` 包下的类\r\n\r\n## WCMapper.java\r\n```java\r\n// 泛型分别是：输入的键值类型; 输出的键值类型 \r\npublic class WCMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\r\n\r\n    @Override\r\n    protected void map(LongWritable key, @NotNull Text value, Context context) throws IOException, InterruptedException {\r\n        String line = value.toString();\r\n        String[] words = line.split(\" \");\r\n        for (String word : words) {\r\n            context.write(new Text(word), new IntWritable(1));\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n\r\n## WCReducer.java\r\n```java\r\n// 泛型分别是：输入的键值类型; 输出的键值类型 \r\npublic class WCReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\r\n\r\n    @Override\r\n    protected void reduce(Text key, @NotNull Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\r\n        int count = 0;\r\n        for (IntWritable v : values) {\r\n            count += v.get();\r\n        }\r\n        context.write(key, new IntWritable(count));\r\n    }\r\n\r\n}\r\n```\r\n\r\n## WCJob.java\r\n```java\r\npublic class WCJob {\r\n\r\n    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n\r\n        job.setJarByClass(WCJob.class);\r\n\r\n        job.setMapperClass(WCMapper.class);\r\n        job.setReducerClass(WCReducer.class);\r\n        \r\n//        Mapper 输出键值类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n\r\n//        Reducer 输出键值类型\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n\r\n//         前期准备, 在 Hadoop /wc/input 目录中上传进待分析的文件\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\"));\r\n\r\n//        等待执行完并检查是否执行成功\r\n        System.exit(job.waitForCompletion(true)? 0:-1);\r\n    }\r\n\r\n}\r\n```\r\n\r\n## pom.xml\r\n```xml\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-jar-plugin</artifactId>\r\n                <version>3.3.0</version>\r\n                <configuration>\r\n                    <archive>\r\n                        <manifest>\r\n                            <addClasspath>true</addClasspath>\r\n                            <classpathPrefix>lib/</classpathPrefix>\r\n                            <mainClass>org.jxch.study.hadoop.mr.wc.WCJob</mainClass>\r\n                        </manifest>\r\n                    </archive>\r\n                </configuration>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 运行\r\n编译 jar 包: `mvn package -Dmaven.test.skip=true -f pom.xml`\r\n将 jar 包上传到 Hadoop 服务器之后，执行命令: `hadoop jar /home/jxch/study-hadoop-1.0-SNAPSHOT.jar `\r\n\r\n跑完后，检查运行结果:\r\n* `hadoop fs -ls /wc/output`\r\n* `hadoop fs -cat /wc/output/part-r-00000`\r\n\r\n---\r\n\r\n## 依赖包\r\n```xml\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-common</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-hdfs</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-client</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>junit</groupId>\r\n            <artifactId>junit</artifactId>\r\n            <version>4.13.2</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-api</artifactId>\r\n            <version>2.0.7</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-simple</artifactId>\r\n            <version>2.0.7</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.projectlombok</groupId>\r\n            <artifactId>lombok</artifactId>\r\n            <version>1.18.26</version>\r\n            <scope>provided</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.jetbrains</groupId>\r\n            <artifactId>annotations</artifactId>\r\n            <version>RELEASE</version>\r\n            <scope>compile</scope>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.1. Demo 单词统计",
      "lvl1": "WCMapper.java",
      "lvl2": "WCReducer.java",
      "lvl3": "WCJob.java",
      "lvl4": "pom.xml",
      "lvl5": "运行",
      "lvl6": "依赖包"
    },
    "frontmatter": {
      "title": "15.1. Demo 单词统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.2. Demo 单词分组排序统计",
    "path": "/docs/architect/hadoop/Hadoop-15.2.Demodancifenzupaixutongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.2.Demodancifenzupaixutongji.html",
    "content": "---\r\ntitle: 15.2. Demo 单词分组排序统计\r\ndate: 2025/07/02\r\n---\r\n\r\n先进行单词统计: [15.Demo单词统计](./Hadoop-15.Demo单词统计.md)\r\n\r\n## 排序\r\n利用对Mapper输出的Key的自动排序进行排序\r\n\r\n```java\r\npublic class WCSortMapper extends Mapper<LongWritable, Text, DescIntWritable, Text> {\r\n    @Override\r\n    protected void map(LongWritable key, @NotNull Text value, @NotNull Context context) throws IOException, InterruptedException {\r\n        String line = value.toString();\r\n        String[] words = line.split(\"\\t\");\r\n        if (words.length == 2) {\r\n            context.write(new DescIntWritable(Integer.parseInt(words[1])), new Text(words[0]));\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n```java\r\npublic class WCSortReducer extends Reducer<DescIntWritable, Text, Text, IntWritable> {\r\n    @Override\r\n    protected void reduce(DescIntWritable key, @NotNull Iterable<Text> values, Context context) throws IOException, InterruptedException {\r\n        for (Text word : values) {\r\n            context.write(word, key);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n```java\r\npublic class DescIntWritable extends IntWritable {\r\n\r\n    public DescIntWritable() {\r\n    }\r\n\r\n    public DescIntWritable(int value) {\r\n        super(value);\r\n    }\r\n\r\n    @Override\r\n    public int compareTo(IntWritable o) {\r\n        return -super.compareTo(o);\r\n    }\r\n}\r\n```\r\n\r\n## 分组\r\n\r\n```java\r\npublic class WCPartitioner extends Partitioner<DescIntWritable, Text> {\r\n\r\n    @Override\r\n    public int getPartition(DescIntWritable descIntWritable, @NotNull Text text, int numPartitions) {\r\n        return text.toString().contains(\"jxch\") ? 0 : 1;\r\n    }\r\n\r\n}\r\n```\r\n\r\n## Job\r\n先完成单词统计的任务，然后在此基础上进行分组排序\r\n```java\r\npublic class WCSortJob {\r\n    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {\r\n        Job job = Job.getInstance(new Configuration());\r\n\r\n        job.setJarByClass(WCSortJob.class);\r\n\r\n        job.setMapperClass(WCMapper.class);\r\n        job.setReducerClass(WCReducer.class);\r\n\r\n//        Mapper 输出键值类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n\r\n//        Reducer 输出键值类型\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\"));\r\n\r\n//        等待执行完并检查是否执行成功\r\n        if (job.waitForCompletion(true)) {\r\n            Job sortJob = Job.getInstance(new Configuration());\r\n\r\n            sortJob.setJarByClass(WCSortJob.class);\r\n            sortJob.setMapperClass(WCSortMapper.class);\r\n            sortJob.setReducerClass(WCSortReducer.class);\r\n            sortJob.setMapOutputKeyClass(DescIntWritable.class);\r\n            sortJob.setMapOutputValueClass(Text.class);\r\n            sortJob.setOutputKeyClass(Text.class);\r\n            sortJob.setOutputValueClass(IntWritable.class);\r\n            sortJob.setInputFormatClass(TextInputFormat.class);\r\n            sortJob.setOutputFormatClass(TextOutputFormat.class);\r\n            sortJob.setPartitionerClass(WCPartitioner.class);\r\n            sortJob.setNumReduceTasks(2);\r\n\r\n            FileInputFormat.setInputPaths(sortJob, new Path(\"/wc/output\"));\r\n            FileOutputFormat.setOutputPath(sortJob, new Path(\"/wc/output_sort\"));\r\n\r\n            System.exit(sortJob.waitForCompletion(true)? 0:-1);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n## pom.xml\r\n```xml\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-jar-plugin</artifactId>\r\n                <version>3.3.0</version>\r\n                <configuration>\r\n                    <archive>\r\n                        <manifest>\r\n                            <addClasspath>true</addClasspath>\r\n                            <classpathPrefix>lib/</classpathPrefix>\r\n                            <mainClass>org.jxch.study.hadoop.mr.wc.sort.WCSortJob</mainClass>\r\n                        </manifest>\r\n                    </archive>\r\n                </configuration>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 运行\r\n编译 jar 包: `mvn package -Dmaven.test.skip=true -f pom.xml`\r\n将 jar 包上传到 Hadoop 服务器之后，执行命令: `hadoop jar /home/jxch/study-hadoop-1.1-SNAPSHOT.jar `\r\n\r\n跑完后，检查运行结果:\r\n* `hadoop fs -ls /wc/output_sort`\r\n* `hadoop fs -cat /wc/output_sort/part-r-00000`\r\n* `hadoop fs -cat /wc/output_sort/part-r-00001`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.2. Demo 单词分组排序统计",
      "lvl1": "排序",
      "lvl2": "分组",
      "lvl3": "Job",
      "lvl4": "pom.xml",
      "lvl5": "运行"
    },
    "frontmatter": {
      "title": "15.2. Demo 单词分组排序统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.3. Demo 倒排索引-文章单词统计",
    "path": "/docs/architect/hadoop/Hadoop-15.3.Demodaopaisuoyin-wenzhangdancitongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.3.Demodaopaisuoyin-wenzhangdancitongji.html",
    "content": "---\r\ntitle: 15.3. Demo 倒排索引-文章单词统计\r\ndate: 2025/07/02\r\n---\r\n\r\n## 思路 (倒推法)\r\n\r\n第二步:\r\n* Reduce\r\n    * key:单词\r\n    * values[] 文章--次数\r\n* Map \r\n    * key: 单词\r\n    * value: 文章--次数\r\n\r\n第一步:\r\n* Reduce\r\n    * key: 单词--文档位置 \r\n    * value: 单词次数\r\n* Map\r\n    * key: 单词--文档位置 \r\n    * value: 1\r\n\r\n---\r\n\r\n## JAVA 代码\r\n\r\n### IndexStepOne.java\r\n```java\r\npublic class IndexStepOne {\r\n    public static class IndexStepOneMapper extends Mapper<LongWritable, Text, Text, IntWritable>{\r\n        Text k = new Text();\r\n        IntWritable v = new IntWritable(1);\r\n\r\n        @Override\r\n        protected void map(LongWritable key, Text value,Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] words = line.split(\" \");\r\n            FileSplit Split = (FileSplit)context.getInputSplit();\r\n            String filename = Split.getPath().getName();\r\n            //输出 key :单词--文件名 value:1\r\n            for(String word : words){\r\n                k.set(word +\"--\"+ filename);\r\n                context.write(k, v);\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class IndexStepOneReducer extends Reducer<Text, IntWritable, Text, IntWritable>{\r\n        IntWritable v = new IntWritable();\r\n\r\n        @Override\r\n        protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\r\n            int count = 0;\r\n            for(IntWritable value : values){\r\n                count += value.get();\r\n            }\r\n            v.set(count);\r\n            context.write(key, v);\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(IndexStepOne.class);\r\n        job.setMapperClass(IndexStepOneMapper.class);\r\n        job.setReducerClass(IndexStepOneReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n        //这里可以进行 combiner 组件的设置\r\n        job.setCombinerClass(IndexStepOneReducer.class);\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:/index/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:/index/output-1\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n### IndexStepTwo.java\r\n```java\r\npublic class IndexStepTwo {\r\n    public static class IndexStepTwoMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        Text k = new Text();\r\n        Text v = new Text();\r\n        \r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] fields = line.split(\"\\t\");\r\n            String word_file = fields[0];\r\n            String count = fields[1];\r\n            String[] split = word_file.split(\"--\");\r\n            String word = split[0];\r\n            String file = split[1];\r\n            k.set(word);\r\n            v.set(file+\"--\"+count);\r\n            context.write(k, v);\r\n        }\r\n    }\r\n\r\n    public static class IndexStepTwoReducer extends Reducer<Text, Text, Text, Text>{\r\n        Text v = new Text();\r\n\r\n        @Override\r\n        protected void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for (Text value : values) {\r\n                sBuffer.append(value.toString()).append(\" \");\r\n            }\r\n            v.set(sBuffer.toString());\r\n            context.write(key, v);\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(IndexStepTwo.class);\r\n        //告诉程序，我们的程序所用的 mapper 类和 reducer 类是什么\r\n        job.setMapperClass(IndexStepTwoMapper.class);\r\n        job.setReducerClass(IndexStepTwoReducer.class);\r\n        //告诉框架，我们程序输出的数据类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        //这里可以进行 combiner 组件的设置\r\n        job.setCombinerClass(IndexStepTwoReducer.class);\r\n        //告诉框架，我们要处理的数据文件在那个路劲下\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:/index/output-1\"));\r\n        //告诉框架，我们的处理结果要输出到什么地方\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:/index/output-2\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.3. Demo 倒排索引-文章单词统计",
      "lvl1": "思路 (倒推法)",
      "lvl2": "JAVA 代码"
    },
    "frontmatter": {
      "title": "15.3. Demo 倒排索引-文章单词统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.4. Demo 共同好友",
    "path": "/docs/architect/hadoop/Hadoop-15.4.Demogongtonghaoyou.html",
    "url": "/docs/architect/hadoop/Hadoop-15.4.Demogongtonghaoyou.html",
    "content": "---\r\ntitle: 15.4. Demo 共同好友\r\ndate: 2025/07/02\r\n---\r\n\r\n## 思路\r\n原数据:\r\n```text\r\nA:B,C,D,F,E,O\r\nB:A,C,E,K\r\nC:F,A,D,I\r\nD:A,E,F,L\r\nE:B,C,D,M,L\r\nF:A,s,C,D,E,O,M\r\nG:A,C,D,E,F\r\nH:A,C,D,E,O\r\nI:A,O\r\nJ:B,O\r\nK:A,C,D\r\nL:D,E,F\r\nM:E,F,G\r\nO:A,H,I,J\r\n```\r\n\r\n1. 先找出一个用户是哪些用户的共同好友（比如 C 是哪些用户的共同好友，以上题目中的 C 是用户 A,B,E,F,G,H,K 的共同好友，所以 AB 的共同好友为 C，AE 的共同好友为 C，以此类推。。。）\r\n2. 经过第一步推算，得到 AE 的 共同好友还有 D，最后将 AE 的共同好友合并得到 C,D，这只是举个例子，他们的共同好友还有很多，即将两两用户作为 key，好友作为 value，以此类推，因此需要写两个 mapreduce\r\n\r\n## JAVA 代码\r\n### FriendsStepOne.java\r\n```java\r\npublic class FriendsStepOne {\r\n    public static class FriendsStepOneMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] splits = line.split(\":\");\r\n            String person = splits[0];\r\n            String[] friends = splits[1].split(\",\");\r\n            for(String fString :friends){\r\n                context.write(new Text(fString), new Text(person));\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class FriendsStepOneReducer extends Reducer<Text, Text, Text, Text>{\r\n        @Override\r\n        protected void reduce(Text friend, Iterable<Text> persons, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for(Text pText :persons){\r\n                sBuffer.append(pText).append(\"-\");\r\n            }\r\n            context.write(friend, new Text(sBuffer.toString()));\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(FriendsStepOne.class);\r\n        job.setMapperClass(FriendsStepOneMapper.class);\r\n        job.setReducerClass(FriendsStepOneReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:\\\\friends\\\\input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:\\\\friends\\\\output-1\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n### FriendsStepTwo.java\r\n```java\r\npublic class FriendsStepTwo {\r\n    public static class FriendsStepTwoMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] splits = line.split(\"\\t\");\r\n            String friend = splits[0];\r\n            String[] persons = splits[1].split(\"-\");\r\n            Arrays.sort(persons);\r\n            for (int i = 0; i < persons.length-1; i++) {\r\n                for (int j = i+1; j < persons.length; j++) {\r\n                    context.write(new Text(persons[i]+\"-\"+persons[j]), new Text(friend));\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class FriendsStepTwoReducer extends Reducer<Text, Text, Text, Text>{\r\n        @Override\r\n        protected void reduce(Text person_pair, Iterable<Text> friends, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for(Text fText : friends){\r\n                sBuffer.append(fText).append(\" \");\r\n            }\r\n            context.write(person_pair, new Text(sBuffer.toString()));\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(FriendsStepTwo.class);\r\n        job.setMapperClass(FriendsStepTwoMapper.class);\r\n        job.setReducerClass(FriendsStepTwoReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:\\\\friends\\\\output-1\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:\\\\friends\\\\output-2\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.4. Demo 共同好友",
      "lvl1": "思路",
      "lvl2": "JAVA 代码"
    },
    "frontmatter": {
      "title": "15.4. Demo 共同好友",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.5. Demo 自定义 InputFileFormat",
    "path": "/docs/architect/hadoop/Hadoop-15.5.DemozidingyiInputFileFormat.html",
    "url": "/docs/architect/hadoop/Hadoop-15.5.DemozidingyiInputFileFormat.html",
    "content": "---\r\ntitle: 15.5. Demo 自定义 InputFileFormat\r\ndate: 2025/07/02\r\n---\r\n\r\n以 excel 的文件举例\r\n\r\n## pom.xml\r\n```xml\r\n<dependency>\r\n    <groupId>net.sourceforge.jexcelapi</groupId>\r\n    <artifactId>jxl</artifactId>\r\n    <version>2.6.12</version>\r\n</dependency>\r\n```\r\n\r\n## ExcelInputFormat.java\r\n```java\r\npublic class ExcelFileInputFormat extends FileInputFormat<IntWritable,Text> {\r\n    @Override\r\n    protected boolean isSplitable(JobContext context, Path filename) {\r\n        return false;\r\n    }\r\n    public RecordReader<IntWritable, Text> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {\r\n        return new ExcelRecordReader();\r\n    }\r\n}\r\n```\r\n\r\n## ExcelRecordReader.java\r\n```java\r\npublic class ExcelRecordReader extends RecordReader<IntWritable,Text> {\r\n    private int rows;\r\n    private int current = -1;\r\n    private Sheet sheet;\r\n    private Workbook workbook;\r\n    \r\n    @Override\r\n    public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {\r\n        FileSplit filesplit = (FileSplit) split;\r\n        Configuration conf= context.getConfiguration();\r\n        Path filePath =filesplit.getPath();\r\n        FileSystem fs=filePath.getFileSystem(conf);\r\n        FSDataInputStream inputStream = fs.open(filePath);\r\n        try {\r\n            workbook = Workbook.getWorkbook(inputStream);\r\n            sheet = workbook.getSheets()[0];\r\n            rows = sheet.getRows();\r\n        } catch (BiffException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public boolean nextKeyValue() throws IOException, InterruptedException {\r\n        if(current<rows-1) {\r\n            current++;\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n\r\n    @Override\r\n    public IntWritable getCurrentKey() throws IOException, InterruptedException {\r\n        return new IntWritable(current);\r\n    }\r\n\r\n    @Override\r\n    public Text getCurrentValue() throws IOException, InterruptedException {\r\n        StringBuffer sb = new StringBuffer(\"\");\r\n        for(int i=0; i<sheet.getColumns(); i++){\r\n            Cell cell = sheet.getCell(i, current);\r\n            sb.append(cell.getContents() + \" \");\r\n        }\r\n        return new Text(sb.toString());\r\n    }\r\n\r\n    @Override\r\n    public float getProgress() throws IOException, InterruptedException {\r\n        return current/rows;\r\n    }\r\n\r\n    @Override\r\n    public void close() throws IOException {\r\n        workbook.close();\r\n    }\r\n}\r\n```\r\n\r\n## ExcelMapper.java\r\n```java\r\npublic class ExcelMapper extends Mapper<IntWritable,Text,IntWritable,Text> {\r\n    @Override\r\n    protected void map(IntWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n        super.map(key, value, context);\r\n    }\r\n}\r\n```\r\n\r\n## ExcelJob.java\r\n```java\r\npublic class ExcelJob {\r\n    public static void main(String[] args) throws Exception{\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(ExcelJob.class);\r\n        job.setMapperClass(ExcelMapper.class);\r\n        job.setMapOutputKeyClass(IntWritable.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setInputFormatClass(ExcelFileInputFormat.class);\r\n        //不需要Reduce\r\n        job.setNumReduceTasks(0);\r\n        //指定文件得读取位置\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/excel\"));\r\n        //指定文件得输出位置\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/excelout\"));\r\n\r\n        System.exit(job.waitForCompletion(true) ? 0 : -1);\r\n    }\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.5. Demo 自定义 InputFileFormat",
      "lvl1": "pom.xml",
      "lvl2": "ExcelInputFormat.java",
      "lvl3": "ExcelRecordReader.java",
      "lvl4": "ExcelMapper.java",
      "lvl5": "ExcelJob.java"
    },
    "frontmatter": {
      "title": "15.5. Demo 自定义 InputFileFormat",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.6. Demo 自定义 OutputFileFormat",
    "path": "/docs/architect/hadoop/Hadoop-15.6.DemozidingyiOutputFileFormat.html",
    "url": "/docs/architect/hadoop/Hadoop-15.6.DemozidingyiOutputFileFormat.html",
    "content": "---\r\ntitle: 15.6. Demo 自定义 OutputFileFormat\r\ndate: 2025/07/02\r\n---\r\n\r\n如果单词是老师人名，放到一个目录，否则放到另外一个目录\r\n\r\n## TeacherOutPutFormat.java\r\n```java\r\npublic class TeacherOutPutFormat extends FileOutputFormat<Text,NullWritable> {\r\n    \r\n    public RecordWriter<Text,NullWritable> getRecordWriter(TaskAttemptContext job) throws IOException, InterruptedException {\r\n        FileSystem fs = FileSystem.get(job.getConfiguration());\r\n        Path teacherPath = new Path(\"/wc/excelteacher/excelteacher.txt\");\r\n        Path otherPath = new Path(\"/wc/excelother/excelother.txt\");\r\n        FSDataOutputStream teacherOut = fs.create(teacherPath);\r\n        FSDataOutputStream otherOut = fs.create(otherPath);\r\n        return new TeacherRecordWriter(teacherOut,otherOut);\r\n    }\r\n\r\n    static class TeacherRecordWriter extends RecordWriter<Text,NullWritable> {\r\n        FSDataOutputStream teacherOut;\r\n        FSDataOutputStream otherOut;\r\n        \r\n        public TeacherRecordWriter(FSDataOutputStream teacherOut, FSDataOutputStream otherOut) {\r\n            this.teacherOut = teacherOut;\r\n            this.otherOut = otherOut;\r\n        }\r\n\r\n        public void write(Text key, NullWritable value) throws IOException, InterruptedException {\r\n            String keyStr = key.toString()+\"\\n\";\r\n            if(keyStr.contains(\":teacher\")){\r\n                String resultKey = keyStr.replace(\":teacher\", \"\");\r\n                teacherOut.write(resultKey.getBytes());\r\n            }else {\r\n                otherOut.write(keyStr.getBytes());\r\n            }\r\n        }\r\n\r\n        public void close(TaskAttemptContext context) throws IOException, InterruptedException {\r\n            if(teacherOut !=null) {\r\n                teacherOut.close();\r\n            }\r\n            if(otherOut !=null) {\r\n                otherOut.close();\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n## ExcelMapper.java\r\n```java\r\npublic class ExcelMapper extends Mapper<IntWritable,Text,Text,NullWritable> {\r\n    private List<String> teachers = null;\r\n    \r\n    @Override\r\n    protected void map(IntWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n        String[] words = value.toString().split(\" \");\r\n        for(String word :words) {\r\n            if(teachers.contains(word)) {\r\n                word = word+\":teacher\";\r\n            }\r\n            context.write(new Text(word),NullWritable.get());\r\n        }\r\n    }\r\n\r\n    @Override\r\n    protected void setup(Context context) throws IOException, InterruptedException {\r\n        teachers = new ArrayList<String>();\r\n        teachers.add(\"deer\");\r\n        teachers.add(\"james\");\r\n        teachers.add(\"peter\");\r\n        teachers.add(\"lison\");\r\n        teachers.add(\"king\");\r\n        teachers.add(\"mark\");\r\n    }\r\n}\r\n```\r\n\r\n## ExcelJob.java\r\n```java\r\npublic class ExcelJob {\r\n    public static void main(String[] args) throws Exception{\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(ExcelJob.class);\r\n        job.setMapperClass(ExcelMapper.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(NullWritable.class);\r\n        job.setInputFormatClass(ExcelFileInputFormat.class);\r\n        job.setOutputFormatClass(TeacherOutPutFormat.class);\r\n        //不需要Reduce\r\n        job.setNumReduceTasks(0);\r\n        //指定文件得读取位置\r\n        FileInputFormat.setInputPaths(job,new Path(\"D:\\\\wc\\\\excel\"));\r\n        //指定文件得输出位置 还有success文件需要输出 \r\n        FileOutputFormat.setOutputPath(job,new Path(\"D:\\\\wc\\\\excelout\"));\r\n\r\n        System.exit(job.waitForCompletion(true) ? 0 : -1);\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.6. Demo 自定义 OutputFileFormat",
      "lvl1": "TeacherOutPutFormat.java",
      "lvl2": "ExcelMapper.java",
      "lvl3": "ExcelJob.java"
    },
    "frontmatter": {
      "title": "15.6. Demo 自定义 OutputFileFormat",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.7. Demo 文件操作 FileSystem",
    "path": "/docs/architect/hadoop/Hadoop-15.7.DemowenjiancaozuoFileSystem.html",
    "url": "/docs/architect/hadoop/Hadoop-15.7.DemowenjiancaozuoFileSystem.html",
    "content": "---\r\ntitle: 15.7. Demo 文件操作 FileSystem \r\ndate: 2025/07/02\r\n---\r\n\r\n\r\n## FSTest.java\r\n```java\r\n/**\r\n * 需要安装Hadoop程序, 并配置环境变量(HADOOP_HOME)\r\n * 不配置也可以使用部分功能\r\n * 配置本地的hosts文件, 对应hadoop01的ip地址\r\n */\r\n@Slf4j\r\npublic class FSTest {\r\n\r\n    public static FileSystem fileSystem;\r\n\r\n\r\n    @Before\r\n    public void init() throws URISyntaxException, IOException, InterruptedException {\r\n        fileSystem = FileSystem.get(new URI(\"hdfs://hadoop01:9000\"), new Configuration(), \"root\");\r\n    }\r\n\r\n    @After\r\n    public void close() throws IOException {\r\n        fileSystem.close();\r\n    }\r\n\r\n    //显示根目录下文件\r\n    @Test\r\n    public void showRootFiles() throws Exception {\r\n        RemoteIterator<LocatedFileStatus> files = fileSystem.listFiles(new Path(\"/\"), false);\r\n        while (files.hasNext()) {\r\n            LocatedFileStatus fileStatus = files.next();\r\n            Path path = fileStatus.getPath();\r\n            String name = path.getName();\r\n            log.info(\"{} -> {}\", path, name);\r\n        }\r\n    }\r\n\r\n    //测试上传文件\r\n    @Test\r\n    public void testCopyFromLocalFile() throws Exception {\r\n        Path src = new Path(\"E:\\\\work\\\\test.txt\");\r\n        Path dst = new Path(\"/\");\r\n        fileSystem.copyFromLocalFile(src, dst);\r\n    }\r\n\r\n    //测试删除文件\r\n    @Test\r\n    public void testDelete() throws Exception {\r\n        Path dst = new Path(\"/test.txt\");\r\n        fileSystem.delete(dst, true);\r\n    }\r\n\r\n    //测试使用流的方式上传\r\n    @Test\r\n    public void testUploadUseStream() throws Exception {\r\n        FileInputStream fis = new FileInputStream(\"E:\\\\work\\\\test.txt\");\r\n        Path path = new Path(\"/test.txt\");\r\n        FSDataOutputStream fos = fileSystem.create(path);\r\n        IOUtils.copy(fis, fos);\r\n    }\r\n\r\n    //测试下载文件\r\n    @Test\r\n    public void testCopyToLocalFile() throws Exception {\r\n//        这种方式只有配置了HADOOP_HOME之后才能使用\r\n//        fileSystem.copyToLocalFile(new Path(\"/test.txt\"), new Path(\"E:\\\\work\\\\test2.txt\"));\r\n\r\n//        使用Java默认的方式 (RawLocalFileSystem)\r\n        fileSystem.copyToLocalFile(false, new Path(\"/test.txt\"), new Path(\"E:\\\\work\\\\test2.txt\"), true);\r\n    }\r\n}\r\n```\r\n\r\n\r\n## pom.xml\r\n```xml\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-common</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-hdfs</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-client</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>junit</groupId>\r\n            <artifactId>junit</artifactId>\r\n            <version>4.13.2</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-api</artifactId>\r\n            <version>2.0.7</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-simple</artifactId>\r\n            <version>2.0.7</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.projectlombok</groupId>\r\n            <artifactId>lombok</artifactId>\r\n            <version>1.18.26</version>\r\n            <scope>provided</scope>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.7. Demo 文件操作 FileSystem",
      "lvl1": "FSTest.java",
      "lvl2": "pom.xml"
    },
    "frontmatter": {
      "title": "15.7. Demo 文件操作 FileSystem",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "16.1. 启动时没有启动 datanode",
    "path": "/docs/architect/hadoop/Hadoop-16.1.qidongshimeiyouqidongdatanode.html",
    "url": "/docs/architect/hadoop/Hadoop-16.1.qidongshimeiyouqidongdatanode.html",
    "content": "---\r\ntitle: 16.1. 启动时没有启动 datanode\r\ndate: 2025/07/02\r\n---\r\n\r\n原因:\r\n在第一次格式化`dfs`后，启动并使用了`hadoop`，后来又重新执行了格式化命令 `hdfs namenode -format`，这时`namenode`的`clusterID`会重新生成，而`datanode`的`clusterID` 保持不变。\r\n\r\n解决方法:\r\n1. 删除目录，重新格式化\r\n2. 将`name/current`下的`VERSION`中的`clusterID`复制到`data/current`下的`VERSION`中，覆盖掉原来的`clusterID`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "16.1. 启动时没有启动 datanode"
    },
    "frontmatter": {
      "title": "16.1. 启动时没有启动 datanode",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "16.2. ClassNotFoundException",
    "path": "/docs/architect/hadoop/Hadoop-16.2.ClassNotFoundException.html",
    "url": "/docs/architect/hadoop/Hadoop-16.2.ClassNotFoundException.html",
    "content": "---\r\ntitle: 16.2. ClassNotFoundException\r\ndate: 2025/07/02\r\n---\r\n\r\n1. 输入命令 `hadoop classpath`, 将结果复制下来\r\n2. `mapred-site.xml` 中加入:\r\n```xml\r\n  <property>\r\n     <name>mapreduce.application.classpath</name>\r\n     <value>刚才复制的值</value>\r\n   </property>\r\n```\r\n1. `yarn-site.xml` 中加入:\r\n```xml\r\n  <property>\r\n     <name>yarn.application.classpath</name>\r\n     <value>刚才复制的值</value>\r\n   </property>\r\n\r\n```\r\n4. 重启 hadoop 集群\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "16.2. ClassNotFoundException"
    },
    "frontmatter": {
      "title": "16.2. ClassNotFoundException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "17.1. 常用命令 fs",
    "path": "/docs/architect/hadoop/Hadoop-17.1.changyongminglingfs.html",
    "url": "/docs/architect/hadoop/Hadoop-17.1.changyongminglingfs.html",
    "content": "---\r\ntitle: 17.1. 常用命令 fs\r\ndate: 2025/07/02\r\n---\r\n\r\n|命令|作用|\r\n|-|-|\r\n|`hadoop fs -help`|帮助命令|\r\n|`hadoop fs -ls /`|显示目录信息|\r\n|`hadoop fs -ls hdfs://hadoop01:9000/`|显示目录信息(使用Nn节点)|\r\n|`hadoop fs -mkdir -p /path1/path2/path3`|创建目录|\r\n|`hadoop fs -moveFromLocal /file/a.txt /path1/path2`|从本地剪切粘贴到hdfs|\r\n|`hadoop fs -appendToFile  b.txt /file/a.txt`|追加文件|\r\n|`hadoop fs -cat /a.txt`|显示文件|\r\n|`hadoop fs -chmod 666 /file/a.txt`|改权限|\r\n|`hadoop fs -chown root:root /file/a.txt`|改组和拥有者|\r\n|`hadoop fs -chgrp group /file/a.txt`|改组|\r\n|`hadoop fs -copyFromLocal ./b.txt /`|拷贝文件到HDFS (上传)|\r\n|`hadoop fs -copyToLocal /b.txt /c.txt`|拷贝HDFS文件到本地 (下载)|\r\n|`hadoop fs -cp /aa.txt /bbb.txt`|复制|\r\n|`hadoop fs -mv /aa.txt /bbb.txt`|移动|\r\n|`hadoop fs -get /aa.txt`|下载|\r\n|`hadoop fs -put aa.txt /file`|上传|\r\n|`hadoop fs -getmerge /file bb.txt`|合并下载某个目录中的多个文件|\r\n|`hadoop fs -rmdir /file1/file2`|删除空目录|\r\n|`hadoop fs -rm -r /d.txt`|删除文件或文件夹|\r\n|`hadoop fs -df -h /`|统计文件系统可用空间|\r\n|`hadoop fs -du -s -h /file`|统计文件夹大小|\r\n|`hadoop fs -count /file`|统计文件夹节点数量|\r\n|`hadoop fs -setrep 3 /aa.txt`|设置副本数量|\r\n|`hdfs dfsadmin -report`|查看集群状态|\r\n\r\n---\r\n[官方文档](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html)\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "17.1. 常用命令 fs"
    },
    "frontmatter": {
      "title": "17.1. 常用命令 fs",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "2.节点",
    "path": "/docs/architect/hadoop/Hadoop-2.jiedian.html",
    "url": "/docs/architect/hadoop/Hadoop-2.jiedian.html",
    "content": "---\r\ntitle: 2.节点\r\ndate: 2025/07/02\r\n---\r\n\r\n* NN: NameNode fdfs 节点的 leader\r\n* DN: DataNode fdfs 的数据节点\r\n* SNN SecondaryNameNode fdfs 节点的镜像复制节点\r\n* RM: resoucemanager yarn 资源管理器的主节点\r\n* NM: nodemanager yarn 资源管理器的从节点\r\n* JN: JournalNode 日志节点\r\n\r\n---\r\n\r\n* ZKFC: DFSZKFailoverController Zookeeper 高可用控制\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.节点"
    },
    "frontmatter": {
      "title": "2.节点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "3. HDFS 读写文件流程",
    "path": "/docs/architect/hadoop/Hadoop-3.HDFSduxiewenjianliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-3.HDFSduxiewenjianliucheng.html",
    "content": "---\r\ntitle: 3. HDFS 读写文件流程\r\ndate: 2025/07/02\r\n---\r\n\r\n## HDFS 特点\r\n\r\n1. hdfs 里的文件是分块（block）存储的，默认大小是 128M\r\n2. hdfs 使用统一的抽象目录树管理文件，客户端不需要关心具体的文件分块\r\n    * 例如：hdfs://hadoop01:port/path1/path2/file\r\n3. 抽象目录树以及分块的信息由 namenode 节点管理\r\n4. 具体的 block 存储在每一个节点上，并且每一个 block 可以有多个副本（dfs.replication）\r\n5. Hdfs 适合设计成一次写入多次读取的情况，不支持修改\r\n\r\n## HDFS 写文件流程\r\n\r\n![HDFS 写文件流程](static/HDFS-W.png)\r\n\r\n举例来说，现在要上传一个 hadoop.jar 文件, 200M（按默认得配置应该分成两个 block [128,72]）\r\n对应命令是： `hadoop fs put hadoop.jar /`\r\n\r\n1. 客户端使用 FIleSystem 上传\r\n2. FIleSystem 与 namenode 进行通信，nn 会检查自己维护得目录树，判断当前目录是否存在\r\n3. 当 namenode 正确返回后，客户端再向 namenode 请求上传第一个 block, namenode 确认 datanode 的状态，把健康的 datanode 集合返回给客户端，客户端会根据返回的 datanode 集合挑选一个进行连接\r\n4. 客户端对每一个用于传输的节点都建立 pipeline 管道，并对传输第一个 block 块的数据（每次传输的并不是一整个 block 块，而是一个 packet，默认大小为 64K，64K 的 packet 中每次传输 512b 的数据时（一个 chunk）会进行一次校验）所以你可以把 packet 又理解成 chunk的集合\r\n5. 每个 datenode 写完个 block 后再返回确认信息\r\n6. 所有写完了，关闭输出流\r\n7. 整个完成后最后通知 namdenode 完成数据上传\r\n\r\n\r\n## HDFS 读文件流程\r\n\r\n![HDFS 写文件流程](static/HDFS-R.png)\r\n\r\n`hadoop fs get /hadoop.jar`\r\n\r\n1. client 访问 NameNode，查询元数据信息，获得这个文件的数据块位置列表，返回输入流对象。\r\n2. 就近挑选一台 datanode 服务器，请求建立输入流\r\n3. DataNode 向输入流中中写数据，以 packet 为单位\r\n4. 关闭输入流\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3. HDFS 读写文件流程",
      "lvl1": "HDFS 特点",
      "lvl2": "HDFS 写文件流程",
      "lvl3": "HDFS 读文件流程"
    },
    "frontmatter": {
      "title": "3. HDFS 读写文件流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "4.元数据管理 edits fsimage",
    "path": "/docs/architect/hadoop/Hadoop-4.yuanshujuguanli-edits_fsimage.html",
    "url": "/docs/architect/hadoop/Hadoop-4.yuanshujuguanli-edits_fsimage.html",
    "content": "---\r\ntitle: 4.元数据管理 edits fsimage\r\ndate: 2025/07/02\r\n---\r\n\r\n## 元数据的存储形式\r\nhdfs 的读写流程都离不开 namenode，在 namenode 中维护了文件、文件块的信息，这些信息统统称之为元数据\r\n\r\n元数据在 hdfs 中有 3 种存在形式 (<font color=\"red\">内存的数据 = fsimage + edits 文件</font>)\r\n1. 存在内存中，这个最全的元数据\r\n2. fsimage 磁盘元数据镜像文件\r\n3. 最新的操作日志文件\r\n\r\n查看存储结构:\r\n* `cd /soft/data/tmp/dfs/name/current`\r\n* `hdfs oev -i edits_0000000000000001913-0000000000000001959 -o edits.xml`\r\n* `hdfs oiv -i fsimage_0000000000000001972 -p XML -o fsimage.xml`\r\n\r\n## checkpoint\r\n当达到某个条件后，secondary namenode 会把 namenode 上保存的 edits 和最新的 fsimage 下载到本地，并把这些 edits 和 fsimage 进行合并，产生新的 fsimage，这整个过程把他称作 <font color=\"red\">checkpoint</font> ([官方文档](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml))\r\n\r\ncheckpoint 的条件配置 (hdfs-site.xml):\r\n```properties\r\n#检查触发条件是否满足的频率，60 秒\r\ndfs.namenode.checkpoint.check.period=60 \r\n\r\n# 以下两个参数做checkpoint 操作时，代表 secondary namenode 的本地工作目录\r\ndfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary\r\ndfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir} \r\n\r\n#最大重试次数\r\ndfs.namenode.checkpoint.max-retries=3 \r\n#两次 checkpoint 之间的时间间隔 3600 秒\r\ndfs.namenode.checkpoint.period=3600 \r\n#两次 checkpoint 之间最大的操作记录\r\ndfs.namenode.checkpoint.txns=1000000 \r\n```\r\n\r\n## checkpoint 工作机制\r\n\r\n![checkpoint 工作机制](static/checkpoint.png)\r\n\r\n1. SecondaryNameNode 会定时的和 NameNode 通信，请求其停止使用 edits 文件，暂时将新的写操作写到一个新的文件 edits.new 上，这个操作是瞬时完成的，上层的写日志函数完全感觉不到差别\r\n2. econdaryNameNode 通过 HTTP 的 get 方法从 NameNode 上获取到 fsimage 和 edits 文件，SecondaryNameNode 将 fsimage 文件载入内存中，逐一执行 edits 文件中的事务，创建新的合并后的 fsimage 文件，<font color=\"red\">使得内存中的 fsimage 保存最新</font>。\r\n3. SecondaryNameNode 执行完 2 之后，会通过 post 方法将新的 fsimage 文件发送到 NameNode 节点上\r\n4. NameNode 将从 SecondaryNameNode 接收到的新的 fsimage 文件保存为.ckpt 文件\r\n5. NameNode 重新命名 fsimage.ckpt 为 fsimage 替换旧的 fsimage 文件，同时将 edits.new 替换为 edits 文件，<font color=\"red\">通过这个过程 edits 文件就变小了</font>。\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.元数据管理 edits fsimage",
      "lvl1": "元数据的存储形式",
      "lvl2": "checkpoint",
      "lvl3": "checkpoint 工作机制"
    },
    "frontmatter": {
      "title": "4.元数据管理 edits fsimage",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "5. mapreduce 工作机制",
    "path": "/docs/architect/hadoop/Hadoop-5.mapreducegongzuojizhi.html",
    "url": "/docs/architect/hadoop/Hadoop-5.mapreducegongzuojizhi.html",
    "content": "---\r\ntitle: 5. mapreduce 工作机制\r\ndate: 2025/07/02\r\n---\r\n\r\n一个完整的 mapreduce 程序在分布式运行时有三类实例进程：\r\n1. MRAppMaster：负责整个程序的过程调度及状态协调\r\n2. MapTask：负责 map 阶段的整个数据处理流程\r\n3. ReduceTask：负责 reduce 阶段的整个数据处理流程\r\n\r\n---\r\n流程:\r\n1. 一个 mr 程序启动的时候，最先启动的是 MRAppMaster，MRAppMaster 启动后根据本次 job 的描述信息，计算出需要的 maptask 实例数量，然后向集群申请机器启动相应数量的 maptask 进程（这里先理解成一个文件一个 maptask）\r\n2. maptask 进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：\r\n    1. 利用客户指定的 inputformat 来获取数据，形成输入 K，V 对\r\n    2. 将输入 KV 对传递给客户定义的 `map()` 方法，做逻辑运算，并将 `map()` 方法输出的 KV 对收集到缓存\r\n    3. 将缓存中的 KV 对按照 K 分区排序后不断溢写到磁盘文件\r\n3. MRAppMaster 监控到所有 maptask 进程任务完成之后，会根据客户指定的参数启动相应数量的 reducetask 进程，并告知 reducetask 进程要处理的数据范围（数据分区）\r\n4. Reducetask 进程启动之后，根据 MRAppMaster 告知的待处理数据所在位置，从若干台 maptask 运行所在机器上获取到若干个 maptask 输出结果文件，并在本地进行重新归并排序，然后按照相同 key 的 KV 为一个组，调用客户定义的 `reduce()` 方法进行逻辑运算，并收集运算输出的结果 KV，然后调用客户指定的 outputformat 将结果数据输出到外部存储\r\n\r\n---\r\n\r\n{% mermaid %}\r\ngraph TD\r\n    M -.->|开启两个MapTask| C1\r\n    M -.->|所有maptask进程完成后<br>开启两个ReduceTask<br>告知数据所在位置| R1\r\n    M(MRAppMaster) --> A(input dir)\r\n    A --> B1([1.txt])\r\n    A --> B2([2.txt])\r\n    B1 --InputFormat<br>TextInputFormat--> C1([MapTask1])\r\n    B2 --InputFormat<br>TextInputFormat--> C2([MapTask2])\r\n    M -.->|开启两个MapTask| C2\r\n    C1 --Mapper.map-->D1([context.write])\r\n    C2 --Mapper.map-->D2([context.write])\r\n    D1 --> E1(内存缓存-环形缓冲区)\r\n    D2 --> E2(内存缓存-环形缓冲区)\r\n    E1 --按照KEY分区排序<br>写入磁盘--> F1(溢出文件1) \r\n    E1 --按照KEY分区排序<br>写入磁盘--> F2(溢出文件2) \r\n    E2 --按照KEY分区排序<br>写入磁盘--> F3(溢出文件3) \r\n    E2 --按照KEY分区排序<br>写入磁盘--> F4(溢出文件4)\r\n    F1 --> H1([Shuffle流程])\r\n    F2 --> H1([Shuffle流程])\r\n    F3 --> H2([Shuffle流程])\r\n    F4 --> H2([Shuffle流程])\r\n    H1 -.-> F5(所有客户机的数据)\r\n    H2 -.-> F5\r\n    F5 --从客户机获取溢出文件<br>key.hashcode%2=0--> R1([ReduceTask1])\r\n    F5 --从客户机获取溢出文件<br>key.hashcode%2=1--> R2([ReduceTask2])\r\n    M -.->|所有maptask进程完成后<br>开启两个ReduceTask<br>告知数据所在位置| R2\r\n    R1 --归并排序分组<br>Reducer.reduce--> G1([context.write])\r\n    R2 --归并排序分组<br>Reducer.reduce--> G2([context.write])\r\n    G1 --OutputFormat<br>TextOutputFormat--> P1(part-r-00000)\r\n    G2 --OutputFormat<br>TextOutputFormat--> P2(part-r-00001)\r\n{% endmermaid %}\r\n\r\n---\r\n\r\n关于Shuffle流程: [6.提交任务流程与Shuffle流程](./Hadoop-6.提交任务流程与Shuffle流程.md)\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5. mapreduce 工作机制"
    },
    "frontmatter": {
      "title": "5. mapreduce 工作机制",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "6.提交任务流程与 Shuffle 流程",
    "path": "/docs/architect/hadoop/Hadoop-6.tijiaorenwuliuchengyuShuffleliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-6.tijiaorenwuliuchengyuShuffleliucheng.html",
    "content": "---\r\ntitle: 6.提交任务流程与 Shuffle 流程\r\ndate: 2025/07/02\r\n---\r\n\r\n\r\nshuffle 并不是个组件，而是 mr 处理流程中的一个子过程，它过程开始于 maptask 把数据写入环形缓存一直到数据到 reduce 之间的整个过程\r\n\r\n![Shuffle 流程](static/shuffle.png)\r\n\r\n1. maptask 收集我们的 `map()` 方法输出的 kv 对，放到内存缓冲区中\r\n2. 从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件\r\n3. 多个溢出文件会被合并成大的溢出文件\r\n4. <font color=\"orange\">在溢出过程中，及合并 Combine 的过程中，都要调用 partitoner 进行分组和针对 key 进行排序 (compare)</font>\r\n5. reducetask 根据自己的分区号，去各个 maptask 机器上取相应的结果分区数据\r\n6. reducetask 会取到同一个分区的来自不同 maptask 的结果文件，<font color=\"orange\">reducetask 会将这些文件再进行合并（归并排序）</font>\r\n7. 合并成大文件后，shuffle 的过程也就结束了，后面进入 reducetask 的逻辑运算过程（从文件中取出一个个的键值对 group，调用用户自定义的 `reduce()`方法）\r\n8. 缓冲区的大小可以通过参数调整, 参数：`mapreduce.task.io.sort.mb` 默认 100M\r\n\r\n---\r\n[官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "6.提交任务流程与 Shuffle 流程"
    },
    "frontmatter": {
      "title": "6.提交任务流程与 Shuffle 流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "7.切片逻辑",
    "path": "/docs/architect/hadoop/Hadoop-7-qiepianluoji.html",
    "url": "/docs/architect/hadoop/Hadoop-7-qiepianluoji.html",
    "content": "---\r\ntitle: 7.切片逻辑\r\ndate: 2025/07/02\r\n---\r\n\r\n默认切片的大小与 hdfs 的 block 的 size 相等\r\n切片大小: `Math.max(minSize, Math.min(maxSize, blockSize))`\r\n* `mapreduce.input.fileinputformat.split.minsize` 默认值 `1`\r\n* `mapreduce.input.fileinputformat.split.maxsize` 默认值 `Long.MAX_VALUE`\r\n\r\n切片规则: `剩余长度 / splitsize < 1.1`\r\n\r\n---\r\n\r\n流程:\r\n\r\n{% mermaid %}\r\ngraph TD\r\n    A(input.txt) --> F([FileInputFormat])\r\n    F --> J([Jobsubmit])\r\n    J -.->|剩余/splitsize<1.1| S1([切片1])\r\n    J -.->|剩余/splitsize<1.1| S2([切片2])\r\n    S1 --写入文件--> JS(job.split)\r\n    S2 --写入文件--> JS(job.split)\r\n    JS --MrAppMaster--> M1([MapTask1])\r\n    JS --MrAppMaster--> M2([MapTask2])\r\n{% endmermaid %}\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "7.切片逻辑"
    },
    "frontmatter": {
      "title": "7.切片逻辑",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "8.YARN流程",
    "path": "/docs/architect/hadoop/Hadoop-8-YARNliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-8-YARNliucheng.html",
    "content": "---\r\ntitle: 8.YARN流程\r\ndate: 2025/07/02\r\n---\r\n\r\nYARN 是运算资源调度系统，他只做运算资源的分配和调度，不参与用户程序内部的具体工作，所以 YARN 可以作为一个通用的资源调度平台\r\n\r\n在 Hadoop1.x 的时候其实是没有 YRAN，当初的 MapReduce 由两个组件组成\r\n* Job Tracker: 相当于 RM + MrAppMaster\r\n* Task Tracker: 相当于 NM + Task(MapTask, ReduceTask)\r\n\r\n---\r\n\r\n![YARN 流程](static/YARN.png)\r\n\r\n1. 客户端程序向 ResourceManager 提交应用并请求一个 ApplicationMaster 实例\r\n2. ResourceManager 找到一个可以运行一个 Container 的 NodeManager，并在这个 Container 中启动 ApplicationMaster 实例\r\n3. ApplicationMaster 向 ResourceManager 进行注册 ，注册之后客户端就可以查询 ResourceManager 获得自己 ApplicationMaster 的详细信息 ，以后就可以和自己的 ApplicationMaster 直接交互了（这个时候，客户端主动和 ApplicationMaster 交互，应用先向 ApplicationMaster 发送一个满足自己需求的资源请求）\r\n4. 在平常的操作过程中，ApplicationMaster 根据协议向 ResourceManager 发送资源请求\r\n5. 当 Container 被成功分配后，ApplicationMaster 通过向 NodeManager 发送信息来启动 Container，信息包含了能够让 Container 和 ApplicationMaster 交互所需要的资料\r\n6. 应用程序的代码以 task 形式在启动的 Container 中运行，并把运行的进度、状态等信息通过协议发送给 ApplicationMaster\r\n7. 在应用程序运行期间，提交应用的客户端主动和 ApplicationMaster 交流获得应用的运行状态、进度更新等信息\r\n8. 一旦应用程序执行完成并且所有相关工作也已经完成，ApplicationMaster 向 ResourceManager 取消注册然后关闭，用到所有的 Container 也归还给系统\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "8.YARN流程"
    },
    "frontmatter": {
      "title": "8.YARN流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "9. mapreduce YARN 流程",
    "path": "/docs/architect/hadoop/Hadoop-9-mapreduce-YARNliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-9-mapreduce-YARNliucheng.html",
    "content": "---\r\ntitle: 9. mapreduce YARN 流程\r\ndate: 2025/07/02\r\n---\r\n\r\n![mapreduce-YARN流程](static/YARN-MR.png)\r\n\r\n1. 应用申请运行RM的JOB\r\n2. RM返回JOBID以及提交资源的目录\r\n3. 应用提交相关文件到资源目录\r\n4. 通知RM, JOB资源提交完毕\r\n5. RM初始任务TASK, 加入调度队列\r\n6. 空闲NM领取任务\r\n7. NM根据任务信息创建Container (并且从资源目录获取JOB资源)\r\n8. 应用发送指令启动NM的MrAppMaster\r\n9. MrAppMaster向RM请求运算节点\r\n10. MrAppMaster向请求回来的运算节点中启动MapTask\r\n11. MrAppMaster向请求回来的运算节点中启动ReduceTask\r\n12. JOB执行完成后, MrAppMaster向RM注销自己\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "9. mapreduce YARN 流程"
    },
    "frontmatter": {
      "title": "9. mapreduce YARN 流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "1.基础操作",
    "path": "/docs/architect/mongodb/MongoDB-1.jichucaozuo.html",
    "url": "/docs/architect/mongodb/MongoDB-1.jichucaozuo.html",
    "content": "---\r\ntitle: 1.基础操作\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- 特性：文档数据库（以 JSON 为数据模型）\r\n- Mongo shell：基于JavaScript（`interpreterVersion()`）\r\n- MongoDB 文档操作\r\n\r\n---\r\n## 特性\r\n\r\n- 数据格式是BSON，一种类似JSON的二进制形式的存储格式，简称Binary JSON \r\n- 集合（collection）：相当于SQL中的表，一个集合可以存放多个不同的文档\r\n- 文档（document）：一个文档相当于数据表中的一行，由多个不同的字段组成\r\n-  聚合操作（$lookup）：MongoDB用于实现“类似”表连接（tablejoin）的聚合操作符\r\n- 半结构化，在一个集合中，文档所拥有的字段并不需要是相同的，而且也不需要对所用的字段进行声明\r\n\t- 文档还可以支持多级的嵌套、数组等灵活的数据类型\r\n- 弱关系，MongoDB没有外键的约束，也没有非常强大的表连接能力。类似的功能需要使用聚合管道技术来弥补\r\n- 应用场景：不需要复杂/长事务和join支持\r\n- MongoDB Database Tools\r\n\t- mongostat 数据库性能监控工具\r\n\t- mongotop 热点表监控工具\r\n\t- mongodump 数据库逻辑备份工具\r\n\t- mongorestore 数据库逻辑恢复工具\r\n\t- mongoexport 数据导出工具\r\n\t- mongoimport 数据导入工具\r\n\t- bsondump BSON格式转换工具\r\n\t- mongofiles GridFS文件工具\r\n\r\n## Mongo shell\r\n\r\n- `show dbs | show databases`\r\n- use 数据库名 \r\n- `db.dropDatabase() `\r\n- `show collections | show tables`\r\n- `db.createCollection(\"集合名\", options)`\r\n\t- options\r\n\t\t- capped：（可选）如果为true，则创建固定集合。固定集合是指有着固定大小的集合，当达到最大值时，它会自动覆盖最早的文档\r\n\t\t\t- size：固定集合最大值（以字节计）\r\n\t\t\t- max：固定集合中包含文档的最大数量\r\n\t-  当集合不存在时，向集合中插入文档也会创建集合\r\n- `db.集合名.stats() `\r\n- `db.集合名.drop() `\r\n- `db.createUser({user:\"jxch\",pwd:\"jxch\",roles:[\"root\"]})` 创建管理员\r\n\t- 常用权限\r\n\t\t- `read readWrite`\r\n\t\t- `dbAdmin`  允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问`system.profile`\r\n\t\t- `dbOwner` 允许用户在指定数据库中执行任意操作，增、删、改、查等\r\n\t\t- `userAdmin`  允许用户向system.users集合写入，可以在指定数据库里创建、删除和管理用户\r\n\t\t- 只在 admin 数据库中可用\r\n\t\t\t- `clusterAdmin` 赋予用户所有分片和复制集相关函数的管理权限\r\n\t\t\t- `readAnyDatabase readWriteAnyDatabase` \r\n\t\t\t- `userAdminAnyDatabase` \r\n\t\t\t- `dbAdminAnyDatabase`\r\n\t\t\t- `root` 超级账号，超级权限\r\n\t- `db.grantRolesToUser( \"jxch\" , [{ role: \"clusterAdmin\", db: \"admin\" }])` 重新赋予用户操作权限\r\n\t- `db.dropUser(\"jxch\")`\r\n\t- `db.dropAllUser()` 删除当前数据库所有用户\r\n\t- `db.auth(\"jxch\", \"jxch\")` 用户认证，返回1表示认证成功\r\n\t\t- 默认情况下，MongoDB不会启用鉴权，以鉴权模式启动MongoDB\r\n\t\t\t- `mongod ‐f /mongodb/conf/mongo.conf ‐‐auth`\r\n\t\t\t- `mongo 192.168.65.174:27017 ‐u jxch ‐p jxch ‐‐authenticationDatabase=admin`\r\n\t- 创建应用数据库用户\r\n\t\t- `use appdb`\r\n\t\t- `db.createUser({user:\"jxch\",pwd:\"jxch\",roles:[\"dbOwner\"]})`\r\n- `show users | show roles```\r\n- `db.system.users.find() ` 显示所有用户\r\n- `show profile` 显示最近发生的操作\r\n- `load(\"xxx.js\") `\r\n- `exit | quit() `\r\n- `help | db.help() | db.集合名.help()`\r\n\r\n## MongoDB 文档操作\r\n\r\n- `db.xxxcollection.xxxfunc`\r\n- 插入文档\r\n\t- 新增单个文档\r\n\t\t- `insertOne` 支持 writeConcern\r\n\t\t\t- writeConcern 决定一个写操作落到多少个节点上才算成功\r\n\t\t\t\t- 0：发起写操作，不关心是否成功\r\n\t\t\t\t- 1~集群最大数据节点数：写操作需要被复制到指定节点数才算成功\r\n\t\t\t- majority：写操作需要被复制到大多数节点上才算成功\r\n\t\t- insert: 若插入的数据主键已经存在，则会抛 DuplicateKeyException 异常，提示主键重复，不保存当前数据\r\n\t\t- save: 如果 `_id` 主键存在则更新数据，如果不存在就插入数据\r\n\t- 批量新增文档 \r\n\t\t- `insertMany` 向指定集合中插入多条文档数据\r\n\t\t\t- writeConcern：写入策略，默认为 1，即要求确认写操作，0 是不要求\r\n\t\t\t- ordered：指定是否按顺序写入，默认 true，按顺序写入\r\n\t\t- insert和save也可以实现批量插入\r\n- 查询文档\r\n\t- find 查询集合中的若干文档  `db.collection.find(query, projection)`\r\n\t\t- query ：可选，使用查询操作符指定查询条件\r\n\t\t\t- 查询逻辑运算符\r\n\t\t\t\t- $lt: 存在并小于\r\n\t\t\t\t- $lte: 存在并小于等于\r\n\t\t\t\t- $gt: 存在并大于\r\n\t\t\t\t- $gte: 存在并大于等于\r\n\t\t\t\t- $ne: 不存在或存在但不等于\r\n\t\t\t\t- $in: 存在并在指定数组中\r\n\t\t\t\t- $nin: 不存在或不在指定数组中 \r\n\t\t\t\t- $or: 匹配两个或多个条件中的一个 \r\n\t\t\t\t- $and: 匹配全部条件\r\n\t\t\t- 查询条件对照表\r\n\t\t\t\t- `a = 1    {a: 1}`\r\n\t\t\t\t- `a <> 1   {a: {$ne: 1}}`\r\n\t\t\t\t- `a > 1    {a: {$gt: 1}}`\r\n\t\t\t\t- `a >= 1   {a: {$gte: 1}}`\r\n\t\t\t\t- `a < 1    {a: {$lt: 1}}`\r\n\t\t\t\t- `a <= 1   {a: {$lte: 1}}`\r\n\t\t\t- 查询逻辑对照表\r\n\t\t\t\t- `a = 1 AND b = 1     {a: 1, b: 1}或{$and: [{a: 1}, {b: 1}]}`\r\n\t\t\t\t- `a = 1 OR b = 1      {$or: [{a: 1}, {b: 1}]}`\r\n\t\t\t\t- `a IS NULL           {a: {$exists: false}}`\r\n\t\t\t\t- `a IN (1, 2, 3)      {a: {$in: [1, 2, 3]}}`\r\n\t\t\t- 正则表达式匹配查询： 使用 `$regex` 操作符来设置匹配字符串的正则表达式\r\n\t\t\t\t- `db.xx.find({type:{$regex:\"so\"}})`\r\n\t\t\t\t- `db.xx.find({type:/so/})`\r\n\t\t- projection ：可选，使用投影操作符指定返回的键。默认查询时返回文档中所有键值\r\n\t\t\t- 投影时，`_id`为1的时候，其他字段必须是1\r\n\t\t\t- `_id`是0的时候，其他字段可以是0\r\n\t\t\t- 如果没有`_id`字段约束，多个其他字段必须同为0或同为1\r\n\t\t- `find().pretty()` 格式化\r\n\t\t- 指定排序 `db.xx.find({type:\"value\"}",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础操作",
      "lvl1": "特性",
      "lvl2": "Mongo shell",
      "lvl3": "MongoDB 文档操作"
    },
    "frontmatter": {
      "title": "1.基础操作",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "1.基础操作",
    "path": "/docs/architect/mongodb/MongoDB-1.jichucaozuo.html",
    "url": "/docs/architect/mongodb/MongoDB-1.jichucaozuo.html",
    "content": ").sort({favCount:‐1})`\r\n\t\t\t- 1 为升序排列，而 -1 是用于降序排列\r\n\t\t- 分页查询 `db.xx.find().skip(8).limit(4)` （每页大小为8条，查询第3页）\r\n\t\t\t- skip用于指定跳过记录数，limit则用于限定返回结果数量\r\n\t\t- 巧分页（使用查询条件 + 唯一排序条件）：数据量大的时候，应该避免使用skip/limit形式的分页\r\n\t\t\t- 第一页：`db.posts.find({}).sort({_id: 1}).limit(20); `\r\n\t\t\t- 第二页：`db.posts.find({_id: {$gt: <第一页最后一个_id>}}).sort({_id: 1}).limit(20);`\r\n\t\t\t- 第三页：`db.posts.find({_id: {$gt: <第二页最后一个_id>}}).sort({_id: 1}).limit(20);`\r\n\t\t- 如果查询返回的条目数量较多，mongo shell 则会自动实现分批显示\r\n\t\t\t- 默认情况下每次只显示20条，可以输入it命令读取下一批\r\n\t\t- 避免使用 count ，特别是数据量大和查询条件不能完整命中索引时\r\n\t- findOne 查询集合中的第一个文档\r\n- 更新文档\r\n\t- update 命令对指定的数据进行更新 `db.collection.update(query,update,options)`\r\n\t\t- query：描述更新的查询条件\r\n\t\t- update：描述更新的动作及新的内容\r\n\t\t\t- 更新操作符\r\n\t\t\t\t- `{$set:{field:value}}` 指定一个键并更新值，若键不存在则创建\r\n\t\t\t\t- `{$unset:{field:1}}` 删除一个键\r\n\t\t\t\t- `{$inc:{field:value}}` 对数值类型进行增减\r\n\t\t\t\t- `{$rename:{old_field_name:new_field_name}}` 修改字段名称\r\n\t\t\t\t- `{$push:{field:value}}` 将数值追加到数组中，若数组不存在则会进行初始化\r\n\t\t\t\t- `{$pushAll:{field:value_array}}` 追加多个值到一个数组字段内\r\n\t\t\t\t- `{$pull:{field:_value}}` 从数组中删除指定的元素\r\n\t\t\t\t- `{$addToSet:{field:value}}` 添加元素到数组中，具有排重功能\r\n\t\t\t\t- `{$pop:{field:1}}` 删除数组的第一个或最后一个元素\r\n\t\t\t\t- 如果更新描述中不包含任何操作符，那么MongoDB会实现文档的replace语义\r\n\t\t- options：描述更新的选项\r\n\t\t\t- upsert：可选，如果不存在update的记录，是否插入新的记录。默认false，不插入\r\n\t\t\t- multi：可选，是否按条件查询出的多条记录全部更新。 默认false，只更新找到的第一条记录\r\n\t\t\t- writeConcern：可选，决定一个写操作落到多少个节点上才算成功\r\n\t- updateOne：更新单个文档\r\n\t- updateMany：更新多个文档\r\n\t- replaceOne：替换单个文档\r\n\t- findAndModify：兼容了查询和修改指定文档的功能，findAndModify 只能更新单个文档\r\n\t\t- 返回符合查询条件的文档数据，并完成对文档的修改\r\n\t\t- 默认情况下，findAndModify会返回修改前的“旧”数据\r\n\t\t- 如果希望返回修改后的数据，则可以指定new选项： `new: true`\r\n\t- findOneAndUpdate：更新单个文档并返回更新前（或更新后）的文档\r\n\t- findOneAndReplace：替换单个文档并返回替换前（或替换后）的文档\r\n- 删除文档\r\n\t- remove\r\n\t\t- 匹配查询条件的文档会被删除\r\n\t\t- 指定一个空文档条件会删除所有文档\r\n\t\t- 默认会删除匹配条件的全部文档，如果希望明确限定只删除一个文档（首条），则需要指定justOne参数\r\n\t\t\t- `db.xxx.remove({type:\"cc\"}, true)`\r\n\t- deleteOne\r\n\t- deleteMany\r\n\t- findOneAndDelete 返回被删除的文档\r\n\t\t- 按照指定顺序删除找到的第一个文档\r\n\t\t\t- `db.xx.findOneAndDelete({type:\"cc\"},{sort:{favCount:1}})`\r\n\t\t\t- 可以实现队列的先进先出\r\n\t- remove、deleteOne等命令只能按默认顺序删除\r\n\t- remove、deleteMany等命令需要对查询范围内的文档逐个删除，如果希望删除整个集合，则使用drop命令会更加高效\r\n- 文档操作最佳实践\r\n\t- 关于文档结构 \r\n\t\t- 防止使用太长的字段名（浪费空间）\r\n\t\t- 防止使用太深的数组嵌套（超过2层操作比较复杂）\r\n\t\t- 不使用中文，标点符号等非拉丁字母作为字段名\r\n\t- 关于写操作\r\n\t\t- update 语句里只包括需要更新的字段 \r\n\t\t- 尽可能使用批量插入来提升写入性能 \r\n\t\t- 使用TTL自动过期日志类型的数据\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础操作",
      "lvl1": "特性",
      "lvl2": "Mongo shell",
      "lvl3": "MongoDB 文档操作"
    },
    "frontmatter": {
      "title": "1.基础操作",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "10.Change Stream",
    "path": "/docs/architect/mongodb/MongoDB-10.ChangeStream.html",
    "url": "/docs/architect/mongodb/MongoDB-10.ChangeStream.html",
    "content": "---\r\ntitle: 10.Change Stream\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- Change Stream 指数据的变化事件流，MongoDB从3.6版本开始提供订阅数据变更的功能\r\n\t- 是用于实现变更追踪的解决方案\r\n\t- ![Change Stream](static/MongoDB-Change-Stream-1.png)\r\n- Change Stream 的实现原理：是基于 oplog 实现的，提供推送实时增量的推送功能\r\n\t- 它在 oplog 上开启一个 tailable cursor 来追踪所有复制集上的变更操作，最终调用应用中定义的回调函数\r\n\t- 被追踪的变更事件主要包括\r\n\t\t- insert/update/delete：插入、更新、删除；\r\n\t\t- drop：集合被删除；\r\n\t\t- rename：集合被重命名；\r\n\t\t- dropDatabase：数据库被删除；\r\n\t\t- invalidate：drop/rename/dropDatabase 将导致 invalidate 被触发， 并关闭 change stream；\r\n- 如果只对某些类型的变更事件感兴趣，可以使用使用聚合管道的过滤步骤过滤事件\r\n\t- `var cs = db.user.watch([{ $match:{operationType:{$in:[\"insert\",\"delete\"]}} }])`\r\n- Change Stream会采用 `readConcern:majority` 这样的一致性级别，保证写入的变更不会被回滚\r\n\t- 未开启 majority readConcern 的集群无法使用 Change Stream；\r\n\t- 当集群无法满足 `{w:majority}` 时，不会触发 Change Stream（例如 PSA 架构 中的 S 因故障宕机）\r\n- Change Stream 故障恢复\r\n\t- ![Change Stream 故障恢复](static/MongoDB-Change-Stream-2.png)\r\n\t- 假设在一系列写入操作的过程中，订阅 Change Stream 的应用在接收到“写3”之后 于 t0 时刻崩溃\r\n\t\t- 想要从上次中断的地方继续获取变更流，只需要保留上次变更通知中的 `_id` 即可\r\n\t\t- Change Stream 回调所返回的的数据带有 `_id`，这个 `_id` 可以用于断点恢复\r\n\t\t- `var cs = db.collection.watch([], {resumeAfter: <_id>})`\r\n- 使用场景\r\n\t- 跨集群的变更复制——在源集群中订阅 Change Stream，一旦得到任何变更立即写入目标集群\r\n\t- 微服务联动——当一个微服务变更数据库时，其他微服务得到通知并做出相应的变更\r\n\t- 其他任何需要系统联动的场景\r\n\t\t- 监控；消息推送\r\n\t\t- 分析平台：推到下游的计算平台\r\n\t\t- 数据同步：热备份；冷备份\r\n- 注意事项\r\n\t- Change Stream 依赖于 oplog，因此中断时间不可超过 oplog 回收的最大时间窗\r\n\t- 在执行 update 操作时，如果只更新了部分数据，那么 Change Stream 通知的也是增量部分\r\n\t- 删除数据时通知的仅是删除数据的 `_id`\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "10.Change Stream"
    },
    "frontmatter": {
      "title": "10.Change Stream",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content"
  },
  {
    "title": "11.开发规范",
    "path": "/docs/architect/mongodb/MongoDB-11.kaifaguifan.html",
    "url": "/docs/architect/mongodb/MongoDB-11.kaifaguifan.html",
    "content": "---\r\ntitle: 11.开发规范\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- 命名原则：数据库名和集合名称均不能超过64个字符\r\n\t- 数据库、集合命名需要简单易懂，数据库名使用小写字符\r\n\t- 集合名称使用统一命名风格，可以统一大小写或使用驼峰式命名\r\n- 集合设计：\r\n\t- 对少量数据的包含关系，使用嵌套模式有利于读性能和保证原子性的写入\r\n\t- 对于复杂的关联关系，以及后期可能发生演进变化的情况，建议使用引用模式\r\n- 文档设计：避免使用大文档，MongoDB的文档最大不能超过16MB\r\n\t- 尽可能减少字段名的长度，一般建议将字段名称控制在32个字符以内\r\n- 索引设计：在必要时使用索引加速查询\r\n\t- 避免建立过多的索引，单个集合建议不超过10个索引\r\n\t- 对集合的写入操作很可能也会触发索引的写入，从而触发更多的I/O操作\r\n\t- 及时清理不使用或不合理的索引\r\n\t- 遵循索引优化原则，如覆盖索引、优先前缀匹配等，使用explain命令分析索引性能\r\n- 分片设计：对可能出现快速增长或读写压力较大的业务表考虑分片\r\n\t- 分片键的设计满足均衡分布的目标\r\n\t- 业务上尽量避免广播查询\r\n\t- 在集合达到256GB之前就进行分片\r\n\t- 如果集合中存在唯一性索引，则应该确保该索引覆盖分片键，避免冲突\r\n\t- 为了降低风险，单个分片的数据集合大小建议不超过2TB\r\n- 升级设计：需支持对旧版本数据的兼容性\r\n\t- 在添加唯一性约束索引之前，对数据表进行检查并及时清理冗余的数据\r\n\t- 新增、修改数据库对象等操作需要经过评审，并保持对数据字典进行更新\r\n- 数据老化：及时清理无效、过期的数据\r\n\t- 优先考虑为系统日志、历史数据表添加合理的老化策略\r\n- 数据一致性：\r\n\t- 非关键业务使用默认的 `WriteConcern:1`（更高性能写入）\r\n\t- 关键业务类，使用 `WriteConcern:majority` 保证一致性（性能下降）\r\n\t- 如果业务上严格不允许脏读，则使用 `ReadConcern:majority` 选项\r\n- 重复数据：使用`update`、`findAndModify`对数据进行修改时，如果设置了`upsert:true`，则必须使用唯一性索引避免产生重复数据\r\n- 业务上尽量避免短连接：使用官方最新驱动的连接池实现，控制客户端连接池的大小，最大值建议不超过200\r\n- 对大量数据写入使用Bulk Write批量化API，建议使用无序批次更新\r\n- 优先使用单文档事务保证原子性\r\n\t- 如果需要使用多文档事务，则必须保证事务尽可能小，一个事务的执行时间最长不能超过60s\r\n- 在条件允许的情况下，利用读写分离降低主节点压力\r\n\t- 对于一些统计分析类的查询操作，可优先从节点上执行\r\n- 考虑业务数据的隔离\r\n\t- 例如将配置数据、历史数据存放到不同的数据库中\r\n\t- 微服务之间使用单独的数据库，尽量避免跨库访问\r\n- 维护数据字典文档并保持更新，提前按不同的业务进行数据容量的规划\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "11.开发规范"
    },
    "frontmatter": {
      "title": "11.开发规范",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content"
  },
  {
    "title": "12.SpringBoot集成",
    "path": "/docs/architect/mongodb/MongoDB-12.SpringBootjicheng.html",
    "url": "/docs/architect/mongodb/MongoDB-12.SpringBootjicheng.html",
    "content": "---\r\ntitle: 12.SpringBoot集成\r\ndate: 2025-07-04\r\n---\r\n\r\n- MongoTemplate\r\n\t- CRUD\r\n\t\t- 实体 `@Document @Id @Field @Transient`\r\n\t\t\t- `@Transient` 指定此成员变量不参与文档的序列化\r\n\t\t- `Query`\r\n\t\t\t- `Criteria`\r\n\t\t\t- `Sort`\r\n\t\t\t- `new BasicQuery(json)`\r\n\t- 聚合操作 `MongoTemplate#aggregate`\r\n\t\t- `Aggregation`\r\n\t\t- `TypedAggregation`\r\n\t\t\t- `GroupOperation`\r\n\t\t\t- `MatchOperation`\r\n\t\t\t- `SortOperation`\r\n\t\t\t- `ProjectionOperation`\r\n\t- 事务操作\r\n\t\t- 编程式事务：`TransactionOptions -> ClientSession`\r\n\t\t- 声明式事务（配置事务管理器）：`MongoDatabaseFactory -> MongoTransactionManager`\r\n\t- change stream：`MessageListenerContainer`\r\n\r\n---\r\n```java\r\n// 编程式事务\r\nvar txo = TransactionOptions.builder()\r\n\t.readPreference(ReadPreference.primary())\r\n\t.readConcern(ReadConcern.MAJORITY)\r\n\t.writeConcern(WriteConcern.MAJORITY).build();\r\ntry (ClientSession clientSession = client.startSession()) {\r\n\tclientSession.startTransaction(txo);\r\n\tclientSession.commitTransaction();\r\n\tclientSession.abortTransaction(); // 回滚事务\r\n}\r\n\r\n// 声明式事务：配置事务管理器 -> @Transactional\r\n@Bean\r\nMongoTransactionManager transactionManager(MongoDatabaseFactory factory){\r\n\tTransactionOptions txnOptions = TransactionOptions.builder()\r\n\t\t.readPreference(ReadPreference.primary())\r\n\t\t.readConcern(ReadConcern.MAJORITY)\r\n\t\t.writeConcern(WriteConcern.MAJORITY).build();\r\n\treturn new MongoTransactionManager(factory);\r\n}\r\n```\r\n\r\n---\r\n```java\r\n// change stream\r\n// 配置 mongo 监听器的容器 MessageListenerContainer\r\n// spring 启动时会自动启动监听的任务用于接收 changestream\r\n@Bean\r\nMessageListenerContainer messageListenerContainer(MongoTemplate template, \r\n\t\t\t\t\tDocumentMessageListener documentMessageListener) {\r\n  Executor executor = Executors.newFixedThreadPool(5);\r\n\t\r\n  MessageListenerContainer messageListenerContainer = \r\n\tnew DefaultMessageListenerContainer(template, executor) { \r\n\t\t@Override \r\n\t\tpublic boolean isAutoStartup() { return true; } \r\n\t}; \r\n\t\t\t\r\n  ChangeStreamRequest<Document> request = ChangeStreamRequest\r\n\t.builder(documentMessageListener) \r\n\t.collection(\"user\") //需要监听的集合名 \r\n\t\t\t\r\n\t//过滤需要监听的操作类型，可以根据需求指定过滤条件 \r\n\t.filter(Aggregation.newAggregation(\r\n\t  Aggregation.match( \r\n\t\tCriteria\r\n\t\t  .where(\"operationType\")\r\n\t\t  .in(\"insert\", \"update\", \"delete\")))) \r\n\t\t\t\r\n\t//不设置时，文档更新时，只会发送变更字段的信息，设置UPDATE_LOOKUP会返回文档的全部信息 \r\n\t.fullDocumentLookup(FullDocument.UPDATE_LOOKUP) \r\n\t.build(); \r\n\t\r\n  messageListenerContainer.register(request, Document.class); \r\n  return messageListenerContainer;\r\n}\r\n\r\n// 配置mongo监听器，用于接收数据库的变更信息\r\n@Component\r\npublic class DocumentMessageListener<S, T> implements MessageListener<S, T> {\r\n  @Override \r\n  public void onMessage(Message<S, T> message) { \r\n\tSystem.out.println(String.format(\r\n\t  \"Received Message in collection %s.\\n\\trawsource: %s\\n\\tconverted: %s\", \r\n\t\tmessage.getProperties().getCollectionName(), \r\n\t\tmessage.getRaw(), \r\n\t\tmessage.getBody())); \r\n\t}\r\n}\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.SpringBoot集成"
    },
    "frontmatter": {
      "title": "12.SpringBoot集成",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content"
  },
  {
    "title": "2.聚合操作",
    "path": "/docs/architect/mongodb/MongoDB-2.juhecaozuo.html",
    "url": "/docs/architect/mongodb/MongoDB-2.juhecaozuo.html",
    "content": "---\r\ntitle: 2.聚合操作\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- 单一作用聚合：提供了对常见聚合过程的简单访问，操作都从单个集合聚合文档\r\n- 聚合管道：是一个数据聚合的框架，模型基于数据处理流水线的概念。文档进入多级管道，将文档转换为聚合结果\r\n- MapReduce 操作具有两个阶段（已被弃用，使用聚合管道代替）\r\n\t- 处理每个文档并向每个输入文档发射一个或多个对象的map阶段\r\n\t- reduce组合map操作的输出阶段\r\n\r\n---\r\n## 单一作用聚合\r\n\r\n聚合来自单个集合文档：\r\n- `db.collection.estimatedDocumentCount()` 返回集合或视图中所有文档的计数\r\n- `db.collection.count()` 返回与find()集合或视图的查询匹配的文档计数\r\n\t- `db.books.count(query)` 等同于 `db.collection.find(query).count()`\r\n\t- 在分片群集上，如果存在孤立文档或正在进行块迁移，则 `db.collection.count()` 没有查询谓词可能导致计数不准确\r\n\t\t- 要避免这些情况，请在分片群集上使用 `db.collection.aggregate()` 方法\r\n- `db.collection.distinct()`  在单个集合或视图中查找指定字段的不同值，并在数组中返回结果\r\n\t- `db.books.distinct(\"type\")`\r\n\t- `db.books.distinct(\"type\",{favCount:{$gt:90}})`\r\n\r\n---\r\n## 聚合管道\r\n\r\n- MongoDB 聚合框架（Aggregation Framework）是一个计算框架\r\n\t- 作用在一个或几个集合上\r\n\t- 对集合中的数据进行的一系列运算\r\n\t- 将这些数据转化为期望的形式\r\n- 从效果而言，聚合框架相当于 SQL 查询中的 GROUP BY、 LEFT OUTER JOIN 、 AS等\r\n- 管道（Pipeline）和阶段（Stage）：整个聚合运算过程称为管道（Pipeline），它是由多个阶段（Stage）组成的\r\n\t- ![Pipeline](static/MongoDB-聚合操作-1.png)\r\n\t- 每个管道\r\n\t\t- 接受一系列文档（原始数据）\r\n\t\t- 每个阶段对这些文档进行一系列运算\r\n\t\t- 结果文档输出给下一个阶段\r\n- 聚合管道操作语法：`db.collection.aggregate([$stage1, $stage2, ...$stageN], {options})`\r\n\t- pipelines 一组数据聚合阶段\r\n\t\t- 除`$out`、`$Merge` 和 `$geonear` 阶段之外，每个阶段都可以在管道中出现多次\r\n\t- options 可选，聚合操作的其他参数\r\n\t\t- 查询计划、是否使用临时文件、 游标、最大操作时间、读写策略、强制索引等\r\n\t- ![聚合管道](static/MongoDB-聚合操作-2.png)\r\n- 常用的管道聚合阶段\r\n\t- `$match` 筛选条件 \r\n\t- `$project` 投影 \r\n\t- `$lookup` 左外连接 \r\n\t- `$sort` 排序 \r\n\t- `$group` 分组 \r\n\t- `$skip/$limit` 分页\r\n\t- `$unwind` 展开数组\r\n\t- `$graphLookup` 图搜索\r\n\t- `$facet/$bucket` 分面搜索\r\n- 聚合表达式\r\n\t- 获取字段信息\r\n\t\t- `$<field>`  用 `$` 指示字段路径\r\n\t\t- `$<field>.<sub field>` 使用 `$` 和 `.` 来指示内嵌文档的路径\r\n\t- 常量表达式\r\n\t\t-  `$literal:<value>`  指示常量 `<value>`\r\n\t- 系统变量表达式\r\n\t\t- `$$<variable>` 使用 `$$` 指示系统变量\r\n\t\t- `$$CURRENT` 指示管道中当前操作的文档\r\n- `$project`：投影操作， 将原始字段投影成指定名称\r\n\t- `db.books.aggregate([{$project:{name:\"$title\"}}])` \r\n\t\t- 将集合中的 title 投影成 name\r\n\t- `db.books.aggregate([{$project:{name:\"$title\",_id:0,type:1,author:1}}])`\r\n\t\t- 剔除不需要的字段\r\n\t- 从嵌套文档中排除字段\r\n\t\t- `db.books.aggregate([{$project:{name:\"$title\",_id:0,type:1,\"author.name\":1}}])`\r\n\t\t- `db.books.aggregate([{$project:{name:\"$title\",_id:0,type:1,author:{name:1}}}])`\r\n- `$match` 用于对文档进行筛选，之后可以在得到的文档子集上做聚合，可以使用除了地理空间之外的所有常规查询操作符\r\n\t- `db.books.aggregate([{$match:{type:\"technology\"}}])`\r\n\t- 在实际应用中尽可能将`$match`放在管道的前面位置\r\n\t\t- 可以减少后续管道操作符要操作的文档数，提升效率\r\n\t\t- 如果再投射和分组之前执行`$match`，查询可以使用索引\r\n- `$count` 计数并返回与查询匹配的结果数\r\n\t- `db.books.aggregate([{$match:{type:\"technology\"}},{$count: \"type_count\"}])`\r\n\t\t- `$match`阶段筛选出type匹配technology的文档，并传到下一阶段\r\n\t\t- `$count`阶段返回聚合管道中剩余文档的计数，并将该值分配给`type_count`\r\n- `$group` 按指定的表达式对文档进行分组，并将每个不同分组的文档输出到下一个阶段\r\n\t- 输出文档包含一个`_id`字段，该字段按键包含不同的组\r\n\t- 输出文档还可以包含计算字段，该字段保存由`$group`的`_id`字段分组的一些`accumulator`表达式的值\r\n\t- `$group`不会输出具体的文档而只是统计信息\r\n\t- `{$group:{_id:<expression>,<field1>:{<accumulator1>:<expression1>},...}}`\r\n\t\t- `_id`字段是必填的;但是，可以指定`_id`值为`null`来为整个输入文档计算累计值\r\n\t\t- 剩余的计算字段是可选的，并使用`<accumulator>`运算符进行计算\r\n\t\t- `_id`和`<accumulator>`表达式可以接受任何有效的表达式\r\n\t- `accumulator` 操作符 \r\n\t\t- `$avg` 计算均值 \r\n\t\t- `$first` 返回每组第一个文档，如果有排序，按照排序，如果没有按照默认的存储的顺序的第一个文档\r\n\t\t- `$last` 返回每组最后一个文档，如果有排序，按照排序，如果没有按照默认的存储的顺序的最后个文档\r\n\t\t- `$max` 根据分组，获取集合中所有文档对应值得最大值\r\n\t\t- `$min` 根据分组，获取集合中所有文档对应值得最小值\r\n\t\t- `$push` 将指定的表达式的值添加到一个数组中\r\n\t\t- `$addToSet` 将表达式的值添加到一个集合中（无重复值，无序）\r\n\t\t- `$sum` 计算总和\r\n\t\t- `$stdDevPop` 返回输入值的总体标准偏差（population standard deviation）\r\n\t\t- `$stdDevSamp` 返回输入值的样本标准偏差（the sample standard deviation）\r\n\t- `$group` 阶段的内存限制为100M\r\n\t\t- 默认情况下，如果stage超过此限制，`$group`将产生错误\r\n\t\t- 将 `allowDiskUse` 选项设置为 `true` 以启用`$group`操作写入临时文件来允许处理大型数据集\r\n\t- `db.b",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.聚合操作",
      "lvl1": "单一作用聚合",
      "lvl2": "聚合管道",
      "lvl3": "MapReduce"
    },
    "frontmatter": {
      "title": "2.聚合操作",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "2.聚合操作",
    "path": "/docs/architect/mongodb/MongoDB-2.juhecaozuo.html",
    "url": "/docs/architect/mongodb/MongoDB-2.juhecaozuo.html",
    "content": "ooks.aggregate([{$group:{_id:null,count:{$sum:1},pop:{$sum:\"$favCount\"},avg:{$avg:\"$favCount\"}}}])`\r\n\t\t- book的数量，收藏总数和平均值\r\n\t- `db.books.aggregate([{$group:{_id:\"$author.name\",pop:{$sum:\"$favCount\"}}}])`\r\n\t\t- 统计每个作者的book收藏总数\r\n\t- `db.books.aggregate([{$group:{_id:\"$author.name\",types:{$addToSet:\"$type\"}}}])`\r\n\t\t- 每个作者的book的type合集\r\n- `$merge` 用于将聚合结果写入到指定的集合中。可以将结果合并到现有集合中，或者创建一个新集合\r\n\t- into 输出集合的名称，如果目标集合不存在，MongoDB 将创建它\r\n\t- on 用于查找匹配文档的字段或字段组合\r\n\t- whenMatched 当文档匹配时执行的操作，可选值包括 “replace”, “merge”, “keepExisting”, “fail”, “pipeline”（自定义聚合阶段，用于更复杂的更新逻辑）\r\n\t- whenNotMatched 当文档不匹配时执行的操作，可选值包括 “insert”, “discard”, “fail”\r\n- `$unwind` 可以将数组拆分为单独的文档\r\n\t- path 要指定字段路径，在字段名称前加上`$`符并用引号括起来\r\n\t- includeArrayIndex 可选，一个新字段的名称用于存放元素的数组索引。该名称不能以`$`开头\r\n\t- preserveNullAndEmptyArrays 可选，`default :false`\r\n\t\t- 若为true，如果路径为空，缺少或为空数组，则`$unwind`输出文档\r\n- `$sort` 对所有输入文档进行排序，并按排序顺序将它们返回到管道\r\n\t- `db.books.aggregate([{$sort : {favCount:‐1,title:1}}])`\r\n\t- 要对字段进行排序，请将排序顺序设置为1或-1，以分别指定升序或降序排序\r\n- `$limit` 限制传递到管道中下一阶段的文档数\r\n\t- 当`$sort`在管道中的`$limit`之前立即出现时，`$sort`操作只会在过程中维持前n个结果，其中n是指定的限制，而MongoDB只需要将n个项存储在内存中\r\n- `$skip` 跳过进入stage的指定数量的文档，并将其余文档传递到管道中的下一个阶段\r\n- `$bucket` 用于对输入文档进行分组，根据指定的边界（buckets）将文档分配到指定的组，类似于 `GROUP BY`\r\n\t- groupBy（必需）：指定要分组的字段或表达式。文档将根据该字段的值来分配到不同的 bucket 中\r\n\t- boundaries（必需）：一个数组，定义了 buckets 的分界点。数组元素是按升序排列的，表示不同的边界值\r\n\t\t- 值必须是相同的数据类型\r\n\t\t- 例如，`[0, 10, 20, 30]` 表示创建三个 buckets\r\n\t- default（可选）：指定一个 bucket，用于存储所有不在 `boundaries` 定义的范围内的文档。如果未指定，超出边界范围的文档将被丢弃\r\n\t- output（可选）：一个文档，定义了每个 bucket 中需要包含的计算字段。每个字段是一个聚合表达式，该表达式操作落入该 bucket 中的文档\r\n\t\t- 例如，可以计算每个 bucket 中的文档总数、最大值、最小值、平均值等\r\n- `$lookup` 主要用来实现多表关联查询\r\n\t- 每个输入待处理的文档，经过 `$lookup` 阶段的处理，输出的新文档中会包含一个新生成的数组（可根据需要命名新key ）\r\n\t- 数组列存放的数据是来自被Join集合的适配文档，如果没有，集合为空（即 为`[ ]`)\r\n\t- 参数\r\n\t\t- from 同一个数据库下等待被Join的集合\r\n\t\t- localField 源集合中的match值，如果输入的集合中，某文档没有 localField 这个Key（Field），在处理的过程中，会默认为此文档含有 `localField:null` 的键值对\r\n\t\t\t- 注意：`null = null` 此为真\r\n```js\r\ndb.collection.aggregate([{\r\n\t$lookup: {\r\n\t\tfrom: \"<collection to join>\",\r\n\t\tlocalField: \"<field from the input documents>\",\r\n\t\tforeignField: \"<field from the documents of the from collection>\",\r\n\t\tas: \"<output array field>\"\r\n\t}\r\n```\r\n\r\n---\r\n## MapReduce\r\n\r\n- 从MongoDB 5.0开始，map-reduce操作已被弃用\r\n\t- 聚合管道比map-reduce操作提供更好的性能和可用性\r\n\t- Map-reduce操作可以使用聚合管道操作符重写，例如`$group`、 `$merge`等\r\n- MapReduce操作将大量的数据处理工作拆分成多个线程并行处理，然后将结果合并在一起\r\n- MapReduce具有两个阶段\r\n\t- 将具有相同Key的文档数据整合在一起的map阶段 \r\n\t- 组合map操作的结果进行统计输出的reduce阶段\r\n-  MapReduce的基本语法 \r\n\t- ![MapReduce](static/MongoDB-聚合操作-3.png)\r\n\r\n```js\r\ndb.collection.mapReduce(\r\n\tfunction() {emit(key,value);}, //map 函数，将数据拆分成键值对，交给reduce函数\r\n\tfunction(key,values) {return reduceFunction}, //reduce 函数，根据键将值做统计运算\r\n\t{\r\n\t\tout: <collection>,   // 可选，将结果汇入指定表\r\n\t\tquery: <document>,   // 可选，筛选数据的条件，筛选的数据送入map \r\n\t\tsort: <document>,    // 排序完后，送入map \r\n\t\tlimit: <number>,     // 限制送入map的文档数 \r\n\t\tfinalize: <function>,// 可选，修改reduce的结果后进行输出\r\n\t\tscope: <document>,   // 可选，指定map、reduce、finalize的全局变量 \r\n\t\tjsMode: <boolean>,   // 可选，默认false。在mapreduce过程中是否将数据转换成bson格式\r\n\t\tverbose: <boolean>,  // 可选，是否在结果中显示时间，默认false \r\n\t\tbypassDocumentValidation: <boolean> // 可选，是否略过数据校验\r\n\t}\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.聚合操作",
      "lvl1": "单一作用聚合",
      "lvl2": "聚合管道",
      "lvl3": "MapReduce"
    },
    "frontmatter": {
      "title": "2.聚合操作",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "3.数据模型",
    "path": "/docs/architect/mongodb/MongoDB-3.shujumoxing.html",
    "url": "/docs/architect/mongodb/MongoDB-3.shujumoxing.html",
    "content": "---\r\ntitle: 3.数据模型\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- BSON\r\n- ObjectId 生成器\r\n- 内嵌文档和数组\r\n- 固定集合\r\n- WiredTiger读写模型\r\n\r\n---\r\n## BSON\r\n\r\n- JSON基于文本的解析效率并不是最好的，在某些场景下往往会考虑选择更合适的编/解码格式\r\n- BSON（Binary JSON）是二进制版本的JSON，其在性能方面有更优的表现\r\n\t- 在空间的使用上，BSON相比JSON并没有明显的优势\r\n- MongoDB在文档存储、命令协议上都采用了BSON作为编/解码格式\r\n\t- 类JSON的轻量级语义，支持简单清晰的嵌套、数组层次结构，可以实现模式灵活的文档结构\r\n\t- 更高效的遍历，BSON在编码时会记录每个元素的长度，可以直接通过seek操作进行元素的内容读取，相对JSON解析来说，遍历速度更快\r\n\t- 更丰富的数据类型，除了JSON的基本数据类型，BSON还提供了MongoDB所需的一些扩展类型，比如日期、二进制数据等，这更加方便数据的表示和操作\r\n- 一个BSON文档最大大小为16M，文档嵌套的级别不超过100\r\n- $type 操作符基于BSON类型来检索集合中匹配的数据类型，并返回结果\r\n\t- `db.xx.find({\"title\" : {$type : \"string\"}})`\r\n- 日期类型 `db.dates.insert([{data1:Date()},{data2:new Date()},{data3:ISODate()}])`\r\n\t- `Date()` 使用UTC（Coordinated Universal Time）进行存储，也就是+0时区的时间\r\n\t- 使用`new Date()`与`ISODate()`最终都会生成ISODate类型的字段（对应于UTC时间）\r\n\r\n---\r\n## ObjectId 生成器\r\n\r\n- MongoDB集合中所有的文档都有一个唯一的_id字段，作为集合的主键\r\n\t- 在默认情况下，`_id`字段使用ObjectId类型，采用16进制编码形式，共12个字节\r\n- 为了避免文档的`_id`字段出现重复，ObjectId被定义为3个部分\r\n\t- ![ObjectId](static/MongoDB-数据模型-1.png)\r\n\t- 4字节表示Unix时间戳（秒）\r\n\t- 5字节表示随机数（机器号+进程号唯一）\r\n\t\t- 5字节的随机数并没有明确定义，客户端可以采用机器号、进程号来实现\r\n\t- 3字节表示计数器（初始化时随机）\r\n- 大多数客户端驱动都会自行生成这个字段，比如MongoDB Java Driver会根据插入的文档是否包含`_id`字段来自动补充ObjectId对象。这样做不但提高了离散性，还可以降低MongoDB服务器端的计算压力\r\n- `x = ObjectId()` 生成一个新的 ObjectId\r\n- 属性/方法\r\n\t- `str` 返回对象的十六进制字符串表示\r\n\t- `ObjectId.getTimestamp()` 将对象的时间戳部分作为日期返回\r\n\t- `ObjectId.toString()` 以字符串文字的形式返回 JavaScript 表示 ObjectId(...)\r\n\t- `ObjectId.valueOf()` 将对象的表示形式返回为十六进制字符串。返回的字符串是`str`属性\r\n\r\n---\r\n## 内嵌文档和数组\r\n\r\n- 内嵌文档：可以嵌套文档，比如查询时可以用`.`操作符\r\n- 数组\r\n\t- `$slice`获取最后一个tag\r\n\t\t- `db.books.find({\"author.name\":\"三毛\"},{title:1,tags:{$slice:‐1}})`\r\n\t- `$push`在数组末尾追加元素\r\n\t\t- `db.books.updateOne({\"author.name\":\"三毛\"},{$push:{tags:\"猎奇\"}})`\r\n\t\t- `$each`操作符配合可以用于添加多个元素\r\n\t\t\t- `db.books.updateOne({\"author.name\":\"三毛\"},{$push:{tags:{$each:[\"伤感\",\"想象力\"]}}})`\r\n\t\t\t- 加上`$slice`操作符，那么只会保留经过切片后的元素\r\n\t\t\t\t- `db.books.updateOne({\"author.name\":\"三毛\"},{$push:{tags:{$each:[\"伤感\",\"想象力\"],$slice:‐3}}})`\r\n\t- 根据元素查询\r\n\t\t- `db.books.find({tags:\"伤感\"})` 查出所有包含伤感的文档\r\n\t\t- `db.books.find({tags:{$all:[\"伤感\",\"想象力\"]}})`\r\n- 嵌套型的数组：数组元素可以是基本类型，也可以是内嵌的文档结构\r\n\t- `$elementMatch` 根据数组内文档的属性进行检索\r\n\t\t- `db.goods.find({tags:{$elemMatch:{tagKey:\"color\",tagValue:\"黑色\"}}})`\r\n\t\t\t- 筛选出 `color=黑色` 的商品信息\r\n\t- 如果进行组合式的条件检索，则可以使用多个`$elemMatch`操作符\r\n\t\t- `db.goods.find({tags:{$all:[{$elemMatch:{tagKey:\"color\",tagValue:\"黑色\"}},{$elemMatch:{tagKey:\"size\",tagValue:\"XL\"}}]}})`\r\n\r\n---\r\n## 固定集合\r\n\r\n- 固定集合（capped collection）是一种限定大小的集合。跟普通的集合相比，数据在写入这种集合时遵循FIFO原则\r\n\t- 可以保证数据库只会存储“限额”的数据，超过该限额的旧数据都会被丢弃\r\n- 创建固定集合：`db.createCollection(\"logs\",{capped:true,size:4096,max:10})`\r\n\t- max：指集合的文档数量最大值，这里是10条\r\n\t- size：指集合的空间占用最大值，这里是4096字节（4KB）\r\n\t- 只要任一条件达到阈值都会认为集合已经写满。其中size是必选的，而max则是可选的\r\n- `db.logs.stats()` 查看文档的占用空间\r\n- 优势\r\n\t- 固定集合在底层使用的是顺序I/O操作，因此固定集合的写入性能是很高的\r\n\t- 如果按写入顺序进行数据读取，也会获得非常好的性能表现\r\n- 限制\r\n\t- 无法动态修改存储的上限，如果需要修改max或size，则只能先执行`collection.drop`命令，将集合删除后再重新创建\r\n\t- 无法删除已有的数据，对固定集合中的数据进行删除会报错\r\n\t- 对已有数据进行修改，新文档大小必须与原来的文档大小一致，否则不允许更新\r\n\t- 默认情况下，固定集合只有一个`_id`索引，而且最好是按数据写入的顺序进行读取\r\n\t\t- 也可以添加新的索引，但这会降低数据写入的性能\r\n\t-  固定集合不支持分片\r\n\t\t- 在MongoDB 4.2版本中规定了事务中也无法对固定集合执行写操作\r\n- 适用场景：很适合用来存储一些“临时态”的数据，意味着数据在一定程度上可以被丢弃，随着时间的推移，数据的重要性逐渐降低，直至被淘汰处理\r\n\t- 系统日志\r\n\t\t- 在MongoDB内部，副本集的同步日志（oplog）就使用了固定集合\r\n\t- 最新发布的TopN条文章信息（少量文档）\r\n\t\t- 得益于内部缓存的作用，对于这种少量文档的查询是非常高效的\r\n- 使用固定集合实现FIFO队列：采用",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.数据模型",
      "lvl1": "BSON",
      "lvl2": "ObjectId 生成器",
      "lvl3": "内嵌文档和数组",
      "lvl4": "固定集合",
      "lvl5": "WiredTiger 读写模型"
    },
    "frontmatter": {
      "title": "3.数据模型",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "3.数据模型",
    "path": "/docs/architect/mongodb/MongoDB-3.shujumoxing.html",
    "url": "/docs/architect/mongodb/MongoDB-3.shujumoxing.html",
    "content": "读取游标的方式（游标在获取不到数据时并不会被关闭）\r\n\t- `var cursor = db.xx.find({timestamped:{$gte:new Date()}}).tailable();`\r\n\t- `cursor.hasNext()`\r\n\t- `var doc = cursor.next()`\r\n\r\n---\r\n## WiredTiger 读写模型\r\n\r\n- MongoDB从3.0开始引入可插拔存储引擎的概念\r\n\t- 目前主要有MMAPV1、WiredTiger存储引擎（节省约60%以上的硬盘资源）可供选择\r\n- 读缓存：理想情况下，MongoDB可以提供近似内存式的读写性能\r\n\t- WiredTiger引擎实现了数据的二级缓存，第一层是操作系统的页面缓存，第二层则是引擎提供的内部缓存\r\n\t- ![WiredTiger](static/MongoDB-数据模型-2.png)\r\n\t- 读取数据时的流程如下\r\n\t\t- 数据库发起Buffer I/O读操作，由操作系统将磁盘数据页加载到文件系统的页缓存区\r\n\t\t- 引擎层读取页缓存区的数据，进行解压后存放到内部缓存区\r\n\t\t- 在内存中完成匹配查询，将结果返回给应用\r\n\t- MongoDB为了尽可能保证业务查询的“热数据”能快速被访问，其内部缓存的默认大小达到了内存的一半，该值由wiredTigerCacheSize参数指定\r\n\t\t- `wiredTigerCacheSize=Math.max((RAM/2‐1GB),256MB)`\r\n- 写缓冲\r\n\t- 当数据发生写入时，MongoDB并不会立即持久化到磁盘上，而是先在内存中记录这些变更，之后通过CheckPoint机制将变化的数据写入磁盘\r\n\t\t- 如果每次写入都触发一次磁盘I/O，那么开销太大，而且响应时延会比较大\r\n\t\t- 多个变更的写入可以尽可能进行I/O合并，降低资源负荷\r\n- MongoDB单机下保证数据可靠性的机制包括以下两个部分\r\n\t- CheckPoint（检查点）机制\r\n\t\t- 快照（snapshot）描述了某一时刻（point-in-time）数据在内存中的一致性视图，而这种数据的一致性是WiredTiger通过MVCC（多版本并发控制）实现的\r\n\t\t- 当建立CheckPoint时，WiredTiger会在内存中建立所有数据的一致性快照，并将该快照覆盖的所有数据变化一并进行持久化（fsync）\r\n\t\t- 成功之后，内存中数据的修改才得以真正保存\r\n\t\t- 默认情况下，MongoDB每60s建立一次CheckPoint，在检查点写入过程中，上一个检查点仍然是可用的。这样可以保证一旦出错，MongoDB仍然能恢复到上一个检查点\r\n\t\t\t- CheckPoint的刷新周期可以调整`storage.syncPeriodSecs`参数（默认值60s）\r\n\t\t\t- 在MongoDB 3.4及以下版本中，当Journal日志达到2GB时同样会触发CheckPoint行为\r\n\t\t- 如果应用存在大量随机写入，则CheckPoint可能会造成磁盘I/O的抖动。在磁盘性能不足的情况下，问题会更加显著，此时适当缩短CheckPoint周期可以让写入平滑一些\r\n\t- Journal 日志\r\n\t\t- Journal是一种预写式日志（write ahead log）机制，主要用来弥补CheckPoint机制的不足\r\n\t\t- 如果开启了Journal日志，那么WiredTiger会将每个写操作的redo日志写入Journal缓冲区，该缓冲区会频繁地将日志持久化到磁盘上\r\n\t\t- 默认情况下，Journal缓冲区每100ms执行一次持久化\r\n\t\t\t- Journal日志达到100MB，或是应用程序指定 `journal:true`，写操作都会触发日志的持久化\r\n\t\t- Journal日志的刷新周期可以通过参数`storage.journal.commitIntervalMs`指定\r\n\t\t\t- MongoDB 3.4及以下版本的默认值是50ms，而3.6版本之后调整到了100ms\r\n\t\t- 由于Journal日志采用的是顺序I/O写操作，频繁地写入对磁盘的影响并不是很大\r\n\t- 一旦MongoDB发生宕机，重启程序时会先恢复到上一个检查点，然后根据Journal日志恢复增量的变化。由于Journal日志持久化的间隔非常短，数据能得到更高的保障，如果按照当前版本的默认配置，则其在断电情况下最多会丢失100ms的写入数据\r\n- WiredTiger写入数据的流程\r\n\t- ![WiredTiger](static/MongoDB-数据模型-3.png)\r\n\t- 应用向MongoDB写入数据（插入、修改或删除）\r\n\t- 数据库从内部缓存中获取当前记录所在的页块，如果不存在则会从磁盘中加载（Buffer I/O） \r\n\t- WiredTiger开始执行写事务，修改的数据写入页块的一个更新记录表，此时原来的记录仍然保持不变\r\n\t- 如果开启了Journal日志，则在写数据的同时会写入一条Journal日志（Redo Log）\r\n\t\t- 该日志在最长不超过100ms之后写入磁盘\r\n\t- 数据库每隔60s执行一次CheckPoint操作，此时内存中的修改会真正刷入磁盘\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.数据模型",
      "lvl1": "BSON",
      "lvl2": "ObjectId 生成器",
      "lvl3": "内嵌文档和数组",
      "lvl4": "固定集合",
      "lvl5": "WiredTiger 读写模型"
    },
    "frontmatter": {
      "title": "3.数据模型",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "4.索引",
    "path": "/docs/architect/mongodb/MongoDB-4.suoyin.html",
    "url": "/docs/architect/mongodb/MongoDB-4.suoyin.html",
    "content": "---\r\ntitle: 4.索引\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- 索引数据结构\r\n- 索引设计原则\r\n- 索引操作\r\n- 索引类型\r\n\t- 单键索引；复合索引；多键索引；地理空间索引；全文索引；Hash索引；通配符索引\r\n- 索引属性\r\n\t- 唯一索引；部分索引；稀疏索引；TTL索引；隐藏索引\r\n- 索引使用建议\r\n- Explain 执行计划\r\n\r\n---\r\n## 索引数据结构\r\n\r\n- MongoDB采用B+Tree 做索引，索引创建在colletions上\r\n\t- 不使用索引的查询，先扫描所有的文档，再匹配符合条件的文档\r\n\t-  使用索引的查询，通过索引找到文档，使用索引能够极大的提升查询效率\r\n- WiredTiger 数据文件在磁盘的存储结构\r\n\t- ![WiredTiger](static/MongoDB-索引-1.png)\r\n\t\t- B+ Tree中的leaf page包含一个页头（page header）、块头（block header）和真正的数据（key/value）\r\n\t\t\t- 页头定义了页的类型、页中实际载荷数据的大小、页中记录条数等信息\r\n\t\t\t- 块头定义了此页的checksum、块在磁盘上的寻址位置等信息\r\n\t\t- WiredTiger有一个块设备管理的模块，用来为page分配block\r\n\t\t\t- 如果要定位某一行数据\r\n\t\t\t\t- 先通过block的位置找到此page（相对于文件起始位置的偏移量）\r\n\t\t\t\t- 再通过page找到行数据的相对位置\r\n\t\t\t\t- 最后可以得到行数据相对于文件起始位置的偏移量offsets\r\n\r\n---\r\n## 索引设计原则\r\n\r\n- 每个查询原则上都需要创建对应索引 \r\n- 单个索引设计应考虑满足尽量多的查询 \r\n- 索引字段选择及顺序需要考虑查询覆盖率及选择性 \r\n- 慎重\r\n\t- 对于更新及其频繁的字段上创建索引需慎重 \r\n\t- 对于数组索引需要慎重考虑未来元素个数 \r\n\t- 对于超长字符串类型字段上慎用索引 \r\n\t- 并发更新较高的单个集合上不宜创建过多索引\r\n\r\n---\r\n## 索引操作\r\n\r\n- 创建索引 ` db.collection.createIndex(keys, options)`\r\n\t- Key 值为你要创建的索引字段，1 按升序创建索引， -1  按降序创建索引\r\n\t- 可选参数\r\n\t\t- background 创建索引后台执行，默认值为 false\r\n\t\t- unique 创建唯一索引，默认值为 false\r\n\t\t- name 索引的名称，如果未指定，MongoDB将通过连接索引的字段名和排序顺序生成一个索引名称\r\n\t\t- dropDups （已废弃）在建立唯一索引时是否删除重复记录\r\n\t\t\t- 指定 true 创建唯一索引。默认值为 false\r\n\t\t- sparse 对文档中不存在的字段数据不启用索引（稀疏索引）\r\n\t\t\t- 如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档。默认值为 false\r\n\t\t- expireAfterSeconds 设定集合的生存时间，TTL设定以秒为单位\r\n\t\t- v 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本\r\n\t\t- weights 索引权重值，数值在 1 到 99_999 之间，表示该索引相对于其他索引字段的得分权重\r\n\t\t- default_language 对于文本索引，该参数决定了停用词及词干和词器的规则列表。 默认为英语\r\n\t\t- language_override 对于文本索引，该参数指定了包含在文档中的字段名\r\n\t\t\t- 语言覆盖默认的 language，默认值为 language\r\n\t\t- hidden 隐藏索引\r\n- 查看索引 \r\n\t- `db.books.getIndexes()` 查看索引信息\r\n\t- `db.books.getIndexKeys()` 查看索引键\r\n\t- `db.collection.totalIndexSize([is_detail])` 查看索引占用空间\r\n\t\t- is_detail：可选参数，传入除0或false外的任意数据，都会显示该集合中每个索引的大小及总大小\r\n\t\t\t- 如果传入0或false则只显示该集合中所有索引的总大小。默认值为false\r\n- 删除索引\r\n\t- `db.col.dropIndex(\"索引名称\")` 删除集合指定索引\r\n\t- `db.col.dropIndexes()` 删除集合所有索引，不能删除主键索引\r\n\r\n---\r\n## 索引类型\r\n\r\n- 单键索引（Single Field Indexes）：在某一个特定的字段上建立索引\r\n\t- MongoDB在ID上建立了唯一的单键索引\r\n\t- `db.books.createIndex({title:1})`\r\n- 复合索引（Compound Index）：是多个字段组合而成的索引\r\n\t- `db.books.createIndex({type:1,favCount:1})`\r\n- 多键索引（Multikey Index）：在数组的属性上建立索引\r\n\t- 针对这个数组的任意值的查询都会定位到这个文档，既多个索引入口或者键值引用同一个文档（多键）\r\n\t- 多键索引很容易与复合索引产生混淆\r\n\t\t- 复合索引是多个字段的组合，而多键索引则仅仅是在一个字段上出现了多键（multi key）\r\n\t\t- 多键索引也可以出现在复合字段上\r\n\t\t\t-  MongoDB 并不支持一个复合索引中同时出现多个数组字段\r\n\t\t\t- `db.inventory.createIndex( { item:1, ratings: 1 } )`\r\n\t- 支持在包含嵌套对象的数组字段上创建多键索引\r\n\t- `db.inventory.createIndex( { ratings: 1 } )`\r\n- 地理空间索引（Geospatial Index）：专门用于实现位置检索的一种特殊索引\r\n\t- 文档属性：`location:{type:\"Point\",coordinates:[‐73.97,40.77]}`\r\n\t- `db.restaurant.createIndex({location : \"2dsphere\"})`\r\n\t\t- 创建一个2dsphere索引\r\n\t- 查询附近10000米：`db.restaurant.find({location:{$near:{$geometry:{type:\"Point\",coordinates:[-73.88,40.78]},$maxDistance:10000}}})`\r\n\t\t- `$near` 查询操作符，用于实现附近检索，返回数据结果会按距离排序\r\n\t\t- `$geometry` 操作符用于指定一个GeoJSON格式的地理空间对象\r\n\t\t\t- `type=Point` 表示地理坐标点\r\n\t\t\t- coordinates 则是用户当前所在的经纬度位置\r\n\t\t- `$maxDistance` 限定了最大距离，单位是米\r\n- 全文索引（Text Indexes）：可通过建立文本索引来实现简易的分词检索\r\n\t- `db.reviews.createIndex( { comments: \"text\" } )`\r\n\t- `db.reviews.find({$text: {$search: \"java coffee shop\"}})`\r\n\t\t- `$text`操作符可以在有text index的集合上执行文本检索\r\n\t\t- `$text`将会使用空格和标点符号作为分隔符对检索字符串进行分词， 并且对检索字符串中所有的分词结果进行一个逻辑上的 OR 操作\r\n\t- MongoDB的文本索引功能存在诸多限制，而官方并未提供中",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.索引",
      "lvl1": "索引数据结构",
      "lvl2": "索引设计原则",
      "lvl3": "索引操作",
      "lvl4": "索引类型",
      "lvl5": "索引属性",
      "lvl6": "索引使用建议",
      "lvl7": "Explain 执行计划"
    },
    "frontmatter": {
      "title": "4.索引",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 3
  },
  {
    "title": "4.索引",
    "path": "/docs/architect/mongodb/MongoDB-4.suoyin.html",
    "url": "/docs/architect/mongodb/MongoDB-4.suoyin.html",
    "content": "文分词的功能\r\n- Hash索引（Hashed Indexes）：在索引字段上进行精确匹配但不支持范围查询，不支持多键hash\r\n\t- `db.users.createIndex({username : 'hashed'})`\r\n\t-  Hash索引上的入口是均匀分布的，在分片集合中非常有用\r\n- 通配符索引（Wildcard Indexes）：支持对未知或任意字段的查询\r\n\t- `db.products.createIndex( { \"product_attributes.$**\" : 1 } )`\r\n\t- 通配符索引不兼容的索引类型或属性\r\n\t\t- TTL - TTL索引\r\n\t\t- Compound - 复合索引\r\n\t\t- Text - 全文索引\r\n\t\t- 2d (Geospatial) - 地理空间索引\r\n\t\t- 2dsphere (Geospatial) - 地理空间索引\r\n\t\t- Hashed - Hash索引\r\n\t\t- Unique - 唯一索引\r\n\t- 通配符索引是稀疏的，不索引空字段\r\n\t\t- 通配符索引不能支持查询字段不存在的文档\r\n\t- 通配符索引为文档或数组的内容生成条目，而不是文档/数组本身\r\n\t\t- 通配符索引不能支持精确的文档/数组相等匹配\r\n\t\t- `db.products.find({ \"product_attributes.colors\" : [ \"Blue\", \"Black\" ] } )`\r\n\t\t\t- 不支持通配符索引\r\n\t- 通配符索引可以支持查询字段等于空文档`{}`的情况\r\n\r\n---\r\n## 索引属性\r\n\r\n- 唯一索引（Unique Indexes）\r\n\t- 唯一性索引对于文档中缺失的字段，会使用null值代替，因此不允许存在多个文档缺失索引字段的情况\r\n\t- 对于分片的集合，唯一性约束必须匹配分片规则\r\n\t\t- 为了保证全局的唯一性，分片键必须作为唯一性索引的前缀字段\r\n- 部分索引（Partial Indexes）\r\n\t- 部分索引仅对满足指定过滤器表达式的文档进行索引\r\n\t\t- 通过在一个集合中为文档的一个子集建立索引\r\n\t- 部分索引具有更低的存储需求和更低的索引创建和维护的性能成本\r\n\t- 部分索引提供了稀疏索引功能的超集，应该优先于稀疏索引\r\n\t- `db.restaurants.createIndex({cuisine:1,name:1},{partialFilterExpression:{rating:{$gt:5}}})`\r\n\t\t- partialFilterExpression 选项接受指定过滤条件的文档\r\n\t\t\t- 等式表达式 (例如 `field:value` 或使用 `$eq` 操作符)\r\n\t\t\t- `$exists:true`\r\n\t\t\t- `$gt $gte $lt $lte`\r\n\t\t\t- `$type `\r\n\t\t\t- 顶层的 `$and`\r\n- 稀疏索引（Sparse Indexes）： 只对存在字段的文档进行索引（包括字段值为null的文档）\r\n\t- 索引的稀疏属性确保索引只包含具有索引字段的文档的条目\r\n\t\t- 索引将跳过没有索引字段的文档\r\n\t- 如果稀疏索引会导致查询和排序操作的结果集不完整，MongoDB将不会使用该索引\r\n\t\t- 除非`hint()`明确指定索引\r\n\t\t-` db.scores.find().sort( { score: ‐1 } ).hint( { score: 1 } )`\r\n- TTL索引（TTL Indexes）：在一定时间或特定时钟时间后自动从集合中删除文档\r\n\t- TTL索引需要声明在一个日期类型的字段中，TTL 索引是特殊的单字段索引\r\n\t\t- TTL索引具有普通索引的功能，同样可以用于加速数据的查询\r\n\t- `db.xx.createIndex( { \"lastModifiedDate\": 1 }, { expireAfterSeconds:3600 } )`\r\n\t\t- 单位是秒\r\n\t- MongoDB会在周期性运行的后台线程中对该集合进行检查及数据清理工作\r\n\t\t- TTL 索引不保证过期数据会在过期后立即被删除\r\n\t\t- 删除过期文档的后台任务每 60 秒运行一次\r\n\t- 可变的过期时间：TTL索引在创建之后，仍然可以对过期时间进行修改\r\n\t\t- collMod 命令对索引的定义进行变更\r\n\t\t- `db.runCommand({collMod:\"xx\",index:{keyPattern:{createdAt:1},expireAfterSeconds:600}})`\r\n\t- 使用约束\r\n\t\t- TTL索引只能支持单个字段，并且必须是非`_id`字段\r\n\t\t- TTL索引不能用于固定集合\r\n\t\t- TTL索引无法保证及时的数据老化\r\n\t\t\t- MongoDB会通过后台的TTLMonitor定时器来清理老化数据，默认的间隔时间是1分钟\r\n\t\t\t- 如果在数据库负载过高的情况下，TTL的行为则会进一步受到影响\r\n\t\t- TTL索引对于数据的清理仅仅使用了remove命令，这种方式并不是很高效\r\n\t\t\t- TTLMonitor在运行期间对系统CPU、磁盘都会造成一定的压力\r\n\t\t\t- 相比之下，按日期分表的方式操作会更加高效\r\n- 隐藏索引（Hidden Indexes）\r\n\t- 隐藏索引对查询规划器不可见，不能用于支持查询\r\n\t- 通过对规划器隐藏索引，用户可以在不实际删除索引的情况下评估删除索引的潜在影响\r\n\t- 创建隐藏索引 `db.restaurants.createIndex({ borough: 1 },{ hidden: true });`\r\n\t- 隐藏现有索引 `db.restaurants.hideIndex( { borough: 1} );`\r\n\t- 取消隐藏索引 `db.restaurants.unhideIndex( { borough: 1} );`\r\n- 多索引属性场景\r\n\t- 唯一约束结合部分索引使用导致唯一约束失效\r\n\t\t- 如果同时指定了partialFilterExpression和唯一约束，那么唯一约束只适用于满足筛选器表达式的文档\r\n\t\t- 如果文档不满足筛选条件，那么带有唯一约束的部分索引不会阻止插入不满足唯一约束的文档\r\n\t- 具有稀疏性和唯一性的索引\r\n\t\t- 可以防止集合中存在字段值重复的文档，但允许不包含此索引字段的文档插入\r\n- 日志存储场景：日期分表；固定集合；TTL索引\r\n\t- 插入： `writeConcern:0`\r\n\t\t- 发起写操作，不关心是否成功\r\n\r\n---\r\n## 索引使用建议\r\n\r\n- 为每一个查询建立合适的索引\r\n\t- 针对于数据量较大比如说超过几十上百万（文档数目）数量级的集合\r\n- 创建合适的复合索引，不要依赖于交叉索引\r\n\t- 交叉索引就是针对每个字段单独建立一个单字段索引，然后在查询执行时候使用相应的单字段索引进行索引交叉而得到查询结果\r\n\t- 交叉索引目前触发率较低，所以如果你有一个多字段查询的时候，建议使用复合索引能够保证索引正常的使用\r\n- 复合索引字段顺序：匹配条件在前，范围条件在后（Equality First, Range After）\r\n- 尽可能使用覆盖索引（Covered Index）\r\n\t- 建议只返回需要的字段，同时，利用覆盖索引来提升性能\r\n- 建索引要在后台运行\r\n\t- 在对一个集合创建索引时，该集合所在的数据库将",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.索引",
      "lvl1": "索引数据结构",
      "lvl2": "索引设计原则",
      "lvl3": "索引操作",
      "lvl4": "索引类型",
      "lvl5": "索引属性",
      "lvl6": "索引使用建议",
      "lvl7": "Explain 执行计划"
    },
    "frontmatter": {
      "title": "4.索引",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 3
  },
  {
    "title": "4.索引",
    "path": "/docs/architect/mongodb/MongoDB-4.suoyin.html",
    "url": "/docs/architect/mongodb/MongoDB-4.suoyin.html",
    "content": "不接受其他读写操作\r\n\t- 所以对大数据量的集合建索引，建议使用后台运行选项 `{background: true}`\r\n- 避免设计过长的数组索引\r\n\t- 数组索引是多值的，在存储时需要使用更多的空间\r\n\r\n---\r\n## Explain 执行计划\r\n\r\n- 我们需要关心的问题\r\n\t- 查询是否使用了索引\r\n\t- 索引是否减少了扫描的记录数量\r\n\t- 是否存在低效的内存排序\r\n- `db.collection.find().explain(<verbose>)`\r\n\t- verbose  可选参数，表示执行计划的输出模式，默认 queryPlanner\r\n\t\t- queryPlanner 执行计划的详细信息，包括查询计划、集合信息、查询条件、最佳执行计划、查询方式和 MongoDB 服务信息等\r\n\t\t- exectionStats 最佳执行计划的执行情况和被拒绝的计划等信息\r\n\t\t\t- executionStats 模式的返回信息中包含了 queryPlanner 模式的所有字段，并且还包含了最佳执行计划的执行情况\r\n\t\t- allPlansExecution 选择并执行最佳执行计划，并返回最佳执行计划和其他执行计划的执行情况\r\n\t\t\t- allPlansExecution返回的信息包含 executionStats 模式的内容，且包含`allPlansExecution:[]`块\r\n- stage 状态\r\n\t- COLLSCAN 全表扫描\r\n\t- IXSCAN 索引扫描\r\n\t- FETCH 根据索引检索指定文档\r\n\t- SHARD_MERGE 将各个分片返回数据进行合并\r\n\t- SORT 在内存中进行了排序\r\n\t- LIMIT 使用limit限制返回数\r\n\t- SKIP 使用skip进行跳过\r\n\t- IDHACK 对_id进行查询\r\n\t- SHARDING_FILTER 通过mongos对分片数据进行查询\r\n\t- COUNTSCAN count不使用Index进行count时的stage返回\r\n\t- COUNT_SCAN count使用了Index进行count时的stage返回\r\n\t- SUBPLA 未使用到索引的`$or`查询的stage返回\r\n\t- TEXT 使用全文索引进行查询时候的stage返回\r\n\t- PROJECTION 限定返回字段时候stage的返回\r\n- 执行计划的返回结果中尽量不要出现以下 stage\r\n\t- COLLSCAN(全表扫描) \r\n\t- SORT (使用sort但是无index) \r\n\t- 不合理的SKIP \r\n\t- SUBPLA (未用到index的$or) \r\n\t- COUNTSCAN (不使用index进行count)\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.索引",
      "lvl1": "索引数据结构",
      "lvl2": "索引设计原则",
      "lvl3": "索引操作",
      "lvl4": "索引类型",
      "lvl5": "索引属性",
      "lvl6": "索引使用建议",
      "lvl7": "Explain 执行计划"
    },
    "frontmatter": {
      "title": "4.索引",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 3
  },
  {
    "title": "5.复制集",
    "path": "/docs/architect/mongodb/MongoDB-5.fuzhiji.html",
    "url": "/docs/architect/mongodb/MongoDB-5.fuzhiji.html",
    "content": "---\r\ntitle: 5.复制集\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- 复制集架构\r\n- 复制集操作\r\n- 复制集成员角色\r\n- 复制集高可用\r\n- 复制集数据同步机制 oplog \r\n\r\n---\r\n## 复制集架构\r\n\r\n- 在生产环境中，不建议使用单机版的MongoDB服务器\r\n\t- 单机版的MongoDB无法保证可靠性，一旦进程发生故障或是服务器宕机，业务将直接不可用\r\n\t- 一旦服务器上的磁盘损坏，数据会直接丢失，而此时并没有任何副本可用\r\n- Mongodb复制集（Replication Set）由一组Mongod实例（进程）组成，包含一个Primary节点和多个Secondary节点\r\n\t- Mongodb Driver（客户端）的所有数据都写入Primary\r\n\t- Secondary从Primary同步写入的数据，以保持复制集内所有成员存储相同的数据集，提供数据的高可用\r\n\t- ![Mongodb复制集](static/MongoDB-复制集-1.png)\r\n- 复制集提供冗余和高可用性，是所有生产部署的基础，依赖于两个方面的功能\r\n\t- 数据写入时将数据迅速复制到另一个独立节点上\r\n\t- 在接受写入的节点发生故障时自动选举出一个新的替代节点\r\n- 在实现高可用的同时，复制集实现了其他几个附加作用\r\n\t- 数据分发：将数据从一个区域复制到另一个区域，减少另一个区域的读延迟\r\n\t- 读写分离：不同类型的压力分别在不同的节点上执行\r\n\t- 异地容灾：在数据中心故障时候快速切换到异地\r\n- local.system.replset：用来记录当前复制集的成员\r\n- local.startup_log：用来记录本地数据库的启动日志信息\r\n- local.replset.minvalid：用来记录复制集的跟踪信息，如初始化同步需要的字段\r\n\r\n---\r\n## 复制集操作\r\n\r\n- PSS模式（官方推荐模式）：由一个主节点和两个备节点所组成，即 Primary+Secondary+Secondary\r\n\t- ![PSS模式](static/MongoDB-复制集-2.png)\r\n\t- 此模式始终提供数据集的两个完整副本，如果主节点不可用，则复制集选择备节点作为主节点并继续正常操作。旧的主节点在可用时重新加入复制集\r\n- PSA模式：由一个主节点、一个备节点和一个仲裁者节点组成，即 Primary+Secondary+Arbiter\r\n\t- ![PSA模式](static/MongoDB-复制集-3.png)\r\n\t- 其中，Arbiter节点不存储数据副本，也不提供业务的读写操作\r\n\t- Arbiter节点发生故障不影响业务，仅影响选举投票\r\n\t- 此模式仅提供数据的一个完整副本，如果主节点不可用，则复制集将选择备节点作为主节点\r\n- 复制集环境搭建\r\n\t- 即使暂时只有一台服务器，也要以单节点模式启动复制集\r\n\t\t- 单机多实例启动复制集\r\n\t\t- 单节点启动复制集\r\n\t- 复制集各节点软件版本必须一致\r\n\t- 增加节点不会增加系统写性能\r\n\t- 启动 MongoDB 进程：`mongod ‐f /data/db1/mongod.conf`\r\n\t- 配置复制集\r\n\t\t- 复制集通过`replSetInitiate`命令或mongo shell的`rs.initiate()`进行初始化\r\n\t\t\t- `rs.initiate()`\r\n\t\t\t- `rs.add(\"192.168.65.174:28018\")`\r\n\t\t\t- 或 `rs.initiate({_id: \"rs0\",members: [{_id: 0,host: \"192.168.65.174:28017\"}]})`\r\n\t\t- 初始化后各个成员间开始发送心跳消息，并发起Priamry选举操作\r\n\t\t- 获得『大多数』成员投票支持的节点，会成为Primary，其余节点成为Secondary\r\n- 复制集状态查询\r\n\t- `rs.status()` 查看复制集整体状态\r\n\t\t- 可查看各成员当前状态，包括是否健康，是否在全量同步，心跳信息，增量同步信息， 选举信息，上一次的心跳时间等\r\n\t- `db.isMaster()` 查看当前节点角色\r\n\t\t- 除了当前节点角色信息，是一个更精简化的信息，也返回整个复制集的成员列表，真正的Primary是谁，协议相关的配置信息等，Driver 在首次连接复制集时会发送该命令\r\n- Mongo Shell 复制集命令\r\n\t- rs.add() 为复制集新增节点\r\n\t- rs.addArb() 为复制集新增一个 arbiter\r\n\t- rs.conf() 返回复制集配置信息\r\n\t- rs.freeze() 防止当前节点在一段时间内选举成为主节点\r\n\t- rs.help() 返回 replica set 的命令帮助\r\n\t- rs.initiate() 初始化一个新的复制集\r\n\t- rs.printReplicationInfo() 以主节点的视角返回复制的状态报告\r\n\t- rs.printSecondaryReplicationInfo() 以从节点的视角返回复制状态报告\r\n\t- rs.reconfig() 通过重新应用复制集配置来为复制集更新配置\r\n\t- rs.remove() 从复制集中移除一个节点\r\n\t- rs.secondaryOk() 为当前的连接设置从节点可读\r\n\t\t- 在默认配置下，MongoDB 的客户端会将读操作只定向到主节点，这样可以确保读取的数据是最新的，因为主节点是接受写操作的唯一节点\r\n\t- rs.status() 返回复制集状态信息\r\n\t- rs.stepDown() 让当前的 primary 变为从节点并触发 election\r\n\t- rs.syncFrom() 设置复制集节点从哪个节点处同步数据，将会覆盖默认选取逻辑\r\n- 安全认证\r\n\t- 创建用户\r\n\t\t- `use admin`\r\n\t\t- `db.createUser({user:\"fox\",pwd:\"fox\",roles:[{role:\"clusterAdmin\",db:\"admin\"}]})`\r\n\t- 创建keyFile文件： 集群之间的安全认证（开启keyfile认证就默认开启了auth认证了）\r\n\t\t- `openssl rand ‐base64 756 > /data/mongo.key`\r\n\t\t- 创建keyFile前，需要先停掉复制集中所有主从节点的mongod服务，然后再创建，否则有可能出现服务启动不了的情况\r\n\t\t- 将主节点中的keyfile文件拷贝到复制集其他从节点服务器中，路径地址对应mongo.conf配置文件中的keyFile字段地址，并设置keyfile权限为600\r\n\t\t- 启动命令 `mongod ‐f /data/db1/mongod.conf ‐‐keyFile /data/mongo.key`\r\n\t\t- 客户端连接 `mongo ‐‐port 28017 ‐ufox ‐pfox ‐‐authenticationDatabase=admin`\r\n- 复制集连接方式\r\n\t- 方式一：直接连接 Primary 节点，正常情况下可读写 MongoDB，但主节点故障切换后，无法正常访问\r\n\t- 方式二（强烈推荐）：通过高可用 Uri 的方式连接 MongoDB，当 Primary 故障切换后，MongoDB Driver 可自动感知并把流量路由到新的 Primary 节点\r\n\t\t- springboot 可以同时配",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.复制集",
      "lvl1": "复制集架构",
      "lvl2": "复制集操作",
      "lvl3": "复制集成员角色",
      "lvl4": "复制集高可用",
      "lvl5": "复制集数据同步机制 oplog"
    },
    "frontmatter": {
      "title": "5.复制集",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 4
  },
  {
    "title": "5.复制集",
    "path": "/docs/architect/mongodb/MongoDB-5.fuzhiji.html",
    "url": "/docs/architect/mongodb/MongoDB-5.fuzhiji.html",
    "content": "置集群内所有节点\r\n\r\n---\r\n## 复制集成员角色\r\n\r\n- 属性一：Priority = 0 \r\n\t- 当 Priority 等于 0 时，它不可以被复制集选举为主\r\n\t- Priority 的值越高，则被选举为主的概率更大\r\n\t- 通常，在跨机房方式下部署复制集可以使用该特性\r\n- 属性二：Vote = 0 \r\n\t- 不可以参与选举投票，此时该节点的 Priority 也必须为 0，即它也不能被选举为主\r\n\t- 由于一个复制集中最多只有7个投票成员，因此多出来的成员则必须将其vote属性值设置为0\r\n- 成员角色\r\n\t- Primary：主节点，其接收所有的写请求，然后把修改同步到所有备节点\r\n\t\t- 一个复制集只能有一个主节点，当主节点“挂掉”后，其他节点会重新选举出来一个主节点\r\n\t- Secondary：备节点，与主节点保持同样的数据集；当主节点“挂掉”时，参与竞选主节点\r\n\t\t- 分为以下三个不同类型\r\n\t\t\t- Hidden = false：正常的只读节点，是否可选为主，是否可投票，取决于 Priority，Vote 的值\r\n\t\t\t- Hidden = true：隐藏节点，对客户端不可见， 可以参与选举，但是 Priority 必须为 0，即不能被提升为主\r\n\t\t\t\t- 由于隐藏节点不会接受业务访问，因此可通过隐藏节点做一些数据备份、离线计算的任务，这并不会影响整个复制集\r\n\t\t\t\t- 在其他节点上执行 db.isMaster() 将不会显示隐藏节点\r\n\t\t\t- Delayed ：延迟节点，必须同时具备隐藏节点和Priority0的特性\r\n\t\t\t\t- 会延迟一定的时间（SlaveDelay 配置决定）从上游复制增量\r\n\t\t\t\t- 常用于快速回滚场景\r\n\t- Arbiter：仲裁节点，只用于参与选举投票，本身不承载任何数据，只作为投票角色\r\n\t\t- 2个节点的复制集，1个 Primary，1个Secondary，任意节点宕机，复制集将不能提供服务了（无法选出Primary），这时可以给复制集添加㇐个 Arbiter节点，即使有节点宕机，仍能选出Primary\r\n\t\t- 当复制集成员为偶数时，最好加入㇐个Arbiter节点，以提升复制集可用性\r\n- 配置隐藏节点：很多情况下将节点设置为隐藏节点是用来协助 delayed members 的\r\n\t- `cfg = rs.conf()`\r\n\t- `cfg.members[1].priority = 0`\r\n\t- `cfg.members[1].hidden = true`\r\n\t- `rs.reconfig(cfg)`\r\n- 配置延时节点：当我们配置一个延时节点的时候，复制过程与该节点的 oplog 都将延时时。延时节点中的数据集将会比复制集中主节点的数据延后\r\n\t- `cfg = rs.conf()`\r\n\t- `cfg.members[1].priority = 0`\r\n\t- `cfg.members[1].hidden = true`\r\n\t- `cfg.members[1].slaveDelay = 60` 延迟1分钟\r\n\t- `rs.reconfig(cfg)`\r\n- 查看复制延迟：如果希望查看当前节点oplog的情况，则可以使用`rs.printReplicationInfo()`命令\r\n\t- oplog的大小、最早一条oplog以及最后一条oplog的产生时间\r\n\t- 通常在oplog大小不变的情况下，业务写操作越频繁，复制窗口（时间差）就会越短\r\n\t- 在节点上执行`rs.printSecondaryReplicationInfo()`命令，可以一并列出所有备节点成员的同步延迟情况\r\n- 添加投票节点\r\n\t- `mongod ‐‐port 30000 ‐‐dbpath /data/arb ‐‐replSet rs0` 启动仲裁节点，指定数据目录和复制集名称\r\n\t- `rs.addArb(\"ip:30000\")` 添加仲裁节点到复制集\r\n- 移除复制集节点\r\n\t- 使用 `rs.remove()` 来移除节点 `rs.remove(\"ip:port\")`\r\n\t- 通过 `rs.reconfig()` 来移除节点\r\n\t\t- `cfg = rs.conf()`\r\n\t\t- `cfg.members.splice(2,1)` 从2开始移除1个元素\r\n\t\t- `rs.reconfig(cfg)`\r\n- 更改复制集节点\r\n\t- `cfg = rs.conf()`\r\n\t- `cfg.members[0].host = \"ip:port\"`\r\n\t- `rs.reconfig(cfg)`\r\n\r\n---\r\n## 复制集高可用\r\n\r\n- 复制集选举：Raft算法实现，选举成功的必要条件是大多数投票节点存活\r\n\t- MongoDB对raft协议添加了一些扩展\r\n\t\t- 支持chainingAllowed链式复制\r\n\t\t\t- 从节点不只是从主节点上同步数据，还可以选择一个离自己最近（心跳延时最小）的节点来复制数据\r\n\t\t- 增加了预投票阶段，即 preVote\r\n\t\t\t- 主要是用来避免网络分区时产生 Term (任期) 值激增的问题\r\n\t\t\t\t- 多个节点同时选举；选举失败重试\r\n\t\t\t- 当一个节点认为自己有资格成为主节点时，它首先会向副本集中的其他节点发送预投票请求\r\n\t\t\t\t- 接收到预投票请求的节点会根据自身的状态进行检查，决定是否同意该请求\r\n\t\t\t\t- 如果接收预投票请求的节点同意该请求，它就会给发起节点一个正面的响应\r\n\t\t\t\t- 如果发起请求的节点收到足够多的正面响应（大多数节点同意它参与正式选举），它才会正式发起选举。否则，该节点会放弃这次尝试，并等待一段时间后再重试\r\n\t\t- 支持投票优先级\r\n\t\t\t- 如果从节点发现自己的优先级比主节点高，则会主动发起投票并尝试成为新的主节点\r\n\t\t- 一个复制集最多可以有50 个成员，但只有 7 个投票成员\r\n\t\t\t- 因为一旦过多的成员参与数据复制、投票过程，将会带来更多可靠性方面的问题\r\n\t- 当复制集内存活的成员数量不足大多数时，整个复制集将无法选举出主节点，此时无法提供写服务，这些节点都将处于只读状态\r\n\t- 如果希望避免平票结果的产生，最好使用奇数个节点成员，比如3个或5个。当然，在MongoDB复制集的实现中，对于平票问题已经提供了解决方案\r\n\t\t- 为选举定时器增加少量的随机时间偏差，这样避免各个节点在同一时刻发起选举，提高成功率\r\n\t\t- 使用仲裁者角色，该角色不做数据复制，也不承担读写业务，仅仅用来投票\r\n- 自动故障转移\r\n\t- 在复制集组建完成之后，各成员节点会开启定时器，持续向其他成员发起心跳；这里涉及的参数为 heartbeatIntervalMillis，即心跳间隔时间，默认值是2s\r\n\t\t- 如果心跳成功，则会持续以2s的频率继续发送心跳\r\n\t\t- 如果心跳失败，则会立即重试心跳，一直到心跳恢复成功\r\n\t- 选举超时检",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.复制集",
      "lvl1": "复制集架构",
      "lvl2": "复制集操作",
      "lvl3": "复制集成员角色",
      "lvl4": "复制集高可用",
      "lvl5": "复制集数据同步机制 oplog"
    },
    "frontmatter": {
      "title": "5.复制集",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 4
  },
  {
    "title": "5.复制集",
    "path": "/docs/architect/mongodb/MongoDB-5.fuzhiji.html",
    "url": "/docs/architect/mongodb/MongoDB-5.fuzhiji.html",
    "content": "测，一次心跳检测失败并不会立即触发重新选举；除了心跳，成员节点还会启动一个选举超时检测定时器，该定时器默认以10s的间隔执行，具体可以通过electionTimeoutMillis参数指定\r\n\t\t- 如果心跳响应成功，则取消上一次的electionTimeout调度（保证不会发起选举），并发起新一轮electionTimeout调度\r\n\t\t- 如果心跳响应迟迟不能成功，那么electionTimeout任务被触发，进而导致备节点发起选举并成为新的主节点\r\n\t- 在MongoDB的实现中，选举超时检测的周期要略大于electionTimeoutMillis设定\r\n\t\t- 该周期会加入一个随机偏移量，大约在10～11.5s，如此的设计是为了错开多个备节点主动选举的时间，提升成功率\r\n\t- 在electionTimeout任务中触发选举必须要满足以下条件\r\n\t\t- 当前节点是备节点；当前节点具备选举权限；在检测周期内仍然没有与主节点心跳成功\r\n- 业务影响评估\r\n\t- 在复制集发生主备节点切换的情况下，会出现短暂的无主节点阶段，此时无法接受业务写操作\r\n\t\t- 如果是因为主节点故障导致的切换，则对于该节点的所有读写操作都会产生超时\r\n\t\t\t- 可以通过开启retryWrite来降低影响\r\n\t\t\t\t- `mongodb://localhost/?retryWrites=true`\r\n\t\t\t\t- `mongo ‐‐retryWrites`\r\n\t\t- 如果主节点属于强制掉电，那么整个Failover过程将会变长，很可能需要在Election定时器超时后才被其他节点感知并恢复，这个时间窗口一般会在12s以内；实际上，对于业务呼损的考量还应该加上客户端或mongos对于复制集角色的监视和感知行为（真实的情况可能需要长达30s以上）\r\n\t\t\t- 对于非常重要的业务，建议在业务层面做一些防护策略，比如设计重试机制\r\n\t- 如果想不丢数据重启复制集，更优雅的打开方式应该是这样的\r\n\t\t- 逐个重启复制集里所有的Secondary节点\r\n\t\t- 对Primary发送rs.stepDown()命令，等待primary降级为Secondary \r\n\t\t- 重启降级后的Primary\r\n\r\n---\r\n## 复制集数据同步机制 oplog \r\n\r\n- 在复制集架构中，主节点与备节点之间是通过oplog来同步数据的\r\n\t- ![oplog](static/MongoDB-复制集-4.png)\r\n\t\t- 这里的oplog是一个特殊的固定集合\r\n\t\t- 当主节点上的一个写操作完成后，会向oplog集合写入一条对应的日志\r\n\t\t- 备节点则通过这个oplog不断拉取到新的日志，在本地进行回放以达到数据同步的目的\r\n- MongoDB oplog\r\n\t- MongoDB oplog 是 Local 库下的一个集合，用来保存写操作所产生的增量日志\r\n\t- 它是一个 Capped Collection（固定集合），即超出配置的最大值后，会自动删除最老的历史数据\r\n\t\t- MongoDB 针对 oplog 的删除有特殊优化，以提升删除效率\r\n\t- 主节点产生新的 oplog Entry，从节点通过复制 oplog 并应用来保持和主节点的状态一致\r\n- 查看 oplog\r\n\t- `use local`\r\n\t- `db.oplog.rs.find().sort({$natural:‐1}).pretty()`\r\n\t\t- ts字段描述了oplog产生的时间戳，可称之为optime。optime是备节点实现增量日志同步的关键，它保证了oplog是节点有序的，其由两部分组成\r\n\t\t\t- 当前的系统时间，即UNIX时间至现在的秒数，32位\r\n\t\t\t- 整数计时器，不同时间值会将计数器进行重置，32位\r\n\t\t- optime属于BSON的Timestamp类型，这个类型一般在MongoDB内部使用\r\n- oplog 保证了节点级有序，那么备节点便可以通过轮询的方式进行拉取；这里会用到可持续追踪的游标（tailable cursor）技术\r\n\t- ![oplog](static/MongoDB-复制集-5.png)\r\n\t\t- 每个备节点都分别维护了自己的一个offset，也就是从主节点拉取的最后一条日志的optime\r\n\t\t- 在执行同步时就通过这个optime向主节点的oplog集合发起查询\t\t\t\t\r\n\t\t- 为了避免不停地发起新的查询链接，在启动第一次查询后可以将cursor挂住（通过将cursor设置为tailable）\r\n\t\t- 这样只要oplog中产生了新的记录，备节点就能使用同样的请求通道获得这些数据\r\n\t\t- tailable cursor只有在查询的集合为固定集合时才允许开启\r\n- oplog 集合的大小 `replication.oplogSizeMB`\r\n\t- 默认值为 `oplogSizeMB = min(磁盘可用空间*5%，50GB)`\r\n\t- `db.oplog.rs.stats().maxSize` 查看oplog大小\r\n\t- `replSetResizeOplog`命令，可以实现动态修改oplogSize而不需要重启服务器\r\n\t\t- `db.adminCommand({replSetResizeOplog: 1, size: 60000})`\r\n- oplog 幂等性：每一条oplog记录都描述了一次数据的原子性变更，对于oplog来说，必须保证是幂等性的\r\n- oplog 幂等性的代价\r\n\t- 简单元素的操作，$inc 转化为 $set并没有什么影响，执行开销上也差不多\r\n\t- 但当遇到数组元素操作时，情况就不一样了\r\n\t\t- `$push`操作被转换为了`$set`操作（设置数组指定位置的元素为某个值），开销上也差不多\r\n\t\t- 当向数组的头部添加元素时，oplog里的`$set`操作不再是设置数组某个位置的值（因为基本所有的元素位置都调整了），而是`$set`数组最终的结果，即整个数组的内容都要写入oplog\r\n\t\t- 当push操作指定了`$slice`或者`$sort`参数时，oplog的记录方式也是一样的，会将整个数组的内容作为`$set`的参数\r\n\t\t- `$pull`, `$addToSet`等更新操作符也是类似，更新数组后，oplog里会转换成`$set`数组的最终内容，才能保证幂等性\r\n\t- 大数组更新：oplog的写入被放大，导致同步追不上（致主备间网卡流量跑满）\r\n\t\t- 当数组非常大时，对数组的一个小更新，可能就需要把整个数组的内容记录到oplog里\r\n\t\t- 由于oplog的量太大，旧的内容很快被删除掉，最终导致Secondary追不上，转换为RECOVERING状态\r\n\t- 使用数组时，尽量注意\r\n\t\t- 数组的元素个数不要太多，总的大小也不要太大\r\n\t\t- 尽量避免对数组进行更新操作\r\n\t\t- 如果一定要更新，尽量只在尾部插入元素，复杂的逻辑可以考虑在业务层面上来支持\r\n- oplog 复",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.复制集",
      "lvl1": "复制集架构",
      "lvl2": "复制集操作",
      "lvl3": "复制集成员角色",
      "lvl4": "复制集高可用",
      "lvl5": "复制集数据同步机制 oplog"
    },
    "frontmatter": {
      "title": "5.复制集",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 4
  },
  {
    "title": "5.复制集",
    "path": "/docs/architect/mongodb/MongoDB-5.fuzhiji.html",
    "url": "/docs/architect/mongodb/MongoDB-5.fuzhiji.html",
    "content": "制延迟\r\n\t- 由于oplog集合是有固定大小的，因此存放在里面的oplog随时可能会被新的记录冲掉\r\n\t- 如果备节点的复制不够快，就无法跟上主节点的步伐，从而产生复制延迟（replication lag）问题\r\n\t- 一旦备节点的延迟过大，则随时会发生复制断裂的风险\r\n\t\t- 这意味着备节点的optime（最新一条同步记录）已经被主节点老化掉，于是备节点将无法继续进行数据同步\r\n- 尽量避免复制延迟带来的风险\r\n\t- 增加oplog的容量大小，并保持对复制窗口的监视\r\n\t- 通过一些扩展手段降低主节点的写入速度\r\n\t- 优化主备节点之间的网络\r\n\t- 避免字段使用太大的数组（可能导致oplog膨胀）\r\n- 数据回滚\r\n\t- 由于复制延迟是不可避免的，这意味着主备节点之间的数据无法保持绝对的同步\r\n\t- 当复制集中的主节点宕机时，备节点会重新选举成为新的主节点\r\n\t\t- 当旧的主节点重新加入时，必须回滚掉之前的一些“脏日志数据”，以保证数据集与新的主节点一致\r\n\t\t\t- 主备复制集合的差距越大，发生大量数据回滚的风险就越高\r\n\t- 对于写入的业务数据来说，如果已经被复制到了复制集的大多数节点，则可以避免被回滚的风险\r\n\t\t- 应用上可以通过设定更高的写入级别（writeConcern：majority）来保证数据的持久性\r\n\t- 这些由旧主节点回滚的数据会被写到单独的rollback目录下，必要的情况下仍然可以恢复这些数据\r\n\t\t- 当rollback发生时，MongoDB将把rollback的数据以BSON格式存放到dbpath路径下rollback文件夹中，BSON文件的命名格式：`<database>.<collection>.<timestamp>.bson`\r\n\t\t- `mongorestore ‐‐host 192.168.192:27018 ‐‐db test ‐‐collection emp ‐ufox ‐pfox  ‐‐authenticationDatabase=admin rollback/emp_rollback.bson`\r\n- 同步源选择：MongoDB 是允许通过备节点进行复制的\r\n\t- 在`settings.chainingAllowed`开启的情况下（默认是开启的），备节点自动选择一个最近的节点（ping命令时延最小）进行同步\r\n\t- 默认情况下备节点并不一定会选择主节点进行同步，这个副作用就是会带来延迟的增加，关闭这个设置：\r\n\t\t- `cfg = rs.config()`\r\n\t\t- `cfg.settings.chainingAllowed = false`\r\n\t\t- `rs.reconfig（cfg)`\r\n\t- 使用`replSetSyncFrom`命令临时更改当前节点的同步源，比如在初始化同步时将同步源指向备节点来降低对主节点的影响\r\n\t\t- `db.adminCommand( { replSetSyncFrom: \"hostname:port\" })`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.复制集",
      "lvl1": "复制集架构",
      "lvl2": "复制集操作",
      "lvl3": "复制集成员角色",
      "lvl4": "复制集高可用",
      "lvl5": "复制集数据同步机制 oplog"
    },
    "frontmatter": {
      "title": "5.复制集",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 4,
    "contentParts": 4
  },
  {
    "title": "6.分片集",
    "path": "/docs/architect/mongodb/MongoDB-6.fenpianji.html",
    "url": "/docs/architect/mongodb/MongoDB-6.fenpianji.html",
    "content": "---\r\ntitle: 6.分片集\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- 分片集群架构\r\n- 分片策略\r\n- 数据均衡\r\n\r\n---\r\n## 分片集群架构\r\n\r\n- 使用分片的场景\r\n\t- 存储容量需求超出单机的磁盘容量\r\n\t- 活跃的数据集超出单机内存容量，导致很多请求都要从磁盘读取数据\r\n\t- 写IOPS超出单个MongoDB节点的写服务能力\r\n- MongoDB 分片集群架构（Sharded Cluster）：水平扩展\r\n\t- 在分片模式下，存储不同的切片数据的节点被称为分片节点，除了分片节点，集群中还需要一些配置节点、路由节点，以保证分片机制的正常运作\r\n\t\t- ![MongoDB 分片集群架构](static/MongoDB-分片集-1.png)\r\n- 核心概念\r\n\t- 数据分片\r\n\t\t- 分片用于存储真正的数据，并提供最终的数据读写访问。分片仅仅是一个逻辑的概念，它可以是一个单独的mongod实例，也可以是一个复制集\r\n\t\t- 在生产环境中也一般会使用复制集的方式，这是为了防止数据节点出现单点故障\r\n\t- 配置服务器（Config Server）\r\n\t\t- 配置服务器包含多个节点，并组成一个复制集结构\r\n\t\t- 配置复制集中保存了整个分片集群中的元数据，其中包含各个集合的分片策略，以及分片的路由表等\r\n\t- 查询路由（mongos）\r\n\t\t- mongos是分片集群的访问入口，其本身并不持久化数据\r\n\t\t- mongos启动后，会从配置服务器中加载元数据\r\n\t\t- 之后mongos开始提供访问服务，并将用户的请求正确路由到对应的分片\r\n\t\t- 在分片集群中可以部署多个mongos以分担客户端请求的压力\r\n- 使用分片集群\r\n\t- `sh.enableSharding(\"shop\")` 先开启database的分片功能\r\n\t- `sh.shardCollection(\"shop.product\",{productId:\"hashed\"},false,{numInitialChunks:4})`\r\n\t\t- 对集合执行分片初始化\r\n\t\t- shop.product集合将productId作为分片键，并采用了哈希分片策略\r\n\t\t- “numInitialChunks：4”表示将初始化4个chunk\r\n\t\t- numInitialChunks 必须和哈希分片策略配合使用\r\n\t\t- 这个选项只能用于空的集合，如果已经存在数据则会返回错误\r\n- 查询数据分布 `db.product.getShardDistribution()` \r\n- chunk的意思是数据块，一个chunk代表了集合中的“一段数据”\r\n\t- chunk所描述的是范围区间，就是分片键各个值（或哈希值）的连续区间\r\n\t- 集群在操作分片集合时，会根据分片键找到对应的chunk，并向该chunk所在的分片发起操作请求\r\n\t- chunk的分布在一定程度上会影响数据的读写路径，这由以下两点决定\r\n\t\t- chunk的切分方式，决定如何找到数据所在的chunk\r\n\t\t- chunk的分布状态，决定如何找到chunk所在的分片\r\n\r\n---\r\n## 分片策略\r\n\r\n- 分片算法：chunk切分是根据分片策略进行实施的，分片策略的内容包括分片键和分片算法\r\n\t- 范围分片（range sharding）：范围分片能很好地满足范围查询的需求\r\n\t\t- 缺点在于，如果Shard Key有明显递增（或者递减）趋势，则新插入的文档会分布到同一个chunk，此时写压力会集中到一个节点，从而导致单点的性能瓶颈\r\n\t\t\t- 时间值；ObjectId，自动生成的_id由时间、计数器组成；UUID，包含系统时间、时钟序列；自增整数序列\r\n\t- 哈希分片（hash sharding）：适用于日志，物联网等高并发场景\r\n\t\t- 事先根据分片键计算出一个新的哈希值（64位整数），再根据哈希值按照范围分片的策略进行chunk的切分\r\n\t\t- ![哈希分片](static/MongoDB-分片集-2.png)\r\n\t\t- 哈希分片与范围分片是互补的（哈希分片的离散性既是优点也是缺点）\r\n\t\t\t- 由于哈希算法保证了随机性，所以文档可以更加离散地分布到多个chunk上，这避免了集中写问题\r\n\t\t\t- 然而，在执行一些范围查询时，哈希分片并不是高效的（离散）\r\n\t- 哈希分片只能选择单个字段，而范围分片允许采用组合式的多字段作为分片键\r\n\t\t- 4.4 以后的版本，可以将单个字段的哈希分片和一个到多个的范围分片键字段来进行组合\r\n\t\t\t- `{x:1 , y:\"hashed\"}`\r\n- 分片标签：MongoDB允许通过为分片添加标签（tag）的方式来控制数据分发\r\n\t- 一个标签可以关联到多个分片区间（TagRange）\r\n\t\t- 均衡器会优先考虑chunk是否正处于某个分片区间上（被完全包含）；意思是当前的chunk是不是在某个分片区间上被完全包含了（可以关联多个分片区间）\r\n\t\t\t- 如果是则会将chunk迁移到分片区间所关联的分片，否则按一般情况处理\r\n\t- 分片标签适用于一些特定的场景\r\n\t\t- 集群中可能同时存在OLTP和OLAP处理\r\n\t\t\t- 一些系统日志的重要性相对较低，而且主要以少量的统计分析为主\r\n\t\t\t- 为了便于单独扩展，我们可能希望将日志与实时类的业务数据分开，此时就可以使用标签\r\n\t- `sh.addShardTag(\"shard01\",\"oltp\")` 让分片拥有指定的标签\r\n\t- `sh.addTagRange(\"main.devices\",{shardKey:MinKey},{shardKey:MaxKey},\"oltp\")` 指定分片标签\r\n- 分片键（ShardKey）的选择\r\n\t- 在选择分片键时，需要根据业务的需求及范围分片、哈希分片的不同特点进行权衡\r\n\t- 在设计分片键时需要考虑的因素包括\r\n\t\t- 分片键的基数（cardinality），取值基数越大越有利于扩展\r\n\t\t- 分片键的取值分布应该尽可能均匀\r\n\t\t- 业务读写模式，尽可能分散写压力，而读操作尽可能来自一个或少量的分片\r\n\t\t- 分片键应该能适应大部分的业务操作\r\n- 分片键（ShardKey）的约束：ShardKey 必须是一个索引\r\n\t- 非空集合须在 ShardCollection 前创建索引\r\n\t- 空集合 ShardCollection 自动创建索引\r\n\t- ShardKey 大小无限制\r\n\t- 支持复合哈希分片键\r\n\t- Document 中可以不包含 ShardKey，插入时被当 做 Null 处理\r\n\t- 为 ShardKey 添加后缀 refineCollectionShardKey 命令，可以修改 ShardKey 包含的 Field\r\n\t- 如果 ShardKey 为非 `_ID` 字段， 那么可以修改 ShardKey 对应的值\r\n\r\n---\r\n## 数据均衡",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "6.分片集",
      "lvl1": "分片集群架构",
      "lvl2": "分片策略",
      "lvl3": "数据均衡"
    },
    "frontmatter": {
      "title": "6.分片集",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "6.分片集",
    "path": "/docs/architect/mongodb/MongoDB-6.fenpianji.html",
    "url": "/docs/architect/mongodb/MongoDB-6.fenpianji.html",
    "content": "\r\n\r\n- 均衡的方式：为了保证分片集群的水平扩展能力，业务数据应当尽可能地保持均匀分布\r\n\t- 所有的数据应均匀地分布于不同的chunk上（由业务场景和分片策略来决定）\r\n\t- 每个分片上的chunk数量尽可能是相近的\r\n\t\t- 手动均衡\r\n\t\t\t- 可以在初始化集合时预分配一定数量的chunk（仅适用于哈希分片）\r\n\t\t\t- 可以通过splitAt、moveChunk命令进行手动切分、迁移\r\n\t\t- 自动均衡：开箱即用\r\n\t\t\t- 均衡器会在后台对各分片的chunk进行监控，一旦发现了不均衡状态就会自动进行chunk的搬迁以达到均衡\r\n- chunk 不均衡通常来自于两方面的因素\r\n\t- 在没有人工干预的情况下，chunk会持续增长并产生分裂（split），而不断分裂的结果就会出现数量上的不均衡\r\n\t- 在动态增加分片服务器时，也会出现不均衡的情况\r\n- chunk 分裂：默认情况下，一个chunk的大小为64MB，该参数由配置的chunksize参数指定\r\n\t- 如果持续地向该chunk写入数据，并导致数据量超过了chunk大小，则MongoDB会自动进行分裂，将该chunk切分为两个相同大小的chunk\r\n\t\t- ![chunk 分裂](static/MongoDB-分片集-3.png)\r\n\t- chunk分裂是基于分片键进行的，如果分片键的基数太小，则可能因为无法分裂而会出现 jumbo chunk（超大块）的问题\r\n\t\t- jumbo chunk对水平扩展有负面作用，该情况不利于数据的均衡，业务上应尽可能避免\r\n- 写入压力过大的情况可能会导致chunk多次失败（split）\r\n\t- 最终当chunk中的文档数大于`1.3×avgObjectSize`时会导致无法迁移\r\n- 自动均衡\r\n\t- MongoDB的数据均衡器运行于Primary Config Server（配置服务器的主节点）上，而该节点也同时会控制chunk数据的搬迁流程\r\n\t\t- ![自动均衡](static/MongoDB-分片集-4.png)\r\n\t\t- 分片shard0在持续的业务写入压力下，产生了chunk分裂\r\n\t\t- 分片服务器通知Config Server进行元数据更新\r\n\t\t- Config Server的自动均衡器对chunk分布进行检查，发现shard0和shard1的chunk数差异达到了阈值\r\n\t\t\t- 向shard0下发moveChunk命令以执行chunk迁移\r\n\t\t- shard0执行指令，将指定数据块复制到shard1\r\n\t\t\t- 该阶段会完成索引、chunk数据的复制\r\n\t\t\t- 整个过程中业务侧对数据的操作仍然会指向shard0\r\n\t\t\t- 在第一轮复制完毕之后，目标shard1会向shard0确认是否还存在增量更新的数据\r\n\t\t\t\t- 如果存在则继续复制\r\n\t\t- shard0完成迁移后发送通知，此时Config Server开始更新元数据库，将chunk的位置更新为目标shard1\r\n\t\t\t- 在更新完元数据库后并确保没有关联cursor的情况下，shard0会删除被迁移的chunk副本\r\n\t\t- Config Server通知mongos服务器更新路由表\r\n\t\t\t- 新的业务请求将被路由到shard1\r\n- 迁移阈值：均衡器对于数据的“不均衡状态”判定是根据两个分片上的chunk个数差异来进行的\r\n\t- chunk个数少于20 迁移阈值 2\r\n\t- chunk个数20～79 迁移阈值 4\r\n\t- chunk个数80及以上 迁移阈值 8\r\n- 迁移速度：整个过程并不是很快\r\n\t- `_secondaryThrottle`：用于调整迁移数据写到目标分片的安全级别（默认设定为 false）\r\n\t\t- 如果没有设定，则会使用`w:2`选项，即至少一个备节点确认写入迁移数据后才算成功\r\n\t\t- MongoDB 3.4版本开始，`_secondaryThrottle`被默认设定为false，chunk迁移不再等待备节点写入确认\r\n\t- `_waitForDelete`：在chunk迁移完成后，源分片会将不再使用的chunk删除（默认设定为 false）\r\n\t\t- 如果`_waitForDelete`是true，那么均衡器需要等待chunk同步删除后才进行下一次迁移\r\n\t\t- 该选项默认为false，这意味着对于旧chunk的清理是异步进行的\r\n\t- 并行迁移数量：允许n个分片的集群同时执行n/2个并发任务\r\n\t- 从MongoDB 4.0版本开始，支持在迁移数据的过程中并发地读取源端和写入目标端\r\n\t\t- 使得新加入的分片能更快地分担集群的访问读写压力\r\n- 数据均衡带来的问题：会影响性能\r\n\t- 在分片间进行数据块的迁移是一个“繁重”的工作，很容易带来磁盘I/O使用率飙升，或业务时延陡增等一些问题\r\n\t\t- 提升磁盘能力\r\n\t\t- 将数据均衡的窗口对齐到业务的低峰期以降低影响\r\n\t\t\t- `use config`\r\n\t\t\t- `sh.setBalancerState(true)`\r\n\t\t\t- `db.settings.update({_id:\"balancer\"},{$set:{activeWindow:{start:\"02:00\",stop:\"04:00\"}}},{upsert:true})`\r\n\t\t\t\t- 启用了自动均衡器，同时在每天的凌晨2点到4点运行数据均衡操作\r\n\t- 对分片集合中执行count命令可能会产生不准确的结果\r\n\t\t- mongos在处理count命令时会分别向各个分片发送请求，并累加最终的结果\r\n\t\t\t- 如果分片上正在执行数据迁移，则可能导致重复的计算\r\n\t\t- 替代办法是使用`db.collection.countDocuments({})`方法\r\n\t\t\t- 该方法会执行聚合操作进行实时扫描，可以避免元数据读取的问题，但需要更长时间\r\n\t- 在执行数据库备份的期间，不能进行数据均衡操作，会产生不一致的备份数据\r\n\t\t- 在备份操作之前，可以通过如下命令确认均衡器的状态\r\n\t\t\t- `sh.getBalancerState()`：查看均衡器是否开启\r\n\t\t\t- `sh.isBalancerRunning()`：查看均衡器是否正在运行\r\n\t\t\t- `sh.getBalancerWindow()`：查看当前均衡的窗口设定\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "6.分片集",
      "lvl1": "分片集群架构",
      "lvl2": "分片策略",
      "lvl3": "数据均衡"
    },
    "frontmatter": {
      "title": "6.分片集",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "7.高级集群架构",
    "path": "/docs/architect/mongodb/MongoDB-7.gaojijiqunjiagou.html",
    "url": "/docs/architect/mongodb/MongoDB-7.gaojijiqunjiagou.html",
    "content": "---\r\ntitle: 7.高级集群架构\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- 两地三中心集群架构\r\n- 全球多写集群架构\r\n\r\n---\r\n## 两地三中心集群架构\r\n\r\n![](static/MongoDB-高级集群架构-1.png)\r\n![](static/MongoDB-高级集群架构-2.png)\r\n![](static/MongoDB-高级集群架构-3.png)\r\n![](static/MongoDB-高级集群架构-4.png)\r\n\r\n---\r\n## 全球多写集群架构\r\n\r\n![](static/MongoDB-高级集群架构-5.png)\r\n![](static/MongoDB-高级集群架构-6.png)\r\n![MongoDB Zone Sharding - 全球集群](static/MongoDB-高级集群架构-7.png)\r\n![](static/MongoDB-高级集群架构-8.png)\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "7.高级集群架构",
      "lvl1": "两地三中心集群架构",
      "lvl2": "全球多写集群架构"
    },
    "frontmatter": {
      "title": "7.高级集群架构",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content"
  },
  {
    "title": "8.事务",
    "path": "/docs/architect/mongodb/MongoDB-8.shiwu.html",
    "url": "/docs/architect/mongodb/MongoDB-8.shiwu.html",
    "content": "---\r\ntitle: 8.事务\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- MongoDB 多文档事务\r\n\t- writeConcern\r\n\t- readPreference\r\n\t- readConcern\r\n- 事务隔离级别\r\n\r\n---\r\n## MongoDB 多文档事务\r\n\r\n- 对单个文档的操作是原子的\r\n\t- 由于可以在单个文档结构中使用内嵌文档和数组来获得数据之间的关系，而不必跨多个文档和集合进行范式化，所以这种单文档原子性避免了许多实际场景中对多文档事务的需求\r\n- 支持多文档事务（能不用尽量不用）\r\n\t- 通过合理地设计文档模型，可以规避绝大部分使用事务的必要性\r\n- 支持分布式事务，事务可以跨多个操作、集合、数据库、文档和分片使用\r\n- 使用事务的原则\r\n\t- 无论何时，事务的使用总是能避免则避免\r\n\t- 模型设计先于事务，尽可能用模型设计规避事务\r\n\t- 不要使用过大的事务（尽量控制在 1000 个文档更新以内）\r\n\t- 当必须使用事务时，尽可能让涉及事务的文档分布在同一个分片上，这将有效地提高效率\r\n- 事务支持机制\r\n\t- Atomocity 原子性：单表单文档；复制集多表多行；分片集群多表多行\r\n\t- Consistency 一致性： writeConcern, readConcern\r\n\t- Isolation 隔离性：readConcern\r\n\t- Durability 持久性：Journal and Replication\r\n- 使用方法\r\n```java\r\n// java\r\ntry (ClientSession clientSession = client.startSession()) { \r\n\tclientSession.startTransaction();\r\n\tcollection.insertOne(clientSession, docOne);\r\n\tcollection.insertOne(clientSession, docTwo);\r\n\tclientSession.commitTransaction();\r\n}\r\n\r\n// js\r\nvar session = db.getMongo().startSession()\r\nsession.startTransaction({readConcern:{level:\"snapshot\"},writeConcern:{w:\"majority\"}})\r\nsession.commitTransaction()\r\nsession.abortTransaction() // 回滚事务\r\n```\r\n\r\n### writeConcern\r\n\r\n- writeConcern 决定一个写操作落到多少个节点上才算成功\r\n\t- w: 数据写入到number个节点才向用客户端确认\r\n\t\t- {w: 0} 对客户端的写入不需要发送任何确认，适用于性能要求高，但不关注正确性的场景\r\n\t\t- {w: 1} 默认的writeConcern，数据写入到Primary就向客户端发送确认\r\n\t\t\t- ![w: 1](static/MongoDB-事务-1.png)\r\n\t\t- {w: \"majority\"} 数据写入到副本集大多数成员后向客户端发送确认，适用于对数据安全性要求比较高的场景，该选项会降低写入性能\r\n\t\t\t- ![w: \"majority\"](static/MongoDB-事务-2.png)\r\n\t-  j: 写入操作的journal持久化后才向客户端确认\r\n\t\t- 默认为{j: false}，如果要求Primary写入持久化了才向客户端确认，则指定该选项为true\r\n\t- wtimeout: 写入超时时间，仅w的值大于1时有效\r\n\t\t- 当指定{w: }时，数据需要成功写入number个节点才算成功，如果写入过程中有节点故障，可能导致这个条件一直不能满足，从而一直不能向客户端发送确认结果\r\n\t\t\t- 客户端可设置wtimeout选项来指定超时时间，当写入过程持续超过该时间仍未结束，则认为写入失败\r\n- 注意事项\r\n\t- 然多于半数的 writeConcern 都是安全的，但通常只会设置 majority，因为这是等待写入延迟时间最短的选择\r\n\t- 不要设置 writeConcern 等于总节点数，因为一旦有一个节点故障，所有写操作都将失败\r\n\t- writeConcern 虽然会增加写操作延迟时间，但并不会显著增加集群压力，因此无论是否等待，写操作最终都会复制到所有节点上。设置 writeConcern 只是让写操作等待复制后再返回而已\r\n\t- 应对重要数据应用 {w: “majority”}，普通数据可以应用 {w: 1} 以确保最佳性能\r\n\r\n### readPreference\r\n\r\n- readPreference 决定使用哪一个节点来满足正在发起的读请求\r\n\t- primary: 只选择主节点，默认模式\r\n\t- primaryPreferred：优先选择主节点，如果主节点不可用则选择从节点\r\n\t- secondary：只选择从节点\r\n\t- secondaryPreferred：优先选择从节点， 如果从节点不可用则选择主节点\r\n\t- nearest：根据客户端对节点的 Ping 值判断节点的远近，选择从最近的节点读取\r\n- 场景举例\r\n\t- primary/primaryPreferred 用户下订单后马上将用户转到订单详情页（此时从节点可能还没复制到新订单）\r\n\t- secondary/secondaryPreferred 用户查询自己下过的订单（时效性通常没有太高要求）\r\n\t- secondary 生成报表（对时效性要求不高，但资源需求大）\r\n\t- nearest 将用户上传的图片分发到全世界，让各地用户能够就近读取\r\n- readPreference 配置\r\n\t- `mongodb://host1:27107,host2:27107,host3:27017/?replicaSet=rs0&readPreference=secondary`\r\n\t- `MongoCollection.withReadPreference(ReadPreference readPref)`\r\n\t- `db.collection.find().readPref( \"secondary\" )`\r\n- Tag：readPreference 只能控制使用一类节点。Tag 则可以将节点选择控制到一个或几个节点\r\n\t- ![Tag](static/MongoDB-事务-3.png)\r\n\t- `conf = rs.conf()`\r\n\t- `conf.members[1].tags = { purpose: \"online\"}`\r\n\t- `conf.members[4].tags = { purpose: \"analyse\"}`\r\n\t- `rs.reconfig(conf)`\r\n\t- `db.collection.find({}).readPref( \"secondary\", [ {purpose: \"analyse\"} ] )`\r\n- 注意事项\r\n\t- 指定 readPreference 时也应注意高可用问题\r\n\t\t- 将 readPreference 指定 primary，则发生故障转移不存在 primary 期间将没有节点可读。如果业务允许，则应选择 primaryPreferred\r\n\t- 使用 Tag 时也会遇到同样的问题，如果只有一个节点拥有一个特定 Tag，则在这个节点失效时将无节点可读。这在有时候是期望的结果，有时候不是\r\n\t- Tag 有时需要与优先级、选举权综合考虑。例如做报表的节点通常不会希望它成为主节点，则优先级应为 0\r\n\r\n### readConcern\r\n\r\n- 在 readPreference 选择了指定的节点后，readConcern 决定这个节点上的数据哪些是可读的，类似事务隔离级别\r\n\t- available：读取所有可用的数据\r\n\t- local（默认）：读取所有可用且属于当前分片的数据\r\n\t- majority（数据读一致性的充分保",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "8.事务",
      "lvl1": "MongoDB 多文档事务",
      "lvl2": "事务隔离级别"
    },
    "frontmatter": {
      "title": "8.事务",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "8.事务",
    "path": "/docs/architect/mongodb/MongoDB-8.shiwu.html",
    "url": "/docs/architect/mongodb/MongoDB-8.shiwu.html",
    "content": "证）：读取在大多数节点上提交完成的数据\r\n\t- linearizable（增强处理 majority 情况下主节点失联时候的例外情况 ）：可线性化读取文档，仅支持从主节点读\r\n\t- snapshot（最高隔离级别）：读取最近快照中的数据，仅可用于多文档事务\r\n\t- `db.user.find().readConcern(\"local\")`\r\n- 在复制集中 local 和 available 是没有区别的，两者的区别主要体现在分片集上\r\n\t- 一个 chunk x 正在从 shard1 向 shard2 迁移\r\n\t- 整个迁移过程中 chunk x 中的部分数据会在 shard1 和 shard2 中同时存在，但源分片 shard1仍然是chunk x 的负责方\r\n\t\t- 所有对 chunk x 的读写操作仍然进入 shard1\r\n\t\t- config 中记录的信息 chunk x 仍然属于 shard1\r\n\t- 此时如果读 shard2，则会体现出 local 和 available 的区别\r\n\t\t- local：只取应该由 shard2 负责的数据（不包括 x）\r\n\t\t- available：shard2 上有什么就读什么（包括 x）\r\n\t- 注意事项\r\n\t\t- 虽然看上去总是应该选择 local，但毕竟对结果集进行过滤会造成额外消耗。在一些无关紧要的场景（例如统计）下，也可以考虑 available\r\n\t\t- 从主节点读取数据时默认 readConcern 是 local\r\n\t\t- 从从节点读取数据时默认 readConcern 是 available（向前兼容原因）\r\n- `readConcern:majority` 只读取大多数据节点上都提交了的数据\r\n\t- ![readConcern: majority](static/MongoDB-事务-4.png)\r\n\t- ![readConcern: majority](static/MongoDB-事务-5.png)\r\n\t- 考虑 t3 时刻的 Secondary1\r\n\t\t- 对于要求 majority 的读操作，它将返回 x=0\r\n\t\t- 对于不要求 majority 的读操作，它将返回 x=1\r\n\t- 配置文件：`replication:enableMajorityReadConcern: true`\r\n- MVCC 机制（节点上维护多个 x 版本），MongoDB 通过维护多个快照来链接不同的版本\r\n\t- 每个被大多数节点确认过的版本都将是一个快照\r\n\t- 快照持续到没有人使用为止才被删除\r\n- MongoDB 中的回滚\r\n\t- 写操作到达大多数节点之前都是不安全的，一旦主节点崩溃，而从节点还没复制到该次操作，刚才的写操作就丢失了\r\n\t- 把一次写操作视为一个事务，从事务的角度，可以认为事务被回滚了\r\n- `readConcern:majority` 可以有效避免脏读\r\n\t- 如果在一次写操作到达大多数节点前读取了这个写操作，然后因为系统故障该操作回滚了，则发生了脏读问题\r\n- 安全的读写分离：向主节点写入一条数据之后立即从从节点读取这条数据（可能读不到）\r\n\t- 使用 writeConcern+readConcern majority 来解决\r\n\t\t- `db.orders.insert({oid:101,sku:\"kite\",q:1},{writeConcern:{w:\"majority\"}})`\r\n\t\t- `db.orders.find({oid:101}).readPref(\"secondary\").readConcern(\"majority\")`\r\n- `readConcern: linearizable` 只读取大多数节点确认过的数据。和 majority 最大差别是保证绝对的操作线性顺序\r\n\t- 在写操作自然时间后面的发生的读，一定可以读到之前的写 \r\n\t- 只对读取单个文档时有效\r\n\t- 可能导致非常慢的读，因此总是建议配合使用 maxTimeMS\r\n\t- ![rreadConcern: linearizable](static/MongoDB-事务-6.png)\r\n- `readConcern: snapshot` 只在多文档事务中生效\r\n\t- 将保证在事务中的读：不出现脏读、不可重复读、幻读\r\n\t- 因为所有的读都将使用同一个快照，直到事务提交为止该快照才被释放\r\n\r\n---\r\n## 事务隔离级别\r\n\r\n- 事务完成前，事务外的操作对该事务所做的修改不可访问\r\n\t- readPreference \r\n\t\t- available：读取所有可用的数据\r\n\t\t- local（默认）：读取所有可用且属于当前分片的数据\r\n\t\t- majority（数据读一致性的充分保证）：读取在大多数节点上提交完成的数据\r\n\t\t- linearizable（增强处理 majority 情况下主节点失联时候的例外情况 ）\r\n\t\t\t- 可线性化读取文档，仅支持从主节点读\r\n\t\t- snapshot（最高隔离级别）：读取最近快照中的数据，仅可用于多文档事务\r\n- 如果事务内使用 {readConcern: “snapshot”}，则可以达到可重复读 \r\n- 事务超时\r\n\t- 默认情况下MongoDB会为每个事务设置1分钟的超时时间，如果在该时间内没有提交，就会强制将其终止\r\n\t- 该超时时间可以通过transactionLifetimeLimitSecond变量设定\r\n- 事务写机制\r\n\t- 当一个事务开始后，如果事务要修改的文档在事务外部被修改过，则事务修改这个文档时会触发 Abort 错误，因为此时的修改冲突了\r\n\t\t- 这种情况下，只需要简单地重做事务就可以了\r\n\t- 如果一个事务已经开始修改一个文档，在事务以外尝试修改同一个文档，则事务以外的修改会等待事务完成才能继续进行\r\n- 注意事项\r\n\t- 可以实现和关系型数据库类似的事务场景\r\n\t- 必须使用与 MongoDB 4.2 兼容的驱动\r\n\t- 事务默认必须在 60 秒（可调）内完成，否则将被取消\r\n\t- 涉及事务的分片不能使用仲裁节点\r\n\t- 事务会影响 chunk 迁移效率。正在迁移的 chunk 也可能造成事务提交失败（重试即可）\r\n\t- 多文档事务中的读操作必须使用主节点读\r\n\t- readConcern 只应该在事务级别设置，不能设置在每次读写操作上\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "8.事务",
      "lvl1": "MongoDB 多文档事务",
      "lvl2": "事务隔离级别"
    },
    "frontmatter": {
      "title": "8.事务",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "9.调优",
    "path": "/docs/architect/mongodb/MongoDB-9.diaoyou.html",
    "url": "/docs/architect/mongodb/MongoDB-9.diaoyou.html",
    "content": "---\r\ntitle: 9.调优\r\ndate: 2025-07-04\r\n---\r\n\r\n\r\n- 影响 MongoDB 性能的因素\r\n- MongoDB 性能监控工具：mongostat；mongotop；Profiler；`db.currentOp()`\r\n\r\n---\r\n\r\n## 影响 MongoDB 性能的因素\r\n\r\n- 导致MongoDB性能不佳的原因\r\n\t- 慢查询；阻塞等待（通常是因为模型/索引设计不佳导致的）\r\n\t- 硬件资源不足\r\n- 影响MongoDB性能的因素\r\n\t- ![影响MongoDB性能的因素](static/MongoDB-调优-1.png)\r\n- MongoDB 优化建模\r\n\t- 使用数组索引区分不同的属性，比如一张电影票在不同影院的价格，用户查最优价格的时候就可以使用数组索引\r\n\t- 对数据的分段存储\r\n\t\t- 比如高频时序数据，那么可以利用嵌套文档把每秒钟的数据单独存放为一个属性，然后把每分钟的数据单独存放为一个文档（恰好WiredTiger是每分钟进行一次刷盘）\r\n\r\n---\r\n\r\n## MongoDB 性能监控工具\r\n\r\n- mongostat：可以提供数据库节点或者整个集群当前的状态视图（当前的QPS/内存使用/连接数，以及多个分片的压力分布），采用Go语言实现，其内部使用了`db.serverStatus()`命令，要求执行用户需具备clusterMonitor角色权限\r\n\t- `mongostat -h 192.168.65.174 --port 28017 -ufox -pfox --authenticationDatabase=admin --discover -n 300 2`\r\n\t\t- `--discover`：启用自动发现，可展示集群中所有分片节点的状态\r\n\t\t- `-n 300 2`：表示输出300次，每次间隔2s。也可以不指定`-n 300`，此时会一直保持输出\r\n\t- 需要关注的指标主要有\r\n\t\t- 插入、删除、修改、查询的速率是否产生较大波动，是否超出预期\r\n\t\t- qrw、arw：队列是否较高，若长时间大于0则说明此时读写速度较慢\r\n\t\t\t- `qrw` 客户端读写等待队列数量，高并发时，一般队列值会升高\r\n\t\t\t- `arw` 客户端读写活跃个数\r\n\t\t- conn：连接数是否太多\r\n\t\t\t- `conn` 当前连接数\r\n\t\t- dirty：百分比是否较高，若持续高于10%则说明磁盘I/O存在瓶颈\r\n\t\t\t- `%dirty` WiredTiger 缓存中脏数据百分比\r\n\t\t\t- `%used` WiredTiger 正在使用的缓存百分比\r\n\t\t- netIn、netOut：是否超过网络带宽阈值\r\n\t\t\t- `netIn` 网络接收数据量\r\n\t\t\t- `netOut` 网络发送数据量\r\n\t\t- repl：状态是否异常，如PRI、SEC、RTR为正常，若出现REC等异常值则需要修复\r\n\t\t\t- `repl` 复制节点状态（主节点/二级节点……)\r\n\t- `--interactive`选项，用来实现非滚动式的监视（交互模式）\r\n\t\t- `mongostat -h 192.168.65.174 --port 28017 -ufox -pfox --authenticationDatabase=admin --discover --interactive -n 2`\r\n- mongotop：可用于查看数据库的热点表，可以判定是哪些集合占用了大部分读写时间，mongotop与mongostat的实现原理类似，同样需要clusterMonitor角色权限\r\n\t- `mongotop -h 192.168.65.174 --port=28017 -ufox -pfox --authenticationDatabase=admin`\r\n\t\t- 默认情况下，mongotop会持续地每秒输出当前的热点表\r\n\t- 需要关注的因素主要有\r\n\t\t- 热点表操作耗费时长是否过高\r\n\t\t\t- 这里的时长是在一定的时间间隔内的统计值，它代表某个集合读写操作所耗费的时间总量\r\n\t\t\t- 在业务高峰期时，核心表的读写操作一般比平时高一些，通过mongotop的输出可以对业务尖峰做出一些判断\r\n\t\t- 是否存在非预期的热点表。一些慢操作导致的性能问题可以从mongotop的结果中体现出来\r\n\t- `mongotop -h 192.168.65.174 --port=28017 -ufox -pfox --authenticationDatabase=admin -n 100 2`\r\n\t\t- 最多输出100次，每次间隔时间为2s\r\n- Profiler：可以用来记录、分析MongoDB的详细操作日志。默认情况下该功能是关闭的，对某个业务库开启Profiler模块之后，符合条件的慢操作日志会被写入该库的system.profile集合中\r\n\t- 提供了几种调试级别\r\n\t\t- 0 日志关闭，无任何输出\r\n\t\t- 1 部分开启，仅符合条件（时长大于slowms）的操作日志会被记录\r\n\t\t- 2 日志全开，所有的操作日志都被记录\r\n\t- `db.setProfilingLevel(2)` 对当前的数据库开启 Profiler 模块，并将 level 设置为2（日志全开）\r\n\t- `db.getProfilingStatus()` 检查是否生效\r\n\t\t- slowms 是慢操作的阈值，单位是毫秒\r\n\t\t- sampleRate 表示日志随机采样的比例，1.0则表示满足条件的全部输出\r\n\t- `db.setProfilingLevel(1,500)` 只记录时长超过500ms的操作，则可以将level设置为1\r\n\t- `db.setProfilingLevel(1,{slowms:500,sampleRate:0.5})` 设置随机采样的比例\r\n\t- `db.system.profile.find().limit(5).sort({ts:-1}).pretty()` 查看最近发生的操作日志\r\n\t\t- ns：名称空间，格式为 `{db}.{collection}`\r\n\t\t- numYield：操作数，大于0表示等待锁或者是磁盘I/O操作\r\n\t\t- nreturned：返回条目数\r\n\t\t- keysExamined：扫描索引条目数，如果比nreturned大出很多，则说明查询效率不高\r\n\t\t- docsExamined：扫描文档条目数，如果比nreturned大出很多，则说明查询效率不高\r\n\t\t- locks：锁占用的情况\r\n\t\t- responseLength：响应数据大小（字节数），一次性查询太多的数据会影响性能，可以使用limit、batchSize进行一些限制\r\n\t\t- ts：命令执行的时间点\r\n\t- `db.system.profile.find().limit(10).sort({millis:-1}).pretty()` 查看执行时长最大的10条操作记录\r\n\t- `db.system.profile.find({op:\"update\",ns:\"shop.user\"})` 查看某个集合中的update操作日志\r\n\t- 注意事项\r\n\t\t- system.profile是一个1MB的固定大小的集合，随着记录日志的增多，一些旧的记录会被滚动删除\r\n\t\t- 在线上开启Profiler模块需要非常谨慎，这是因为其对MongoDB的性能影响比较大。建议按需部分开启，同时slowms的值不要设置太低\r\n\t\t- sampleRate的默认值是1.0，该字段可以控制记录日志的命令数比例，但只有在MongoDB 4.0版本之后才支持\r\n\t\t- Profiler模块的设置是内存级的，重启服务器后会自动恢复默认状态\r\n- `db.currentOp()` 用来查看数据库当前正在执行的一些操作，读取的是当前数据库的命令快照\r\n\t- 返回有用的信息\r\n\t\t- 操作的运行时长，快速发现耗时漫长的低效扫描操作\r\n\t\t- 执行计划信息，用于判断是否命中了索引，或者存在锁冲突的情况\r\n\t\t- 操作ID、时间、客户端等信息，方便定位出产生慢操作的源头\r\n\t- 优化\r\n\t\t- 字段加索引\r\n\t\t- 如果更新的数据集非常大，要避免大范围update操作，切分成小批量的操作\r\n\t- `db.killOp(4001)`\r\n\t\t- opid表示当前操作在数据库进程中的唯一编号\r\n\t\t- 如果已经发现该操作正在导致数据库系统响应缓慢，则可以考虑将其“杀”死\r\n\t- 命令输出\r\n\t\t- currentOp.type：操作类型，可以是op、idleSession、idleCursor的一种，一般的操作信息以op表示\r\n\t\t- currentOp.currentOpTime：操作的开始时间\r\n\t\t- currentOp.opid：操作的标志编号\r\n\t\t- currentOp.active：操作是否活跃。如果是空闲状态则为false\r\n\t\t- currentOp.secs_running：操作持续时间（以秒为单位）\r\n\t\t- currentOp.ns：操作目标的集合命名空间\r\n\t\t- currentOp.locks：当前操作持有锁的类型和模式\r\n\t\t- currentOp.waitingForLock：是否正在等待锁\r\n\t\t- currentOp.numYields：当前操作执行yield的次数。一些锁互斥或者磁盘I/O读取都会导致该值大于0\r\n\t\t- currentOp.lockStats：当前操作持有锁的统计\r\n\t- 注意事项\r\n\t\t- db.currentOp返回的是数据库命令的瞬时状态，因此如果数据库压力不大，则通常只会返回极少的结果\r\n\t\t- 如果启用了复制集，那么currentOp还会返回一些复制的内部操作（针对local.oplog.rs），需要筛选\r\n\t\t- db.currentOp的结果是一个BSON文档，如果大小超过16MB则会被压缩。可以使用聚合操作`$currentOp`获得完整的结果\r\n- `db.currentOp()` 过滤条件\r\n\t- `db.currentOp({ secs_running:{$gt:1} })`  查看执行时间超过1s的操作\r\n\t- `db.currentOp({ ns:/test/ })` 查看test数据库中的操作\r\n\t- 查看等待锁的增加、删除、修改、查询操作\r\n\t\t- `db.currentOp({  waitingForLock:true, $or:[ `\r\n\t\t\t- `{op:{$in:[\"insert\",\"update\",\"remove\"]}},{\"query.findandmodify\":{$exists:true}}]})`\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "9.调优",
      "lvl1": "影响 MongoDB 性能的因素",
      "lvl2": "MongoDB 性能监控工具"
    },
    "frontmatter": {
      "title": "9.调优",
      "date": "2025-07-04T00:00:00.000Z"
    },
    "type": "content"
  },
  {
    "title": "Redis-持久化",
    "path": "/docs/architect/redis/Redis-chijiuhua.html",
    "url": "/docs/architect/redis/Redis-chijiuhua.html",
    "content": "---\r\ntitle: Redis-持久化\r\ndate: 2025/03/05\r\n---\r\n\r\n::: tip 介绍\r\n1. RDB：dump.rdb （二进制文件）\r\n2. AOF（append-only file）：appendonly.aof（resp协议格式）\r\n3. 混合持久化：RDB+AOF\r\n4. 数据备份策略\r\n:::\r\n\r\n## RDB: dump.rdb\r\n\r\n- RDB：dump.rdb （二进制文件）\r\n\t- 配置文件：`bgsave` 方式\r\n\t\t- `save 60 1000`  关闭RDB只需要将所有的 `save` 保存策略注释掉即可\r\n\t\t\t- 60 秒内有至少有 1000 个键被改动， 则进行一次 RDB 持久化\r\n\t- 命令：覆盖原有 rdb 快照文件\r\n\t\t- `save`：同步\r\n\t\t- `bgsave`：异步，写时复制 - COW机制\r\n\t\t\t- `bgsave` 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据\r\n\t\t\t\t- 在生成子进程执行调用fork函数时会有短暂阻塞\r\n\t\t\t- 如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。然后，`bgsave` 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据\r\n\r\n::: danger 缺点\r\n宕机后，服务器将丢失最近写入、且仍未保存到快照中的数据\r\n:::\r\n\r\n## AOF: appendonly.aof\r\n\r\n- AOF（append-only file）：appendonly.aof（resp协议格式）\r\n\t- 将修改的每一条指令记录进文件appendonly.aof中（先写入os cache，每隔一段时间fsync到磁盘）\r\n\t- 命令：`bgrewriteaof`  （fork出一个子进程去做）\r\n\t- 配置文件\r\n\r\n|配置文件|介绍|\r\n|-|-|\r\n|`appendonly yes`|开启AOF模式|\r\n|`appendfsync always`|每条命令都fsync一次，拉低性能|\r\n|`appendfsync everysec`|每秒fsync一次，推荐，缺点是宕机后会丢失1秒的数据，但可以从数据库恢复|\r\n|`appendfsync no`|让操作系统决定fsync的时机，快但不安全|\r\n|`auto‐aof‐rewrite‐min‐size 64mb`|AOF文件超过64M时，重写AOF文件（整合命令）|\r\n|`auto‐aof‐rewrite‐percentage 100`|自上一次重写后文件大小增长了100%则再次触发重写|\r\n\r\n::: warning 缺点\r\n体积大，恢复慢\r\n:::\r\n\r\n## 混合持久化\r\n\r\n- 混合持久化：RDB+AOF\r\n\t- 配置文件（必须先开启AOF）：`aof‐use‐rdb‐preamble yes`\r\n\t- 将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令（生成RDB过程中产生的命令）存在一起，都写入新的AOF文件\r\n\t- 新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换\r\n\r\n::: info 优点\r\n在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可以完全替代之前的AOF 全量文件重放，因此重启效率大幅得到提升\r\n:::\r\n\r\n![混合持久化](static/Redis-持久化-appendonly.aof.png)\r\n\r\n## 数据备份策略\r\n\r\n- 数据备份策略：\r\n\t1. 写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份\r\n\t2. 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份\r\n\t3. 每次copy备份的时候，删除一些旧备份\r\n\t4. 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Redis-持久化",
      "lvl1": "RDB: dump.rdb",
      "lvl2": "AOF: appendonly.aof",
      "lvl3": "混合持久化",
      "lvl4": "数据备份策略"
    },
    "frontmatter": {
      "title": "Redis-持久化",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "---\r\ntitle: Zookeeper-特性\r\ndate: 2025/06/16\r\n---\r\n\r\n:::tip\r\n- CP架构\r\n- 常见命令\r\n- 数据结构\r\n- 监听通知机制\r\n- 节点特性\r\n- ACL权限控制\r\n- 集群\r\n- 四字命令\r\n- Leader 选举原理\r\n- 数据同步流程\r\n:::\r\n\r\n---\r\n## CP架构\r\n\r\n- CAP 理论指出对于一个分布式计算系统来说，不可能同时满足以下三点\r\n\t- 一致性：在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性，等同于所有节点访问同一份最新的数据副本。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态\r\n\t- 可用性：每次请求都能获取到正确的响应，但是不保证获取的数据为最新数据\r\n\t- 分区容错性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供服务，除非是整个网络环境都发生了故障\r\n- 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项\r\n\t- P 是必须的，因此只能在 CP 和 AP 中选择，zookeeper 保证的是 CP\r\n- BASE 理论：BASE 是 Basically Available(基本可用)、Soft-state(软状态) 和 Eventually Consistent(最终一致性) 三个短语的缩写\r\n\t- 基本可用：在分布式系统出现故障，允许损失部分可用性（服务降级、页面降级）\r\n\t- 软状态：允许分布式系统出现中间状态。而且中间状态不影响系统的可用性。这里的中间状态是指不同的 data replication（数据备份节点）之间的数据更新可以出现延时的最终一致性\r\n\t- 最终一致性：data replications 经过一段时间达到一致性\r\n- Zookeeper 写入是强一致性，读取是顺序一致性（版本号）\r\n- ZooKeeper本质上是一个分布式的小文件存储系统（Zookeeper=文件系统+监听机制）\r\n\t- 是一个基于观察者模式设计的分布式服务管理框架\r\n\r\n---\r\n## 常见命令\r\n\r\n- ls 查看当前 znode 的子节点 \\[可监听\\]\r\n\t- -w: 监听子节点变化\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t- -R: 表示递归的获取\r\n- create 创建节点\r\n\t- -s : 创建有序节点\r\n\t- -e : 创建临时节点\r\n\t- -c : 创建一个容器节点\r\n\t- \\[-t ttl\\] : 创建一个TTL节点， -t 时间（单位毫秒）\r\n\t- data : 节点的数据，可选，如果不使用时，节点数据就为null\r\n\t- acl : 访问控制\r\n- get 获取节点数据信息\r\n\t-  -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t-  -w: 监听节点变化\r\n- set 设置节点数据\r\n\t- -s: 表示节点为顺序节点\r\n\t- -v: 指定版本号\r\n- getAcl 获取节点的访问控制信息\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n- setAcl 设置节点的访问控制列表\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t- -v: 指定版本号\r\n\t- -R: 递归的设置\r\n- stat 查看节点状态信息\r\n- delete  删除某一节点，只能删除无子节点的节点\r\n\t- -v: 表示节点版本号\r\n- deleteall 递归的删除某一节点及其子节点\r\n- setquota 对节点增加限制\r\n\t- -n: 表示子节点的最大个数\r\n\t- -b: 数据值的最大长度，-1表示无限制\r\n\r\n---\r\n## 数据结构\r\n\r\n- ZooKeeper的数据模型是层次模型，层次模型常见于文件系统。层次模型和key-value模型是两种主流的数据模型。ZooKeeper使用文件系统模型主要基于以下两点考虑\r\n\t- 文件系统的树形结构便于表达数据之间的层次关系\r\n\t- 文件系统的树形结构便于为不同的应用分配独立的命名空间 ( namespace ) \r\n- ZooKeeper的层次模型称作Data Tree，Data Tree的每个节点叫作Znode\r\n\t- 每一个 ZNode 默认能够存储 1MB 的数据\r\n\t- 每个 ZNode 都可以通过其路径唯一标识\r\n\t- 每个节点都有一个版本(version)，版本从0开始计数\r\n\t- ![Zookeeper 节点](static/Zookeeper-特性-节点.png)\r\n- 节点分类\r\n\t- 持久节点 (PERSISTENT): 这样的znode在创建之后即使发生ZooKeeper集群宕机或者client宕机也不会丢失\r\n\t- 临时节点 (EPHEMERAL ): client宕机或者client在指定的timeout时间内没有给ZooKeeper集群发消息，这样的znode就会消失\r\n\t- 持久顺序节点 (PERSISTENT_SEQUENTIAL): znode除了具备持久性znode的特点之外，名字具备顺序性\r\n\t- 临时顺序节点 (EPHEMERAL_SEQUENTIAL): znode除了具备临时性znode的特点之外，名字具备顺序性\r\n\t- Container节点 (3.5.3版本新增)：Container容器节点，当容器中没有任何子节点，该容器节点会被zk定期删除（定时任务默认60s 检查一次)\r\n\t\t- 和持久节点的区别是 ZK 服务端启动后，会有一个单独的线程去扫描，所有的容器节点，当发现容器节点的子节点数量为 0 时，会自动删除该节点\r\n\t\t- 可以用于 leader 或者锁的场景中\r\n\t- TTL节点:  带过期时间节点，默认禁用\r\n\t\t- 在zoo.cfg中添加 `extendedTypesEnabled=true `开启\r\n\t\t- ttl 不能用于临时节点\r\n- 节点状态信息\r\n\t- cZxid ：Znode创建的事务id\r\n\t- ctime：节点创建时的时间戳\r\n\t- mZxid ：Znode被修改的事务id，即每次对znode的修改都会更新mZxid\r\n\t\t- 对于zk来说，每次的变化都会产生一个唯一的事务id，zxid（ZooKeeper Transaction Id）\r\n\t\t- 通过zxid，可以确定更新操作的先后顺序\r\n\t\t- 如果zxid1小于zxid2，说明zxid1操作先于zxid2发生\r\n\t\t- zxid对于整个zk都是唯一的，即使操作的是不同的znode\r\n\t- pZxid: 表示该节点的子节点列表最后一次修改的事务ID\r\n\t\t- 只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid\r\n\t\t\t- 添加子节点或删除子节点就会影响子节点列表\r\n\t\t\t- 但是修改子节点的数据内容则不影响该ID\r\n\t- mtime：节点最新一次更新发生时的时间戳\r\n\t- cversion ：子节点的版本号\r\n\t\t- 当znode",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "的子节点有变化时，cversion 的值就会增加1\r\n\t- dataVersion：数据版本号\r\n\t\t- 每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据）\r\n\t\t- 可有效避免了数据更新时出现的先后顺序问题\r\n\t- ephemeralOwner\r\n\t\t- 如果该节点为临时节点, ephemeralOwner值表示与该节点绑定的session id\r\n\t\t\t- 在client和server通信之前,首先需要建立连接,该连接称为session\r\n\t\t\t- 连接建立后,如果发生连接超时、授权失败,或者显式关闭连接,连接便处于closed状态, 此时session结束\r\n\t\t- 如果不是, ephemeralOwner值为0 (持久节点)\r\n\t- dataLength： 数据的长度\r\n\t- numChildren：子节点的数量（只统计直接子节点的数量）\r\n\r\n---\r\n## 监听通知机制\r\n\r\n- watcher 机制\r\n\t- 一个Watch事件是一个一次性的触发器\r\n\t\t- 当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们\r\n\t- Zookeeper采用了 Watcher机制实现数据的发布订阅功能\r\n\t\t- 多个订阅者可同时监听某一特定主题对象，当该主题对象的自身状态发生变化时例如节点内容改变、节点下的子节点列表改变等，会实时、主动通知所有订阅者\r\n\t- watcher机制事件上与观察者模式类似，也可看作是一种观察者模式在分布式场景下的实现方式\r\n- watcher 的过程\r\n\t- 客户端向服务端注册watcher\r\n\t- 服务端事件发生触发watcher\r\n\t- 客户端回调watcher得到触发事件情况\r\n- Zookeeper中的watch机制，必须客户端先去服务端注册监听，这样事件发送才会触发监听，通知给客户端\r\n- 支持的事件类型\r\n\t- None: 连接建立事件\r\n\t- NodeCreated： 节点创建 \r\n\t- NodeDeleted： 节点删除 \r\n\t- NodeDataChanged：节点数据变化\r\n\t- NodeChildrenChanged：子节点列表变化 \r\n\t- DataWatchRemoved：节点监听被移除 \r\n\t- ChildWatchRemoved：子节点监听被移除\r\n- 特性\r\n\t- 一次性触发：watcher是一次性的，一旦被触发就会移除，再次使用时需要重新注册\r\n\t- 客户端顺序回调：watcher回调是顺序串行执行的，只有回调后客户端才能看到最新的数据状态。一个watcher回调逻辑不应该太多，以免影响别的watcher执行\r\n\t- 轻量级：WatchEvent是最小的通信单位，结构上只包含通知状态、事件类型和节点路径，并不会告诉数据节点变化前后的具体内容\r\n\t- 时效性：watcher只有在当前session彻底失效时才会无效，若在session有效期内快速重连成功，则watcher依然存在，仍可接收到通知\r\n- 使用场景\r\n\t- master-worker 机制\r\n\t- 基于版本号的条件更新\r\n\t\t- ![Zookeeper 更新](static/Zookeeper-特性-更新.png)\r\n\r\n---\r\n## 节点特性\r\n\r\n- 同一级节点 key 名称是唯一的\r\n- 创建节点时，必须要带上全路径\r\n- session 关闭，临时节点清除\r\n- 自动创建顺序节点\r\n- watch 机制，监听节点变化\r\n\t- 监听事件被单次触发后，事件就失效了\r\n- 永久性 Watch（`addWatch [‐m mode] path`）：是Zookeeper 3.6.0版本新增的功能\r\n\t- 在被触发之后，仍然保留，可以继续监听ZNode上的变更\r\n\t- 针对指定节点添加事件监听，支持两种模式\r\n\t\t- PERSISTENT，持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件\r\n\t\t- PERSISTENT_RECURSIVE，持久化递归订阅，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件\r\n- delete 命令只能一层一层删除\r\n- deleteall 命令递归删除\r\n- 应用场景：适用于存储和协同相关的关键数据，不适合用于大数据量存储\r\n\t- 注册中心 \r\n\t- 数据发布/订阅（常用于实现配置中心） \r\n\t\t- 数据量小的KV\r\n\t\t- 数据内容在运行时会发生动态变化\r\n\t\t- 集群机器共享，配置一致\r\n\t\t- 推拉结合\r\n\t\t\t- 服务端会推给注册了监控节点的客户端 Watcher 事件通知\r\n\t\t\t- 客户端获得通知后，然后主动到服务端拉取最新的数据\r\n\t- 统一集群管理\r\n\t- 负载均衡\r\n\t- 命名服务\r\n\t- 分布式协调/通知\r\n\t- 集群管理\r\n\t- Master选举\r\n\t- 分布式锁\r\n\t- 分布式队列\r\n\r\n---\r\n## ACL权限控制\r\n\r\n- zookeeper 的 ACL（Access Control List，访问控制表）权限可以针对节点设置相关读写等权限\r\n- zookeeper 的 acl 通过 `[scheme:id:permissions]` 来构成权限列表\r\n\t- scheme：授权的模式，代表采用的某种权限机制\r\n\t\t- 包括 world、auth、digest、ip、super 几种\r\n\t- id：授权对象，代表允许访问的用户\r\n\t\t- 如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段\r\n\t\t- 而如果使用 Digest 或 Super 方式，则对应于一个用户名\r\n\t\t- 如果是 World 模式，是授权系统中所有的用户\r\n\t- permissions：授权的权限，权限组合字符串，由 cdrwa 组成，其中每个字母代表支持不同权限\r\n\t\t- 创建权限 create(c)、删除权限 delete(d)、读权限 read(r)、写权限 write(w)、管理权限admin(a)。\r\n\r\n| 模式     | 描述                                        |\r\n| ------ | ----------------------------------------- |\r\n| world  | 授权对象只有一个anyone，代表登录到服务器的所有客户端都能对该节点执行某种权限 |\r\n| ip     | 对连接的客户端使用IP地址认证方式进行认证                     |\r\n| auth   | 使用以添加认证的用户进行认证                            |\r\n| digest | 使用用户:密码方式验证                               |\r\n\r\n| 权限类型   | ACL简写 | 描述              |\r\n| ------ | ----- | --------------- |\r\n| read   | r     | 读取节点及显示子节点列表的权限 |\r\n| write  | w     | 设置节点数据的权限       |\r\n| create | c     | 创建子节点的权限        |\r\n| delete | d     | 删除子节点的权限        |\r\n| admin  | a     | 设置该节点ACL权限的权限   |\r\n\r\n| 授权命令    |",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": " 用法                   | 描述             |\r\n| ------- | -------------------- | -------------- |\r\n| getAcl  | getAcl path          | 读取节点的ACL       |\r\n| setAcl  | setAcl path acl      | 设置节点的ACL       |\r\n| create  | create path data acl | 创建节点时设置ACL     |\r\n| addAuth | addAuth scheme auth  | 添加认证用户，类似于登录操作 |\r\n- setAcl\r\n\t- `set Acl /name world:anyone:cdwa`\r\n- auth授权模式\r\n\t- 创建用户 `addauth digest fox:123456`\r\n\t- `setAcl /name auth:fox:123456:cdrwa`\r\n\t- 密码加密\r\n\t\t- `echo -n fox:123456 | openssl dgst -binary -sha1 | openssl base64`\r\n\t\t- `setAcl /name auth:fox:ZsWwgmtnTnx1usRF1voHFJAYGQU=:cdrwa`\r\n- digest授权模式\r\n\t- `setAcl /tuling/fox digest:fox:ZsWwgmtnTnx1usRF1voHFJAYGQU=:cdrwa`\r\n- IP授权模式\r\n\t- `setAcl /node-ip ip:192.168.109.128:cdwra`\r\n\t- `create /node-ip data ip:192.168.109.128:cdwra`\r\n\t\t- 多个指定IP可以通过逗号分隔\r\n\t\t\t- `setAcl /node-ip ip:IP1:rw,ip:IP2:a`\r\n- Super 超级管理员模式\r\n\t- 这是一种特殊的Digest模式， 在Super模式下超级管理员用户可以对Zookeeper上的节点进行任何的操作\r\n\t- 需要在启动脚本上通过添加JVM 参数开启\r\n\t\t- `-Dzookeeper.DigestAuthenticationProvider.superDigest=admin:<base64encoded(SHA1(123456))`\r\n\r\n---\r\n## 集群\r\n\r\n- 集群角色\r\n\t- Leader： 领导者\r\n\t\t- 事务请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性\r\n\t\t- 集群内部各个服务器的调度者\r\n\t\t- 对于create、setData、delete等有写操作的请求，则要统一转发给leader处理，leader需要决定编号、执行操作，这个过程称为事务\r\n\t- Follower：跟随者\r\n\t\t- 处理客户端非事务（读操作）请求（可以直接响应）\r\n\t\t- 转发事务请求给 Leader\r\n\t\t- 参与集群 Leader 选举投票\r\n\t- Observer：观察者\r\n\t\t- 对于非事务请求可以独立处理（读操作）\r\n\t\t- 对于事务性请求会转发给 leader 处理\r\n\t\t- Observer 节点接收来自 leader 的 inform 信息，更新自己的本地存储\r\n\t\t- 不参与提交和选举投票\r\n\t\t- 在不影响集群事务处理能力的前提下提升集群的非事务处理能力\r\n\t\t- Observer 应用场景\r\n\t\t\t- 提升集群的读性能\r\n\t\t\t- 跨数据中心部署\r\n\t\t\t\t- 比如需要部署一个北京和香港两地都可以使用的zookeeper集群服务，并且要求北京和香港客户的读请求延迟都很低。解决方案就是把香港的节点都设置为observer\r\n- 集群架构\r\n\t- ![Zookeeper 集群](static/Zookeeper-特性-集群.png)\r\n\t- leader节点可以处理读写请求\r\n\t- follower只可以处理读请求\r\n\t- follower在接到写请求时会把写请求转发给leader来处理\r\n- Zookeeper数据一致性保证\r\n\t- 全局可线性化 (Linearizable) 写入：先到达leader的写请求会被先处理，leader决定写请求的执行顺序\r\n\t- 客户端FIFO顺序：来自给定客户端的请求按照发送顺序执行\r\n- 集群搭建\r\n\t- 修改zoo.cfg配置，添加server节点配置：`server.A=B:C:D`\r\n\t\t- `dataDir=/data/zookeeper`\r\n\t\t- `server.1=192.168.65.156:2888:3888`\r\n\t\t- A 是一个数字，表示这个是第几号服务器\r\n\t\t\t- 集群模式下配置一个文件 myid，这个文件在 dataDir 目录下，这个文件里面有一个数据 就是 A 的值，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个server\r\n\t\t- B 是这个服务器的地址\r\n\t\t- C 是这个服务器Follower与集群中的Leader服务器交换信息的端口\r\n\t\t- D 是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader\r\n\t\t\t- 而这个端口就是用来执行选举时服务器相互通信的端口\r\n\t- 创建 myid 文件，配置服务器编号\r\n\t- 启动 zookeeper server 集群 `bin/zkServer.sh start`\r\n\r\n---\r\n## 四字命令\r\n\r\n- zookeeper 支持某些特定的四字命令与其交互，用户获取 zookeeper 服务的当前状态及相关信息\r\n\t- 用户在客户端可以通过 telenet 或者 nc（netcat） 向 zookeeper 提交相应的命令\r\n- 开启四字命令\r\n\t- 在 zoo.cfg 文件里加入配置项让这些指令放行\r\n\t\t- `4lw.commands.whitelist=*`\r\n\t- 在 zk 的启动脚本 zkServer.sh 中新增放行指令（添加ＶＭ环境变量）\r\n\t\t- `ZOOMAIN=\"-Dzookeeper.4lw.commands.whitelist=* ${ZOOMAIN}\"`\r\n- `echo [command] | nc [ip] [port]`\r\n\t- stat 命令用于查看 zk 的状态信息\r\n\t\t- `echo stat | nc 192.168.65.156 2181`\r\n\r\n| 四字命令 | 功能描述                                                                        |\r\n| ---- | --------------------------------------------------------------------------- |\r\n| conf | 3.3.0版本引入的。打印出服务相关配置的详细信息。                                                  |\r\n| cons | 3.3.0版本引入的。列出所有连接到这台服务器的客户端全部连接/会话详细信息。包括\"接受/发送\"的包数量、会话id、操作延迟、最后的操作执行等等信息。 |\r\n| crst | 3.3.0版本引入的。重置所有连接的连接和会话统计信息。                                                |\r\n| dump | 列出那些比较重要的会话和临时节点。这个命令只能在leader节点上有用。                                        |\r\n| envi | 打印出服务环境的详细信息。                                                               |\r\n| reqs | 列出未经处理的请求                                                                   |\r\n| ruok | 测试服务是否处于正确状态。如果确实如此，那么服务返回\"imok\"，否则不做任何相应。                                  |\r\n| stat | 输出关于性能和连接的客户端的列表。                                                           |\r\n| srst | 重置服务器的统计。                                                                   |\r\n| srvr | 3.3.0版本引入的。列出连接服务器的详细信息                                                     |\r\n| wchs | 3.3.0版本引入的。列出服务器watch的",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "详细信息。                                                 |\r\n| wchc | 3.3.0版本引入的。通过session列出服务器watch的详细信息，它的输出是一个与watch相关的会话的列表。                  |\r\n| wchp | 3.3.0版本引入的。通过路径列出服务器watch的详细信息。它输出一个与session相关的路径。                          |\r\n| mntr | 3.4.0版本引入的。输出可用于检测集群健康状态的变量列表                                               |\r\n\r\n---\r\n## Leader 选举原理\r\n\r\n- zookeeper 的 leader 选举存在两个阶段\r\n\t- 一个是服务器启动时 leader 选举\r\n\t- 另一个是运行过程中 leader 服务器宕机\r\n- 重要的参数\r\n\t- 服务器 ID(myid)：编号越大在选举算法中权重越大\r\n\t- 事务 ID(zxid)：值越大说明数据越新，权重越大\r\n\t- 逻辑时钟(epoch-logicalclock)：同一轮投票过程中的逻辑时钟值是相同的，每投完一次值会增加\r\n- 选举状态\r\n\t- LOOKING: 竞选状态\r\n\t- FOLLOWING: 随从状态，同步 leader 状态，参与投票 \r\n\t- OBSERVING: 观察状态，同步 leader 状态，不参与投票 \r\n\t- LEADING: 领导者状态\r\n- 服务器启动时的 leader 选举\r\n\t- 每个节点启动的时候都 LOOKING 观望状态，接下来就开始进行选举主流程\r\n\t\t- 第一台服务器 server1启动时，无法进行 leader 选举\r\n\t\t- 当第二台服务器 server2 启动时，两台机器可以相互通信，进入 leader 选举过程\r\n\t- ![Zookeeper 选举](static/Zookeeper-特性-选举.png)\r\n\t\t1. 每台 server 发出一个投票\r\n\t\t\t1. 由于是初始情况，server1 和 server2 都将自己作为 leader 服务器进行投票\r\n\t\t\t2. 每次投票包含所推举的服务器myid、zxid、epoch，使用（myid，zxid）表示\r\n\t\t\t3. 此时 server1 投票为（1,0），server2 投票为（2,0），然后将各自投票发送给集群中其他机器\r\n\t\t2. 接收来自各个服务器的投票\r\n\t\t\t1. 集群中的每个服务器收到投票后，首先判断该投票的有效性\r\n\t\t\t2. 如检查是否是本轮投票（epoch）、是否来自 LOOKING 状态的服务器\r\n\t\t3. 分别处理投票\r\n\t\t\t1. 针对每一次投票，服务器都需要将其他服务器的投票和自己的投票进行对比\r\n\t\t\t\t1. 优先比较 epoch\r\n\t\t\t\t2. 检查 zxid，zxid 比较大的服务器优先作为 leader\r\n\t\t\t\t3. 如果 zxid 相同，那么就比较 myid，myid 较大的服务器作为 leader 服务器\r\n\t\t4. 统计投票\r\n\t\t\t1. 每次投票后，服务器统计投票信息，判断是否有过半机器接收到相同的投票信息\r\n\t\t\t2. server1、server2 都统计出集群中有两台机器接受了（2,0）的投票信息，此时已经选出了 server2 为 leader 节点\r\n\t\t5. 改变服务器状态\r\n\t\t\t1. 一旦确定了 leader，每个服务器响应更新自己的状态\r\n\t\t\t2. 如果是 follower，那么就变更为 FOLLOWING，如果是 Leader，变更为 LEADING\r\n\t\t\t3. 此时 server3继续启动，直接加入变更自己为 FOLLOWING\r\n- 运行过程中的 leader 选举：当集群中 leader 服务器出现宕机或者不可用情况时，整个集群无法对外提供服务，进入新一轮的 leader 选举\r\n\t1. 变更状态：leader 挂后，其他非 Oberver服务器将自身服务器状态变更为 LOOKING\r\n\t2. 每个 server 发出一个投票：在运行期间，每个服务器上 zxid 可能不同\r\n\t3. 处理投票：规则同启动过程\r\n\t4. 统计投票：与启动过程相同\r\n\t5. 改变服务器状态：与启动过程相同\r\n\r\n---\r\n## 数据同步流程\r\n\r\n- 在 Zookeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性\r\n- ZAB 协议分为两部分：消息广播；崩溃恢复\r\n- 消息广播\r\n\t- ![Zookeeper 事务](static/Zookeeper-特性-事务.png)\r\n\t- Zookeeper 使用单一的主进程 Leader 来接收和处理客户端所有事务请求\r\n\t- 并采用 ZAB 协议的原子广播协议，将事务请求以 Proposal 提议广播到所有 Follower 节点\r\n\t- 当集群中有过半的Follower 服务器进行正确的 ACK 反馈\r\n\t\t- 那么Leader就会再次向所有的 Follower 服务器发送commit 消息，将此次提案进行提交\r\n\t- 这个过程可以简称为 2pc 事务提交\r\n\t- 注意 Observer 节点只负责同步 Leader 数据，不参与 2PC 数据同步过程\r\n- 崩溃恢复\r\n\t- 在正常情况消息下广播能运行良好，但是一旦 Leader 服务器出现崩溃，或者由于网络原理导致 Leader 服务器失去了与过半 Follower 的通信，那么就会进入崩溃恢复模式\r\n\t- 需要选举出一个新的 Leader 服务器\r\n\t- 在这个过程中可能会出现两种数据不一致性的隐患，需要 ZAB 协议的特性进行避免\r\n\t\t- Leader 服务器将消息 commit 发出后，立即崩溃\r\n\t\t- Leader 服务器刚提出 proposal 后，立即崩溃\r\n\t- ZAB 协议的恢复模式使用了以下策略\r\n\t\t- 选举 zxid 最大的节点作为新的 leader\r\n\t\t- 新 leader 将事务日志中尚未提交的消息进行处理\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 4,
    "contentParts": 4
  },
  {
    "title": "1. 基础",
    "path": "/docs/architect/rocketmq/RocketMQ-1.jichu.html",
    "url": "/docs/architect/rocketmq/RocketMQ-1.jichu.html",
    "content": "---\r\ntitle: 1. 基础\r\ndate: 2025/07/03\r\n---\r\n\r\n\r\n- RocketMQ 集群架构 \r\n\t- ![](static/RocketMQ-基础-1.png)\r\n\t- Producer：消息生产者集群。通常是业务系统中的一个功能模块。 \r\n\t- Consumer：消息消费者集群。通常也是业务系统中的一个功能模块。\r\n\t- Broker：实际处理消息存储、转发等服务的核心组件。\r\n\t- NameServer : 提供轻量级的Broker路由服务。 管理Broker\r\n\t\t- 所以我们要启动RocketMQ服务，需要先启动NameServer。\r\n\t- Topic：区分消息的种类；\r\n\t\t- 一个发送者可以发送消息给一个或者多个Topic\r\n\t\t- 一个消息的接收者可以订阅一个或者多个Topic消息\r\n\t- Message Queue：相当于是Topic的分区；用于并行发送和接收消息\r\n\t- 这种主从结构是只做数据备份，没有容灾功能\r\n- Dledger 高可用集群：基于Raft协议\r\n\t- 修改conf/dleger下的配置文件\r\n- 系统参数调优\r\n\t- 配置RocketMQ的JVM内存大小 `runbroker.sh`\r\n\t\t- `-XX:+UseG1GC` 使用G1垃圾回收器\r\n\t\t- `-XX:G1HeapRegionSize=16m` 将G1的region块大小设为16M\r\n\t\t- `-XX:G1ReservePercent` 在G1的老年代中预留25%空闲内存\r\n\t\t- `-XX:InitiatingHeapOccupancyPercent=30` 当堆内存的使用率达到30%之后就会启动G1垃圾回收器尝试回收垃圾\r\n\t- RocketMQ的其他一些核心参数\r\n\t\t- `sendMessageThreadPoolNums=16` RocketMQ内部用来发送消息的线程池的线程数量是16个\r\n\t- Linux内核参数定制\r\n\t\t- ulimit，需要进行大量的网络通信和磁盘IO\r\n\t\t- vm.extra_free_kbytes，告诉VM在后台回收（kswapd）启动的阈值与直接回收（通过分配进程）的阈值之间保留额外的可用内存。RocketMQ使用此参数来避免内存分配中的长延迟\r\n\t\t- vm.min_free_kbytes，如果将其设置为低于1024KB，将会巧妙的将系统破坏，并且系统在高负载下容易出现死锁\r\n\t\t- vm.max_map_count，限制一个进程可能具有的最大内存映射区域数。RocketMQ将使用mmap加载CommitLog和ConsumeQueue，因此建议将为此参数设置较大的值\r\n\t\t- vm.swappiness，定义内核交换内存页面的积极程度。较高的值会增加攻击性，较低的值会减少交换量。建议将值设置为10来避免交换延迟\r\n\t\t- File descriptor limits，RocketMQ需要为文件（CommitLog和ConsumeQueue）和网络连接打开文件描述符。我们建议设置文件描述符的值为655350\r\n\t\t\t- `/proc/sys/vm`\r\n\t\t- 另外，RocketMQ的bin目录下有个`os.sh`里面设置了RocketMQ建议的系统内核参数\r\n- RocketMQ消息转发模型\r\n\t- ![](static/RocketMQ-基础-2.png)\r\n\t- 消息模型（Message Model） \r\n\t\t- RocketMQ 主要由 Producer、Broker、Consumer 三部分组成\r\n\t\t- Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息\r\n\t\t- Broker 在实际部署过程中对应一台服务器\r\n\t\t\t- 每个 Broker 可以存储多个Topic的消息，每个Topic 的消息也可以分片存储于不同的 Broker\r\n\t\t- Message Queue 用于存储消息的物理地址\r\n\t\t\t- 每个Topic中的消息地址存储于多个 Message Queue 中\r\n\t\t- ConsumerGroup 由多个Consumer 实例构成\r\n\t- 消息生产者（Producer） \r\n\t\t- 一个消息生产者会把业务应用系统里产生的消息发送到broker服务器\r\n\t\t- 同步发送、异步发送、顺序发送、单向发送\r\n\t\t\t- 同步和异步方式均需要Broker返回确认信息，单向发送不需要\r\n\t\t-  生产者中，会把同一类Producer组成一个集合，叫做生产者组\r\n\t\t\t- 同一组的Producer被认为是发送同一类消息且发送逻辑一致\r\n\t- 消息消费者（Consumer） \r\n\t\t-  负责消费消息，一般是后台系统负责异步消费\r\n\t\t- 一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序\r\n\t\t- 拉取式消费\r\n\t\t\t- 拉取式消费的应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、主动权由应用控制。一旦获取了批量消息，应用就会启动消费过程\r\n\t\t- 推动式消费\r\n\t\t\t- 推动式消费模式下Broker收到数据后会主动推送给消费端，该消费模式一般实时性较高\r\n\t\t-  消费者同样会把同一类Consumer组成一个集合，叫做消费者组\r\n\t\t\t- 这类Consumer通常消费同一类消息且消费逻辑一致\r\n\t\t\t- 消费者组使得在消息消费方面，实现负载均衡和容错的目标变得非常容易\r\n\t\t\t- 消费者组的消费者实例必须订阅完全相同的Topic\r\n\t\t- 集群消费模式下,  相同Consumer Group的每个Consumer实例平均分摊消息\r\n\t\t- 广播消费模式下，相同Consumer Group的每个Consumer实例都接收全量的消息\r\n\t- 主题（Topic）\r\n\t\t- 表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位\r\n\t\t-  Topic只是一个逻辑概念，并不实际保存消息\r\n\t\t- 同一个Topic下的消息，会分片保存到不同的Broker上，而每一个分片单位，就叫做MessageQueue\r\n\t\t- MessageQueue是一个具有FIFO特性的队列结构，生产者发送消息与消费者消费消息的最小单位\r\n\t- 代理服务器（Broker Server） \r\n\t\t- 消息中转角色，负责存储消息、转发消息\r\n\t\t\t- 负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备\r\n\t\t\t- 也存储消息相关的元数据，包括消费者组、消费进度偏移和主题和队列消息等\r\n\t\t- Broker Server是RocketMQ真正的业务核心，包含了多个重要的子模块\r\n\t\t\t- Remoting Module：整个Broker的实体，负责处理来自clients端的请求\r\n\t\t\t- Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息\r\n\t\t\t- Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能\r\n\t\t\t- HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步\r\n\t\t\t- Index Service：根据特定的Message key对投递到Broker的消息进行索引服务\r\n\t\t- RocketMQ中有两种Broker架构模式\r\n\t\t\t- 普通集群\r\n\t\t\t\t- 这种集群模式下会给每个节点分配一个固定的角色\r\n\t\t\t\t- master负责响应客户端的请求，并存储消息\r\n\t\t\t\t- slave则只负责对master的消息进行同步保存，并响应部分客户端的读请求\r\n\t\t\t\t- 消息同步方式分为同步同步和异步同步\r\n\t\t\t\t- 这种集群模式下各个节点的角色无法进行切换\r\n\t\t\t\t\t- 也就是说，master节点挂了，这一组Broker就不可用了\r\n\t\t\t- Dledger高可用集群\r\n\t\t\t\t- 集群会随机选出一个节点作为master\r\n\t\t\t\t\t- 当master节点挂了后，会从slave中自动选出一个节点升级成为master\r\n\t\t\t\t- 完成master节点往slave节点的消息同步\r\n\t- 名字服务（Name Server） \r\n\t\t- 名称服务充当路由消息的提供者\r\n\t\t- Broker Server会在启动时向所有的Name Server注册自己的服务信息\r\n\t\t\t- 后续通过心跳请求的方式保证这个服务信息的实时性\r\n\t\t- 生产者或消费者能够通过名字服务查找各主题相应的Broker IP列表\r\n\t\t- 多个Namesrv实例组成集群，但相互独立，没有信息交换\r\n\t\t\t-  这种特性也就意味着NameServer中任意的节点挂了，只要有一台服务节点正常，整个路由服务就不会有影响\r\n\t- 消息（Message） \r\n\t\t- 消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题Topic\r\n\t\t- RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key\r\n\t\t\t- 系统提供了通过Message ID和Key查询消息的功能\r\n\t\t- 并且Message上有一个为消息设置的标志，Tag标签\r\n\t\t\t- 用于同一主题下区分不同类型的消息\r\n\t\t\t- 来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1. 基础"
    },
    "frontmatter": {
      "title": "1. 基础",
      "date": "2025/07/03"
    },
    "type": "content"
  },
  {
    "title": "2.消息类型&ACL",
    "path": "/docs/architect/rocketmq/RocketMQ-2.xiaoxileixing_ACL.html",
    "url": "/docs/architect/rocketmq/RocketMQ-2.xiaoxileixing_ACL.html",
    "content": "---\r\ntitle: 2.消息类型&ACL\r\ndate: 2025/07/03\r\n---\r\n\r\n- 消息类型\r\n- ACL 权限控制 \r\n\r\n---\r\n## 消息类型\r\n\r\n- 顺序消息 \r\n\t- 保证的是消息的局部有序，而不是全局有序\r\n\t- 消息发送者会采取Round Robin轮询方式把消息发送到不同的 MessageQueue (分区队列)\r\n\t\t- 消费者消费的时候也从多个MessageQueue上拉取消息，这种情况下消息是不能保证顺序的\r\n\t\t- 而只有当一组有序的消息发送到同一个MessageQueue上时，才能利用MessageQueue先进先出的特性保证这一组消息有序\r\n\t\t- MessageListenerConcurrently这个消息监听器则不会锁队列，每次都是从多个Message中取一批数据（默认不超过32条）。因此也无法保证消息有序\r\n\t- 消费者会从多个消息队列上去拿消息\r\n\t\t- 这时虽然每个消息队列上的消息是有序的，但是多个队列之间的消息仍然是乱序的\r\n\t\t- 消费者端要保证消息有序，就需要按队列一个一个来取消息，即取完一个队列的消息后，再去取下一个队列的消息\r\n\t\t- 而给consumer注入的MessageListenerOrderly对象，在RocketMQ内部就会通过锁队列的方式保证消息是一个一个队列来取的\r\n- 广播消息 \r\n- 延迟消息：`Message#setDelayTimeLevel`\r\n\t- 在调用producer.send方法后，消息并不会立即发送出去，而是会等一段时间再发送出去\r\n\t- 只支持18个固定的延迟级别（18种消息队列）\r\n- 批量消息 \r\n\t- 将多条消息合并成一个批量消息，一次发送出去\r\n\t- 如果批量消息大于1MB就不要用一个批次发送，而要拆分成多个批次消息发送\r\n\t\t- 实际最大的限制是4MB\r\n\t- 这些消息应该有相同的Topic，相同的waitStoreMsgOK\r\n\t- 而且不能是延迟消息、事务消息等\r\n- 过滤消息\r\n\t- 可以使用Message的Tag属性来简单快速的过滤信息\r\n\t- 一个应用可以就用一个Topic，而应用中的不同业务就用TAG来区分\r\n\t- 可以使用SQL表达式来对消息进行过滤：`MessageSelector#bySql`\r\n\t\t- 只有推模式的消费者可以使用SQL过滤\r\n- 事务消息\r\n\t- `TransactionMQProducer -> TransactionListener`\r\n\t- 事务消息只保证消息发送者的本地事务与发消息这两个操作的原子性\r\n\t\t- 但是并不保证消费者本地事务的原子性\r\n\t- 事务消息不支持延迟消息和批量消息\r\n\t- 默认将单个消息的检查次数限制为 15 次 `transactionCheckMax`\r\n\t\t- 超过则 Broker 将丢弃此消息，默认情况下同时打印错误日志 `AbstractTransactionCheckListener`\r\n\t- 事务消息将在 Broker 配置文件中的参数 transactionMsgTimeout 这样的特定时间长度之后被检查\r\n\t\t- 用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制\r\n\t\t\t- 该参数优先于 transactionMsgTimeout 参数\r\n\t- 事务性消息可能不止一次被检查或消费\r\n\t- 提交给用户的目标主题消息可能会失败，目前这依日志的记录而定\r\n\t\t- 如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制\r\n\t- 事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享\r\n\t\t- 事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者\r\n\t- 事务消息的实现机制\r\n\t\t- ![](static/RocketMQ-消息类型-ACL-1.png)\r\n\t\t\t- 在发送消息时，会将消息转为一个half半消息，并存入RocketMQ内部的一个 RMQ_SYS_TRANS_HALF_TOPIC 这个Topic，这样对消费者是不可见的\r\n\t\t\t- 再经过一系列事务检查通过后，再将消息转存到目标Topic，这样对消费者就可见了\r\n\t- 事务消息的作用\r\n\t\t- 事务消息只保证了分布式事务的一半\r\n\t\t- 对于复杂的分布式事务，RocketMQ提供的事务消息也是目前业内最佳的降级方案\r\n\r\n---\r\n## ACL 权限控制 \r\n\r\n- 权限控制（ACL）主要为RocketMQ提供Topic资源级别的用户访问控制\r\n- 用户在使用RocketMQ权限控制时，可以在Client客户端通过 RPCHook注入AccessKey和SecretKey签名\r\n\t- 同时，将对应的权限控制属性（包括Topic访问权限、IP白名单和AccessKey和SecretKey签名等）设置在`$ROCKETMQ_HOME/conf/plain_acl.yml`的配置文件中\r\n- Broker端对AccessKey所拥有的权限进行校验，校验不过，抛出异常\r\n- Broker端要在broker.conf中打开acl的标志\r\n\t- 这个配置文件是热加载的，也就是说要修改配置时，只要修改配置文件就可以了，不用重启Broker服务\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.消息类型&ACL",
      "lvl1": "消息类型",
      "lvl2": "ACL 权限控制"
    },
    "frontmatter": {
      "title": "2.消息类型&ACL",
      "date": "2025/07/03"
    },
    "type": "content"
  },
  {
    "title": "3.代码示例",
    "path": "/docs/architect/rocketmq/RocketMQ-3.daimashili.html",
    "url": "/docs/architect/rocketmq/RocketMQ-3.daimashili.html",
    "content": "---\r\ntitle: 3.代码示例\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 消息发送者的固定步骤\r\n\t- 同步发送消息\r\n\t- 异步发送消息\r\n\t- 单向发送消息：只管把消息发出去\r\n- 消息消费者的固定步骤\r\n\t- 拉模式\r\n\t\t- DefaultMQPullConsumerImpl 这个消费者类已标记为过期\r\n\t\t- 替换的类是 DefaultLitePullConsumerImpl\r\n\t- 推模式\r\n- 顺序消息\r\n- 广播消息\r\n- 延迟消息\r\n- 批量消息\r\n- 过滤消息\r\n- 事务消息\r\n- ACL 权限控制 \r\n- SpringBoot 整合 RocketMQ \r\n:::\r\n\r\n---\r\n## 消息发送者的固定步骤 \r\n\r\n1. 创建消息生产者producer，并制定生产者组名 \r\n2. 指定Nameserver地址\r\n3. 启动producer \r\n4. 创建消息对象，指定主题Topic、Tag和消息体 \r\n5. 发送消息：同步发送、异步发送以及单向发送\r\n6. 关闭生产者producer\r\n\r\n```java\r\nDefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage msg = new Message(\"TopicTest\",\"TagA\",\"OrderID188\", \r\n\t\"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\r\n// 同步发送消息\r\nSendResult sendResult = producer.send(msg);\r\n// 异步发送消息\r\nproducer.setRetryTimesWhenSendAsyncFailed(3);\r\nproducer.send(msg, new SendCallback() { });\r\n// 单向发送消息\r\nproducer.sendOneway(msg);\r\nproducer.shutdown();\r\n```\r\n\r\n---\r\n## 消息消费者的固定步骤\r\n \r\n1. 创建消费者Consumer，制定消费者组名 \r\n2. 指定Nameserver地址\r\n3. 订阅主题Topic和Tag \r\n4. 设置回调函数，处理消息\r\n\t- 拉模式；推模式（推模式也是由拉模式封装出来的）\r\n5. 启动消费者consumer\r\n\r\n```java\r\n// 拉模式\r\nDefaultMQPullConsumer consumer = new DefaultMQPullConsumer(\"group_name\");\r\nconsumer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nconsumer.start();\r\nSet<MessageQueue> mqs = consumer.fetchSubscribeMessageQueues(\"TopicTest\");\r\nfor (MessageQueue mq : mqs) {\r\n\t// 从每个 MQ 中拉消息，指定 offset 和 maxNums\r\n\tPullResult pullResult = consumer.pullBlockIfNotFound(mq, null, 0, 32);\r\n\t// 该 MQ 中下一个消息的 offset\r\n\tlong offset = pullResult.getNextBeginOffset()\r\n\tswitch (pullResult.getPullStatus()) {\r\n\t\t// 如果该 MQ 中的消息没取完，应该继续取\r\n\t}\r\n}\r\nconsumer.shutdown();\r\n```\r\n```java\r\n// 订阅-拉模式\r\nDefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(\"lite_pull_consumer\");\r\nlitePullConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);\r\nlitePullConsumer.subscribe(\"TopicTest\", \"*\");\r\nlitePullConsumer.start();\r\nwhile (running) {\r\n\tList<MessageExt> messageExts = litePullConsumer.poll();\r\n}\r\nlitePullConsumer.shutdown();\r\n```\r\n```java\r\n// 分派-拉模式\r\nDefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(\"group_name\");\r\nlitePullConsumer.setAutoCommit(false);\r\nlitePullConsumer.start();\r\nCollection<MessageQueue> mqSet = litePullConsumer.fetchMessageQueues(\"TopicTest\");\r\nList<MessageQueue> list = new ArrayList<>(mqSet);\r\n// list -add-> assignList\r\nList<MessageQueue> assignList = new ArrayList<>();\r\nlitePullConsumer.assign(assignList);\r\nlitePullConsumer.seek(assignList.get(0), 10);\r\nwhile (running) {\r\n\tList<MessageExt> messageExts = litePullConsumer.poll();\r\n\tlitePullConsumer.commitSync();\r\n}\r\n\r\nlitePullConsumer.shutdown();\r\n```\r\n```java\r\n// 推模式\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_JODIE_1\");\r\nconsumer.setNamesrvAddr(\"worker1:9876\");\r\nconsumer.subscribe(\"TopicTest\", \"*\");\r\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);\r\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\r\n\t@Override\r\n\tpublic ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, \r\n\t\t\tConsumeConcurrentlyContext context) {\r\n\t\t// 消费 msgs 之后确认已经消费完毕\r\n\t\treturn ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\r\n\t}\r\n};\r\nconsumer.start();\r\n```\r\n\r\n---\r\n## 顺序消息 \r\n\r\n```java\r\n// 生产者\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage msg = new Message(\"OrderTopicTest\", \"order_\" + orderId, \"KEY\" + orderId,\r\n\t (\"order_\"+orderId+\" step \" + j).getBytes(RemotingHelper.DEFAULT_CHARSET));\r\nSendResult sendResult = producer.send(msg, new MessageQueueSelector() {\r\n\t@Override\r\n\tpublic MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {\r\n\t\t// 根据传入的 arg (即 producer#send 的第二个参数，orderId) 选一个 MessageQueue\r\n\t\treturn mqs.get(index);\r\n\t}\r\n}, orderId);\r\nproducer.shutdown();\r\n```\r\n```java\r\n// 消费者\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group_name\");\r\nconsumer.setNamesrvAddr(\"localhost:9876\");\r\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);\r\nconsumer.subscribe(\"OrderTopicTest\", \"*\");\r\n// 需要使用 MessageListenerOrderly 保证顺序性，而不是 MessageListenerConcurrently\r\nconsumer.registerMessageListener(new MessageListenerOrderly() {\r\n\t@Override\r\n\tpublic ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs, \r\n\t\t\tConsumeOrderlyContext context) {\r\n\t\tcontext.setAutoCommit(true);\r\n\t\t// 消费 msgs 后确认消费完毕\r\n\t\treturn ConsumeOrderlyStatus.SUCCESS;\r\n\t}\r\n});\r\n\r\nconsumer.start();\r\n```\r\n\r\n---\r\n## 广播消息\r\n\r\n```java\r\n// 消费者\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group_name\");\r\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);\r\nconsumer.setMessageModel(MessageModel.BROADCASTING);\r\nconsumer.subscribe(\"TopicTest\", \"*\");\r\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\r\n\t@Override\r\n\tpublic ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\r\n\t\t\tConsumeConcurrentlyContext context) {\r\n\t\t// 消费 msgs 后确认消费完毕\r\n\t\treturn ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\r\n\t}\r\n});\r\nconsumer.start();\r\n```\r\n\r\n---\r\n## 延迟消息 \r\n\r\n```java\r\n// 生产者\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage message = new Message(\"TestTopic\", (\"Hello scheduled message \").g",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.代码示例",
      "lvl1": "消息发送者的固定步骤",
      "lvl2": "消息消费者的固定步骤",
      "lvl3": "顺序消息",
      "lvl4": "广播消息",
      "lvl5": "延迟消息",
      "lvl6": "批量消息",
      "lvl7": "过滤消息",
      "lvl8": "事务消息",
      "lvl9": "ACL 权限控制",
      "lvl10": "SpringBoot 整合 RocketMQ"
    },
    "frontmatter": {
      "title": "3.代码示例",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "3.代码示例",
    "path": "/docs/architect/rocketmq/RocketMQ-3.daimashili.html",
    "url": "/docs/architect/rocketmq/RocketMQ-3.daimashili.html",
    "content": "etBytes());\r\nmessage.setDelayTimeLevel(3);\r\nproducer.send(message);\r\nproducer.shutdown();\r\n```\r\n\r\n---\r\n## 批量消息 \r\n\r\n```java\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nproducer.send(List<Message> messages);\r\nproducer.shutdown();\r\n```\r\n\r\n---\r\n## 过滤消息 \r\n\r\n```java\r\n// tag-生产者\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage msg = new Message(\"TagFilterTest\", \"TagA\", \r\n\t \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\r\nSendResult sendResult = producer.send(msg);\r\nproducer.shutdown();\r\n\r\n// tag-消费者\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group_name\");\r\nconsumer.subscribe(\"TagFilterTest\", \"TagA || TagC\");\r\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\r\n\t@Override\r\n\tpublic ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\r\n\t\t\tConsumeConcurrentlyContext context) {\r\n\t\t// 消费 msgs 后确认消费完毕\r\n\t\treturn ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\r\n\t}\r\n});\r\nconsumer.start();\r\n```\r\n```java\r\n// sql-生产者\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage msg = new Message(\"SqlFilterTest\",\"TagA\",\r\n\t(\"Hello RocketMQ\").getBytes(RemotingHelper.DEFAULT_CHARSET));\r\nmsg.putUserProperty(\"a\", String.valueOf(i));\r\nSendResult sendResult = producer.send(msg);\r\nproducer.shutdown();\r\n\r\n// sql-消费者\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group_name\");\r\nconsumer.subscribe(\"SqlFilterTest\",\r\n\tMessageSelector.bySql(\"(TAGS is not null and TAGS in ('TagA', 'TagB'))\" +\r\n\t\"and (a is not null and a between 0 and 3)\"));\r\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\r\n\t@Override\r\n\tpublic ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\r\n\t\t\tConsumeConcurrentlyContext context) {\r\n\t\t// 消费 msgs 后确认消费完毕\r\n\t\treturn ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\r\n\t}\r\n});\r\nconsumer.start();\r\n```\r\n\r\n---\r\n## 事务消息 \r\n\r\n```java\r\npublic class TransactionListenerImpl implements TransactionListener {\r\n\t@Override\r\n\tpublic LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\r\n\t\t// COMMIT_MESSAGE ROLLBACK_MESSAGE UNKNOW\r\n\t\tmsg.getTransactionId(); // 事务ID\r\n\t\treturn LocalTransactionState.COMMIT_MESSAGE;\r\n\t}\r\n\t@Override\r\n\tpublic LocalTransactionState checkLocalTransaction(MessageExt msg) {\r\n\t\t// COMMIT_MESSAGE ROLLBACK_MESSAGE UNKNOW\r\n\t\tmsg.getTransactionId(); // 事务ID\r\n\t\treturn LocalTransactionState.COMMIT_MESSAGE;\r\n\t}\r\n}\r\n```\r\n```java\r\nTransactionListener transactionListener = new TransactionListenerImpl();\r\nTransactionMQProducer producer = new TransactionMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"127.0.0.1:9876\");\r\nproducer.setExecutorService(executorService);\r\nproducer.setTransactionListener(transactionListener);\r\nproducer.start();\r\nMessage msg = new Message(\"TopicTest\", \"TagA\", \"KEY\", \r\n\t(\"Hello RocketMQ \").getBytes(RemotingHelper.DEFAULT_CHARSET));\r\nSendResult sendResult = producer.sendMessageInTransaction(msg, null);\r\nproducer.shutdown();\r\n```\r\n\r\n---\r\n## ACL 权限控制 \r\n- `<artifactId>rocketmq-acl</artifactId>`\r\n- `broker.conf -> aclEnable=true`\r\n- `plan_acl.yml`\r\n```yaml\r\n#全局白名单，不受ACL控制 \r\n#通常需要将主从架构中的所有节点加进来 \r\nglobalWhiteRemoteAddresses:\r\n- 10.10.103.*\r\n- 192.168.0.*\r\n\r\naccounts:\r\n#第一个账户\r\n- accessKey: RocketMQ\r\n  secretKey: 12345678 \r\n  whiteRemoteAddress: \r\n  admin: false \r\n  defaultTopicPerm: DENY #默认Topic访问策略是拒绝 \r\n  defaultGroupPerm: SUB #默认Group访问策略是只允许订阅 \r\n  topicPerms:\r\n  - topicA=DENY #topicA拒绝\r\n  - topicB=PUB|SUB #topicB允许发布和订阅消息\r\n  - topicC=SUB #topicC只允许订阅\r\n  groupPerms:\r\n  # the group should convert to retry topic\r\n  - groupA=DENY\r\n  - groupB=PUB|SUB\r\n  - groupC=SUB\r\n#第二个账户，只要是来自192.168.1.*的IP，就可以访问所有资源 \r\n- accessKey: rocketmq2\r\n  secretKey: 12345678 \r\n  whiteRemoteAddress: 192.168.1.*\r\n  # if it is admin, it could access all resources \r\n  admin: true\r\n```\r\n\r\n---\r\n## SpringBoot 整合 RocketMQ \r\n\r\n```properties\r\n#NameServer地址 \r\nrocketmq.name-server=192.168.232.128:9876 \r\n#默认的消息生产者组 \r\nrocketmq.producer.group=springBootGroup\r\n```\r\n```java\r\n// 生产者\r\n@Component\r\npublic class SpringProducer {\r\n\t@Resource\r\n\tprivate RocketMQTemplate rocketMQTemplate;\r\n\t// 发送普通消息\r\n\tpublic void sendMessage(String topic,String msg){\r\n\t\tthis.rocketMQTemplate.convertAndSend(topic,msg);\r\n\t}\r\n\t// 发送事务消息\r\n\tpublic void sendMessageInTransaction(String topic,String msg) {\r\n\t\tString destination =topic + \":\" + \"TagA\";\r\n\t\tMessage<String> message = MessageBuilder.withPayload(msg).build();\r\n\t\tSendResult sendResult = rocketMQTemplate.sendMessageInTransaction(\r\n\t\t\tdestination, message, destination);\r\n\t}\r\n}\r\n// 事务消息监听器\r\n@RocketMQTransactionListener(rocketMQTemplateBeanName = \"rocketMQTemplate\")\r\npublic class MyTransactionImpl implements RocketMQLocalTransactionListener{\r\n\t@Override\r\n\tpublic RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) {\r\n\t\t// COMMIT ROLLBACK UNKNOWN\r\n\t\t// SpringBoot 的消息对象中，并没有 transactionId 这个属性\r\n\t\treturn RocketMQLocalTransactionState.COMMIT;\r\n\t}\r\n\t@Override\r\n\tpublic RocketMQLocalTransactionState checkLocalTransaction(Message msg){\r\n\t\t// COMMIT ROLLBACK UNKNOWN\r\n\t\treturn RocketMQLocalTransactionState.COMMIT;\r\n\t}\r\n}\r\n// 消费者\r\n@Component\r\n@RocketMQMessageListener(consumerGroup = \"MyConsumerGroup\", topic = \"TestTopic\")\r\npublic class SpringConsumer implements RocketMQListener<String> {\r\n    @Override\r\n    public void onMessage(String message) { \r\n        System.out.println(\"Received message : \"+ message);\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.代码示例",
      "lvl1": "消息发送者的固定步骤",
      "lvl2": "消息消费者的固定步骤",
      "lvl3": "顺序消息",
      "lvl4": "广播消息",
      "lvl5": "延迟消息",
      "lvl6": "批量消息",
      "lvl7": "过滤消息",
      "lvl8": "事务消息",
      "lvl9": "ACL 权限控制",
      "lvl10": "SpringBoot 整合 RocketMQ"
    },
    "frontmatter": {
      "title": "3.代码示例",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "---\r\ntitle: 4.核心原理\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 读队列与写队列\r\n- 消息持久化\r\n- 过期文件删除\r\n- 高效文件写\r\n\t- 零拷贝\r\n\t- 顺序写\r\n\t- 刷盘机制\r\n- 消息主从复制\r\n- 负载均衡\r\n- 消息重试\r\n- 死信队列\r\n- 消息幂等\r\n- Dledger 集群\r\n\t- 选举\r\n\t- 消息同步\r\n:::\r\n\r\n---\r\n## 读队列与写队列\r\n\r\n- 通常在运行时，都需要设置读队列=写队列\r\n- 读写分离\r\n\t- 写队列会真实的创建对应的存储文件，负责消息写入\r\n\t- 读队列会记录Consumer的Offset，负责消息读取\r\n-  在往写队列里写Message时，会同步写入到一个对应的读队列中\r\n\t- ![](static/RocketMQ-核心原理-1.png)\r\n- 如果写队列大于读队列，就会有一部分写队列无法写入到读队列中，这一部分的消息就无法被读取，就会造成消息丢失（消息存入了，但是读不出来）\r\n- 如果写队列小于读队列，那就有一部分读队列里是没有消息写入的。如果有一个消费者被分配的是这些没有消息的读队列，那这些消费者就无法消费消息，造成消费者空转，极大的浪费性能\r\n- 对Topic的MessageQueue进行缩减的时候，可以考虑将读写队列设置为不一致\r\n\t- 例如原来四个队列，现在要缩减成两个队列\r\n\t- 如果立即缩减读写队列，那么被缩减的MessageQueue上没有被消费的消息，就会丢失\r\n\t- 这时，可以先缩减写队列，待空出来的读队列上的消息都被消费完了之后，再来缩减读队列，这样就可以比较平稳的实现队列缩减了\r\n\r\n---\r\n## 消息持久化\r\n\r\n- RocketMQ消息直接采用磁盘文件保存消息，默认路径在`${user_home}/store`目录（`broker.conf`）\r\n- 存储文件主要分为三个部分\r\n\t- CommitLog：存储消息的元数据\r\n\t\t- 所有消息都会顺序存入到CommitLog文件当中\r\n\t\t- CommitLog由多个文件组成，每个文件固定大小1G\r\n\t\t- 以第一条消息的偏移量为文件名\r\n\t- ConsumerQueue：存储消息在CommitLog的索引\r\n\t\t- 一个MessageQueue一个文件\r\n\t\t- 记录当前MessageQueue被哪些消费者组消费到了哪一条CommitLog\r\n\t- IndexFile\r\n\t\t- 为了消息查询提供了一种通过key或时间区间来查询消息的方法\r\n\t\t- 这通过IndexFile来查找消息的方法不影响发送与消费消息的主流程\r\n\t- CommitLog文件和ConsumeQueue文件都是以偏移量命名\r\n- 还有几个辅助的存储文件\r\n\t- checkpoint：数据存盘检查点\r\n\t\t- 里面主要记录commitlog文件、ConsumeQueue文件以及IndexFile文件最后一次刷盘的时间戳\r\n\t- `config/*.json`：这些文件是将RocketMQ的一些关键配置信息进行存盘保存\r\n\t\t- 例如Topic配置、消费者组配置、消费者组消息偏移量Offset 等等一些信息\r\n\t- abort：这个文件是RocketMQ用来判断程序是否正常关闭的一个标识文件\r\n\t\t- 正常情况下，会在启动时创建，而关闭服务时删除\r\n\t\t- 但是如果遇到一些服务器宕机，这个abort文件就不会删除\r\n\t\t- 因此RocketMQ就可以判断上一次服务是非正常关闭的，后续就会做一些数据恢复的操作\r\n- 整体的消息存储结构\r\n\t- ![](static/RocketMQ-核心原理-2.png)\r\n- CommitLog文件存储所有消息实体\r\n\t- 所有生产者发过来的消息，都会无差别的依次存储到Commitlog文件当中\r\n\t\t- 这样的好处是可以减少查找目标文件的时间，让消息以最快的速度落盘\r\n\t\t- 对比Kafka存文件时，需要寻找消息所属的Partition文件，再完成写入，当Topic比较多时，这样的Partition寻址就会浪费比较多的时间，所以Kafka不太适合多Topic的场景\r\n\t\t- 而RocketMQ的这种快速落盘的方式在多Topic场景下，优势就比较明显\r\n\t-  文件结构：CommitLog的文件大小是固定的，但是其中存储的每个消息单元长度是不固定的\r\n\t\t- 所以RocketMQ在每次存CommitLog文件时，都会去检查当前CommitLog文件空间是否足够\r\n\t\t\t- 如果不够的话，就重新创建一个CommitLog文件\r\n\t\t\t- 文件名为当前消息的偏移量\r\n- ConsumeQueue文件主要是加速消费者的消息索引\r\n\t- 他的每个文件夹对应RocketMQ中的一个MessageQueue\r\n\t\t- 文件夹下的文件记录了每个MessageQueue中的消息在CommitLog文件当中的偏移量\r\n\t\t- 这样，消费者通过ComsumeQueue文件，就可以快速找到CommitLog文件中感兴趣的消息记录\r\n\t\t- 而消费者在ConsumeQueue文件当中的消费进度，会保存在`config/consumerOffset.json`文件当中\r\n\t- 文件结构：每个ConsumeQueue文件固定由30万个固定大小20byte的数据块组成，数据块的内容包括\r\n\t\t- msgPhyOffset (8byte，消息在文件中的起始位置)\r\n\t\t- msgSize (4byte，消息在文件中占用的长度)\r\n\t\t- msgTagCode (8byte，消息的tag的Hash值)\r\n- IndexFile文件主要是辅助消息检索\r\n\t- 消费者进行消息消费时，通过ConsumeQueue文件就足够完成消息检索了，但是如果要按照MeessageId或者MessageKey来检索文件，比如RocketMQ管理控制台的消息轨迹功能，ConsumeQueue文件就不够用了\r\n\t- 他的文件名比较特殊，不是以消息偏移量命名，而是用的时间命名\r\n\t- 文件结构：也是一个固定大小的文件\r\n\t\t- indexHeader (固定40byte)\r\n\t\t- slot (固定500W个，每个固定20byte)\r\n\t\t- index (最多`500W*4`个，每个固定20byte) \r\n\r\n---\r\n## 过期文件删除\r\n\r\n- 判断过期文件：唯一标准就是非当前写文件的保留时间（`broker.conf -> fileReservedTime`）\r\n\t- 如果超过了一定的保留时间，那么这些文件都会被认为是过期文件，随时可以删除\r\n\t- 并不关心文件当中的消息是否被消费过\r\n\t\t- 所以，RocketMQ的消息堆积也是有时间限度的\r\n- 删除过期文件\r\n\t- 内部有一个定时任务，对文件进行扫描，并且触发文件删除的操作\r\n\t\t- `broker.conf -> deleteWhen`，默认是凌晨四点\r\n\t- 还会检查服务器的磁盘空间是否足够，如果磁盘空间的使用率达到一定的阈值，也会触发过期文件删除\r\n\t\t- broker的",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 5
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "磁盘空间不要少于4\r\n\r\n---\r\n## 高效文件写\r\n\r\n### 零拷贝\r\n\r\n- 所谓的零拷贝技术，其实并不是不拷贝，而是要尽量减少CPU拷贝\r\n- 引入DMA拷贝之后，在读写请求的过程中，CPU不再需要参与具体的工作\r\n\t- DMA可以独立完成数据在系统内部的复制\r\n\t- 但是，数据复制过程中，依然需要借助数据总进线\r\n\t\t- 当系统内的IO操作过多时，还是会占用过多的数据总线，造成总线冲突，最终还是会影响数据读写性能\r\n- 为了避免DMA总线冲突对性能的影响，后来又引入了Channel通道的方式\r\n\t- Channel，是一个完全独立的处理器，专门负责IO操作\r\n\t- 既然是处理器，Channel就有自己的IO指令，与CPU无关，他也更适合大型的IO操作，性能更高\r\n- mmap：`FileChannel#map`\r\n\t- mmap机制适合操作小文件，如果文件太大，映射信息也会过大，容易造成很多问题\r\n\t- 通常mmap机制建议的映射文件大小不要超过2G\r\n\t- RocketMQ的CommitLog文件保持在1G固定大小，也是为了方便文件映射\r\n\t- ![](static/RocketMQ-核心原理-3.png)\r\n- sendFile：`FileChannel#transferTo`\r\n\t- 在拷贝过程中，并不直接拷贝文件的内容，而是只拷贝一个带有文件位置和长度等信息的文件描述符FD\r\n\t\t- 这样就大大减少了需要传递的数据\r\n\t- 而真实的数据内容，会交由DMA控制器，从页缓存中打包异步发送到socket中\r\n\t- sendfile机制在内核态直接完成了数据的复制，不需要用户态的参与，所以这种机制的传输效率是非常稳定的\r\n\t- sendfile机制非常适合大数据的复制转移\r\n\t- ![](static/RocketMQ-核心原理-4.png)\r\n\r\n### 顺序写\r\n\r\n- 在磁盘中提前申请一块连续的磁盘空间\r\n\t- 每次写数据时，就可以避免这些寻址操作，直接在之前写入的地址后面接着写就行\r\n- 顺序写的性能基本能够达到内存级别\r\n\r\n### 刷盘机制\r\n\r\n- 在操作系统层面\r\n\t- 当应用程序写入一个文件时，文件内容并不会直接写入到硬件当中，而是会先写入到操作系统中的一个缓存PageCache中\r\n\t\t- PageCache缓存以4K大小为单位，缓存文件的具体内容\r\n\t\t- 这些写入到PageCache中的文件，在应用程序看来，是已经完全落盘保存好了的\r\n\t\t- 但是，本质上，PageCache依然是内存状态，所以一断电就会丢失\r\n\t\t- 因此，需要将内存状态的数据写入到磁盘当中，这样数据才能真正完成持久化，断电也不会丢失\r\n\t\t\t- 这个过程就称为刷盘\r\n\t- PageCache是源源不断产生的，操作系统只会在某些特定的时刻将PageCache写入到磁盘\r\n\t\t- 正常关机时\r\n\t\t- 当 Dirty Page (脏页) 的比例达到一定的阈值时（对于有数据修改的PageCache，会标记为Dirty状态）\r\n\t- 可以通过/proc/meminfo文件查看到Page Cache的状态\r\n\t- fsync：可以让应用程序完成PageCache的强制刷盘\r\n-  RocketMQ对于何时进行刷盘，也设计了两种刷盘机制，同步刷盘和异步刷盘 \r\n\t- `broker.conf -> flushDiskType`\r\n\t- ![](static/RocketMQ-核心原理-5.png)\r\n\t- 同步刷盘：在返回写成功状态时，消息已经被写入磁盘\r\n\t\t- 消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘\r\n\t\t-  然后等待刷盘完成\r\n\t\t- 刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态\r\n\t- 异步刷盘：在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE\r\n\t\t- 写操作的返回快，吞吐量大\r\n\t\t- 当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入\r\n\t- 同步刷盘机制会更频繁的调用fsync，所以吞吐量相比异步刷盘会降低，但是数据的安全性会得到提高\r\n\r\n---\r\n## 消息主从复制 \r\n\r\n- 同步复制：等Master和Slave都写入消息成功后才反馈给客户端写入成功的状态\r\n\t- 如果Master节点故障，Slave上有全部的数据备份，这样容易恢复数据\r\n\t- 但是同步复制会增大数据写入的延迟，降低系统的吞吐量\r\n- 异步复制：只要master写入消息成功，就反馈给客户端写入成功的状态\r\n\t- 然后再异步的将消息复制给Slave节点\r\n\t- 系统拥有较低的延迟和较高的吞吐量\r\n\t- 但是如果master节点故障，而有些数据没有完成复制，就会造成数据丢失\r\n- `broker.conf -> brokerRole`\r\n\t- ASYNC_MASTER、 SYNC_MASTER、SLAVE\r\n\r\n---\r\n## 负载均衡\r\n\r\n- Producer 负载均衡 \r\n\t- ![](static/RocketMQ-核心原理-6.png)\r\n\t- Producer发送消息时，默认会轮询目标Topic下的所有MessageQueue，并采用递增取模的方式往不同的MessageQueue上发送消息，以达到让消息平均落在不同的queue上的目的\r\n\t- 由于MessageQueue是分布在不同的Broker上的，所以消息也会发送到不同的broker上\r\n\t- 同时生产者在发送消息时，可以指定一个MessageQueueSelector\r\n\t\t- 通过这个对象来将消息发送到自己指定的MessageQueue上\r\n\t\t- 这样可以保证消息局部有序\r\n- Consumer负载均衡： Consumer也是以MessageQueue为单位来进行负载均衡\r\n\t- 集群模式 \r\n\t\t- 每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可\r\n\t\t- RocketMQ采用主动拉取的方式拉取并消费消息\r\n\t\t\t- 在拉取的时候需要明确指定拉取哪一条message queue\r\n\t\t- 每当实例的数量有变更，都会触发一次所有实例的负载均衡\r\n\t\t\t- 这时候会按照queue的数量和实例的数量平均分配queue给每个实例\r\n\t\t- 每次分配时，都会将MessageQueue和消费者ID进行排序后，再用不同的分配算法进行分配\r\n\t\t- 内置的分配的算法共有六种，分别对应AllocateMessageQueueStrategy下的六种实现类\r\n\t\t\t- 可以在consumer中直接set来指定。默认情况下使用的是最简单的平均分配策略\r\n\t- 广播模式\r\n\t\t- 每一条消息都会投递给订阅了Topic的所有消费者实例，所以也就没有消息分配这一说\r\n\t\t- 在实现上，就是在Consumer分配Queue时，所有Consumer都分到所有的Queue\r\n\t\t- 实现",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 5
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "的关键是将消费者的消费偏移量不再保存到broker当中\r\n\t\t\t- 而是保存到客户端当中，由客户端自行维护自己的消费偏移量\r\n- 集群模式分配算法\r\n\t- AllocateMachineRoomNearby： 将同机房的Consumer和Broker优先分配在一起\r\n\t\t- 可以通过一个machineRoomResolver对象来定制Consumer和Broker的机房解析规则\r\n\t\t- 然后还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配\r\n\t\t\t- 一般也就用简单的平均分配策略或者轮询分配策略\r\n\t- AllocateMessageQueueAveragely（默认）：平均分配。将所有MessageQueue平均分给每一个消费者\r\n\t- AllocateMessageQueueAveragelyByCircle： 轮询分配。轮流的给一个消费者分配一个MessageQueue\r\n\t- AllocateMessageQueueByConfig： 不分配，直接指定一个messageQueue列表\r\n\t\t- 类似于广播模式，直接指定所有队列\r\n\t- AllocateMessageQueueByMachineRoom：按逻辑机房的概念进行分配\r\n\t\t- 又是对BrokerName和ConsumerIdc有定制化的配置\r\n\t- AllocateMessageQueueConsistentHash：一致性哈希策略\r\n\t\t- 只需要指定一个虚拟节点数，是用的一个哈希环的算法\r\n\t\t- 虚拟节点是为了让Hash数据在换上分布更为均匀\r\n\r\n---\r\n## 消息重试\r\n\r\n- 集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置 \r\n\t- `MessageListener#consume`\r\n\t- 返回 Action.ReconsumeLater（推荐） 消息重试\r\n\t- 返回 Action.CommitMessage 消费失败后不重试\r\n\t- 返回 null\r\n\t- 抛出异常\r\n- 处理重试消息\r\n\t- 重试的消息会进入一个 “%RETRY%”+ConsumeGroup 的队列中\r\n\t- 默认允许每条消息最多重试16次\r\n\t\t- 这个重试时间跟延迟消息的延迟级别是对应的\r\n\t\t- 不过取的是延迟级别的后16级别\r\n\t- `consumer#setMaxReconsumeTimes` 定制重试次数\r\n\t\t- 当定制的重试次数超过16次后，消息的重试时间间隔均为2小时\r\n\t- 如果消息重试16次后仍然失败，消息将不再投递。转为进入死信队列\r\n\t- 一条消息无论重试多少次，这些重试消息的MessageId始终都是一样的\r\n\t\t- 在4.9.1版本中，每次重试MessageId都会重建\r\n\t- 配置覆盖\r\n\t\t- 消息最大重试次数的设置对相同GroupID下的所有Consumer实例有效\r\n\t\t- 并且最后启动的Consumer会覆盖之前启动的Consumer的配置\r\n\r\n---\r\n## 死信队列\r\n\r\n- 如果消息重试16次（`consumer#setMaxReconsumeTimes`）后仍然失败，消息将不再投递。转为进入死信队列\r\n- 死信队列的名称是 %DLQ%+ConsumGroup\r\n- 死信队列的特征\r\n\t- 一个死信队列对应一个ConsumGroup，而不是对应某个消费者实例\r\n\t- 如果一个ConsumeGroup没有产生死信队列，RocketMQ就不会为其创建相应的死信队列\r\n\t- 一个死信队列包含了这个ConsumeGroup里的所有死信消息，而不区分该消息属于哪个Topic\r\n\t- 死信队列中的消息不会再被消费者正常消费\r\n\t- 死信队列的有效期跟正常消息相同。默认3天（`broker.conf -> fileReservedTime`）\r\n\t\t- 超过这个最长时间的消息都会被删除，而不管消息是否消费过\r\n- 一般需要人工去查看死信队列中的消息，对错误原因进行排查\r\n\t- 然后对死信消息进行处理，比如转发到正常的Topic重新进行消费，或者丢弃\r\n- 默认创建出来的死信队列，他里面的消息是无法读取的，在控制台和消费者中都无法读取\r\n\t- 这些默认的死信队列，他们的权限 perm 被设置成了 2:禁读\r\n\t\t- 权限有三种：2:禁读，4:禁写，6:可读可写\r\n\t- 需要手动将死信队列的权限配置成 6，才能被消费\r\n\r\n---\r\n## 消息幂等\r\n\r\n- 在MQ系统中，对于消息幂等有三种实现语义\r\n\t- at most once 最多一次：每条消息最多只会被消费一次\r\n\t- at least once 至少一次：每条消息至少会被消费一次\r\n\t- exactly once 刚刚好一次：每条消息都只会确定的消费一次\r\n- RocketMQ 只能保证 at least once，保证不了 exactly once\r\n\t- 所以，使用RocketMQ时，需要由业务系统自行保证消息的幂等性\r\n- 消息重复\r\n\t- 发送时消息重复\r\n\t\t- 当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败\r\n\t\t- 此时生产者意识到消息发送失败并尝试再次发送消息\r\n\t\t- 消费者后续会收到两条内容相同并且 Message ID 也相同的消息\r\n\t- 投递时消息重复\r\n\t\t- 消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断\r\n\t\t- 为了保证消息至少被消费一次，消息队列 RocketMQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息\r\n\t\t- 消费者后续会收到两条内容相同并且 Message ID 也相同的消息\r\n\t- 负载均衡时消息重复：网络抖动、Broker 重启以及订阅方应用重启\r\n\t\t- 当消息队列 RocketMQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息\r\n- 处理方式：要在业务上自行来保证消息消费的幂等性\r\n\t- RocketMQ的每条消息都有一个唯一的 MessageId，这个参数在多次投递的过程中是不会改变的\r\n\t- 业务上可以用这个MessageId来作为判断幂等的关键依据\r\n\t- 但是，这个MessageId是无法保证全局唯一的，也会有冲突的情况\r\n\t- 所以在一些对幂等性要求严格的场景，最好是使用业务上唯一的一个标识比较靠谱\r\n\t- 而这个业务标识可以使用Message的Key来进行传递\r\n\r\n---\r\n## Dledger 集群\r\n\r\n- 高可用集群：基于Raft，在RocketMQ的主从集群基础上，增加了自动选举的功能\r\n- Dledger集群主要包含两个功能\r\n\t- 从集群中选举产生master节点\r\n\t- 优化master节点往slave节点的消息同步机制\r\n\r\n### 选举\r\n\r\n- Dledger是使用Raft算法来进行节点选举\r\n\t- 节点有三个状态，Leader，follower 和 candidate (候选人)\r\n\t\t- 正常运行的情况下",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 5
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "，集群中会有一个leader，其他都是follower\r\n\t\t- follower只响应Leader和Candidate的请求\r\n\t\t- 客户端的请求全部由Leader处理\r\n\t\t\t- 即使有客户端请求到了一个follower，也会将请求转发到leader\r\n\t- 选举流程\r\n\t\t- 集群刚启动时，每个节点都是follower状态\r\n\t\t- 之后集群内部会发送一个timeout信号\r\n\t\t- 所有follower就转成candidate去拉取选票，获得大多数选票的节点选为leader，其他候选人转为follower\r\n\t\t- 如果一个timeout信号发出时，没有选出leader，将会重新开始一次新的选举\r\n\t- 心跳\r\n\t\t- Leader节点会往其他节点发送心跳信号，确认他的leader状态\r\n\t\t- 然后follower会启动定时器，如果在指定时间内没有收到Leader的心跳，就会转为Candidate状态\r\n\t\t- 然后向其他成员发起投票请求，如果收到半数以上成员的投票，则Candidate会晋升为Leader\r\n\t\t\t- 然后leader也有可能会退化成follower\r\n- 在Raft协议中，会将时间分为一些任意时间长度的时间片段，叫做term\r\n\t- ![](static/RocketMQ-核心原理-7.png)\r\n\t- term会使用一个全局唯一，连续递增的编号作为标识，也就是起到了一个逻辑时钟的作用\r\n\t- 在每一个term时间片里，都会进行新的选举，每一个Candidate都会努力争取成为leader\r\n\t\t- 获得票数最多的节点就会被选举为Leader\r\n\t- 被选为Leader的这个节点，在一个term时间片里就会保持leader状态\r\n\t\t- 保证在同一时间段内，集群中只会有一个Leader\r\n\t- 在某些情况下，选票可能会被各个节点瓜分，形成不了多数派，那这个term可能直到结束都没有leader\r\n\t\t- 直到下一个term再重新发起选举，这也就没有了Zookeeper中的脑裂问题\r\n\t- 在每次重新选举的过程中， leader也有可能会退化成为follower\r\n\t\t- 也就是说，在这个集群中， leader节点是会不断变化的\r\n- 每次选举的过程中，每个节点都会存储当前term编号，并在节点之间进行交流时，都会带上自己的term编号\r\n\t- 如果一个节点发现他的编号比另外一个小，那么他就会将自己的编号更新为较大的那一个\r\n\t- 如果leader或者candidate发现自己的编号不是最新的，他就会自动转成follower\r\n\t- 如果接收到的请求term编号小于自己的编号，term将会拒绝执行\r\n-  在选举过程中，Raft协议会通过心跳机制发起leader选举\r\n\t- 节点都是从follower状态开始的，如果收到了来自leader或者candidate的心跳RPC请求，那他就会保持follower状态，避免争抢成为candidate\r\n\t- leader会往其他节点发送心跳信号，来确认自己的地位\r\n\t- 如果follower一段时间(两个timeout信号)内没有收到Leader的心跳信号，他就会认为leader挂了，发起新一轮选举\r\n-  选举开始后，每个follower会增加自己当前的term，并将自己转为candidate\r\n\t- 然后向其他节点发起投票请求，请求时会带上自己的编号和term，也就是说都会默认投自己一票\r\n\t- 之后candidate状态可能会发生以下三种变化\r\n\t\t- 赢得选举，成为leader\r\n\t\t\t- 如果它在一个term内收到了大多数的选票，将会在接下的剩余term时间内称为leader\r\n\t\t\t- 然后就可以通过发送心跳确立自己的地位\r\n\t\t\t- 每一个server在一个term内只能投一张选票，并且按照先到先得的原则投出\r\n\t\t- 其他节点成为leader\r\n\t\t\t- 在等待投票时，可能会收到其他server发出心跳信号，说明其他leader已经产生了\r\n\t\t\t- 这时通过比较自己的term编号和RPC过来的term编号\r\n\t\t\t\t- 如果比对方大，说明leader的term过期了，就会拒绝该RPC,并继续保持候选人身份\r\n\t\t\t\t- 如果对方编号不比自己小,则承认对方的地位,转为follower\r\n\t\t- 选票被瓜分,选举失败\r\n\t\t\t- 如果没有candidate获取大多数选票, 则没有leader产生\r\n\t\t\t- candidate们等待超时后发起另一轮选举\r\n\t\t\t- 为了防止下一次选票还被瓜分, raft采用随机electiontimeout(随机休眠时间)的机制防止选票被持续瓜分\r\n\t\t\t- 通过将timeout随机设为一段区间上的某个值, 因此很大概率会有某个candidate率先超时然后赢得大部分选票\r\n- 所以以三个节点的集群为例，选举过程会是这样的\r\n\t- 集群启动时，三个节点都是follower，发起投票后，三个节点都会给自己投票。这样一轮投票下来，三个节点的term都是1，是一样的，这样是选举不出Leader的\r\n\t- 当一轮投票选举不出Leader后，三个节点会进入随机休眠，例如A休眠1秒，B休眠3秒，C休眠2秒\r\n\t- 一秒后，A节点醒来，会把自己的term加一票，投为2。然后2秒时，C节点醒来，发现A的term已经是2，比自己的1大，就会承认A是Leader，把自己的term也更新为2。实际上这个时候，A已经获得了集群中的多数票，2票，A就会被选举成Leader。这样，一般经过很短的几轮选举，就会选举出一个Leader来\r\n\t- 到3秒时，B节点会醒来，他也同样会承认A的term最大，他是Leader，自己的term也会更新为2。这样集群中的所有Candidate就都确定成了leader和follower\r\n\t- 然后在一个任期内，A会不断发心跳给另外两个节点。当A挂了后，另外的节点没有收到A的心跳，就会都转化成Candidate状态，重新发起选举\r\n\r\n### 消息同步\r\n\r\nDledger还会采用Raft协议进行多副本的消息同步：\r\n- 使用Dledger集群后，数据主从同步会分为两个阶段，一个是uncommitted阶段，一个是commited阶段\r\n- Leader Broker上的Dledger收到一条数据后，会标记为uncommitted状态，然后他通过自己的DledgerServer组件把这个uncommitted数据发给Follower Broker的DledgerServer组件\r\n- 接着Follower Broker的DledgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的Dledger。然后如果Leader Broker收到超过半数的Follower Broker返回的ack之后，就会把消息标记为committed状态\r\n-  再接下来， Leader Broker上的DledgerServer就",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 4,
    "contentParts": 5
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "会发送committed消息给Follower Broker上的DledgerServer，让他们把消息也标记为committed状态。这样，就基于Raft协议完成了两阶段的数据同步\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 5,
    "contentParts": 5
  },
  {
    "title": "5.整体架构",
    "path": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "url": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "content": "---\r\ntitle: 5.整体架构\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- NameServer的结构\r\n- Broker的结构\r\n- Netty服务注册框架\r\n- RocketMQ的同步结果推送与异步结果推送\r\n- Broker心跳注册过程\r\n- Producer发送消息过程\r\n- Consumer拉取消息过程\r\n- 文件存储\r\n- 延迟消息\r\n- 长轮询机制\r\n:::\r\n\r\n---\r\n## NameServer的结构\r\n\r\n- NameServer的核心作用\r\n\t- 一是维护Broker的服务地址并进行及时的更新\r\n\t- 二是给Producer和Consumer提供服务获取Broker列表\r\n- NameServer的启动入口为NamesrvStartup类的main方法\r\n- 整个NameServer的核心就是一个NamesrvController对象\r\n\r\n![](static/RocketMQ-整体架构-1.png)\r\n\r\n---\r\n## Broker的结构\r\n\r\n- Broker是整个RocketMQ的业务核心，所有消息存储、转发这些最为重要的业务都是在Broker中进行处理的\r\n- Broker启动的入口在BrokerStartup这个类的main方法\r\n- 重点也是围绕一个BrokerController对象\r\n- 在BrokerStartup.createBrokerController方法中可以看到Broker的几个核心配置\r\n\t- BrokerConfig \r\n\t- NettyServerConfig  ：Netty服务端占用了10911端口。同样也可以在配置文件中覆盖\r\n\t- NettyClientConfig  \r\n\t- MessageStoreConfig\r\n\r\n![](static/RocketMQ-整体架构-2.png)\r\n\r\n---\r\n## Netty服务注册框架\r\n\r\n- RocketMQ使用Netty框架提供了一套基于服务码的服务注册机制，让各种不同的组件都可以按照自己的需求，注册自己的服务方法\r\n- Netty的所有远程通信功能都由remoting模块实现。RemotingServer模块里包含了RPC的服务端RemotingServer以及客户端RemotingClient\r\n- RocketMQ基于Netty保持客户端与服务端的长连接Channel\r\n- 所有的请求都封装成RemotingCommand对象。而每个处理消息的服务逻辑，会封装成一个NettyRequestProcessor对象\r\n- 服务端和客户端都维护了一个processorTable，这是个HashMap，key是服务码requestCode，value是对应的运行单元\r\n\t- Pair<NettyRequestProcessor, ExecutorService>  类型，包含了处理逻辑Prcessor和执行线程池ExecutorService\r\n- 服务端的注册BrokerController.registerProcessor() ，客户端的服务注册见MQClientAPIImpl。NameServer则会注册一个大的DefaultRequestProcessor，统一处理所有的服务\r\n- 服务注册流程：\r\n\r\n![](static/RocketMQ-整体架构-3.png)\r\n\r\n- NameServer会维护Broker的路由列表，并对路由列表进行实时更新\r\n- BrokerController.this.registerBrokerAll方法会发起向NameServer注册心跳。启动时会立即注册，同时也会启动一个线程池，以10秒延迟，默认30秒的间隔持续向NameServer发送心跳\r\n-  BrokerController.this.registerBrokerAll这个方法就是注册心跳的入口\r\n- 然后，在NameServer中也会启动一个定时任务，扫描不活动的Broker。具体观察NamesrvController.initialize方法\r\n\r\n![](static/RocketMQ-整体架构-4.png)\r\n\r\n---\r\n## RocketMQ的同步结果推送与异步结果推送\r\n\r\n- RocketMQ的RemotingServer服务端，会维护一个responseTable，这是一个线程同步的Map结构。 key为请求的ID，value是异步的消息结果 ConcurrentMap<Integer  , ResponseFuture>\r\n- 处理同步请求(NettyRemotingAbstract#invokeSyncImpl)时，处理的结果会存入responseTable，通过ResponseFuture提供一定的服务端异步处理支持，提升服务端的吞吐量。 请求返回后，立即从responseTable中移除请求记录\r\n-  处理异步请求(NettyRemotingAbstract#invokeAsyncImpl)时，处理的结果依然会存入responsTable，等待客户端后续再来请求结果。但是他保存的依然是一个ResponseFuture，也就是在客户端请求结果时再去获取真正的结果\r\n\t- 另外，在RemotingServer启动时，会启动一个定时的线程任务，不断扫描responseTable，将其中过期的response清除掉\r\n\r\n---\r\n## Producer发送消息过程 \r\n\r\n- Producer有两种\r\n\t- 普通发送者：DefaultMQProducer。只负责发送消息，发送完消息，就可以停止了\r\n\t\t- DefaultMQProducer只需要构建一个Netty客户端，往Broker发送消息就行了\r\n\t\t- 异步回调只是在Producer接收到Broker的响应后自行调整流程，不需要提供Netty服务\r\n\t- 事务消息发送者： TransactionMQProducer。支持事务消息机制。需要在事务消息过程中提供事务状态确认的服务，这就要求事务消息发送者虽然是一个客户端，但是也要完成整个事务消息的确认机制后才能退出\r\n\t\t- TransactionMQProducer由于需要在事务消息机制中给Broker提供状态确认服务，所以在发送消息的同时，还需要保持连接，提供服务\r\n\t\t- TransactionMQProducer的启动过程中，会往RemotingClient中注册相应的Processor，这样RemotingServer和RemotingClient之间就可以通过channel进行双向的服务请求了\r\n- 整个Producer的流程，大致分两个步骤\r\n\t- start方法，进行一大堆的准备工作\r\n\t- 各种各样的send方法，进行消息发送\r\n- 重点关注以下几个问题\r\n\t- Producer的核心启动流程以及两种消息发送者的区别\r\n\t\t- 所有Producer的启动过程，最终都会调用DefaultMQProducerImpl#start方法\r\n\t\t\t- 在start方法中的通过一个mQClientFactory对象，启动生产者的一大堆重要服务\r\n\t\t- 所有客户端的启动流程是固定的，不同客户端的区别只是在于他们在启动前注册的一些信息不同\r\n\t\t\t- 生产者注册到producerTable，消费者注册到consumerTable，管理控制端注册到adminExtTable\r\n\t- Producer如何管理Borker路由信息\r\n\t\t- Producer需要拉取Broker列表，然后跟Broker建立连接等等很多核心的流程，其实都是在发送消息时建立的。因为在启动时，还不知道要拉取哪个Topic的Broker列表呢\r\n\t\t- 对NameServer的地址管理，则是散布在启动和发送的多个过程当中，并且NameServer地址可以通过一个Http服务来获取\r\n\t\t- Send方法中，首先需要获得Topic的路由信息。这会从本地缓存中获取，如果本地缓存中没有，就从NameServer中去申请 DefaultMQProducerImpl#tryToFindTopicPublishIn",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.整体架构",
      "lvl1": "NameServer的结构",
      "lvl2": "Broker的结构",
      "lvl3": "Netty服务注册框架",
      "lvl4": "RocketMQ的同步结果推送与异步结果推送",
      "lvl5": "Producer发送消息过程",
      "lvl6": "Consumer拉取消息过程",
      "lvl7": "文件存储",
      "lvl8": "延迟消息",
      "lvl9": "长轮询机制"
    },
    "frontmatter": {
      "title": "5.整体架构",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 3
  },
  {
    "title": "5.整体架构",
    "path": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "url": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "content": "fo 方法\r\n\t\t- ![](static/RocketMQ-整体架构-5.png)\r\n\t- Producer的负载均衡\r\n\t\t- Producer在获取路由信息后，会选出一个MessageQueue去发送消息\r\n\t\t- 这个选MessageQueue的方法就是一个索引自增然后取模的方式\r\n\t\t- 然后根据MessageQueue再找所在的Broker，往Broker发送请求\r\n\t- 在发送Netty请求时，如何制定Broker\r\n\t\t- 实际上是指定的MessageQueue，而不是Topic。Topic只是用来找MessageQueue\r\n\r\n---\r\n## Consumer拉取消息过程 \r\n\r\n- 消费者也是有两种，推模式消费者（用的最多）和拉模式消费者\r\n- 消费者组之间有集群模式和广播模式两种消费模式\r\n- 消费者端的负载均衡的原理。即消费者是如何绑定消费队列的，哪些消费策略到底是如何落地的\r\n- 在推模式的消费者中，MessageListenerConcurrently 和MessageListenerOrderly这两种消息监听器的处理逻辑到底有什么不同，为什么后者能保持消息顺序\r\n-  DefaultMQPushConsumer.start作为入口。最终消费者的启动过程，跟生产者一样，也交由了mQClientFactory\r\n\t- pullMessageService主要处理拉取消息服务；rebalanceService主要处理客户端的负载均衡\r\n- 客户端负载均衡策略\r\n\t- 在消费者示例的start方法中，启动RebalanceService，这个是客户端进行负载均衡策略的启动服务。他只负责根据负载均衡策略获取当前客户端分配到的MessageQueue\r\n\t- 五种负载策略，可以由Consumer的allocateMessageQueueStrategy属性来选择\r\n\t\t- 这个属性可以在DefaultMQPushConsumer的构造方法当中指定。默认是AllocateMessageQueueAveragely策略\r\n\t\t- 最常用的是AllocateMessageQueueAveragely平均分配和AllocateMessageQueueAveragelyByCircle平均轮询分配\r\n\t\t\t- 平均分配是把MessageQueue按组内的消费者个数平均分配\r\n\t\t\t- 平均轮询分配就是把MessageQueue按组内的消费者一个一个轮询分配\r\n- 并发消费与顺序消费的过程\r\n\t- 消费的过程依然是在DefaultMQPushConsumerImpl的 consumeMessageService中\r\n\t- 他有两个子类ConsumeMessageConcurrentlyService和ConsumeMessageOrderlyService\r\n\t- 最主要的差别是ConsumeMessageOrderlyService会在消费前把队列锁起来，优先保证拉取同一个队列里的消息\r\n\t- 消费过程的入口在DefaultMQPushConsumerImpl的pullMessage中定义的PullCallback中\r\n- RocketMQ消息消费方式分别为集群模式、广播模式\r\n- 消息队列负载由RebalanceService线程默认每隔20s进行一次消息队列负载\r\n\t- 根据当前消费者组内消费者个数与主题队列数量按照某一种负载算法进行队列分配\r\n\t- 分配原则为同一个消费者可以分配多个消息消费队列\r\n\t- 同一个消息消费队列同一个时间只会分配给一个消费者\r\n- 消息拉取由PullMessageService线程根据RebalanceService线程创建的拉取任务进行拉取\r\n\t- 默认每次拉取一批消息(可以由业务指定，默认是1)，提交给消费者消费线程后继续下一次消息拉取\r\n\t- 如果消息消费过慢产生消息堆积会触发消息消费拉取流控\r\n- 并发消息消费指消费线程池中的线程可以并发对同一个消息队列的消息进行消费\r\n\t- 消费成功后，取出消息队列中最小的消息偏移量作为消息消费进度偏移量存储在于消息消费进度存储文件中\r\n\t- 集群模式消息消费进度存储在Broker（消息服务器）\r\n\t- 广播模式消息消费进度存储在消费者端\r\n- RocketMQ不支持任意精度的定时调度消息，只支持自定义的消息延迟级别\r\n\t- 可通过在broker配置文件中设置messageDelayLevel\r\n- 顺序消息一般使用集群模式，是指对消息消费者内的线程池中的线程对消息消费队列只能串行消费\r\n\t- 与并发消息消费最本质的区别是消息消费时必须成功锁定消息消费队列\r\n\t- 在Broker端会存储消息消费队列的锁占用情况\r\n- 拉模式核心服务类： PullMessageService\r\n\t- PullRequest里有messageQueue和processQueue，其中messageQueue负责拉取消息，拉取到后，将消息存入processQueue，进行处理。 存入后就可以清空messageQueue，继续拉取了\r\n\t- ![](static/RocketMQ-整体架构-6.png)\r\n\r\n---\r\n## 文件存储\r\n\r\n- Broker接收到消息后是如何把消息进行存储的\r\n- 最终存储的文件\r\n\t- commitLog：消息存储目录\r\n\t- config：运行期间一些配置信息\r\n\t- consumerqueue：消息消费队列存储目录\r\n\t- index：消息索引文件存储目录 \r\n\t- abort：如果存在改文件寿命Broker非正常关闭 \r\n\t- checkpoint：文件检查点，存储CommitLog文件最后一次刷盘时间戳、 consumerquueue最后一次刷盘时间，index索引文件最后一次刷盘时间戳\r\n- messageStore就是负责消息存储的核心组件\r\n- 消息存储的入口在：DefaultMessageStore.putMessage\r\n- commitLog写入\r\n\t- CommitLog的doAppend方法就是Broker写入消息的实际入口\r\n\t- 这个方法最终会把消息追加到MappedFile映射的一块内存里，并没有直接写入磁盘\r\n\t- 写入消息的过程是串行的，一次只会允许一个线程写入\r\n- 分发ConsumeQueue和IndexFile\r\n\t- 当CommitLog写入一条消息后，在DefaultMessageStore的start方法中，会启动一个后台线程reputMessageService每隔1毫秒就会去拉取CommitLog中最新更新的一批消息，然后分别转发到ComsumeQueue和IndexFile里去\r\n\t- 如果服务异常宕机，会造成CommitLog和ConsumeQueue、IndexFile文件不一致，有消息写入CommitLog后，没有分发到索引文件，这样消息就丢失了\r\n\t- DefaultMappedStore的load方法提供了恢复索引文件的方法，入口在load方法\r\n- 文件同步刷盘与异步刷盘：CommitLog.submitFlushRequest\r\n\t- 同步刷盘也是使用异步机制实现的\r\n\t\t- 刷盘是一个很重的操作，所以，RocketMQ即便是同步刷盘，也要对刷盘次数精打细算\r\n\t\t\t- 单条消息，那么直接将commitlog刷盘即可\r\n\t\t\t- 批量消息，RockeMQ会先收集这一批次消息的刷盘请求，再进行一次统一的刷盘操作\r\n\t\t\t- 一",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.整体架构",
      "lvl1": "NameServer的结构",
      "lvl2": "Broker的结构",
      "lvl3": "Netty服务注册框架",
      "lvl4": "RocketMQ的同步结果推送与异步结果推送",
      "lvl5": "Producer发送消息过程",
      "lvl6": "Consumer拉取消息过程",
      "lvl7": "文件存储",
      "lvl8": "延迟消息",
      "lvl9": "长轮询机制"
    },
    "frontmatter": {
      "title": "5.整体架构",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 3
  },
  {
    "title": "5.整体架构",
    "path": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "url": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "content": "批消息有可能会跨两个commitlog文件，所以在刷盘时，要严格计算commitlog文件的刷盘次数\r\n\t- 异步刷盘\r\n\t\t- 通过RocketMQ自己实现的一个CountDownLatch2提供了线程阻塞，使用CAS来驱动CountDownLatch2的countDown操作\r\n\t\t- 每来一个消息就启动一次CAS，成功后，调用一次countDown\r\n\t\t- 这个CountDownLatch2在CountDownLatch的基础上，增加实现了reset功能，实现了对象的重用\r\n\t- TransientStorePoolEnable。如果开启了堆外内存，会在启动时申请一个跟CommitLog文件大小一致的堆外内存，这部分内存就可以确保不会被交换到虚拟内存中\r\n- CommigLog主从复制：CommitLog.submitReplicaRequest\r\n\t- RocketMQ整体是基于Netty实现的网络请求，而在主从复制这一块，却放弃了Netty框架，转而使用更轻量级的Java的NIO来构建\r\n\t-  在主要的HAService中，会在启动过程中启动三个守护进程\r\n\t\t- 其中与Master相关的是acceptSocketService和groupTransferService\r\n\t\t\t- acceptSocketService主要负责维护Master与Slave之间的TCP连接\r\n\t\t\t- groupTransferService主要与主从同步复制有关\r\n\t\t- 而slave相关的则是haClient\r\n- 过期文件删除：DefaultMessageStore.addScheduleTask -> DefaultMessageStore.this.cleanFilesPeriodically\r\n\t- Broker会启动后台线程，每60秒，检查CommitLog、ConsumeQueue文件\r\n\t\t- 然后对超过72小时的数据进行删除\r\n\t\t- 默认情况下， RocketMQ只会保存3天内的数据\r\n\t\t- 可以通过fileReservedTime来配置\r\n\t- 他删除时，并不会检查消息是否被消费了\r\n- 整个文件存储的核心入口在DefaultMessageStore的start方法中\r\n\r\n![](static/RocketMQ-整体架构-7.png)\r\n\r\n---\r\n## 延迟消息\r\n\r\n- 延迟消息的核心使用方法就是在Message中设定一个MessageDelayLevel参数，对应18个延迟级别\r\n- 然后Broker中会创建一个默认的Schedule_Topic主题，这个主题下有18个队列，对应18个延迟级别\r\n- 消息发过来之后，会先把消息存入Schedule_Topic主题中对应的队列\r\n\t- 等延迟时间到了，再转发到目标队列，推送给消费者进行消费\r\n- 延迟消息的处理入口在scheduleMessageService， 他会在broker启动时也一起加载\r\n- 消息写入：CommitLog.putMessage\r\n\t- 在CommitLog写入消息时，会判断消息的延迟级别，然后修改Message的Topic和Queue，达到转储Message的目的\r\n- 消息转储到目标Topic：scheduleMessageService\r\n\t- 这个服务只在master节点上启动，而在slave节点上会主动关闭这个服务\r\n\t-  由于RocketMQ的主从节点支持切换，所以就需要考虑这个服务的幂等性\r\n\t\t- 在节点切换为slave时就要关闭服务，切换为master时就要启动服务\r\n\t\t- 即便节点多次切换为master，服务也只启动一次：通过一个CAS操作来保证服务的启动状态\r\n\t\t-  这个CAS操作还保证了在后面，同一时间只有一个DeliverDelayedMessageTimerTask执行\r\n\t- ScheduleMessageService会每隔1秒钟执行一个executeOnTimeup任务，将消息从延迟队列中写入正常Topic中：ScheduleMessageService -> DeliverDelayedMessageTimerTask.executeOnTimeup\r\n\r\n![](static/RocketMQ-整体架构-8.png)\r\n\r\n---\r\n## 长轮询机制\r\n\r\n- RocketMQ对消息消费者提供了Push推模式和Pull拉模式两种消费模式\r\n\t- 但是这两种消费模式的本质其实都是Pull拉模式\r\n\t- Push模式可以认为是一种定时的Pull机制\r\n- 长轮询机制简单来说，就是当Broker接收到Consumer的Pull请求时，判断如果没有对应的消息，不用直接给Consumer响应 (给响应也是个空的，没意义)，而是就将这个Pull请求给缓存起来\r\n\t- 当Producer发送消息过来时，增加一个步骤去检查是否有对应的已缓存的Pull请求，如果有，就及时将请求从缓存中拉取出来，并将消息通知给Consumer\r\n\r\n![](static/RocketMQ-整体架构-9.png)\r\n\r\n---\r\n\r\n![](static/RocketMQ-整体架构-10.png)\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.整体架构",
      "lvl1": "NameServer的结构",
      "lvl2": "Broker的结构",
      "lvl3": "Netty服务注册框架",
      "lvl4": "RocketMQ的同步结果推送与异步结果推送",
      "lvl5": "Producer发送消息过程",
      "lvl6": "Consumer拉取消息过程",
      "lvl7": "文件存储",
      "lvl8": "延迟消息",
      "lvl9": "长轮询机制"
    },
    "frontmatter": {
      "title": "5.整体架构",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 3
  },
  {
    "title": "6.常见问题",
    "path": "/docs/architect/rocketmq/RocketMQ-6.changjianwenti.html",
    "url": "/docs/architect/rocketmq/RocketMQ-6.changjianwenti.html",
    "content": "---\r\ntitle: 6.常见问题\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 消息零丢失\r\n- 消息顺序\r\n- 消息积压\r\n- 消息轨迹\r\n:::\r\n\r\n---\r\n## 消息零丢失\r\n\r\n- 哪些环节会有丢消息的可能\r\n\t- ![](static/RocketMQ-常见问题-1.png)\r\n\t- 1，2，4 三个场景都是跨网络的，而跨网络就肯定会有丢消息的可能\r\n\t- 通常MQ存盘时都会先写入操作系统的缓存page cache中，然后再由操作系统异步的将消息写入硬盘\r\n\t\t- 这个中间有个时间差，就可能会造成消息丢失\r\n\t\t- 如果服务挂了，缓存中还没有来得及写入硬盘的消息就会丢失\r\n- 生产者使用事务消息机制保证消息零丢失\r\n\t- ![事务消息](static/RocketMQ-常见问题-2.png)\r\n\t- half 消息\r\n\t\t- 这个half消息是在订单系统进行下单操作前发送，并且对下游服务的消费者是不可见的\r\n\t\t- 这个消息的作用更多的体现在确认RocketMQ的服务是否正常\r\n\t\t- half 消息如果写入失败了，可以在下单时给订单一个状态标记，然后等待MQ服务正常后再进行补偿操作，等MQ服务正常后重新下单通知下游服务\r\n\t- 订单系统写数据库失败\r\n\t\t- 可以另外找个地方把订单消息先缓存起来\r\n\t\t- 然后给RocketMQ返回一个UNKNOWN状态\r\n\t\t\t- 这样RocketMQ就会过一段时间来回查事务状态\r\n\t\t- 可以在回查事务状态时再尝试把订单数据写入数据库，如果数据库这时候已经恢复了，那就能完整正常的下单，再继续后面的业务\r\n\t- half消息写入成功后RocketMQ挂了\r\n\t\t- 未知状态的事务状态回查是由RocketMQ的Broker主动发起的\r\n\t\t- 等RocketMQ恢复后，只要存储的消息没有丢失，RocketMQ就会再次继续状态回查的流程\r\n\t- 下单成功后如何优雅的等待支付成功\r\n\t\t- 可以用事务消息的状态回查机制来替代定时的任务\r\n\t\t- 在下单时，给Broker返回一个UNKNOWN的未知状态\r\n\t\t- 在状态回查的方法中去查询订单的支付状态\r\n\t\t- 我们只需要配置RocketMQ中的事务消息回查次数(默认15次)和事务回查间隔时间(messageDelayLevel)\r\n\t- 事务消息机制的作用\r\n\t\t- 保证的是订单系统下单和发消息这两个事件的事务一致性\r\n\t\t- 而对下游服务的事务并没有保证\r\n- RocketMQ配置同步刷盘+Dledger主从架构保证MQ主从同步时不会丢消息\r\n\t- 同步刷盘\r\n\t- Dledger的文件同步：基于Raft协议\r\n\t\t- ![Dledger的文件同步](static/RocketMQ-常见问题-3.png)\r\n\t\t- Dledger会通过两阶段提交的方式保证文件在主从之间成功同步\r\n\t\t\t- uncommitted阶段\r\n\t\t\t\t- Leader Broker上的Dledger收到一条数据后，会标记为uncommitted状态\r\n\t\t\t\t- 然后他通过自己的DledgerServer组件把这个uncommitted数据发给Follower Broker的DledgerServer组件\r\n\t\t\t\t- 接着Follower Broker的DledgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的Dledger\r\n\t\t\t- commited阶段\r\n\t\t\t\t- 如果Leader Broker收到超过半数的Follower Broker返回的ack之后，就会把消息标记为committed状态\r\n\t\t\t\t- 再接下来， Leader Broker上的DledgerServer就会发送committed消息给Follower Broker上的DledgerServer\r\n\t\t\t\t- 让他们把消息也标记为committed状态\r\n- 消费者端不要使用异步消费机制\r\n\t- 正常情况下，消费者端都是需要先处理本地事务，然后再给MQ一个ACK响应，这时MQ就会修改Offset，将消息标记为已消费，从而不再往其他消费者推送消息\r\n\t- 所以在Broker的这种重新推送机制下，消息是不会在传输过程中丢失的\r\n\t- 但是如果在开启异步消费线程后，直接返回 `ConsumeConcurrentlyStatus.CONSUME_SUCCESS`\r\n\t\t- 那么一旦消费失败，这个消息就丢失了\r\n- RocketMQ特有的问题，NameServer挂了如何保证消息不丢失\r\n\t- NameServer在RocketMQ中，是扮演的一个路由中心的角色，提供到Broker的路由功能\r\n\t- 集群中任意多的节点挂掉，都不会影响他提供的路由功能\r\n\t- 如果集群中所有的NameServer节点都挂了，生产者和消费者立即就无法工作了\r\n\t\t- RocketMQ相当于整个服务都不可用了，那他本身肯定无法给我们保证消息不丢失了\r\n\t- 降级方案\r\n\t\t- 可以暂存到其他地方，然后起一个线程定时的扫描这些失败的订单消息，尝试往RocketMQ发送\r\n- 这整套的消息零丢失方案，在各个环节都大量的降低了系统的处理性能以及吞吐量\r\n\t- 要根据实际的业务情况来考虑\r\n\t- 在有些对消息可靠性要求没有那么高的场景\r\n\t\t- 在生产者端就可以采用其他一些更简单的方案来提升吞吐\r\n\t\t- 而采用定时对账、补偿的机制来提高消息的可靠性\r\n\r\n---\r\n## 消息顺序\r\n\r\n- 全局有序：整个MQ系统的所有消息严格按照队列先入先出顺序进行消费\r\n\t- 通常意义下，全局有序都可以压缩成局部有序的问题\r\n- 局部有序：只保证一部分关键消息的消费顺序\r\n\t- 在大部分的MQ业务场景，我们只需要能够保证局部有序就可以了\r\n- 通常情况下，发送者发送消息时，会通过MessageQueue轮询的方式保证消息尽量均匀的分布到所有的MessageQueue上，而消费者也就同样需要从多个MessageQueue上消费消息\r\n\t- MessageQueue是RocketMQ存储消息的最小单元，他们之间的消息都是互相隔离的，在这种情况下，是无法保证消息全局有序的\r\n\t\t- 通常所谓的保证Topic全局消息有序的方式，就是将Topic配置成只有一个MessageQueue队列(默认是4个)\r\n\t\t- 对整个Topic的消息吞吐影响是非常大的，如果这样用，基本上就没有用MQ的必要了\r\n\t-  而对于局部有序的要求，只需要将有序的一组消息都存入同一个MessageQueue里，这样MessageQueue的FIFO设计天生就可以保证这一组消息的有序\r\n\t\t- RocketMQ中，可以在发送者发送消息时指定一个MessageSelector对象，让这个对象来决定消息发入哪一个MessageQueue。这样就可以保证一组有序的消息能够发到同一个MessageQueue里\r\n\r\n---\r\n## 消息积压\r\n\r\n- 如何确定RocketMQ有大量的消息积压\r\n\t- 在正常情况下，使用MQ都会要尽量保证他的消息生产速度和消费速度整体上是平衡的\r\n\t- 但是如果部分消费者系统出现故障，就会造成大量的消息积累\r\n\t- 使用web控制台，就能直接看到消息的积压情况\r\n\t- 也可以通过mqadmin指令在后台检查各个Topic的消息延迟情况\r\n\t- RocketMQ也会在他的 ${storePathRootDir}/config目录下落地一系列的json文件，也可以用来跟踪消息积压情况\r\n- 如何处理大量积压的消息\r\n\t- 如果Topic下的MessageQueue配置得是足够多的，那每个Consumer实际上会分配多个MessageQueue来进行消费\r\n\t\t- 可以简单的通过增加Consumer的服务节点数量来加快消息的消费，等积压消息消费完了，再恢复成正常情况\r\n\t\t- 最极限的情况是把Consumer的节点个数设置成跟MessageQueue的个数相同\r\n\t\t\t- 再继续增加Consumer的服务节点就没有用了\r\n\t- 如果Topic下的MessageQueue配置得不够多的话：可以创建一个新的Topic，配置足够多的MessageQueue\r\n\t\t- 然后把所有消费者节点的目标Topic转向新的Topic，并紧急上线一组新的消费者，只负责消费旧Topic中的消息，并转储到新的Topic中，这个速度是可以很快的\r\n\t\t- 然后在新的Topic上，就可以通过增加消费者个数来提高消费速度了。之后再根据情况恢复成正常情况\r\n- 如果RocketMQ原本是采用的普通方式搭建主从架构，而现在想要中途改为使用Dledger高可用集群\r\n\t- 这时候如果不想历史消息丢失，就需要先将消息进行对齐，也就是要消费者把所有的消息都消费完，再来切换主从架构\r\n\t- 因为Dledger集群会接管RocketMQ原有的CommitLog日志，所以切换主从架构时，如果有消息没有消费完，这些消息是存在旧的CommitLog中的，就无法再进行消费了\r\n\t\t- 这个场景下也是需要尽快的处理掉积压的消息\r\n\r\n---\r\n## 消息轨迹\r\n\r\n- `broker.conf -> traceTopicEnable=true`\r\n- 消息轨迹数据存储 \r\n\t- 默认情况下，消息轨迹数据是存于一个系统级别的 Topic (RMQ_SYS_TRACE_TOPIC)\r\n\t\t- 这个Topic在Broker节点启动时，会自动创建出来\r\n\t\t- 也支持客户端自定义轨迹数据存储的 Topic\r\n- 在客户端的两个核心对象 DefaultMQProducer 和 DefaultMQPushConsumer 的构造函数中，都有两个可选的参数来打开消息轨迹存储\r\n\t- enableMsgTrace：是否打开消息轨迹。默认是false\r\n\t- customizedTraceTopic：配置将消息轨迹数据存储到用户指定的Topic\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "6.常见问题",
      "lvl1": "消息零丢失",
      "lvl2": "消息顺序",
      "lvl3": "消息积压",
      "lvl4": "消息轨迹"
    },
    "frontmatter": {
      "title": "6.常见问题",
      "date": "2025/07/03"
    },
    "type": "content"
  },
  {
    "title": "2025-03",
    "path": "/docs/diary/2025/2025-03.html",
    "url": "/docs/diary/2025/2025-03.html",
    "content": "---\r\ntitle: 2025-03\r\npassword: b593bf97f44387eb6fdc629acef2d138\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## 2025-03-08\r\n\r\n- 优化博客站点\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2025-03",
      "lvl1": "2025-03-08"
    },
    "frontmatter": {
      "title": "2025-03",
      "password": "b593bf97f44387eb6fdc629acef2d138",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "边缘填充算法",
    "path": "/docs/it/jisuanjituxingxue/bianyuantianchongsuanfa.html",
    "url": "/docs/it/jisuanjituxingxue/bianyuantianchongsuanfa.html",
    "content": "---\r\ntitle: 边缘填充算法\r\ndate: 2025/03/08\r\n---\r\n\r\n## 填充原理\r\n边缘填充算法是先求出多边形的每条边与扫描线的交点，然后**将交点右侧的所有像素颜色全部取为补色（或反色**）。按任意顺序处理完多边形的所有边后，就完成了多边形的填充任务。边缘填充算法利用了图像处理中的求“补”或求“反”的概念，对于黑白图像，求补就是把RGB(1,1,1)（白色）的像素置为RGB(0,0,0)（黑色），反之亦然；对于彩色图像，求补就是将背景色置为填充色，反之亦然。求补的一条基本性质是**一个像素求补两次就恢复为原色**。**如果多边形内部的像素被求补偶数次，保持原色，如果被求补奇数次，显示填充色。**\r\n\r\n## 填充过程\r\n假定边的顺序为E0、E1、E2、E3、E4、E5和E6。这里，边的顺序并不影响填充结果，只是方便编写循环结构而已。\r\n\r\n\r\n![边缘填充算法](static/边缘填充算法.png)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "边缘填充算法",
      "lvl1": "填充原理",
      "lvl2": "填充过程"
    },
    "frontmatter": {
      "title": "边缘填充算法",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "实盘日记 - 2025 年",
    "path": "/docs/trading_journal/diary/2025.html",
    "url": "/docs/trading_journal/diary/2025.html",
    "content": "---\r\ntitle: 实盘日记 - 2025 年\r\ndate: 2025/03/19\r\n---\r\n\r\n## 2025/3/19 TQQQ CALL\r\n\r\n:::info\r\n- 策略类型：看涨期权（短期反弹博弈）\r\n- 期权类型：买入TQQQ Call期权\r\n- 行权价：61-62美元附近\r\n- 到期日：2-4周\r\n- 仓位：500美元以内\r\n- 止盈目标：EMA20（68美元附近）\r\n- 止损位：57美元以下\r\n\r\n|情境|股价目标|期权预估价值|盈亏金额|盈亏百分比|\r\n|-|-|-|-|-|\r\n|止盈|68美元|约6.2美元|盈利740美元|+148%|\t\t\t\t\r\n|止损|57美元|约0.8美元|亏损340美元|-68%|\r\n\r\n盈亏比大于2，属于较好的盈亏比\r\n:::\r\n\r\n预计收益计算（止盈情境）：假设未来1-2周内TQQQ上涨到EMA20附近（约68美元）\r\n- 行权价：62美元\r\n- 股价上涨到：68美元\r\n- 期权的内在价值 = 股票价格 – 行权价格 = 68 – 62 = 6美元\r\n- 期权买入成本：2.5美元/张\r\n- 期权到期时预估的价值：6美元（内在价值）+ 0.2美元左右的时间价值估计（由于临近到期，时间价值不多）= 约6.2美元\r\n- 每张期权盈利 = 6.2美元 - 2.5美元 = 3.7美元\r\n- 2张期权总盈利 = 3.7美元 × 2张 × 100股 = 740美元\r\n\r\n止盈情境下的收益率：\r\n- 总盈利 = 740美元\r\n- 总成本 = 500美元\r\n- 净利润 = 740美元\r\n- 盈利比例 = (740 ÷ 500) × 100% = 148%\r\n\r\n预计亏损计算（止损情境）：假设未来几天内TQQQ下跌到57美元以下\r\n- 行权价：62美元（看涨期权）\r\n- 跌破支撑位到57美元甚至更低，此时期权变为深度价外，价值快速缩水。\r\n- 假设跌破57美元时，看涨期权的价值大幅缩水到0.8美元左右（甚至更低），此时及时止损：\r\n- 每张期权亏损 = 买入成本 - 期权剩余价值 = 2.5美元 - 0.8美元 = 1.7美元\r\n- 2张期权总亏损 = 1.7美元 × 2张 × 100股 = 340美元\r\n\r\n止损情境下的亏损率：\r\n- 总亏损 = 340美元\r\n- 总成本 = 500美元\r\n- 亏损比例 = (340 ÷ 500) × 100% = 68%\r\n\r\n盈亏比评估：盈亏比大于2，属于较好的盈亏比\r\n- 盈利情境预期盈利 = 740美元\r\n- 亏损情境预期亏损 = 340美元\r\n- 盈亏比 = 740 ÷ 340 ≈ 2.18\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "实盘日记 - 2025 年",
      "lvl1": "2025/3/19 TQQQ CALL"
    },
    "frontmatter": {
      "title": "实盘日记 - 2025 年",
      "date": "2025/03/19"
    },
    "type": "content"
  },
  {
    "title": "期权交易策略",
    "path": "/docs/trader/options/qiquanjiaoyicelue.html",
    "url": "/docs/trader/options/qiquanjiaoyicelue.html",
    "content": "---\r\ntitle: 期权交易策略\r\ndate: 2025/03/06\r\n---\r\n\r\n## 单向策略\r\n\r\n::: tip\r\n|评估|Long Call|Long Put|Short Call|Short Put|\r\n|-|-|-|-|-|\r\n|预期|上涨|下跌|微涨/不变|微跌/不变/有买入意愿|\r\n|场景|看涨|看跌|赚权利金|赚权利金/低价买入|\r\n|权利|按行权价买入|按行权价卖出|-|-|\r\n|义务|-|-|按行权价卖出|按行权价买入|\r\n|成本|权利金|权利金|保证金|保证金|\r\n|收益|涨幅 - 权利金|跌幅 - 权利金|权利金 - (市价 - 行权价)|权利金 - (行权价 - 市价)|\r\n|亏损|损失权利金|损失权利金|越涨越亏|越跌越亏 （最低为0）|\r\n|风险|风险低；收益无限|风险低；收益高|风险无限；收益低|风险高；收益低|\r\n\r\n::: danger\r\n1. 卖方的最大成本取决于市场的波动性，虽然表格中用“保证金”表示，但实际计算中，卖方承担的亏损可能远超保证金。\r\n:::\r\n\r\n\r\n- 买入看涨期权：Long Call\r\n  - 预期：标的资产价格将上涨\r\n  - 权利：买方有权利在期权到期时按行权价买入标的资产，但没有义务。\r\n  - 成本：买方需要支付权利金。\r\n  - 收益：潜在收益是无限的（标的资产价格上涨越多，收益越大）。\r\n  - 风险：风险有限，最大损失是支付的权利金。\r\n- 买入看跌期权：Long Put\r\n  - 预期：标的资产价格将下跌\r\n  - 权利：买方有权利在期权到期时按行权价卖出标的资产，但没有义务。\r\n  - 成本：买方需要支付权利金。\r\n  - 收益：潜在收益有限，但标的资产价格跌得越多，收益越大（最低价格为0）。\r\n  - 风险：风险有限，最大损失是支付的权利金。\r\n- 卖出看涨期权：Short Call\r\n  - 预期：标的资产价格不会上涨太多或保持不变\r\n  - 义务：卖方有义务按行权价卖出标的资产给买方（如果买方行权）。\r\n  - 收益：收益有限，最大收益是收到的权利金。\r\n  - 风险：风险无限（标的资产价格上涨越多，卖方亏损越大）。\r\n- 卖出看跌期权：Short Put\r\n  - 预期：标的资产价格不会大幅下跌或保持不变\r\n  - 义务：卖方有义务按行权价买入标的资产（如果买方行权）。\r\n  - 收益：收益有限，最大收益是收到的权利金。\r\n  - 风险：风险很高（标的资产价格下跌越多，卖方亏损越大，但跌幅有限，最低为0）。\r\n\r\n\r\n## 价差策略\r\n\r\n::: tip\r\n|评估|Bull Spread|Bear Spread|\r\n|-|-|-|\r\n|预期|温和上涨|温和下跌|\r\n|场景|在看涨市场中降低成本|在看跌市场中降低成本|\r\n|收益|行权价差 - 净权利金|行权价差 - 净权利金|\r\n|成本|净权利金|净权利金|\r\n|亏损|净权利金|净权利金|\r\n|风险|风险低；收益低|风险低；收益低|\r\n|构成|买入较低行权价的看涨期权 <br/> 卖出较高行权价的看涨期权|买入较高行权价的看跌期权 <br/> 卖出较低行权价的看跌期权|\r\n\r\n::: info\r\n1. 如果标的价格超出价格区间以外，那么期权的权利与义务会互相抵消，所以限制了最大收益，同时也限制了最大亏损\r\n2. Bull Spread 和 Bear Spread 都是低风险、低收益的策略，适合温和的市场走势，而非剧烈波动\r\n:::\r\n\r\n- 牛市价差：Bull Spread\r\n  - 预期：适用于看涨市场，收益和风险都有限\r\n  - 构成：\r\n    - 买入较低行权价的看涨期权（成本较高）\r\n    - 卖出较高行权价的看涨期权（获得权利金）\r\n  - 收益风险：\r\n    - 最大收益：两行权价差 - 净支出\r\n    - 最大亏损：净支出（买入权利金 - 卖出权利金）\r\n- 熊市价差：Bear Spread\r\n  - 预期：适用于看跌市场，收益和风险都有限\r\n  - 构成：\r\n    - 买入较高行权价的看跌期权（成本较高）\r\n    - 卖出较低行权价的看跌期权（获得权利金）\r\n  - 收益风险：\r\n    - 最大收益：两行权价差 - 净支出\r\n    - 最大亏损：净支出（买入权利金 - 卖出权利金）\r\n\r\n\r\n### 跨式策略\r\n\r\n::: tip\r\n|评估|Long Straddle|Long Strangle|Short Straddle|Short Strangle|\r\n|-|-|-|-|-|\r\n|预期|大幅波动|大幅波动|||\r\n|场景|重大事件前|重大事件前|||\r\n|收益|波幅 - 净权利金|波幅 - 净权利金|||\r\n|成本|净权利金|净权利金|||\r\n|亏损|净权利金|净权利金|||\r\n|风险|风险低；收益高|风险低；收益高；成本低|||\r\n|构成|买入相同行权价的看涨期权 <br/> 买入相同行权价的看跌期权|买入较高行权价的看涨期权 <br/> 买入较低行权价的看跌期权|||\r\n:::\r\n\r\n\r\n\r\n\r\n### 复杂价差策略\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "期权交易策略",
      "lvl1": "单向策略",
      "lvl2": "价差策略"
    },
    "frontmatter": {
      "title": "期权交易策略",
      "date": "2025/03/06"
    },
    "type": "content"
  },
  {
    "title": "期权交易策略收益图表",
    "path": "/docs/trader/options/qiquanjiaoyicelueshouyitubiao.html",
    "url": "/docs/trader/options/qiquanjiaoyicelueshouyitubiao.html",
    "content": "---\r\ntitle: 期权交易策略收益图表\r\ndate: 2025/03/08\r\n---\r\n\r\n<iframe src=\"/html/OptionsStrategy.html\" style=\"width:100%; height: 1000px\"></iframe>\r\n\r\n<a href=\"/html/OptionsStrategy.html\" target=\"_blank\">全屏展示</a>\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "期权交易策略收益图表"
    },
    "frontmatter": {
      "title": "期权交易策略收益图表",
      "date": "2025/03/08"
    },
    "type": "content"
  }
]