[
  {
    "title": "Java 根据 Getter 方法获取字段及注解值",
    "path": "/blogs/bianmabiji/JavagenjuGetterfangfahuoquziduanjizhujiezhi.html",
    "url": "/blogs/bianmabiji/JavagenjuGetterfangfahuoquziduanjizhujiezhi.html",
    "content": "---\r\ntitle: Java 根据 Getter 方法获取字段及注解值\r\ndate: 2025/04/12\r\ntags:\r\n - Java\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```java\r\n@FunctionalInterface\r\npublic interface SIFunction<T, R> extends Function<T, R>, Serializable {}\r\n```\r\n\r\n```java\r\npublic class FieldUtil {\r\n\r\n    public static <T, R> String getFieldNameByGetter(SIFunction<T, R> func) {\r\n        try {\r\n            SerializedLambda serializedLambda = getSerializedLambda(func);\r\n            String getterMethodName = serializedLambda.getImplMethodName();\r\n            return methodToFieldName(getterMethodName);\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(\"获取字段名失败\", e);\r\n        }\r\n    }\r\n\r\n    private static SerializedLambda getSerializedLambda(Serializable lambda) throws Exception {\r\n        // 通过反射调用writeReplace方法获取SerializedLambda\r\n        Method writeReplace = lambda.getClass().getDeclaredMethod(\"writeReplace\");\r\n        writeReplace.setAccessible(true);\r\n        return (SerializedLambda) writeReplace.invoke(lambda);\r\n    }\r\n\r\n    private static String methodToFieldName(String getterMethodName) {\r\n        String fieldName;\r\n        if (getterMethodName.startsWith(\"get\")) {\r\n            fieldName = getterMethodName.substring(3);\r\n        } else if (getterMethodName.startsWith(\"is\")) {\r\n            fieldName = getterMethodName.substring(2);\r\n        } else {\r\n            throw new IllegalArgumentException(\"无效的getter方法名称: \" + getterMethodName);\r\n        }\r\n        // 将首字母转小写\r\n        return fieldName.substring(0, 1).toLowerCase(Locale.ROOT) + fieldName.substring(1);\r\n    }\r\n\r\n    public static <T, R> Field getFieldByGetter(SIFunction<T, R> getter, Class<T> clazz) {\r\n        try {\r\n            return clazz.getDeclaredField(getFieldNameByGetter(getter));\r\n        } catch (NoSuchFieldException e) {\r\n            throw new RuntimeException(\"字段不存在\", e);\r\n        }\r\n    }\r\n\r\n    public static <T, R, A extends Annotation> String getAnnotationValueByGetter(SIFunction<T, R> getter, Class<T> clazz, Class<A> annotationClass) {\r\n        try {\r\n            // 获取字段名\r\n            String fieldName = getFieldNameByGetter(getter);\r\n\r\n            // 获取字段对象\r\n            Field field = clazz.getDeclaredField(fieldName);\r\n\r\n            // 获取字段上的注解\r\n            A annotation = field.getAnnotation(annotationClass);\r\n\r\n            // 如果注解存在，返回其 value 属性值\r\n            if (annotation != null) {\r\n                // 使用反射获取注解的 value 属性值\r\n                Method valueMethod = annotationClass.getMethod(\"value\");\r\n                return (String) valueMethod.invoke(annotation);\r\n            } else {\r\n                throw new RuntimeException(\"字段没有指定的注解: \" + fieldName);\r\n            }\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(\"获取注解值失败\", e);\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Java 根据 Getter 方法获取字段及注解值"
    },
    "frontmatter": {
      "title": "Java 根据 Getter 方法获取字段及注解值",
      "date": "2025/04/12",
      "tags": [
        "Java"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Java 获取接口泛型类型",
    "path": "/blogs/bianmabiji/Javahuoqujiekoufanxingleixing.html",
    "url": "/blogs/bianmabiji/Javahuoqujiekoufanxingleixing.html",
    "content": "---\r\ntitle: Java 获取接口泛型类型\r\ndate: 2025/04/12\r\ntags:\r\n - Java\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```java\r\n    @SuppressWarnings(\"unchecked\")\r\n    public Class<S> getTypeClass() {\r\n        Class<?> clazz = this.getClass();\r\n        Type result = InterfaceUtils.findParameterizedType(clazz, ProjectTypeServiceGetter.class);\r\n        if (result != null) {\r\n            ParameterizedType pt = (ParameterizedType) result;\r\n            // 获取第一个泛型参数，它对应 S\r\n            Type sType = pt.getActualTypeArguments()[0];\r\n            if (sType instanceof Class) {\r\n                return (Class<S>) sType;\r\n            } else if (sType instanceof ParameterizedType) {\r\n                // 处理嵌套泛型情况\r\n                return (Class<S>) ((ParameterizedType) sType).getRawType();\r\n            }\r\n        }\r\n        throw new IllegalStateException(\"无法获取泛型类型 S 的 Class 对象\");\r\n    }\r\n```\r\n\r\n\r\n```java\r\npublic class InterfaceUtils {\r\n\r\n    /**\r\n     * 获取指定类实现的所有接口，包括父类实现的接口以及接口之间的继承关系。\r\n     *\r\n     * @param clazz 要查找接口的类\r\n     * @return 包含所有接口的集合\r\n     */\r\n    public static Set<Class<?>> getAllInterfaces(Class<?> clazz) {\r\n        Set<Class<?>> interfaces = new HashSet<>();\r\n        // 遍历类的继承层次结构\r\n        while (clazz != null) {\r\n            // 获取当前类直接实现的接口\r\n            Class<?>[] directInterfaces = clazz.getInterfaces();\r\n            for (Class<?> intf : directInterfaces) {\r\n                collectInterfaces(intf, interfaces);\r\n            }\r\n            clazz = clazz.getSuperclass();\r\n        }\r\n        return interfaces;\r\n    }\r\n\r\n    /**\r\n     * 递归地将接口及其扩展的接口加入到集合中。\r\n     *\r\n     * @param intf       当前的接口\r\n     * @param interfaces 用来保存所有接口的集合\r\n     */\r\n    private static void collectInterfaces(Class<?> intf, Set<Class<?>> interfaces) {\r\n        if (interfaces.add(intf)) {\r\n            // 获取接口可能扩展的其他接口\r\n            for (Class<?> superInterface : intf.getInterfaces()) {\r\n                collectInterfaces(superInterface, interfaces);\r\n            }\r\n        }\r\n    }\r\n\r\n    public static Type findParameterizedType(Type clazz, Class<?> targetType) {\r\n        if (clazz instanceof ParameterizedType) {\r\n            ParameterizedType pt = (ParameterizedType) clazz;\r\n            // 如果直接匹配目标接口\r\n            if (targetType.equals(pt.getRawType())) {\r\n                return pt;\r\n            }\r\n            // 检查该参数化类型的原始类型的接口\r\n            return findParameterizedType(pt.getRawType(), targetType);\r\n        } else if (clazz instanceof Class) {\r\n            Class<?> currentClass = (Class<?>) clazz;\r\n\r\n            // 检查当前类所有直接实现的接口\r\n            for (Type intf : currentClass.getGenericInterfaces()) {\r\n                Type result = findParameterizedType(intf, targetType);\r\n                if (result != null) {\r\n                    return result;\r\n                }\r\n            }\r\n            // 检查父类\r\n            Type superClass = currentClass.getGenericSuperclass();\r\n            if (superClass != null) {\r\n                return findParameterizedType(superClass, targetType);\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Java 获取接口泛型类型"
    },
    "frontmatter": {
      "title": "Java 获取接口泛型类型",
      "date": "2025/04/12",
      "tags": [
        "Java"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "MAVEN 上传到中心仓库",
    "path": "/blogs/bianmabiji/MAVENshangchuandaozhongxincangku.html",
    "url": "/blogs/bianmabiji/MAVENshangchuandaozhongxincangku.html",
    "content": "---\r\ntitle: MAVEN 上传到中心仓库\r\ndate: 2025/03/05\r\ntags:\r\n - MAVEN\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n1. 注册中心仓库账户：[central.sonatype.com](https://central.sonatype.com)\r\n2. 使用 GPG 生成密钥并上传到公钥服务器\r\n3. 配置 Maven 的 Setting.xml 文件\r\n4. pom.xml 文件模板\r\n5. 发布到中心仓库\r\n:::\r\n\r\n## 注册中心仓库账户 \r\n\r\n1. 注册中心仓库的账户：[central.sonatype.com](https://central.sonatype.com)\r\n2. 使用 Github 登录，可以自动获得命名空间 -> 有效的 groupId\r\n3. Generate User Token  ->  自动生成 maven setting.xml 的 server 配置项（修改 id 为 central）\r\n\r\n## GPG\r\n\r\n```powershell\r\n# 安装GPG\r\nwinget install GnuPG.Gpg4win\r\n\r\n# 生成密钥\r\ngpg --full-generate-key\r\n\r\n# 上传公钥到GPG公钥服务器\r\ngpg --keyserver pgp.mit.edu --send-keys <KEY_ID>\r\ngpg --keyserver keyserver.ubuntu.com --send-keys <KEY_ID>\r\n\r\n# 导出公钥\r\ngpg --armor --export <KEY_ID> > public_key_1.asc\r\n# 导出私钥\r\ngpg --armor --export-secret-keys <KEY_ID> > private_key_2.asc\r\n```\r\n\r\n## Maven Setting.xml\r\n\r\n```xml\r\n\t<servers>\r\n\t\t<server>\r\n\t\t\t<id>central</id>\r\n\t\t\t<username>${username}</username>\r\n\t\t\t<password>${token}</password>\r\n\t\t</server>\r\n    </servers>\r\n\r\n\t<profiles>\r\n\t\t<profile>\r\n\t\t\t<id>gpg-profile</id>\r\n\t\t\t<properties>\r\n\t\t\t\t<gpg.keyname> ${KEY_ID} </gpg.keyname>\r\n\t\t\t\t<gpg.passphrase><![CDATA[password]]></gpg.passphrase>\r\n\t\t\t</properties>\r\n\t\t</profile>\r\n\t</profiles>\r\n\t<activeProfiles>\r\n\t\t<activeProfile>gpg-profile</activeProfile>\r\n\t</activeProfiles>\r\n```\r\n\r\n## pom.xml\r\n\r\n```xml\r\n    <groupId>io.github.jxch</groupId>\r\n    <artifactId>capital-py4j-spring-boot-starter</artifactId>\r\n    <version>3.2.5-alpha.1</version>\r\n    <name>capital-py4j-spring-boot-starter</name>\r\n    <description>py4j本地执行引擎与springboot的无缝集成</description>\r\n    <url>https://github.com/jxch-capital/capital-py4j-spring-boot-starter</url>\r\n\r\n    <properties>\r\n        <maven.compiler.source>21</maven.compiler.source>\r\n        <maven.compiler.target>21</maven.compiler.target>\r\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\r\n        <lombok.version>1.18.32</lombok.version>\r\n        <hutool.version>5.8.27</hutool.version>\r\n        <maven-source-plugin.version>3.3.1</maven-source-plugin.version>\r\n        <maven-javadoc-plugin.version>3.6.3</maven-javadoc-plugin.version>\r\n        <maven-gpg-plugin.version>3.2.4</maven-gpg-plugin.version>\r\n        <maven-release-plugin.version>3.0.1</maven-release-plugin.version>\r\n        <central-publishing-maven-plugin.version>0.4.0</central-publishing-maven-plugin.version>\r\n    </properties>\r\n\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-source-plugin</artifactId>\r\n                <version>${maven-source-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>attach-sources</id>\r\n                        <goals>\r\n                            <goal>jar-no-fork</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-javadoc-plugin</artifactId>\r\n                <version>${maven-javadoc-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>attach-javadocs</id>\r\n                        <goals>\r\n                            <goal>jar</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.sonatype.central</groupId>\r\n                <artifactId>central-publishing-maven-plugin</artifactId>\r\n                <version>${central-publishing-maven-plugin.version}</version>\r\n                <extensions>true</extensions>\r\n                <configuration>\r\n                    <publishingServerId>central</publishingServerId>\r\n                    <tokenAuth>true</tokenAuth>\r\n                    <autoPublish>true</autoPublish>\r\n                    <waitUntil>published</waitUntil>\r\n                </configuration>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-release-plugin</artifactId>\r\n                <version>${maven-release-plugin.version}</version>\r\n                <configuration>\r\n                    <goals>deploy nexus-staging:release</goals>\r\n                    <autoVersionSubmodules>true</autoVersionSubmodules>\r\n                    <useReleaseProfile>false</useReleaseProfile>\r\n                    <releaseProfiles>release</releaseProfiles>\r\n                </configuration>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-gpg-plugin</artifactId>\r\n                <version>${maven-gpg-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>sign-artifacts</id>\r\n                        <phase>verify</phase>\r\n                        <goals>\r\n                            <goal>sign</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n\r\n    <licenses>\r\n        <license>\r\n            <name>The Apache Software License, Version 2.0</name>\r\n            <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>\r\n            <distribution>repo</distribution>\r\n        </license>\r\n    </licenses>\r\n\r\n    <scm>\r\n        <connection>scm:git:git://github.com/jxch-capital/capital-py4j-spring-boot-starter.git</connection>\r\n        <developerConnection>scm:git:ssh://github.com:jxch-capital/capital-py4j-spring-boot-starter.git</developerConnection>\r\n        <url>${developer_github_project_url}</url>\r\n    </scm>\r\n\r\n    <developers>\r\n        <developer>\r\n            <id>${developer_id}</id>\r\n            <name>${developer_name}</name>\r\n            <email>${developer_email}</email>\r\n            <url>${developer_github_url}</url>\r\n        </developer>\r\n    </developers>\r\n\r\n    <distributionManagement>\r\n        <snapshotRepository>\r\n            <id>central</id>\r\n            <url>https://s01.oss.sonatype.org/content/repositories/snapshots</url>\r\n        </snapshotRepository>\r\n        <repository>\r\n            <id>central</id>\r\n            <url>https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/</url>\r\n        </repository>\r\n    </distributionManagement>\r\n```\r\n\r\n## 发布\r\n\r\n```shell\r\nmvn deploy -f pom.xml\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MAVEN 上传到中心仓库",
      "lvl1": "注册中心仓库账户",
      "lvl2": "GPG",
      "lvl3": "Maven Setting.xml",
      "lvl4": "pom.xml",
      "lvl5": "发布"
    },
    "frontmatter": {
      "title": "MAVEN 上传到中心仓库",
      "date": "2025/03/05",
      "tags": [
        "MAVEN"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 实现 Chrome 环境隔离的多开方案",
    "path": "/blogs/bianmabiji/PowerShellshixianChromehuanjinggelideduokaifangan.html",
    "url": "/blogs/bianmabiji/PowerShellshixianChromehuanjinggelideduokaifangan.html",
    "content": "---\r\ntitle: PowerShell 实现 Chrome 环境隔离的多开方案\r\ndate: 2025/07/01\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n- 下载地址：[https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/chromej.ps1](https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/chromej.ps1)\r\n:::\r\n\r\n使用示例：\r\n```powershell\r\n    chromej.ps1 1 2 --disable-web-security --incognito\r\n        # 启动/多开 1、2 两个 profile，并传递原生参数\r\n\r\n    chromej.ps1 dev -a -u \"https://example.com\" --disable-gpu\r\n        # 激活已开的 dev profile，或未开则以指定网址和参数新开\r\n\r\n    chromej.ps1 1 -Delete -y\r\n        # 强制删除 1 号 profile 目录，无需确认\r\n\r\n    chromej.ps1 --disable-software-rasterizer -sc\r\n        # 启动 Chrome 并显示完整命令行\r\n\r\n    chromej.ps1 -s\r\n        # 静默启动 Chrome 本体\r\n\r\n    chromej.ps1 1 2 3 -Activate -ShowCmd -Silent\r\n        # 激活/多开 1、2、3，命令行输出，静默执行\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 实现 Chrome 环境隔离的多开方案"
    },
    "frontmatter": {
      "title": "PowerShell 实现 Chrome 环境隔离的多开方案",
      "date": "2025/07/01",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 实现图片大小压缩",
    "path": "/blogs/bianmabiji/PowerShellshixiantupiandaxiaoyasuo.html",
    "url": "/blogs/bianmabiji/PowerShellshixiantupiandaxiaoyasuo.html",
    "content": "---\r\ntitle: PowerShell 实现图片大小压缩\r\ndate: 2025/07/04\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n- 下载地址：[https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/imageQ.ps1](https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/imageQ.ps1)\r\n:::\r\n\r\n使用示例：\r\n```powershell\r\n    .\\imageQ.ps1 -Help\r\n    \r\n    .\\imageQ.ps1 -i .\\*.jpg\r\n    .\\imageQ.ps1 -i img1.jpg,img2.png -s 2MB\r\n    .\\imageQ.ps1 -i img1.jpg,img2.jpg -o out1.jpg,out2.jpg -q 90\r\n    .\\imageQ.ps1 -i .\\*.png -Silent\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 实现图片大小压缩"
    },
    "frontmatter": {
      "title": "PowerShell 实现图片大小压缩",
      "date": "2025/07/04",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 目录栈",
    "path": "/blogs/bianmabiji/PowerShellmuluzhan.html",
    "url": "/blogs/bianmabiji/PowerShellmuluzhan.html",
    "content": "---\r\ntitle: PowerShell 目录栈\r\ndate: 2025/04/23\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n如果只是在脚本里临时切换目录，使用 `Push-Location / Pop-Location` 更优雅\r\n:::\r\n\r\n```powershell\r\ntry {\r\n    Push-Location path/to/dir\r\n    # todo ...\r\n}\r\nfinally {\r\n    Pop-Location\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 目录栈"
    },
    "frontmatter": {
      "title": "PowerShell 目录栈",
      "date": "2025/04/23",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 设置定时任务",
    "path": "/blogs/bianmabiji/PowerShellshezhidingshirenwu.html",
    "url": "/blogs/bianmabiji/PowerShellshezhidingshirenwu.html",
    "content": "---\r\ntitle: PowerShell 设置定时任务\r\ndate: 2025/03/05\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n1. 注册任务\r\n2. 注销任务\r\n\r\n---\r\n\r\n[使用VBS保持PS脚本的静默执行](./VBS静默执行PS脚本.md)\r\n:::\r\n\r\n\r\n## 注册任务\r\n\r\n```powershell\r\n# 使用vbs脚本的好处是可以保持静默执行\r\n$Action = New-ScheduledTaskAction -Execute \"wscript.exe\" -Argument \"D:\\personal-folder\\app\\powershell\\wallpaper-kline.vbs\"\r\n\r\n# 设置开机执行一次\r\n$Trigger1 = New-ScheduledTaskTrigger -AtStartup\r\n# 设置每小时执行一次\r\n$Trigger2 = New-ScheduledTaskTrigger -Once -At (Get-Date).Date -RepetitionInterval (New-TimeSpan -Hours 1)\r\n\r\n# 注册任务\r\n$Settings = New-ScheduledTaskSettingsSet -AllowStartIfOnBatteries -DontStopIfGoingOnBatteries -StartWhenAvailable -RunOnlyIfNetworkAvailable\r\nRegister-ScheduledTask -Action $Action -Trigger $Trigger1,$Trigger2 -TaskName \"wallpaper-kline-task\" -Description \"wallpaper-kline.vbs\"  -Settings $Settings\r\n```\r\n\r\n## 注销任务\r\n\r\n```powershell\r\nUnregister-ScheduledTask -TaskName \"wallpaper-kline-task\" -Confirm:$false\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 设置定时任务",
      "lvl1": "注册任务",
      "lvl2": "注销任务"
    },
    "frontmatter": {
      "title": "PowerShell 设置定时任务",
      "date": "2025/03/05",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Python 导出最简项目依赖",
    "path": "/blogs/bianmabiji/PYdaochuzuijianxiangmuyilai.html",
    "url": "/blogs/bianmabiji/PYdaochuzuijianxiangmuyilai.html",
    "content": "---\r\ntitle: Python 导出最简项目依赖\r\ndate: 2025/03/05\r\ntags:\r\n - Python\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n使用 `pipreqs` 导出项目依赖\r\n:::\r\n\r\n## 导出依赖\r\n\r\n```shell\r\n# 安装 pipreqs\r\npip install pipreqs\r\n\r\n# 导出项目依赖到 requirements.txt\r\npipreqs ./ --encoding=utf-8\r\n\r\n# 覆盖 requirements.txt\r\npipreqs ./ --encoding=utf-8 --force\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Python 导出最简项目依赖",
      "lvl1": "导出依赖"
    },
    "frontmatter": {
      "title": "Python 导出最简项目依赖",
      "date": "2025/03/05",
      "tags": [
        "Python"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "shlink 部署及 openfeign 调用",
    "path": "/blogs/bianmabiji/shlinkbushujiopenfeigndiaoyong.html",
    "url": "/blogs/bianmabiji/shlinkbushujiopenfeigndiaoyong.html",
    "content": "---\r\ntitle: shlink 部署及 openfeign 调用\r\ndate: 2025/04/16\r\ntags:\r\n - shlink\r\n - openfeign\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## shlink 部署\r\n\r\n```yml\r\nservices:\r\n  shlink:\r\n    image: shlinkio/shlink:latest\r\n    ports:\r\n      - \"28881:8080\"\r\n    environment:\r\n      - SHLINK_SHORT_CODES_LENGTH=5\r\n      - INITIAL_API_KEY=cda4282f-27a5-4a93-bb8a-47234309628f\r\n      - DB_DRIVER=mysql\r\n      - DB_HOST=mysql_host\r\n      - DB_PORT=3306\r\n      - DB_NAME=shlink\r\n      - DB_USER=shlink\r\n      - DB_PASSWORD=662caa92-1f0e-40f5-9656-2147c76a4f73\r\n```\r\n\r\n## openfeign\r\n\r\n```java\r\n@FeignClient(name = CloudName.SHLINK, path = \"/rest/v3\",\r\n        fallbackFactory = ShlinkClientFallbackFactory.class,\r\n        configuration = ShlinkHeaderConfig.class)\r\npublic interface ShlinkClient {\r\n    @PostMapping(\"/short-urls\")\r\n    ShortUrlRes shortUrls(@RequestBody ShortUrlParam param);\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Builder\r\n@NoArgsConstructor\r\n@AllArgsConstructor\r\n@Accessors(chain = true)\r\npublic class ShortUrlParam {\r\n    private String longUrl;\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Builder\r\n@NoArgsConstructor\r\n@AllArgsConstructor\r\n@Accessors(chain = true)\r\npublic class ShortUrlRes {\r\n    private String shortUrl;\r\n    private String shortCode;\r\n    private String longUrl;\r\n    @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ssXXX\")\r\n    private Date dateCreated;\r\n    private String domain;\r\n    private String title;\r\n    private Boolean crawlable;\r\n    private Boolean forwardQuery;\r\n    private Boolean hasRedirectRules;\r\n}\r\n```\r\n\r\n```java\r\n@RequiredArgsConstructor\r\npublic class ShlinkHeaderConfig {\r\n    private final ShlinkConfig shlinkConfig;\r\n    @Bean\r\n    public RequestInterceptor requestInterceptor() {\r\n        return requestTemplate -> requestTemplate.header(\"X-Api-Key\", shlinkConfig.getApiKey());\r\n    }\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConfigurationProperties(prefix = \"app.shlink\")\r\npublic class ShlinkConfig {\r\n    private String apiKey;\r\n}\r\n```\r\n\r\n```yml\r\napp:\r\n  shlink:\r\n    api-key: cda4282f-27a5-4a93-bb8a-47234309628f\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "shlink 部署及 openfeign 调用",
      "lvl1": "shlink 部署",
      "lvl2": "openfeign"
    },
    "frontmatter": {
      "title": "shlink 部署及 openfeign 调用",
      "date": "2025/04/16",
      "tags": [
        "shlink",
        "openfeign"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 Starter 自定义环境变量",
    "path": "/blogs/bianmabiji/SpringBoot2Starterzidingyihuanjingbianliang.html",
    "url": "/blogs/bianmabiji/SpringBoot2Starterzidingyihuanjingbianliang.html",
    "content": "---\r\ntitle: SpringBoot2 Starter 自定义环境变量\r\ndate: 2025/04/12\r\ntags:\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```\r\nMETA-INF\r\n  - application-referenced.yml\r\n  - spring.factories\r\n```\r\n\r\nspring.factories\r\n```prop\r\norg.springframework.boot.env.EnvironmentPostProcessor=package.path.CommonEnvironmentPostProcessor\r\n```\r\n\r\n```java\r\npublic class CommonEnvironmentPostProcessor implements EnvironmentPostProcessor {\r\n    private static final String PROPERTY_SOURCE_NAME = CommonEnvironmentPostProcessor.class.getSimpleName();\r\n\r\n    @Override\r\n    public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) {\r\n        YamlPropertySourceLoader loader = new YamlPropertySourceLoader();\r\n        Resource resource = new ClassPathResource(\"META-INF/application-referenced.yml\");\r\n\r\n        if (resource.exists()) {\r\n            try {\r\n                PropertySource<?> yamlProps = loader.load(PROPERTY_SOURCE_NAME, resource).get(0);\r\n                environment.getPropertySources().addLast(yamlProps);  // 注意：使用 `.addLast()`，确保主项目配置优先\r\n            } catch (IOException e) {\r\n                throw new IllegalStateException(\"Failed to load YAML file: \" + resource.getFilename(), e);\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 Starter 自定义环境变量"
    },
    "frontmatter": {
      "title": "SpringBoot2 Starter 自定义环境变量",
      "date": "2025/04/12",
      "tags": [
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 实现 SpringCache 集成多个 CacheManager",
    "path": "/blogs/bianmabiji/SpringBoot2shixianSpringCachejichengduogeCacheManager.html",
    "url": "/blogs/bianmabiji/SpringBoot2shixianSpringCachejichengduogeCacheManager.html",
    "content": "---\r\ntitle: SpringBoot2 实现 SpringCache 集成多个 CacheManager\r\ndate: 2025/04/29\r\ntags:\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n- 通过 `CachingConfigurerSupport` 指定全局默认的主 `CacheManager`\r\n- `@Cacheable` 等 SpringCache 注解可以通过 `cacheManager` 属性指定自定义的 `CacheManager`\r\n:::\r\n\r\n```java\r\n@Configuration\r\n@EnableCaching\r\npublic class CacheConfig extends CachingConfigurerSupport {\r\n    private final CacheManager cacheManager;\r\n\r\n    public CacheConfig(@Qualifier(RedisCacheConfig.REDIS_CACHE_NAME) CacheManager cacheManager) {\r\n        this.cacheManager = cacheManager;\r\n    }\r\n\r\n    @Override\r\n    public CacheManager cacheManager() {\r\n        return cacheManager;\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConditionalOnClass(name = \"com.github.benmanes.caffeine.cache.Caffeine\")\r\npublic class LocalCacheConfig {\r\n    public static final String LOCAL_CACHE_MANAGER = \"caffeineCacheManager\";\r\n    @Value(\"${app.cache.ttl-seconds:3600}\")\r\n    private Long ttlSeconds;\r\n    @Value(\"${app.cache.maximum:5000}\")\r\n    private Integer maximum;\r\n\r\n    @Bean(LOCAL_CACHE_MANAGER)\r\n    public CaffeineCacheManager caffeineCacheManager() {\r\n        CaffeineCacheManager cacheManager = new CaffeineCacheManager();\r\n        cacheManager.setCaffeine(Caffeine.newBuilder()\r\n                .expireAfterWrite(ttlSeconds, TimeUnit.SECONDS)\r\n                .maximumSize(maximum));\r\n        return cacheManager;\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConditionalOnClass(name = \"org.springframework.data.redis.cache.RedisCacheManager\")\r\npublic class RedisCacheConfig {\r\n    public static final String REDIS_CACHE_NAME = \"cacheManager\";\r\n    @Value(\"${app.cache.ttl-seconds:3600}\")\r\n    private Long ttlSeconds;\r\n\r\n    @Bean\r\n    @ConditionalOnMissingBean(RedisCacheConfiguration.class)\r\n    public RedisCacheConfiguration redisCacheConfiguration() {\r\n        return RedisCacheConfiguration.defaultCacheConfig()\r\n                .entryTtl(Duration.ofSeconds(ttlSeconds))\r\n                .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()))\r\n                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));\r\n    }\r\n\r\n    @Primary\r\n    @Bean(REDIS_CACHE_NAME)\r\n    public CacheManager cacheManager(RedisConnectionFactory connectionFactory, RedisCacheConfiguration config) {\r\n        return RedisCacheManager.builder(connectionFactory)\r\n                .cacheDefaults(config)\r\n                .build();\r\n    }\r\n\r\n}\r\n```\r\n\r\n```yml\r\napp:\r\n  cache:\r\n    ttl-seconds: 3600\r\n    maximum: 5000\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 实现 SpringCache 集成多个 CacheManager"
    },
    "frontmatter": {
      "title": "SpringBoot2 实现 SpringCache 集成多个 CacheManager",
      "date": "2025/04/29",
      "tags": [
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
    "path": "/blogs/bianmabiji/SpringBoot2jichengZipkinheSleuthshixianlianluzhuizong.html",
    "url": "/blogs/bianmabiji/SpringBoot2jichengZipkinheSleuthshixianlianluzhuizong.html",
    "content": "---\r\ntitle: SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪\r\ndate: 2025/04/22\r\ntags:\r\n - SpringBoot\r\n - Zipkin\r\n - Sleuth\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>2.7.9</version>\r\n        <relativePath/>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-sleuth</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-sleuth-zipkin</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-openfeign</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-loadbalancer</artifactId>\r\n        </dependency>\r\n```\r\n\r\n## 配置\r\n\r\n:::tip\r\n- 关闭 sleuth 组件自动注入的链路日志信息：`spring.sleuth.default-logging-pattern-enabled: false`\r\n- logback 自定义链路日志：`%X{traceId:-} %X{spanId:-}`\r\n- logback 中自定义的默认就可以上传到 ELK，而 sleuth 默认输出的则默认上传不到 ELK\r\n- ELK 搭建见：[ELK 部署](../运维手册/ELK部署.md)\r\n:::\r\n\r\n```yml\r\nspring:\r\n  sleuth:\r\n    default-logging-pattern-enabled: false\r\n    jdbc:\r\n      datasource-proxy:\r\n        query:\r\n          enable-logging: true\r\n        slow-query:\r\n          enable-logging: true\r\n      p6spy:\r\n        enable-logging: true\r\n    sampler:\r\n      probability: 1.0\r\n      rate: 100\r\n  zipkin:\r\n    base-url: http://zipkin:port\r\n    sender:\r\n      type: web\r\n```\r\n\r\n## 标签\r\n\r\n:::info\r\n- 多环境公用一个Zipkin的时候，可以使用打标签的方式进行环境隔离\r\n- Zipkin 查询语句：`tagQuery=env=dev`\r\n:::\r\n\r\n```java\r\n@Configuration\r\npublic class ZipkinTracingConfig {\r\n    @Value(\"${spring.profiles.active:unknown}\")  // 读取当前环境\r\n    private String activeProfile;\r\n\r\n    @Bean\r\n    public SpanHandler spanHandler() {\r\n        return new SpanHandler() {\r\n            @Override\r\n            public boolean end(TraceContext context, MutableSpan span, Cause cause) {\r\n                span.tag(\"env\", activeProfile); // 给 Zipkin 添加环境信息\r\n                return true;\r\n            }\r\n        };\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
      "lvl1": "依赖",
      "lvl2": "配置",
      "lvl3": "标签"
    },
    "frontmatter": {
      "title": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
      "date": "2025/04/22",
      "tags": [
        "SpringBoot",
        "Zipkin",
        "Sleuth"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot3 集成 GraalVM 云原生",
    "path": "/blogs/bianmabiji/SpringBoot3jichengGraalVMyunyuansheng.html",
    "url": "/blogs/bianmabiji/SpringBoot3jichengGraalVMyunyuansheng.html",
    "content": "---\r\ntitle: SpringBoot3 集成 GraalVM 云原生\r\ndate: 2025/04/18\r\ntags:\r\n - GraalVM\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n:::info\r\nSpringBoot 版本必须在 3.4.4 之上\r\n:::\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>3.4.4</version>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n    <build>\r\n        <finalName>image-name</finalName>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.graalvm.buildtools</groupId>\r\n                <artifactId>native-maven-plugin</artifactId>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n                <version>3.4.4</version>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 构建发布\r\n\r\n```shell\r\nmvn clean -Pnative spring-boot:build-image -f pom.xml\r\ndocker tag image-name:{version} jxch/image-name:latest\r\ndocker push jxch/image-name:latest\r\n```\r\n\r\n## 兼容性\r\n\r\n### 反射声明配置\r\n\r\n需要声明哪些类被反射过（尤其是被JSON序列化的类）\r\n\r\n```java\r\n@Configuration\r\n@RegisterReflectionForBinding({\r\n        CPunchCardNormal.class, CPunchCardState.class, UserConfig.class, User.class\r\n})\r\npublic class NativeReflectionConfig {\r\n}\r\n```\r\n\r\n### 静态资源声明配置\r\n\r\n声明用到了哪些 resources 目录下的静态资源文件\r\n\r\n```java\r\n@Configuration\r\n@ImportRuntimeHints(NativeRuntimeHints.class)\r\npublic class NativeRuntimeHints implements RuntimeHintsRegistrar {\r\n    @Override\r\n    public void registerHints(RuntimeHints hints, ClassLoader classLoader) {\r\n        hints.resources().registerPattern(\"xxx.json\");\r\n    }\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot3 集成 GraalVM 云原生",
      "lvl1": "依赖",
      "lvl2": "构建发布",
      "lvl3": "兼容性"
    },
    "frontmatter": {
      "title": "SpringBoot3 集成 GraalVM 云原生",
      "date": "2025/04/18",
      "tags": [
        "GraalVM",
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 Dockerfile 健康检查",
    "path": "/blogs/bianmabiji/SpringBootjichengDockerfilejiankangjiancha.html",
    "url": "/blogs/bianmabiji/SpringBootjichengDockerfilejiankangjiancha.html",
    "content": "---\r\ntitle: SpringBoot 集成 Dockerfile 健康检查\r\ndate: 2025/04/23\r\ntags:\r\n - Docker\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n健康检查成功后，容器才视为启动成功，包括 docker swarm 的 update 也是这样，可以利用这个特性实现集群的不停机更新\r\n:::\r\n\r\n## HEALTHCHECK\r\n\r\n```dockerfile\r\nENV ACTUATOR_PORT=13011\r\nENV ACTUATOR_USER=admin\r\nENV ACTUATOR_PASS=123456\r\n\r\nHEALTHCHECK --interval=30s --timeout=10s --start-period=300s CMD curl -f -u $ACTUATOR_USER:$ACTUATOR_PASS http://127.0.0.1:$ACTUATOR_PORT/actuator/health || exit 1\r\n\r\nENTRYPOINT [...]\r\n```\r\n\r\n## 依赖\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-actuator</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-security</artifactId>\r\n        </dependency>\r\n```\r\n\r\n## 配置\r\n\r\n```yml\r\nmanagement:\r\n  server:\r\n    port: 13011\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: '*'\r\n\r\nspring:\r\n  security:\r\n    user:\r\n      name: admin\r\n      password: 123456\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 Dockerfile 健康检查",
      "lvl1": "HEALTHCHECK",
      "lvl2": "依赖",
      "lvl3": "配置"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 Dockerfile 健康检查",
      "date": "2025/04/23",
      "tags": [
        "Docker",
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
    "path": "/blogs/bianmabiji/VaadinjichengSpringBoot3jiGraalVMyunyuansheng.html",
    "url": "/blogs/bianmabiji/VaadinjichengSpringBoot3jiGraalVMyunyuansheng.html",
    "content": "---\r\ntitle: Vaadin 集成 SpringBoot3 及 GraalVM 云原生\r\ndate: 2025/04/18\r\ntags:\r\n - GraalVM\r\n - SpringBoot\r\n - Vaadin\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n:::info\r\n- SpringBoot 版本必须在 3.4.4 之上\r\n- Vaadin 版本必须在 24.7.2 之上\r\n:::\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>3.4.4</version>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.vaadin</groupId>\r\n            <artifactId>vaadin-spring-boot-starter</artifactId>\r\n            <version>24.7.2</version>\r\n        </dependency>\r\n```\r\n\r\n```xml\r\n    <build>\r\n        <finalName>image-name</finalName>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.graalvm.buildtools</groupId>\r\n                <artifactId>native-maven-plugin</artifactId>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n                <version>3.4.4</version>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>com.vaadin</groupId>\r\n                <artifactId>vaadin-maven-plugin</artifactId>\r\n                <version>24.7.2</version>\r\n                <executions>\r\n                    <execution>\r\n                        <goals>\r\n                            <goal>prepare-frontend</goal>\r\n                            <goal>build-frontend</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 兼容性\r\n\r\n:::info\r\nVaadin 组件中用到过的所有类都必须声明反射\r\n\r\n其他兼容性（静态资源、反射等）参见 [SpringBoot3集成GraalVM云原生](./SpringBoot3集成GraalVM云原生.md)\r\n:::\r\n\r\n## view\r\n\r\n```java\r\n@Route(\"clock\")\r\npublic class ClockView extends VerticalLayout {\r\n    public ClockView(){\r\n        // todo 在构造方法中编写这个页面（可以通过构造方法参数直接注入 SpringBean）\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
      "lvl1": "依赖",
      "lvl2": "兼容性",
      "lvl3": "view"
    },
    "frontmatter": {
      "title": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
      "date": "2025/04/18",
      "tags": [
        "GraalVM",
        "SpringBoot",
        "Vaadin"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "VBS 静默执行 PowerShell 脚本",
    "path": "/blogs/bianmabiji/VBSjingmozhixingPSjiaoben.html",
    "url": "/blogs/bianmabiji/VBSjingmozhixingPSjiaoben.html",
    "content": "---\r\ntitle: VBS 静默执行 PowerShell 脚本\r\ndate: 2025/03/05\r\ntags:\r\n - VBS\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 创建 VBS 脚本\r\n\r\n```powershell\r\nSet WshShell = CreateObject(\"WScript.Shell\")\r\nWshShell.Run \"powershell.exe -WindowStyle Hidden -File D:\\personal-folder\\app\\powershell\\wallpaper-kline.ps1\", 0\r\nSet WshShell = Nothing\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "VBS 静默执行 PowerShell 脚本",
      "lvl1": "创建 VBS 脚本"
    },
    "frontmatter": {
      "title": "VBS 静默执行 PowerShell 脚本",
      "date": "2025/03/05",
      "tags": [
        "VBS"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "AMD 架构上运行 ARM 架构的 Docker 容器",
    "path": "/blogs/yunweishouce/AMDjiagoushangyunxingARMjiagoudeDockerrongqi.html",
    "url": "/blogs/yunweishouce/AMDjiagoushangyunxingARMjiagoudeDockerrongqi.html",
    "content": "---\r\ntitle: AMD 架构上运行 ARM 架构的 Docker 容器\r\ndate: 2025/05/06\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n安装 QEMU binfmt 支持：\r\n```bash\r\ndocker run --privileged --rm tonistiigi/binfmt --install all\r\n```\r\n\r\n测试：\r\n```bash\r\ndocker run --rm --platform linux/arm64/v8 arm64v8/alpine uname -m\r\n```\r\n\r\n:::tip\r\n- QEMU 是一个开源的硬件虚拟化工具，可以在 x86_64 主机上模拟 ARM64（aarch64）环境，从而让 Docker 能“假装”自己是 ARM 机器，运行 ARM 容器镜像。\r\n- QEMU 虚拟化会大大降低运行速度（比真实 ARM 机子慢很多），只适合测试和编译。\r\n- 某些复杂场景（如需内核特性、特殊指令集等）可能不完全兼容。\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "AMD 架构上运行 ARM 架构的 Docker 容器"
    },
    "frontmatter": {
      "title": "AMD 架构上运行 ARM 架构的 Docker 容器",
      "date": "2025/05/06",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Cloudflared 防 DNS 污染",
    "path": "/blogs/yunweishouce/CloudflaredfangDNSwuran.html",
    "url": "/blogs/yunweishouce/CloudflaredfangDNSwuran.html",
    "content": "---\r\ntitle: Cloudflared 防 DNS 污染\r\ndate: 2025/06/29\r\ntags:\r\n - DNS\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n- 下载：[https://github.com/cloudflare/cloudflared/releases](https://github.com/cloudflare/cloudflared/releases)\r\n- 启动命令：`cloudflared proxy-dns`\r\n- win11 安装：`winget install Cloudflare.cloudflared`，然后把 `C:\\Program Files (x86)\\cloudflared` 设进环境变量 path\r\n- win11 开机自启\r\n  - NSSM方式参考：[WIN使用NSSM管理Service](./WIN使用NSSM管理Service.md)\r\n  - VBS方式：\r\n    - 启动脚本参考：[VBS静默执行PS脚本](../编码笔记/VBS静默执行PS脚本.md)\r\n    - 脚本放入 `win + r` 输入 `shell:startup` 回车后出现的文件夹中\r\n:::\r\n\r\n## 以 Ubuntu - arm64 为例\r\n\r\n### 安装\r\n```shell\r\n# 下载\r\nwget https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-arm64.deb\r\n\r\n# 安装\r\ndpkg -i cloudflared-linux-arm64.deb\r\n\r\n# 启动\r\ncloudflared proxy-dns\r\n```\r\n\r\n### 部署\r\n设为 service\r\n```shell\r\n# 查看路径\r\nwhich cloudflared\r\n# 编辑配置文件\r\nvi /etc/systemd/system/cloudflared-proxy-dns.service\r\n# 启动 service\r\nsystemctl daemon-reload\r\nsystemctl enable --now cloudflared-proxy-dns\r\nsystemctl status cloudflared-proxy-dns\r\n```\r\n\r\n`cloudflared-proxy-dns.service` 配置文件：\r\n\r\n```shell \r\n[Unit]\r\nDescription=cloudflared DNS over HTTPS Proxy\r\nAfter=network.target\r\n\r\n[Service]\r\nType=simple\r\nUser=nobody\r\nCapabilityBoundingSet=CAP_NET_BIND_SERVICE\r\nAmbientCapabilities=CAP_NET_BIND_SERVICE\r\nExecStart=/usr/local/bin/cloudflared proxy-dns\r\nRestart=on-failure\r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Cloudflared 防 DNS 污染",
      "lvl1": "以 Ubuntu - arm64 为例"
    },
    "frontmatter": {
      "title": "Cloudflared 防 DNS 污染",
      "date": "2025/06/29",
      "tags": [
        "DNS"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "dnsmasq 部署",
    "path": "/blogs/yunweishouce/dnsmasqbushu.html",
    "url": "/blogs/yunweishouce/dnsmasqbushu.html",
    "content": "---\r\ntitle: dnsmasq 部署\r\ndate: 2025/03/05\r\ntags:\r\n - dnsmasq\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n1. 使用 docker 部署，docker-compose.yml 文件\r\n2. 配置文件，dnsmasq.conf 文件\r\n:::\r\n\r\n## docker-compose.yml\r\n\r\n```yml\r\nservices:\r\n  dns-server:\r\n    image: jpillora/dnsmasq\r\n    container_name: dns-server\r\n    restart: unless-stopped\r\n    environment:\r\n      - TZ=Asia/Shanghai\r\n      - HTTP_USER=username\r\n      - HTTP_PASS=password\r\n    ports:\r\n      - \"53:53/udp\"\r\n      - \"5380:8080\"\r\n    volumes:\r\n      - \"./dns/dnsmasq.conf:/etc/dnsmasq.conf\"\r\n```\r\n\r\n## dnsmasq.conf\r\n\r\n```shell\r\n# 服务器上游DNS服务器地址\r\nresolv-file=/etc/resolv.conf\r\n# 默认缓存条数150，这里增加到1000\r\ncache-size=1000\r\n# 重启后清空缓存\r\nclear-on-reload\r\n\r\n# DNS 服务器\r\nserver=8.8.4.4\r\nserver=8.8.8.8\r\nserver=4.2.2.1\r\nserver=4.2.2.2\r\nserver=114.114.114.114\r\n\r\n# 自定义域名\r\naddress=/example.com/192.168.1.10\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "dnsmasq 部署",
      "lvl1": "docker-compose.yml",
      "lvl2": "dnsmasq.conf"
    },
    "frontmatter": {
      "title": "dnsmasq 部署",
      "date": "2025/03/05",
      "tags": [
        "dnsmasq"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker Registry2 镜像仓库清理",
    "path": "/blogs/yunweishouce/DockerRegistry2jingxiangcangkuqingli.html",
    "url": "/blogs/yunweishouce/DockerRegistry2jingxiangcangkuqingli.html",
    "content": "---\r\ntitle: Docker Registry2 镜像仓库清理\r\ndate: 2025/04/23\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::info\r\n1. 必须在配置文件中允许删除镜像：`/etc/docker/registry/config.yml`\r\n2. 手动删除镜像：`/var/lib/registry/docker/registry/v2/repositories/`\r\n3. 清理镜像：`registry garbage-collect /etc/docker/registry/config.yml`\r\n:::\r\n\r\n```yml\r\n# /etc/docker/registry/config.yml\r\nstorage:\r\n  delete:\r\n    enabled: true\r\n```\r\n\r\n```bash\r\ncd /var/lib/registry/docker/registry/v2/repositories/\r\nrm -rf ./<要删除的镜像>\r\n\r\nregistry garbage-collect /etc/docker/registry/config.yml\r\n```\r\n\r\n```bash\r\n# 检查清理效果\r\ndf -h\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker Registry2 镜像仓库清理"
    },
    "frontmatter": {
      "title": "Docker Registry2 镜像仓库清理",
      "date": "2025/04/23",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker Swarm 将服务部署到指定标签的节点上",
    "path": "/blogs/yunweishouce/DockerSwarmjiangfuwubushudaozhidingbiaoqiandejiedianshang.html",
    "url": "/blogs/yunweishouce/DockerSwarmjiangfuwubushudaozhidingbiaoqiandejiedianshang.html",
    "content": "---\r\ntitle: Docker Swarm 将服务部署到指定标签的节点上\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip \r\n1. 给节点打标签\r\n2. 给服务加约束\r\n:::\r\n\r\n```shell\r\n# 给节点打标签\r\ndocker node update --label-add memory=high NODE_ID\r\n\r\n# 给服务添加约束，他就会自动调度到特定标签的节点上\r\ndocker service update --constraint-add 'node.labels.memory == high' SERVICE_ID\r\n```\r\n\r\n```shell\r\n# 查看节点上的标签\r\ndocker node inspect <node_id> --format '{{json .Spec.Labels}}'\r\n```\r\n\r\n```shell\r\n# 使该节点不接受任务调度，但是仍然可以通过该节点的端口访问集群中的服务\r\ndocker node update --availability drain <node_id>\r\n```\r\n\r\n```yml\r\nservices:\r\n  app:\r\n    image: app-images\r\n    deploy:\r\n      placement:\r\n        constraints:\r\n          - node.labels.memory == high\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker Swarm 将服务部署到指定标签的节点上"
    },
    "frontmatter": {
      "title": "Docker Swarm 将服务部署到指定标签的节点上",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker 容器启动时提示内存太小",
    "path": "/blogs/yunweishouce/Dockerrongqiqidongshitishinacuntaixiao.html",
    "url": "/blogs/yunweishouce/Dockerrongqiqidongshitishinacuntaixiao.html",
    "content": "---\r\ntitle: Docker 容器启动时提示内存太小\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: danger 类似的报错信息\r\n`Maximum number of memory map areas per process (vm.max_map_count) 262144 is too low, recommended value: 1048575, you can change it with sysctl.`\r\n:::\r\n\r\n## 解决方案\r\n\r\n:::: code-group\r\n::: code-group-item LINUX\r\n```bash\r\nsysctl -w vm.max_map_count=1048575\r\n```\r\n:::\r\n::: code-group-item WINDOWS\r\n```powershell\r\nwsl -d docker-desktop sh -c \"sysctl -w vm.max_map_count=1048575\"\r\n```\r\n:::\r\n::::\r\n\r\n::: info \r\n1. 提示应该设置多少就设置多少\r\n2. 然后重启docker服务即可\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker 容器启动时提示内存太小",
      "lvl1": "解决方案"
    },
    "frontmatter": {
      "title": "Docker 容器启动时提示内存太小",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker 清理",
    "path": "/blogs/yunweishouce/Dockerqingli.html",
    "url": "/blogs/yunweishouce/Dockerqingli.html",
    "content": "---\r\ntitle: Docker 清理\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n通常可以直接使用 `docker system prune --all -f` 命令进行深度清理并且无需手动确认\r\n:::\r\n\r\n|命令|作用|\r\n|-|-|\r\n|`docker container prune`|容器清理|\r\n|`docker image prune`|镜像清理|\r\n|`docker volume prune`|数据卷清理|\r\n|`docker builder prune`|缓存清理|\r\n|`docker system prune`|一键清理|\r\n|`docker system prune -a`|深度清理|\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker 清理"
    },
    "frontmatter": {
      "title": "Docker 清理",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "ELK 部署",
    "path": "/blogs/yunweishouce/ELKbushu.html",
    "url": "/blogs/yunweishouce/ELKbushu.html",
    "content": "---\r\ntitle: ELK 部署\r\ndate: 2025/04/16\r\ntags:\r\n - elasticsearch\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## docker-compose.yml\r\n\r\n```yml\r\nservices:\r\n  elasticsearch: \r\n    image: elasticsearch:8.16.1\r\n    restart: always\r\n    environment:\r\n      - discovery.type=single-node \r\n      - xpack.security.enabled=true\r\n    volumes:\r\n      - /mnt/nexus3/es_data:/usr/share/elasticsearch/data \r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  kibana: \r\n    image: kibana:8.16.1 \r\n    ports:\r\n      - \"12563:5601\"\r\n    environment:\r\n      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\r\n      - XPACK_SECURITY_ENABLED=true\r\n      - ELASTICSEARCH_USERNAME=kibana_system\r\n      - ELASTICSEARCH_PASSWORD=\"3UGDvTkAmzhprC5*9PUw\"\r\n    depends_on:\r\n      - elasticsearch\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  zipkin:\r\n    image: bitnami/zipkin:3\r\n    ports:\r\n      - \"12411:9411\"\r\n    environment:\r\n      - STORAGE_TYPE=elasticsearch\r\n      - ES_HOSTS=elasticsearch:9200\r\n      - ES_USERNAME=elastic\r\n      - ES_PASSWORD=rC4hG9mR9DUC109=DeS8\r\n    depends_on:\r\n      - elasticsearch\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  logstash:\r\n    image: bitnami/logstash:8.17.0\r\n    ports: \r\n      - \"5044:8080\"\r\n    volumes:\r\n      - ./logstash.conf:/opt/bitnami/logstash/pipeline/logstash.conf\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n```\r\n\r\n## logstash.conf\r\n\r\n```config\r\ninput {\r\n  tcp {\r\n    port => 8080 \r\n    codec => json_lines \r\n  }\r\n}\r\n\r\n\r\noutput {\r\n  elasticsearch {\r\n    hosts => [\"http://elasticsearch:9200\"] \r\n    user => \"elastic\"\r\n    password => \"rC4hG9mR9DUC109=DeS8\"\r\n    index => \"logs-%{+YYYY.MM.dd}\"\r\n    ssl => false \r\n  }\r\n}\r\n```\r\n\r\n## 设置密码\r\n\r\n```bash\r\n# 进入 elasticsearch 容器内部\r\ndocker exec -it <elasticsearch> sh\r\n\r\n# 设置超级用户的密码，此用户名密码可以用在logstash、zipkin和kibana web ui的登录上\r\nbin/elasticsearch-reset-password -u elastic\r\n\r\n# 设置kibana用户的密码，此用户专用于kibana容器与elasticsearch容器的交互\r\nbin/elasticsearch-reset-password -u kibana_system\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "ELK 部署",
      "lvl1": "docker-compose.yml",
      "lvl2": "logstash.conf",
      "lvl3": "设置密码"
    },
    "frontmatter": {
      "title": "ELK 部署",
      "date": "2025/04/16",
      "tags": [
        "elasticsearch"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "HAProxy TCP 端口代理",
    "path": "/blogs/yunweishouce/HAProxy-TCPduankoudaili.html",
    "url": "/blogs/yunweishouce/HAProxy-TCPduankoudaili.html",
    "content": "---\r\ntitle: HAProxy TCP 端口代理\r\ndate: 2025/07/02\r\ntags:\r\n - proxy\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n\r\n## docker-compose.yml\r\n```yml\r\nversion: '3.8'\r\nservices: \r\n  haproxy: \r\n    image: haproxy:lts-alpine\r\n    privileged: true\r\n    ports:\r\n      - 1080:1080\r\n      - 3306:3306\r\n    volumes: \r\n      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg\r\n```\r\n\r\n## haproxy.cfg\r\n```properties\r\ndefaults\r\n    mode            tcp\r\n    log             global\r\n    option          tcplog\r\n    option          dontlognull\r\n    option http-server-close\r\n    option          redispatch\r\n    retries         3\r\n    timeout http-request 10s\r\n    timeout queue   1m\r\n    timeout connect 10s\r\n    timeout client  1m\r\n    timeout server  1m\r\n    timeout http-keep-alive 10s\r\n    timeout check   10s\r\n    maxconn         3000\r\nfrontend    mysql\r\n    bind        0.0.0.0:3306\r\n    mode        tcp\r\n    log         global\r\n    default_backend mysql_server\r\nbackend     mysql_server\r\n    balance roundrobin\r\n    server capital_mysql qbh.jiangxicheng.xyz:3306 check inter 5s rise 2 fall 3\r\nlisten stats\r\n    mode    http\r\n    bind    0.0.0.0:1080\r\n    stats   enable\r\n    stats   hide-version\r\n    stats uri /haproxyamdin?stats\r\n    stats realm Haproxy\\ Statistics\r\n    stats auth admin:admin\r\n    stats admin if TRUE\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "HAProxy TCP 端口代理",
      "lvl1": "docker-compose.yml",
      "lvl2": "haproxy.cfg"
    },
    "frontmatter": {
      "title": "HAProxy TCP 端口代理",
      "date": "2025/07/02",
      "tags": [
        "proxy"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "hexo 下载内部文件",
    "path": "/blogs/yunweishouce/hexo-xiazainabuwenjian.html",
    "url": "/blogs/yunweishouce/hexo-xiazainabuwenjian.html",
    "content": "---\r\ntitle: hexo 下载内部文件\r\ndate: 2025/07/02\r\ntags:\r\n - hexo\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n1. `_config.yml` 文件内修改属性 `post_asset_folder: true`\r\n2. 在 `source` 文件夹内创建下载目录 `download`\r\n3. 下载链接：`[xxxxxx](/download/xxxxxx)`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "hexo 下载内部文件"
    },
    "frontmatter": {
      "title": "hexo 下载内部文件",
      "date": "2025/07/02",
      "tags": [
        "hexo"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Jumpserver 部署",
    "path": "/blogs/yunweishouce/Jumpserverbushu.html",
    "url": "/blogs/yunweishouce/Jumpserverbushu.html",
    "content": "---\r\ntitle: Jumpserver 部署\r\ndate: 2025/06/16\r\ntags:\r\n - Jumpserver\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## docker compose\r\n\r\n```yml\r\nservices:\r\n  jumpserver: \r\n    image: jumpserver/jms_all\r\n    restart: unless-stopped\r\n    user: root\r\n    privileged: true\r\n    ports:\r\n      - \"10880:80\"\r\n    environment:\r\n      SECRET_KEY: \"uuid\"\r\n      BOOTSTRAP_TOKEN: \"uuid\"\r\n      LOG_LEVEL: \"ERROR\"\r\n      DB_ENGINE: mysql\r\n      DB_HOST: \"\"\r\n      DB_PORT: \"3306\"\r\n      DB_USER: \"root\"\r\n      DB_PASSWORD: \"\"\r\n      DB_NAME: \"jumpserver\"\r\n      REDIS_HOST: \"\"\r\n      REDIS_PORT: \"\"\r\n      REDIS_PASSWORD: \"\"\r\n      DOMAINS: host:port\r\n    volumes:\r\n      - /mnt/nexus3/jumpserver:/opt/jumpserver/data\r\n```\r\n\r\n:::tip\r\n- [Docker Hub - Jumpserver/jms_all](https://hub.docker.com/r/jumpserver/jms_all)\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Jumpserver 部署",
      "lvl1": "docker compose"
    },
    "frontmatter": {
      "title": "Jumpserver 部署",
      "date": "2025/06/16",
      "tags": [
        "Jumpserver"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 关闭 iptables 防火墙",
    "path": "/blogs/yunweishouce/Linuxguanbiiptablesfanghuoqiang.html",
    "url": "/blogs/yunweishouce/Linuxguanbiiptablesfanghuoqiang.html",
    "content": "---\r\ntitle: Linux 关闭 iptables 防火墙\r\ndate: 2025/03/11\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 允许所有流量\r\n\r\n```shell\r\niptables -P FORWARD ACCEPT \r\niptables -P OUTPUT ACCEPT \r\niptables -P INPUT ACCEPT\r\niptables -F \r\n```\r\n\r\n::: warning\r\n该方式会在重启后失效\r\n:::\r\n\r\n## 自动生效\r\n\r\n```shell\r\napt install iptables-persistent\r\n\r\nnetfilter-persistent save\r\n\r\n# 重启后验证\r\niptables -L -v\r\n```\r\n\r\n::: tip\r\n适用于 Debian/Ubuntu 系统\r\n:::\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 关闭 iptables 防火墙",
      "lvl1": "允许所有流量",
      "lvl2": "自动生效"
    },
    "frontmatter": {
      "title": "Linux 关闭 iptables 防火墙",
      "date": "2025/03/11",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 开启 BBR",
    "path": "/blogs/yunweishouce/LinuxkaiqiBBR.html",
    "url": "/blogs/yunweishouce/LinuxkaiqiBBR.html",
    "content": "---\r\ntitle: Linux 开启 BBR\r\ndate: 2025/03/05\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 开启 BBR\r\n\r\n```bash\r\necho \"net.core.default_qdisc=fq\" >> /etc/sysctl.conf\r\necho \"net.ipv4.tcp_congestion_control=bbr\" >> /etc/sysctl.conf\r\n\r\n# 生效\r\nsysctl -p\r\n\r\n# 查看内核是否已开启BBR\r\nsysctl net.ipv4.tcp_available_congestion_control\r\n\r\n# 查看BBR是否启动\r\nlsmod | grep bbr\r\n```\r\n\r\n::: warning 内核版本\r\n1. Linux 内核版本 4.9 以上才可以开启\r\n2. 查看版本是否符合要求：`uname -r` \r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 开启 BBR",
      "lvl1": "开启 BBR"
    },
    "frontmatter": {
      "title": "Linux 开启 BBR",
      "date": "2025/03/05",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 添加 Swap 交换空间",
    "path": "/blogs/yunweishouce/LinuxtianjiaSwapjiaohuankongjian.html",
    "url": "/blogs/yunweishouce/LinuxtianjiaSwapjiaohuankongjian.html",
    "content": "---\r\ntitle: Linux 添加 Swap 交换空间\r\ndate: 2025/03/07\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 添加交换空间\r\n\r\n```bash\r\nmkdir /swap\r\n\r\n# 创建交换空间文件\r\nfallocate -l 2G /swap/swapfile1\r\n# 或者使用 dd 命令\r\ndd if=/dev/zero of=/swap/swapfile1 bs=1024 count=2097152\r\n\r\n# 启用并挂载交换空间\r\nchmod 600 /swap/swapfile1\r\nmkswap /swap/swapfile1\r\nswapon /swap/swapfile1\r\necho \"/swap/swapfile1 swap swap defaults 0 0\" | sudo tee -a /etc/fstab\r\n\r\n# 查看是否挂载成功\r\nswapon --show\r\nfree -h\r\n```\r\n\r\n## 删除交换空间\r\n```bash\r\n# 卸载交换空间\r\nswapoff -v /swap/swapfile1\r\n\r\n# 删除挂载交换空间的配置\r\nvi /etc/fstab\r\nrm /swap/swapfile1\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 添加 Swap 交换空间",
      "lvl1": "添加交换空间",
      "lvl2": "删除交换空间"
    },
    "frontmatter": {
      "title": "Linux 添加 Swap 交换空间",
      "date": "2025/03/07",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MySQL 僵尸锁",
    "path": "/blogs/yunweishouce/MySQLjiangshisuo.html",
    "url": "/blogs/yunweishouce/MySQLjiangshisuo.html",
    "content": "---\r\ntitle: MySQL 僵尸锁\r\ndate: 2025/05/10\r\ntags:\r\n - MySQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 僵尸锁\r\n\r\n```sql\r\nSELECT * FROM performance_schema.data_locks;\r\n```\r\n\r\n存在锁，而查不到\r\n\r\n```sql\r\nSELECT\r\n    THREAD_ID,\r\n    PROCESSLIST_ID,\r\n    NAME,\r\n    TYPE\r\nFROM performance_schema.threads\r\nWHERE THREAD_ID IN (5468414, 5468475);\r\n```\r\n\r\n是一个假死的长事务导致的   \r\n \r\n```sql\r\nselect * from information_schema.INNODB_TRX;\r\n```\r\n\r\n但是查不到这个事务的线程id  \r\n \r\n```sql\r\nSELECT\r\n    trx_id,\r\n    trx_state,\r\n    trx_mysql_thread_id,\r\n    trx_started,\r\n    trx_query\r\nFROM information_schema.INNODB_TRX\r\nWHERE trx_id = 65772512;\r\n```\r\n\r\n也无法回滚事务\r\n\r\n```sql\r\nXA RECOVER;\r\nXA ROLLBACK '10.0.6.112.tm17458036649580053510.0.6.112.tm238';\r\n```\r\n\r\n## 回滚事务\r\n\r\n:::info\r\n根据16进制xid中不同的位数，直接回滚那个造成僵尸锁的事务\r\n:::\r\n\r\n```sql\r\nXA RECOVER CONVERT XID;\r\nXA ROLLBACK X'31302E302E362E3131322E746D313734353830333636343935383030353335', X'31302E302E362E3131322E746D323338', 1096044365;\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MySQL 僵尸锁",
      "lvl1": "僵尸锁",
      "lvl2": "回滚事务"
    },
    "frontmatter": {
      "title": "MySQL 僵尸锁",
      "date": "2025/05/10",
      "tags": [
        "MySQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
    "path": "/blogs/yunweishouce/MYSQLzengliangbinlogdenixianghuifangzhibinlog2sql.html",
    "url": "/blogs/yunweishouce/MYSQLzengliangbinlogdenixianghuifangzhibinlog2sql.html",
    "content": "---\r\ntitle: MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】\r\ndate: 2025/06/28\r\ntags:\r\n - MYSQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 下载工具 `binlog2sql`: `git clone https://github.com/danfengcao/binlog2sql.git`\r\n2. 初始化依赖环境\r\n3. 校验 mysql binlog 功能：其他实例的binlog在本地实例中的应用\r\n4. 生成逆向sql：兼容性问题（字符集问题）\r\n:::\r\n\r\n## binlog2sql\r\n\r\n```shell\r\n# 下载\r\ngit clone https://github.com/danfengcao/binlog2sql.git\r\n# 依赖环境（conda 为例）\r\nconda create -n binlog2sql_env python=3.9 -y\r\nconda activate binlog2sql_env\r\n\r\npip install -r requirements.txt\r\npip install mysqlclient\r\npip install pymysql\r\npip install requests\r\npip install python-dateutil\r\n\r\n# 验证\r\ncd .\\binlog2sql\\\r\npython binlog2sql.py --help\r\n```\r\n\r\n## binlog\r\n:::warning\r\n- 如果你的binlog文件来自其他实例，记得提前把binlog文件放入mysql的数据文件夹下（`/var/lib/mysql`），并修改`mysql-bin.index`文件\r\n- 查看binlog：`SHOW BINARY LOGS;`\r\n- 查看数据库字符集：`SHOW CREATE DATABASE matcheasy_new;`\r\n- 查看数据库表字符集：`SHOW FULL COLUMNS FROM matcheasy_new.i_resume;`\r\n:::\r\n\r\n以本地环境（docker mysql）为例（把线上实例的binlog放在本地实例上回放测试）\r\n\r\n```yml\r\nservices:\r\n  mysql:\r\n    image: mysql:8.0\r\n    environment:\r\n      MYSQL_ROOT_PASSWORD: password\r\n      MYSQL_USER: root_user\r\n      MYSQL_PASSWORD: password\r\n    ports:\r\n      - \"33306:3306\"\r\n    command:\r\n      --default-authentication-plugin=mysql_native_password\r\n      --character-set-server=utf8mb4\r\n      --collation-server=utf8mb4_unicode_ci\r\n      --binlog-format=ROW\r\n      --server-id=1\r\n      --log-bin=mysql-bin\r\n      --local-infile=1\r\n      --log-bin-trust-function-creators=1\r\n      --gtid-mode=ON\r\n      --enforce-gtid-consistency=ON\r\n    volumes:\r\n      - ./mysql_data:/var/lib/mysql\r\n```\r\n\r\n```sql\r\n-- 启动实例后给用户赋权\r\nGRANT ALL PRIVILEGES ON *.* TO 'root_user'@'%';\r\nFLUSH PRIVILEGES;\r\n```\r\n\r\n:::tip\r\n- 基础数据准备参考：[MYSQL数据导出导入](./MYSQL数据导出导入.md)\r\n- mysql版本以8.0为例，binlog以开启gtid为例\r\n- 源实例字符集以 utf8mb3 为例（注意我的docker compose文件中字符集指定的是 utf8mb4 ，因为它和 utf8mb3 可能会有兼容性问题，且本工具对 utf8mb3 也有兼容性问题，方便进行演示，实际场景中请保证两实例字符集一致）\r\n:::\r\n\r\n## 生成逆向sql\r\n\r\n:::info\r\n- 本工具可以直接连线上的mysql，包括阿里云什么的，就不用折腾两个实例了，这里只是对这种特殊需求的演示\r\n:::\r\n\r\n```shell\r\npython ..\\binlog2sql\\binlog2sql.py \\\r\n    --start-file=mysql-bin.001030 \\\r\n    --stop-file=mysql-bin.001039 \\\r\n    --host=127.0.0.1 --port=33306 \\\r\n    --user=root_user \\\r\n    --password='password' \\\r\n    --database=test_database \\\r\n    --flashback \\\r\n        > rollback.sql\r\n```\r\n\r\n:::danger utf8mb3字符集兼容性问题报错\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 150, in <module>\r\n    binlog2sql.process_binlog()\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 105, in process_binlog\r\n    for row in binlog_event.rows:\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 428, in rows\r\n    self._fetch_rows()\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 423, in _fetch_rows\r\n    self.__rows.append(self._fetch_one_row())\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 476, in _fetch_one_row\r\n    row[\"values\"] = self._read_column_data(self.columns_present_bitmap)\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 132, in _read_column_data\r\n    values[name] = self.__read_string(1, column)\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 220, in __read_string\r\n    string = string.decode(charset_to_encoding(column.character_set_name))\r\nLookupError: unknown encoding: utf8mb3\r\n```\r\n\r\n解决方案：因为本工具引用的pymysql版本太老，无法识别utf8mb3，所以需要手动修改pymysql包下的`charset.py`\r\n```py\r\ndef charset_to_encoding(name):\r\n    \"\"\"Convert MySQL's charset name to Python's codec name\"\"\"\r\n    if name == 'utf8mb4':\r\n        return 'utf8'\r\n    if name == 'utf8mb3':\r\n        return 'utf8'\r\n    return name\r\n```\r\n:::\r\n\r\n:::danger 字符解码报错\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 150, in <module>\r\n    binlog2sql.process_binlog()\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 121, in process_binlog\r\n    self.print_rollback_sql(filename=tmp_file)\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 129, in print_rollback_sql\r\n    for line in reversed_lines(f_tmp):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql_util.py\", line 249, in reversed_lines\r\n    block = block.decode(\"utf-8\")\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x83 in position 0: invalid start byte\r\n```\r\n\r\n解决方案：因为两实例字符集不同，或实例修改字符集导致的历史数据问题，总之解析binlog时发现存在无法解析的字符编码，所以需要手动修改工具中的解码逻辑，修改`binlog2sql_util.py`文件，这样非法字符就会被`�`代替，等回放完需要去sql文件中手动修改非法字符\r\n```py\r\nblock = block.decode(\"utf-8\")\r\n# 改为\r\nblock = block.decode(\"utf-8\", errors=\"replace\")\r\n```\r\n- 字符编码的报错没有好的办法彻底避免\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
      "lvl1": "binlog2sql",
      "lvl2": "binlog",
      "lvl3": "生成逆向sql"
    },
    "frontmatter": {
      "title": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
      "date": "2025/06/28",
      "tags": [
        "MYSQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MYSQL 数据导出导入",
    "path": "/blogs/yunweishouce/MYSQLshujudaochudaoru.html",
    "url": "/blogs/yunweishouce/MYSQLshujudaochudaoru.html",
    "content": "---\r\ntitle: MYSQL 数据导出导入\r\ndate: 2025/03/05\r\ntags:\r\n - MYSQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n1. 安装 mysqlsh\r\n2. 导出数据\r\n3. 导入数据（需要开启性能模式）\r\n:::\r\n\r\n## 安装 mysqlsh\r\n\r\n```shell\r\nwinget install Oracle.MySQLShell\r\nmysqlsh\r\n```\r\n\r\n## 导出\r\n\r\n```js\r\n\\connect username@host\r\n\\js\r\nutil.dumpTables(\"asktrue_exam\", [\"project_exam_student_result\"], \"E:\\\\DB\\\\asktrue\")\r\nutil.dumpSchemas([\"staffcloud_crm\", \"staffcloud_oa\"], \"E:\\\\DB\\\\staffcloud\");\r\n\r\n// 移除 definer，比如创建该库的用户名\r\nutil.dumpSchemas([\"staffcloud_crm\", \"staffcloud_oa\"], \"E:\\\\DB\\\\staffcloud\", {compatibility:[\"strip_definers\"]});\r\n```\r\n\r\n## 导入\r\n\r\n```js\r\n\\connect username@host\r\n\\js\r\nutil.loadDump(\"E:\\\\DB\\\\asktrue\\\\project_exam_student_result\", {threads: 4});\r\n\r\n// 指定导入另一个 schema\r\nutil.loadDump(\"E:\\\\DB-BACK\\\\matcheasy_new_gray_20250630_0100_2\", {schema: \"matcheasy_new\"})\r\n```\r\n\r\n::: info 需要开启性能模式\r\n开启性能模式：`performance_schema=ON`\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MYSQL 数据导出导入",
      "lvl1": "安装 mysqlsh",
      "lvl2": "导出",
      "lvl3": "导入"
    },
    "frontmatter": {
      "title": "MYSQL 数据导出导入",
      "date": "2025/03/05",
      "tags": [
        "MYSQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
    "path": "/blogs/yunweishouce/prometheusjiagrafanajichengcadvisorhenode-exportershixianjiankongwulijihedockerrongqidexingnenzhibiao.html",
    "url": "/blogs/yunweishouce/prometheusjiagrafanajichengcadvisorhenode-exportershixianjiankongwulijihedockerrongqidexingnenzhibiao.html",
    "content": "---\r\ntitle: prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标\r\ndate: 2025/04/29\r\ntags:\r\n - prometheus\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 部署采集器\r\n\r\n:::tip\r\n- node-exporter 采集物理机指标\r\n- cadvisor 采集各个 Docker 容器的指标\r\n:::\r\n\r\n```yml\r\nservices:\r\n  node-exporter:\r\n    image: prom/node-exporter:latest\r\n    deploy:\r\n      mode: global\r\n      restart_policy:\r\n        condition: any\r\n    ports:\r\n      - 9100:9100\r\n    pid: host\r\n    volumes:\r\n      - /:/host:ro,rslave\r\n    command:\r\n      - --path.rootfs=/host\r\n    labels:\r\n      - \"monitoring=enabled\"\r\n\r\n  cadvisor:\r\n    image: cadvisor/cadvisor:latest\r\n    deploy:\r\n      mode: global\r\n      restart_policy:\r\n        condition: any\r\n    ports: \r\n      - 8080:8080\r\n    volumes:\r\n      - /:/rootfs:ro\r\n      - /var/run:/var/run:rw\r\n      - /sys:/sys:ro\r\n      - /var/lib/docker/:/var/lib/docker:ro\r\n    labels:\r\n      - \"monitoring=enabled\"\r\n```\r\n\r\n## 自动更新采集端点\r\n\r\n:::tip\r\n- 需要整理所有的端点供 prometheus 采集信息\r\n- 保存到 file_sd 文件夹下的 json 文件中，这样 prometheus 就可以自动解析了\r\n:::\r\n\r\n```bash\r\n#!/bin/bash\r\n\r\nEXPORTER_PORTS=(9100 8080)\r\nPROM_FILE_SD_DIR=\"/etc/prometheus/file_sd\"\r\nmkdir -p $PROM_FILE_SD_DIR\r\n\r\n# 只选 Ready 状态节点\r\nNODES=$(docker node ls --format '{{.Hostname}} {{.Status}}' | awk '$2 == \"Ready\" {print $1}')\r\n\r\nfor PORT in \"${EXPORTER_PORTS[@]}\"; do\r\n  JSON_FILE=\"$PROM_FILE_SD_DIR/exporter_${PORT}.json\"\r\n  echo \"[\" > $JSON_FILE\r\n  SEP=\"\"\r\n  for HOST in $NODES; do\r\n    IP=$(docker node inspect \"$HOST\" --format '{{ index .Spec.Labels \"exporter_ip\" }}')\r\n    if [[ -n \"$IP\" ]]; then\r\n      echo \"${SEP}{\\\"targets\\\":[\\\"$IP:$PORT\\\"],\\\"labels\\\":{\\\"node\\\":\\\"$HOST\\\"}}\" >> $JSON_FILE\r\n      SEP=\",\"\r\n    fi\r\n  done\r\n  echo \"]\" >> $JSON_FILE\r\ndone\r\n```\r\n\r\n## prometheus\r\n\r\n```yml\r\n# prometheus.yml\r\n\r\nglobal:\r\n  scrape_interval: 15s\r\n\r\nscrape_configs:\r\n  - job_name: 'node-exporter'\r\n    file_sd_configs:\r\n      - files:\r\n          - /etc/prometheus/file_sd/exporter_9100.json\r\n\r\n  - job_name: 'cadvisor'\r\n    file_sd_configs:\r\n      - files:\r\n          - /etc/prometheus/file_sd/exporter_8080.json\r\n```\r\n\r\n```yml\r\nservices:\r\n  prometheus:\r\n    image: prom/prometheus:latest\r\n    container_name: prometheus\r\n    restart: always\r\n    volumes:\r\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro\r\n      - /etc/prometheus/file_sd:/etc/prometheus/file_sd:ro\r\n    ports:\r\n      - \"9090:9090\"\r\n    command:\r\n      - \"--config.file=/etc/prometheus/prometheus.yml\"\r\n      - \"--web.enable-lifecycle\"\r\n```\r\n\r\n## grafana\r\n\r\n:::tip\r\n- node-exporter 模板：11074、1860、405\r\n- cadvisor 模板：14282\r\n:::\r\n\r\n```yml\r\nservices:\r\n  grafana:\r\n    image: grafana/grafana-oss:latest\r\n    container_name: grafana\r\n    user: root\r\n    ports:\r\n      - \"9300:3000\"\r\n    volumes:\r\n      - ./data/grafana_data:/var/lib/grafana\r\n    environment:\r\n      - GF_SECURITY_ADMIN_USER=admin\r\n      - GF_SECURITY_ADMIN_PASSWORD=admin\r\n    restart: always\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
      "lvl1": "部署采集器",
      "lvl2": "自动更新采集端点",
      "lvl3": "prometheus",
      "lvl4": "grafana"
    },
    "frontmatter": {
      "title": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
      "date": "2025/04/29",
      "tags": [
        "prometheus"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 SpringBootAdmin",
    "path": "/blogs/yunweishouce/SpringBootjichengSpringBootAdmin.html",
    "url": "/blogs/yunweishouce/SpringBootjichengSpringBootAdmin.html",
    "content": "---\r\ntitle: SpringBoot 集成 SpringBootAdmin\r\ndate: 2025/05/15\r\ntags:\r\n - SpringBoot\r\n - SpringBootAdmin\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 部署 SpringBootAdminServer\r\n2. 集成 SpringBootAdminClient\r\n3. 按不同环境修改 SpringBootAdminClient 注册的实例名称\r\n:::\r\n\r\n## 部署 SpringBootAdminServer\r\n\r\n```java\r\n@EnableAdminServer\r\n@SpringBootApplication\r\npublic class AdminServerApplication {\r\n    public static void main(String[] args) {\r\n        SpringApplication.run(AdminServerApplication.class, args);\r\n    }\r\n}\r\n```\r\n\r\n:::info\r\n- 开启 `httpBasic` 来允许 `curl` 使用用户名密码的方式访问 `/actuator`\r\n:::\r\n\r\n```java\r\n@Configuration\r\n@EnableWebSecurity\r\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\r\n    @Override\r\n    protected void configure(HttpSecurity http) throws Exception {\r\n        http\r\n                .authorizeRequests()\r\n                .anyRequest().authenticated()\r\n                .and()\r\n                .formLogin()\r\n                .and()\r\n                .httpBasic()\r\n                .and()\r\n                .logout()\r\n                .and()\r\n                .csrf().disable();\r\n    }\r\n}\r\n```\r\n\r\n:::info\r\n- 可以集成注册中心（如 Nacos）实现服务的自动发现\r\n- SpringBootAdmin2 可以通过 `ignored-services` 属性忽略注册中心的某些服务\r\n- SpringBootAdmin3 可以通过 `metadata-filter` 属性通过元数据来选择注册中心中的某些服务\r\n:::\r\n\r\n```yml\r\nserver:\r\n  port: 8111\r\n\r\nspring:\r\n  application:\r\n    name: SPRING-BOOT-ADMIN-SERVER\r\n  security:\r\n    user:\r\n      name: admin\r\n      password: password\r\n  cloud:\r\n    nacos:\r\n      server-addr: nacos-server-addr\r\n      discovery:\r\n        username: nacos\r\n        password: password\r\n        group: DEFAULT_GROUP\r\n        namespace: public\r\n  boot:\r\n    admin:\r\n      discovery:\r\n        ignored-services: shlink,snowflake\r\n      client:\r\n        url: http://localhost:${server.port}\r\n        username: ${spring.security.user.name}\r\n        password: ${spring.security.user.password}\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            environment: ${spring.profiles.active}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n\r\nmanagement:\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: '*'\r\n      base-path: /actuator\r\n  endpoint:\r\n    health:\r\n      show-details: always\r\n    shutdown:\r\n      enabled: true\r\n```\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>2.7.9</version>\r\n        <relativePath/>\r\n    </parent>\r\n\r\n   <dependencies>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-server</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-server-ui</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-client</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.alibaba.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-actuator</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-security</artifactId>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n## 集成 SpringBootAdminClient\r\n\r\n:::info\r\n- 通过 `spring.boot.admin.client.instance.metadata` 来自定义要注册的元数据\r\n- 通过 `spring.boot.admin.client.instance.metadata.user` 来定义访问 `/actuator` 所需的用户名密码\r\n- 通过 `spring.boot.admin.client.username` 来定义 SpringBootAdminServer 所需的用户名\r\n- 通过 `spring.boot.admin.client.password` 来定义 SpringBootAdminServer 所需的密码\r\n:::\r\n\r\n```yml\r\nspring:\r\n  boot:\r\n    admin:\r\n      client:\r\n        url: http://asktrue.cn:8111\r\n        username: admin\r\n        password: password\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            application: ${spring.application.name}\r\n            environment: ${spring.profiles.active}\r\n            ip: ${spring.cloud.client.ip-address}\r\n            port: ${server.port}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-client</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n```\r\n\r\n## 按不同环境修改 SpringBootAdminClient 注册的实例名称\r\n\r\n:::info\r\n- 只能通过代码修改 `spring.boot.admin.client.instance.name` 属性来修改实例名称\r\n:::error\r\n- 直接在 `application.yml` 中修改 `spring.boot.admin.client.instance.name` 属性是无效的\r\n:::\r\n:::\r\n\r\n```java\r\n@Configuration\r\npublic class SBANameConfig implements ApplicationListener<ApplicationReadyEvent> {\r\n    @Value(\"${spring.application.name}\")\r\n    private String appName;\r\n    @Value(\"${spring.profiles.active:default}\")\r\n    private String active;\r\n\r\n    @PostConstruct\r\n    public void setAdminClientNameProperty() {\r\n        // 设置 System Property 让 SBA client 用自定义 name\r\n        System.setProperty(\"spring.boot.admin.client.instance.name\", appName + \"-[\" + active + \"]\");\r\n    }\r\n    @Override\r\n    public void onApplicationEvent(ApplicationReadyEvent event) {\r\n        // 这里也可以设置，保证启动后仍然有效\r\n        System.setProperty(\"spring.boot.admin.client.instance.name\", appName + \"-[\" + active + \"]\");\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 SpringBootAdmin",
      "lvl1": "部署 SpringBootAdminServer",
      "lvl2": "集成 SpringBootAdminClient",
      "lvl3": "按不同环境修改 SpringBootAdminClient 注册的实例名称"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 SpringBootAdmin",
      "date": "2025/05/15",
      "tags": [
        "SpringBoot",
        "SpringBootAdmin"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
    "path": "/blogs/yunweishouce/SpringBootjichengSpringBootAdminheArthasshixianyuanchengzhenduan.html",
    "url": "/blogs/yunweishouce/SpringBootjichengSpringBootAdminheArthasshixianyuanchengzhenduan.html",
    "content": "---\r\ntitle: SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断\r\ndate: 2025/05/15\r\ntags:\r\n - SpringBoot\r\n - SpringBootAdmin\r\n - Arthas\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 部署 arthas-tunnel-server\r\n2. SpringBoot 集成 arthas-spring-boot-starter\r\n3. 将 agent-id 注册到 SpringBootAdmin\r\n:::\r\n\r\n## 部署 arthas-tunnel-server\r\n\r\n:::tip\r\n- DockerHub 地址：https://hub.docker.com/repository/docker/jxch/arthas-tunnel-server/general\r\n- GitHub 地址：https://github.com/jxch-docker/docker-build/tree/main/arthas/tunnel\r\n:::\r\n\r\n```yml\r\nservices:\r\n  tunnel-server:\r\n    image: jxch/arthas-tunnel-server:4.0.5\r\n    ports:\r\n      - \"7777:7777\"\r\n      - \"10777:8080\"\r\n    environment:\r\n      - ARTHAS_TOKEN=token\r\n      - PASSWORD=password\r\n```\r\n\r\n## 集成 arthas-spring-boot-starter\r\n\r\n:::info\r\n- tunnelWeb 并非 arthas-spring-boot-starter 提供的字段，我的目的是把这个入口注册到 SpringBootAdminServer，这样就可以在 SBA Server 上直接进入远程诊断了\r\n- tunnelToken 是 arthas-spring-boot-starter 提供的字段，但并没有显示的 Java 属性，这个字段是必填的\r\n- tunnelServer 必须用 ws 地址\r\n:::\r\n\r\n```yml\r\narthas:\r\n  tunnelWeb: http://arthas-tunnel-server-ip-address:10777/\r\n  tunnelServer: ws://arthas-tunnel-server-ip-address:7777/ws\r\n  tunnelToken: ARTHAS_TOKEN\r\n  app-name: ${spring.application.name}\r\n  agent-id: ${spring.application.name}-${spring.cloud.client.ip-address:${server.address:127.0.0.1}}-${server.port}\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>com.taobao.arthas</groupId>\r\n            <artifactId>arthas-spring-boot-starter</artifactId>\r\n            <version>4.0.5</version>\r\n        </dependency>\r\n```\r\n\r\n## 集成 SpringBootAdminClient 并注册 agent-id\r\n\r\n:::info\r\n- 参考：[SpringBoot 集成 SpringBootAdmin](./SpringBoot集成SpringBootAdmin.md)\r\n- 把 agent-id 等信息通过元数据注册到 SpringBootAdminServer\r\n- 这样就可以在 SpringBootAdminServer 的 web 面板中直接进入远程诊断了\r\n:::\r\n\r\n```yml\r\nspring:\r\n  boot:\r\n    admin:\r\n      client:\r\n        url: http://asktrue.cn:8111\r\n        username: admin\r\n        password: password\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            application: ${spring.application.name}\r\n            environment: ${spring.profiles.active}\r\n            arthas-tunnel-server: ${arthas.tunnelWeb}\r\n            arthas-agent-id: ${arthas.agent-id}\r\n            ip: ${spring.cloud.client.ip-address}\r\n            port: ${server.port}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
      "lvl1": "部署 arthas-tunnel-server",
      "lvl2": "集成 arthas-spring-boot-starter",
      "lvl3": "集成 SpringBootAdminClient 并注册 agent-id"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
      "date": "2025/05/15",
      "tags": [
        "SpringBoot",
        "SpringBootAdmin",
        "Arthas"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "V2fly Shadowsocks 等翻墙服务部署",
    "path": "/blogs/yunweishouce/v2fly_shadowsocksdengfanqiangfuwubushu.html",
    "url": "/blogs/yunweishouce/v2fly_shadowsocksdengfanqiangfuwubushu.html",
    "content": "---\r\ntitle: V2fly Shadowsocks 等翻墙服务部署\r\ndate: 2025/03/08\r\ntags:\r\n - proxy\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: info\r\n替换一下各配置文件中的 uuid 就可以了\r\n:::\r\n\r\n## docker swarm 部署\r\n\r\n```yml\r\nservices:\r\n  shadowsocks: \r\n    image: shadowsocks/shadowsocks-libev \r\n    restart: unless-stopped\r\n    ports: \r\n      - 12346:12346\r\n      - 12346:12346/udp \r\n    configs: \r\n      - source: shadowsocks_config\r\n        target: /etc/shadowsocks-libev/config.json \r\n    environment:\r\n      - DNS_ADDRS=8.8.8.8,8.8.4.4\r\n    command: ss-server -c /etc/shadowsocks-libev/config.json \r\n  v2fly:\r\n    image: v2fly/v2fly-core\r\n    restart: unless-stopped\r\n    ports:\r\n      - 12345:12345\r\n    configs: \r\n      - source: v2fly_config\r\n        target: /etc/v2ray/config.json\r\n    entrypoint: [\"v2ray\", \"run\",  \"-c\", \"/etc/v2ray/config.json\"]\r\n\r\n\r\nconfigs:\r\n  shadowsocks_config:\r\n    file: /root/server/config/shadowsocks/config.json \r\n  v2fly_config:\r\n    file: /root/server/config/v2fly/config.json\r\n```\r\n\r\n## shadowsocks config.json\r\n\r\n```json\r\n{\r\n    \"server\":\"0.0.0.0\",\r\n    \"server_port\":12346,\r\n    \"password\":\"uuid\",\r\n    \"timeout\":3000,\r\n    \"method\":\"aes-256-gcm\",\r\n    \"fast_open\":false,\r\n    \"mode\":\"tcp_and_udp\"\r\n}\r\n\r\n```\r\n\r\n## v2fly config.json\r\n\r\n```json\r\n{\r\n    \"log\": {\r\n        \"access\": \"/var/log/v2ray/access.log\",\r\n        \"error\": \"/var/log/v2ray/error.log\",\r\n        \"loglevel\": \"warning\"\r\n    },\r\n    \"inbound\": {\r\n        \"port\": 12345,\r\n        \"protocol\": \"vmess\",\r\n        \"settings\": {\r\n            \"clients\": [\r\n                {\r\n                    \"id\": \"uuid\",\r\n                    \"level\": 1,\r\n                    \"alterId\": 0\r\n                }\r\n            ]\r\n        }\r\n    },\r\n    \"outbound\": {\r\n        \"protocol\": \"freedom\",\r\n        \"settings\": {}\r\n    },\r\n    \"inboundDetour\": [],\r\n    \"outboundDetour\": [\r\n        {\r\n            \"protocol\": \"blackhole\",\r\n            \"settings\": {},\r\n            \"tag\": \"blocked\"\r\n        }\r\n    ],\r\n    \"routing\": {\r\n        \"strategy\": \"rules\",\r\n        \"settings\": {\r\n            \"rules\": [\r\n                {\r\n                    \"type\": \"field\",\r\n                    \"ip\": [\r\n                        \"0.0.0.0/8\",\r\n                        \"10.0.0.0/8\",\r\n                        \"100.64.0.0/10\",\r\n                        \"127.0.0.0/8\",\r\n                        \"169.254.0.0/16\",\r\n                        \"172.16.0.0/12\",\r\n                        \"192.0.0.0/24\",\r\n                        \"192.0.2.0/24\",\r\n                        \"192.168.0.0/16\",\r\n                        \"198.18.0.0/15\",\r\n                        \"198.51.100.0/24\",\r\n                        \"203.0.113.0/24\",\r\n                        \"::1/128\",\r\n                        \"fc00::/7\",\r\n                        \"fe80::/10\"\r\n                    ],\r\n                    \"outboundTag\": \"blocked\"\r\n                }\r\n            ]\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "V2fly Shadowsocks 等翻墙服务部署",
      "lvl1": "docker swarm 部署",
      "lvl2": "shadowsocks config.json",
      "lvl3": "v2fly config.json"
    },
    "frontmatter": {
      "title": "V2fly Shadowsocks 等翻墙服务部署",
      "date": "2025/03/08",
      "tags": [
        "proxy"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 使用 Diskpart 永久固定 USB 盘符",
    "path": "/blogs/yunweishouce/WINshiyongDiskpartyongjiugudingUSBpanfu.html",
    "url": "/blogs/yunweishouce/WINshiyongDiskpartyongjiugudingUSBpanfu.html",
    "content": "---\r\ntitle: Windows 使用 Diskpart 永久固定 USB 盘符\r\ndate: 2025/03/05\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip Diskpart\r\n先执行 Diskpart 命令，进入 Diskpart 命令窗\r\n:::\r\n\r\n```powershell\r\n# 列出所有的硬盘\r\nlist volume\r\n\r\n# 选择需要操作的硬盘\r\nselect volume 6\r\n\r\n# 手动设置盘符\r\nassign letter=U\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 使用 Diskpart 永久固定 USB 盘符"
    },
    "frontmatter": {
      "title": "Windows 使用 Diskpart 永久固定 USB 盘符",
      "date": "2025/03/05",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 使用 NSSM 管理 Service",
    "path": "/blogs/yunweishouce/WINshiyongNSSMguanliService.html",
    "url": "/blogs/yunweishouce/WINshiyongNSSMguanliService.html",
    "content": "---\r\ntitle: Windows 使用 NSSM 管理 Service\r\ndate: 2025/06/29\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n- 安装：`winget install NSSM.NSSM`\r\n- 安装服务：`nssm install cloudflared-dns`\r\n  - 在弹出的对话框中\r\n    - Application path 添应用的绝对路径\r\n    - Startup dir 添 `win + r` 输入 `shell:startup` 回车后弹出的文件夹路径\r\n    - Arguments 填应用的启动参数\r\n    - 最后点击 Install service\r\n- 启动服务：`net start cloudflared-dns` 或 `Start-Service cloudflared-dns`\r\n- 检查服务状态： `Get-Service cloudflared-dns`\r\n- 修改服务参数：`nssm edit cloudflared-dns`\r\n- 卸载服务：`nssm remove cloudflared-dns confirm`\r\n\r\n:::info\r\n- 需要以管理员权限运行\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 使用 NSSM 管理 Service"
    },
    "frontmatter": {
      "title": "Windows 使用 NSSM 管理 Service",
      "date": "2025/06/29",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "WIN 安装 ANDROID 安卓子系统",
    "path": "/blogs/yunweishouce/WINanzhuangANDROIDanzhuozixitong.html",
    "url": "/blogs/yunweishouce/WINanzhuangANDROIDanzhuozixitong.html",
    "content": "---\r\ntitle: WIN 安装 ANDROID 安卓子系统\r\ndate: 2025/06/19\r\ntags:\r\n - Windows\r\n - Android\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n1. 打开链接 [https://store.rg-adguard.net/](https://store.rg-adguard.net/)\r\n2. 输入 `https://www.microsoft.com/store/productid/9p3395vx91nr`\r\n3. 选择 `slow`，点击 `√`\r\n4. `MicrosoftCorporationII.WindowsSubsystemForAndroid_1.8.32837.0_neutral_~_8wekyb3d8bbwe.msixbundle`，右键这个链接，复制链接地址，新建标签页，打开这个链接，开始下载\r\n5. 进入管理员模式 PS\r\n6. `Add-AppxPackage \"D:\\xicheng_jiang\\下载\\浏览器\\MicrosoftCorporationII.WindowsSubsystemForAndroid_1.8.32837.0_neutral___8wekyb3d8bbwe.Msixbundle\"`\r\n\r\n\r\n:::danger 安装过程中报错\r\n- 若报错则以同样的方式安装 `Microsoft.UI.Xaml.2.6_2.62112.3002.0_x64__8wekyb3d8bbwe.appx`，然后重试\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "WIN 安装 ANDROID 安卓子系统"
    },
    "frontmatter": {
      "title": "WIN 安装 ANDROID 安卓子系统",
      "date": "2025/06/19",
      "tags": [
        "Windows",
        "Android"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
    "path": "/blogs/yunweishouce/WINshezhiRoutezailianjieVPNdetongshibaochiduihulianwangdezhengchangfangwen.html",
    "url": "/blogs/yunweishouce/WINshezhiRoutezailianjieVPNdetongshibaochiduihulianwangdezhengchangfangwen.html",
    "content": "---\r\ntitle: Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问\r\ndate: 2025/03/08\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 操作方法\r\n\r\n1. `win+R` 输入 `ncpa.cpl`，按回车\r\n2. 右键需要操作的 VPN 设备，点击`属性`\r\n3. 点击`网络`选项卡，双击 `TCP/IPv4`，点击`高级`\r\n4. 取消勾选：`在远程网络上使用默认网关`\r\n5. 连接VPN\r\n6. 管理员模式打开 `powershell` 或 `cmd`\r\n7. 输入命令 `ipconfig /all` 回车，查看需要操作的VPN（如PPP连接）的IP地址，如`192.168.33.19`\r\n8. 添加永久静态路由：`route add 172.16.0.0 mask 255.255.0.0  192.168.33.19 -p` \r\n   - 将 `172.16.0.0` 网段，子网掩码为 `255.255.0.0` 的所有流量通过 `192.168.33.19` 接口访问，而 `192.168.33.19` 正是该VPN的接口\r\n\r\n::: info\r\n该方法的原理是，仅让特定网段的流量走VPN，其他流量依然走本地默认路由\r\n:::\r\n\r\n## Powershell 脚本\r\n\r\n```powershell\r\n# auto-vpn-route.ps1\r\n\r\nparam([String]$vpn, [String]$ip, [String]$mask)\r\n\r\n$vpn_ipv4 = (Get-NetIPAddress | Where-Object {$_.InterfaceAlias -eq $vpn}).IPAddress\r\n\r\nWrite-Host \"vpn: $vpn; vpn-ipv4: $vpn_ipv4\"\r\nIf([String]::IsNullOrEmpty($vpn_ipv4)) {\r\n    Write-Warning \"请连接 VPN：$vpn\"\r\n} Else {\r\n    Write-Host \"route delete $ip\" -ForegroundColor DarkGray\r\n    route delete $ip\r\n    Write-Host \"route add $ip mask $mask $vpn_ipv4\" -ForegroundColor DarkGray\r\n    route add $ip mask $mask $vpn_ipv4\r\n\r\n    If([String]::IsNullOrEmpty((route print | Select-String -Pattern \"\\s0.0.0.0\" | Select-String $vpn_ipv4))) {\r\n        Write-Host \"操作完成！可使用 route print | select-string $ip 查询路由表是否修改。\"\r\n    } Else {\r\n        Write-Host \"route delete $ip\" -ForegroundColor DarkGray\r\n        route delete $ip\r\n        Write-Warning \"请去控制面板关闭 $vpn 网卡的默认网关功能\" \r\n        Write-Warning \"参见：ncpa.cpl -> $vpn -> 属性 -> 网络 -> (TCP/IPv4) -> 高级 -> 在远程网络上使用默认网关\" \r\n        Write-Warning \"重新连接 $vpn\"\r\n    }\r\n}\r\n```\r\n\r\n```powershell\r\n.\\auto-vpn-route.ps1 -vpn 云开发 -ip 172.0.0.0 -mask 255.0.0.0\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
      "lvl1": "操作方法",
      "lvl2": "Powershell 脚本"
    },
    "frontmatter": {
      "title": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
      "date": "2025/03/08",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "JAVA 架构师学习笔记",
    "path": "/docs/architect/architect.html",
    "url": "/docs/architect/architect.html",
    "content": "---\r\ntitle: JAVA 架构师学习笔记\r\ndate: 2025/03/04\r\n---\r\n\r\n## 学习路径\r\n\r\n- 并发编程\r\n- 设计模式\r\n- JAVA反射、流式编程、编码规范\r\n- Spring、SpringBoot（核心启动流程、常见扩展点）\r\n- SpringCloud（微服务、分布式）\r\n- MySQL、MybatisPlus\r\n- 中间件（Redis、Sharding-Sphere、Zookeeper、RabbitMQ、Kafka、RocketMQ、Dubbo）\r\n- 网络编程（Netty）\r\n- JVM（内存模型、垃圾回收、GraalVM）\r\n- 性能调优（数据库、JVM、Tomcat）\r\n- MonoDB、ElasticSearch\r\n- clickhouse、Neo4j\r\n- Docker+K8S\r\n- 架构设计（DDD）\r\n- webflux\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JAVA 架构师学习笔记",
      "lvl1": "学习路径"
    },
    "frontmatter": {
      "title": "JAVA 架构师学习笔记",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "读书笔记",
    "path": "/docs/book/book.html",
    "url": "/docs/book/book.html",
    "content": "---\r\ntitle: 读书笔记\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "读书笔记"
    },
    "frontmatter": {
      "title": "读书笔记",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "日记",
    "path": "/docs/diary/diary.html",
    "url": "/docs/diary/diary.html",
    "content": "---\r\ntitle: 日记\r\npassword: b593bf97f44387eb6fdc629acef2d138\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "日记"
    },
    "frontmatter": {
      "title": "日记",
      "password": "b593bf97f44387eb6fdc629acef2d138",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "计算机技术栈",
    "path": "/docs/it/it.html",
    "url": "/docs/it/it.html",
    "content": "---\r\ntitle: 计算机技术栈\r\ndate: 2025/03/08\r\n---\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "计算机技术栈"
    },
    "frontmatter": {
      "title": "计算机技术栈",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "感谢打赏",
    "path": "/docs/others/donate.html",
    "url": "/docs/others/donate.html",
    "content": "---\r\ntitle: 感谢打赏\r\ndate: 2025/03/05\r\n---\r\n\r\n<div style=\"display: flex; justify-content: space-around; flex-wrap: wrap;\">\r\n    <img src=\"@source/docs/others/static/收款码-支付宝.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n    <img src=\"@source/docs/others/static/收款码-微信.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n    <img src=\"@source/docs/others/static/收款码-QQ.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n</div>\r\n\r\n::: info \r\n加入群聊一起交流哦！如有错误的地方，欢迎指正！\r\n\r\n<ul>\r\n    <li><a target=\"_blank\" href=\"http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=_8OK2fsmwKYXliSoqszUCHZ_RnMmcZsm&authKey=KEju9D76HcqTr3vuFLbdkamaqpGVYcvfo%2F%2BlLd04GucOwH0XnMZjeg0a0WUJ7OwQ&noverify=0&group_code=961215331\">架构师：961215331</a></li>\r\n    <li><a target=\"_blank\" href=\"http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=1CRaLYPuesGlWXEPQmqwmi2UsTgXebSz&authKey=EReo0mUHRG9%2FGdYsRLClzizP%2BcRIzQCVIIHjfMLUmX%2FpoV4RIoAnQBktkimpKqdD&noverify=0&group_code=966469984\">操盘手：966469984</a></li>\r\n</ul>\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "感谢打赏"
    },
    "frontmatter": {
      "title": "感谢打赏",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "诗集",
    "path": "/docs/poetry/poetry.html",
    "url": "/docs/poetry/poetry.html",
    "content": "---\r\ntitle: 诗集\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "诗集"
    },
    "frontmatter": {
      "title": "诗集",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "操盘手学习笔记",
    "path": "/docs/trader/trader.html",
    "url": "/docs/trader/trader.html",
    "content": "---\r\ntitle: 操盘手学习笔记\r\ndate: 2025/03/05\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "操盘手学习笔记"
    },
    "frontmatter": {
      "title": "操盘手学习笔记",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "交易笔记",
    "path": "/docs/trading_journal/trading_journal.html",
    "url": "/docs/trading_journal/trading_journal.html",
    "content": "---\r\ntitle: 交易笔记\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "交易笔记"
    },
    "frontmatter": {
      "title": "交易笔记",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-1",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-1.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-1.html",
    "content": "---\r\ntitle: 格言联璧-名句-1\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n> \r\n> <font color=\"orange\">静坐常思己过，闲谈莫论人非</font><br>\r\n> 怒是猛虎，欲是深渊<br>\r\n> <font color=\"orange\">鱼离水则身枯，心离书则神索</font><br>\r\n> <font color=\"orange\">修己以清心为要，涉世以慎言为先</font><br>\r\n> 谦，美德也，过谦者怀诈。默，懿行也，过默者藏奸<br>\r\n> <font color=\"orange\">天欲祸人，先以微福骄之；天欲福人，先以微祸儆之</font><br>\r\n> 日日行不怕千万里，常常做不怕千万事<br>\r\n> 对失意人，莫谈得意事。处得意日，莫忘失意时<br>\r\n> <font color=\"orange\">以情恕人，以理律己</font><br>\r\n> <font color=\"orange\">恶莫大于纵己之欲，祸莫大于言人之非</font><br>\r\n> 此生不学一可惜，此日闲过二可惜，此身一败三可惜<br>\r\n> 人之谤我也，与其能辩，不如能容；人之侮我也，与其能防，不如能化<br>\r\n> <font color=\"orange\">提得起，放得下，算得到，做得完，看得破，撇得开</font><br>\r\n> <font color=\"orange\">是非窝里，人用口，我用耳；热闹场中，人向前，我落后</font><br>\r\n> <font color=\"orange\">事有机缘，不先不后，刚刚凑巧。命若蹭蹬，走来走去，步步踏空</font><br>\r\n> 胆欲大，心欲小；智欲圆，行欲方<br>\r\n> <font color=\"orange\">事当快意时须转，言到快意时须住</font><br>\r\n> 不自重者取辱，不自畏者招祸，不自满者受益，不自是者博闻<br>\r\n> 读书即未成名，究竟人高品雅。修德不期获报，自然梦稳心安<br>\r\n> 以恕己之心恕人，则全交。以责人之心责己，则寡过<br>\r\n> 世人以七尺为性命，君子以性命为七尺<br>\r\n> 在古人之后议古人之失，则易；处古人之位为古人之事，则难<br>\r\n> 读未见书，如得良友；见已读书，如逢故人<br>\r\n> 事不可做尽，言不可道尽，势不可倚尽，福不可享尽<br>\r\n> <font color=\"orange\">不可吃尽，不可穿尽，不可说尽；又要洞得，又要做得，又要耐得</font><br>\r\n> <font color=\"orange\">有才而性缓，定属大才。有智而气和，斯为大智</font><br>\r\n> 何思何虑，居心当如止水；勿取勿忘，为学当如流水<br>\r\n> 案上不可多书，心中不可少书<br>\r\n> 辱人以不堪，必反辱；伤人以已甚，必反伤<br>\r\n> 无事时埋藏着许多小人，多事时识破了许多君子<br>\r\n> 不自反者，看不出一身病痛；不耐烦者，做不成一件事业<br>\r\n> 无心者公，无我者明<br>\r\n> 论人当节取其长，曲谅其短；做事必先审其害，后计其利<br>\r\n> 人好刚，我以柔胜之；人用术，我以诚感之；人使气，我以理屈之<br>\r\n> 盛喜中勿许人物，盛怒中勿答人书<br>\r\n> 不可不存时时可死之心，不可不行步步求生之事<br>\r\n> 见事贵乎理明，处事贵乎心公<br>\r\n> 气忌盛，心忌满，才忌露<br>\r\n> <font color=\"orange\">一念疏忽，是错起头。一念决裂，是错到底</font><br>\r\n> <font color=\"orange\">龙吟虎啸，凤翥鸾翔，大丈夫之气象</font><br>\r\n> <font color=\"orange\">缓事宜急干，敏则有功；急事宜缓办，忙则多错</font><br>\r\n> 直道事人，虚衷御物<br>\r\n> 小人乐闻君子之过，君子耻闻小人之恶<br>\r\n> <font color=\"orange\">不近人情，举足尽是危机；不体物情，一生俱成梦境</font><br>\r\n> <font color=\"orange\">心慎杂欲，则有余灵；目慎杂观，则有余明</font><br>\r\n> 眼界要阔，遍历名山大川；度量要宏，熟读五经诸史<br>\r\n> 步步占先者，必有人以挤之。事事争胜者，必有人以挫之<br>\r\n> <font color=\"orange\">顽石之中良玉隐焉，寒灰之中星火寓焉</font><br>\r\n> <font color=\"orange\">下手处是自强不息，成就处是至诚无息</font><br>\r\n> <font color=\"orange\">自责之外，无胜人之术。自强之外，无上人之术</font><br>\r\n>\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-1"
    },
    "frontmatter": {
      "title": "格言联璧-名句-1",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-2",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-2.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-2.html",
    "content": "---\r\ntitle: 格言联璧-名句-2\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 穷寇不可追也，遁辞不可攻也，贫民不可威也<br>\r\n> 见人不是，诸恶之根，见己不是，万善之门<br>\r\n> 热闹荣华之境，一过辄生凄凉。清真冷淡之为，历久愈有意味<br>\r\n> 古今来许多世家，无非积德。天地间第一人品，还是读书<br>\r\n> 善用威者不轻怒，善用恩者不妄施<br>\r\n> 事到手，且莫急，便要缓缓想；想到时，切莫缓，便要急急行<br>\r\n> 静以修身，俭以养德。入则笃行，出则友贤<br>\r\n> 作本色人，说根心话，干近情事<br>\r\n> <font color=\"orange\">知足常足，终身不辱；知止常止，终身不耻</font><br>\r\n> 怒如火，不遏则燎原；欲如水，不遏则滔天<br>\r\n> 不让古人，是谓有志；不让今人，是谓无量<br>\r\n> 读书为身上之用，而人以为纸上之用<br>\r\n> 执法如山，守身如玉，爱民如子，去蠹如仇<br>\r\n> 小人专望受人恩，受过辄忘；君子不轻受人恩，受则必报<br>\r\n> 书有未曾经我读，事无不可对人言<br>\r\n> 至乐无如读书，至要莫如教子<br>\r\n> <font color=\"orange\">福莫大于无祸，祸莫大于邀福</font><br>\r\n> 大智兴邦，不过集众思；大愚误国，只为好自用<br>\r\n> <font color=\"orange\">任难任之事，要有力而无气；处难处之人，要有知而无言</font><br>\r\n> 待小人宜宽，防小人宜严<br>\r\n> 无欲之谓圣，寡欲之谓贤，多欲之谓凡，徇欲之谓狂<br>\r\n> <font color=\"orange\">律己宜带秋气，处世须带春风</font><br>\r\n> 有真才者，必不矜才。有实学者，必不夸学<br>\r\n> 天下之势，以渐而成；天下之事，以积而居<br>\r\n> <font color=\"orange\">强不知以为知，此乃大愚；本无事而生事，是谓薄福</font><br>\r\n> 处逆境心，须用开拓法。处顺境心，要用收敛法<br>\r\n> 物忌全胜，事忌全美，人忌全盛<br>\r\n> 一时劝人以言，百世劝人以书<br>\r\n> <font color=\"orange\">有作用者，器宇定是不凡。有智慧者，才情决然不露</font><br>\r\n> 以虚养心，以德养身，以仁养天下万物，以道养天下万世<br>\r\n> <font color=\"orange\">心不欲杂，杂则神荡而不收；心不欲劳，劳则神疲而不入</font><br>\r\n> 对愁人勿乐，对哭人勿笑，对失意人勿矜<br>\r\n> 寡欲故静，有主则虚<br>\r\n> 必有容，德乃大；必有忍，事乃济<br>\r\n> 聪明者，戒太察。刚强者，戒太暴。温良者，戒无断<br>\r\n> 喜来时一检点，怒来时一检点，怠惰时一检点，放肆时一检点<br>\r\n> <font color=\"orange\">毋以小嫌疏至戚，毋以新怨忘旧恩</font><br>\r\n> 倚势欺人，势尽而为人欺；恃财侮人，财散而受人侮<br>\r\n> 彼之理是，我之理非，我让之；彼之理非，我之理是，我容之<br>\r\n> <font color=\"orange\">大着肚皮容物，立定脚跟做人</font><br>\r\n> <font color=\"orange\">闻恶不可遽怒，恐为谗人泄忿；闻善不可就亲，恐引奸人进身</font><br>\r\n> 炎凉之态，富贵其于贫贱；嫉妒之心，骨肉其于外人<br>\r\n> <font color=\"orange\">待人三自反，处世两如何</font><br>\r\n> 涵养冲虚，便是身世学问。省除烦恼，何等心性安和<br>\r\n> <font color=\"orange\">公生明，诚生明，从容生明</font><br>\r\n> 居安虑危，处治思乱<br>\r\n> 丈夫之高华，只在于道德气节。鄙夫之炫耀，但求诸服饰起居<br>\r\n> 古之君子病其无能也，学之；今之君子耻其无能也，讳之<br>\r\n> 身在天地后，心在天地前；身在万物中，心在万物上<br>\r\n> <font color=\"orange\">世事让三分，天空地阔。心田培一点，子种孙收</font><br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-2"
    },
    "frontmatter": {
      "title": "格言联璧-名句-2",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-3",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-3.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-3.html",
    "content": "---\r\ntitle: 格言联璧-名句-3\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> <font color=\"orange\">处事须留余地，责善切戒尽言</font><br>\r\n> 以耐事了天下之多事，以无心息天下之争心<br>\r\n> 读书贵能疑，疑乃可以启信。读书在有渐，渐乃克底有成<br>\r\n> 只是心不放肆，便无过差。只是心不怠忽，便无逸志<br>\r\n> 临事须替别人想，论人先将自己想<br>\r\n> <font color=\"orange\">以镜自照见形容，以心自照见吉凶</font><br>\r\n> 人性中不曾缺一物，人性上不可添一物<br>\r\n> 看书求理，须令自家胸中点头。与人谈理，须令人家胸中点头<br>\r\n> <font color=\"orange\">不为过三字，昧却多少良心；没奈何三字，抹却多少体面</font><br>\r\n> 静能制动，沈能制浮。宽能制褊，缓能制急<br>\r\n> 观天地生物气象，学圣贤克己工夫<br>\r\n> 贫贱是苦境，能善处者自乐；富贵是乐境，不善处者更苦<br>\r\n> 谈人之善，泽于膏沐；暴人之恶，痛于戈矛<br>\r\n> 人未己知，不可急求其知；人未己合，不可急与之合<br>\r\n> 勿施小惠伤大体，毋借公道遂私情<br>\r\n> 心志要苦，意趣要乐。气度要宏，言动要谨<br>\r\n> 勤能补拙，俭以养廉<br>\r\n> 尽前行者地步窄，向后看者眼界宽<br>\r\n> 阿谀取容，男子耻为妾妇之道。本真不凿，大人不失赤子之心<br>\r\n> 穷达有命，吉凶见人<br>\r\n> 省费医贫，恬退医躁，独卧医淫，随缘医愁，读书医俗<br>\r\n> 以鲜花视美色，则孽障自消；以流水听弦歌，则性灵何害<br>\r\n> 当厄之施甘于时雨，伤心之语毒于阴冰<br>\r\n> 能容小人是大人，能培薄德是厚德<br>\r\n> <font color=\"orange\">居处必先精勤，乃能闲暇。凡事务求停妥，然后逍遥</font><br>\r\n> <font color=\"orange\">毋毁众人之名，以成一己之善。毋没天下之理，以护一己之过</font><br>\r\n> <font color=\"orange\">实处着脚，稳处下手</font><br>\r\n> 兄弟争财，父遗不尽不止；妻妾争宠，夫命不死不休<br>\r\n> 盖世功劳，当不得一个“矜”字。弥天罪恶，当不得一个“悔”字<br>\r\n> 古之学者得一善言，附于其身；今之学者得一善言，务以悦人<br>\r\n> 万理澄彻，则一心愈精而愈谨。一心凝聚，则万理愈通而愈流<br>\r\n> 语言间尽可积德，妻子间亦是修身<br>\r\n> 吉凶祸福，是天主张。毁誉予夺，是人主张。主身行己，是我主张<br>\r\n> 位尊身危，财多命殆<br>\r\n> <font color=\"orange\">天下无不是的父母，世间最难得者兄弟</font><br>\r\n> 读书者不贱，力田者不饥。积德者不倾，择交者不败<br>\r\n> 天德只是个无我，王道只是个爱人<br>\r\n> <font color=\"orange\">真圣贤决非迂腐，真豪杰断不粗疏</font><br>\r\n> 防欲如挽逆水之舟，才歇手便下流。力行如缘无枝之树，才住脚便下坠<br>\r\n> 以仁义存心，以勤俭作家，以忍让接物<br>\r\n> <font color=\"orange\">恩怕先益后损，威怕先松后紧</font><br>\r\n> 无事时戒一“偷”字，有事时戒一“乱”字<br>\r\n> 律身惟廉为宜，处世以退为尚<br>\r\n> 俭则约，约则百善俱兴；侈则肆，肆则百恶俱纵<br>\r\n> <font color=\"orange\">欲理会七尺，先理会方寸；欲理会六合，先理会一腔</font><br>\r\n> 径路窄处，留一步与人行；滋味浓处，减三分让人嗜<br>\r\n> 飘风不可以调宫商，巧妇不可以主中馈，词章之士不可以治国家<br>\r\n> <font color=\"orange\">人褊急，我受之以宽宏；人险仄，我待之以坦荡</font><br>\r\n> 工于论人者，察己常阔疏；狃于讦直者，发言多弊病<br>\r\n> <font color=\"orange\">不蹈无人之室，不入有事之门，不处藏物之所</font><br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-3"
    },
    "frontmatter": {
      "title": "格言联璧-名句-3",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-4",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-4.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-4.html",
    "content": "---\r\ntitle: 格言联璧-名句-4\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 敬守此心，则心定；敛抑其气，则气平<br>\r\n> 富以能施为德，贫以无求为德，贵以下人为德，贱以忘势为德<br>\r\n> <font color=\"orange\">要得富贵福泽，天主张由不得我。要做贤人君子，我主张由不得天</font><br>\r\n> <font color=\"orange\">爱惜精神，留他日担当宇宙。蹉跎岁月，尽此身污秽乾坤</font><br>\r\n> 为善最乐，读书便佳<br>\r\n> <font color=\"orange\">富贵家不肯从宽，必遭横祸；聪明人不肯学厚，必殀天年</font><br>\r\n> <font color=\"orange\">海阔从鱼跃，天空任鸟飞</font><br>\r\n> 事以典故为据，故当博洽，不然臆说杜撰也<br>\r\n> 敬为千圣授受真源，慎乃百年提撕紧钥<br>\r\n> 祸到休愁，也要会救；福来休喜，也要会受<br>\r\n> 庙堂之上，以养正气为先；海宇之内，以养元气为本<br>\r\n> <font color=\"orange\">凡为外所胜者，皆内不足；凡为邪所夺者，皆正不足</font><br>\r\n> 只一事不留心，便有一事不得其理；只一物不留心，便有一物不得其所<br>\r\n> 古之从仕者养人，今之从仕者养己<br>\r\n> 未用兵时，全要虚心用人；既用兵时，全要实心活人<br>\r\n> <font color=\"orange\">治家严家乃和，居乡恕乡乃睦</font><br>\r\n> <font color=\"orange\">直不犯祸，和不害义</font><br>\r\n> 困辱非忧，取困辱为忧。荣利非乐，忘荣利为乐<br>\r\n> 接人要和中有介，处事要精中有果，认理要正中有道通<br>\r\n> 意粗性躁，一事无成。心平气和，千祥骈集<br>\r\n> <font color=\"orange\">喜闻人过，不若喜闻己过；乐道己善，何如乐道人善</font><br>\r\n> <font color=\"orange\">在事者，当置身利害之外；建言者，当设身利害之中</font><br>\r\n> 人属寒微，要思矜礼他，着不得一毫傲睨的气象<br>\r\n> 果决人似忙，心中常有余闲。因循人似闲，人中常有余忙<br>\r\n> 俗语近于市，纤语近于娼，诨语近于优<br>\r\n> <font color=\"orange\">岂能尽如人意，但求不愧我心</font><br>\r\n> 能改过，则天地不怒。能安分，则鬼神无权<br>\r\n> 居官先厚民风，处事先求大体<br>\r\n> 事属暖昧，要思回护他，着不得一点攻讦的念头<br>\r\n> 名誉自屈辱中彰，德量自隐忍中大<br>\r\n> <font color=\"orange\">荆棘满野，而望收嘉禾者愚；私念满胸，而欲求福应者悖</font><br>\r\n> 心术不可得罪于天地，言行要留好样与儿孙<br>\r\n> 肆傲者纳侮，诲过者长恶，贪利者害己，纵欲者戕生<br>\r\n> <font color=\"orange\">作恶事须防鬼神知，干好事莫怕旁人笑</font><br>\r\n> 作德日休，是谓福地；居易俟命，是谓洞天<br>\r\n> 藏书可以邀友，积德可以邀天<br>\r\n> <font color=\"orange\">于福作罪，其罪非轻；于苦作福，其福最大</font><br>\r\n> 洁己方能不失己，爱民所重在亲民<br>\r\n> 供人欣赏，侪风月于烟花，是曰亵天<br>\r\n> <font color=\"orange\">宇宙内事，乃己分内事；己分内事，乃宇宙内事</font><br>\r\n> 舍事功更无学问。求性道不外文章<br>\r\n> 事事难上难，举足常虞失坠；件件想一想，浑身都是过差<br>\r\n> 怒宜实力消融，过要细心检点<br>\r\n> 经济出自学问，经济方有本源；心性见之事功，心性方为圆满<br>\r\n> 逞我机锋，借诗书以戏谑，是名侮圣<br>\r\n> 罪莫大于亵天，恶莫大于无耻；苛刻心术之恶，过莫大于深险<br>\r\n> 衣垢不湔，器缺不补，对人犹有惭色<br>\r\n> <font color=\"orange\">盛者衰之始，福者祸之基</font><br>\r\n> 国家立法，不可不严。有司行法，不可不恕<br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-4"
    },
    "frontmatter": {
      "title": "格言联璧-名句-4",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-5",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-5.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-5.html",
    "content": "---\r\ntitle: 格言联璧-名句-5\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 古之名望相近则相得，今之名望相近则相妒<br>\r\n> 孝莫辞劳，转眼便为人父母；善因望报，回头但看尔儿孙<br>\r\n> 理欲交争，肺腑成为吴越。物我一体，参商终是兄弟<br>\r\n> 政令之所重者人才，国家之所重者元气<br>\r\n> 父母所欲为者，我继述之；父母所重念者，我亲厚之<br>\r\n> 兄弟和其中自乐，子孙贤此外何求<br>\r\n> 造物所忌，曰刻曰巧；万类相感，以诚以忠<br>\r\n> 入瑶树琼林中皆宝，有谦德仁心者为祥<br>\r\n> 行垢不湔，德缺不补，对天岂无愧心<br>\r\n> 内不欺己，外不欺人<br>\r\n> 何思何虑，居心当如止水；勿取勿忘，为学当如流水<br>\r\n> 存养宜冲粹，近春温；省察宜谨严，近秋肃<br>\r\n> 惩忿如摧山，窒欲如填壑；惩忿如救火，窒欲如防水<br>\r\n> 奢者富不足，俭者贫有余。奢者心常贫，贫者心常富<br>\r\n> 蚕茧蛛丝，蚁封蚓结，儿女子之经营<br>\r\n> 慎言动于妻子仆隶之间，检身人于食息起居之际<br>\r\n> 宽厚者，毋使人有所恃；精明者，不使人有所容<br>\r\n> 富儿因求宦倾赀，污吏以黩货失职<br>\r\n> 问消息于蓍龟，疑团空结；祈福祉于奥灶，奢想徒劳<br>\r\n> 圣贤学问是一套，行王道必本天德；后世学问是两截，不修己只管治人<br>\r\n> 理以心得为精，故当沈潜，不然耳边口头尔<br>\r\n> <font color=\"orange\">信不足则多言</font><br>\r\n> <font color=\"orange\">立党羽，不如昭信义</font><br>\r\n> 孝子百世之宗，仁人天下之命<br>\r\n> 圣人敛福，君子考祥；作德日休，为善最乐<br>\r\n> 听断之官，成心必不可有；任事之官，成算必不可无<br>\r\n> 做大官底是一样家数，做好人底是一样家数<br>\r\n> 知足常乐，能忍自安<br>\r\n> 休诿罪于气化，一切责之人事。休过望于世间，一切求之我身<br>\r\n> 亲兄弟析箸，璧合翻作瓜分。士大夫爱钱，书香化为铜臭<br>\r\n> <font color=\"orange\">一能胜千，君子不可无此小心。吾何畏彼，丈夫不可无此大志</font><br>\r\n> 安莫安于知足，危莫危于多言<br>\r\n> 人之心胸，多欲则窄，寡欲则宽<br>\r\n> <font color=\"orange\">惟有主，则天地万物自我而立；必无私，斯上下四旁咸得其平</font><br>\r\n> 茹素虽佛氏教也，好生非上天意乎<br>\r\n> 志之所趋，无远勿届，穷山距海，不能限也<br>\r\n> 对痴人莫说梦话，防所误也；见短人莫说矮话，避所忌也<br>\r\n> 有违言为信，践言为非信者<br>\r\n> 情爱过义，子孙之灾也<br>\r\n> 勤俭治家之本，忠孝齐家之本，谨慎保家之本，诗书起家之本，积善传家之本<br>\r\n> 饱肥甘衣轻暖，不知节者损福<br>\r\n> 广积聚骄富贵，不知止者杀身<br>\r\n> <font color=\"orange\">戒久睡，久睡倦神</font><br>\r\n> 慨夏畦之劳劳，秋毫无补；悯冬烘之贸贸，春恩广覃<br>\r\n> 四海和平之福，只是随缘。一生牵惹之劳，总因好事<br>\r\n> 口不妄言，君子所以存诚<br>\r\n> 志之所向，无坚不入，锐兵固甲，不能御也<br>\r\n> 天下无不可化之人，但恐诚心未至；天下无不可为之事，只怕立志不坚<br>\r\n> ",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-5"
    },
    "frontmatter": {
      "title": "格言联璧-名句-5",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "JAVA并发-设计模式",
    "path": "/docs/architect/concurrent/JAVAbingfa-shejimoshi.html",
    "url": "/docs/architect/concurrent/JAVAbingfa-shejimoshi.html",
    "content": "---\r\ntitle: JAVA并发-设计模式\r\ndate: 2025/04/22\r\n---\r\n\r\n- 终止线程的设计模式\r\n\t- Two-phase Termination（两阶段终止）模式：终止标志位\r\n- 避免共享的设计模式\r\n\t- Immutability模式：只读\r\n\t- Copy-on-Write模式：写时复制\r\n\t- Thread-Specific Storage 模式：线程本地存储 ThreadLocal\r\n- 多线程版本的 if 模式\r\n\t- Guarded Suspension 模式（Guarded Wait 模式、Spin Lock 模式）：一个线程需要等待另外的线程完成后继续下一步操作\r\n\t- Balking 模式：一个线程发现另一个线程已经做了某一件相同的事，那么本线程就无需再做了，直接结束返回\r\n- 多线程分工模式\r\n\t- Thread-Per-Message 模式：为每个任务分配一个独立的线程\r\n\t- Worker Thread 模式：线程池\r\n\t- 生产者-消费者模式：核心是一个任务队列\r\n\t\t- 过饱问题：生产者生产的速度大于消费者消费的速度\r\n\t\t\t- 消费者每天能处理的量比生产者生产的少：消费者加机器\r\n\t\t\t- 消费者每天能处理的量比生产者生产的多：适当的加大队列\r\n\t\t\t- 系统高峰期生产者速度太快：生产者限流\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JAVA并发-设计模式"
    },
    "frontmatter": {
      "title": "JAVA并发-设计模式",
      "date": "2025/04/22"
    },
    "type": "content"
  },
  {
    "title": "JVM-内存模型",
    "path": "/docs/architect/jvm/JVM-nacunmoxing.html",
    "url": "/docs/architect/jvm/JVM-nacunmoxing.html",
    "content": "---\r\ntitle: JVM-内存模型\r\ndate: 2025/03/04\r\n---\r\n\r\n::: tip 介绍\r\n1. JVM 内存模型\r\n2. JVM 内存核心参数\r\n3. 存调优案例\r\n:::\r\n\r\n## JVM 内存模型\r\n\r\n![JVM 内存模型](static/JVM-内存模型-内存模型.png)\r\n\r\n## JVM 内存核心参数\r\n\r\n![JVM 核心参数](static/JVM-内存模型-核心参数.png)\r\n\r\n- 关于元空间的JVM参数有两个：`-XX:MetaspaceSize=N` 和 `-XX:MaxMetaspaceSize=N`\r\n\t- `-XX:MaxMetaspaceSize` ： 设置元空间最大值， 默认是 -1， 即不限制， 或者说只受限于本地内存大小\r\n\t- `-XX:MetaspaceSize`： 指定元空间触发Fullgc的初始阈值(元空间无固定初始大小)， 以字节为单位，默认是21M，达到该值就会触发full gc进行类型卸载\r\n\t\t- 同时收集器会对该值进行调整： 如果释放了大量的空间， 就适当降低该值； 如果释放了很少的空间， 那么在不超过 `-XX:MaxMetaspaceSize`（如果设置了的话） 的情况下， 适当提高该值\r\n\t\t- 这个跟早期jdk版本的 `-XX:PermSize` 参数意思不一样，`-XX:PermSize` 代表永久代的初始容量\r\n\t- 由于调整元空间的大小需要Full GC，这是非常昂贵的操作，如果应用在启动的时候发生大量Full GC，通常都是由于永久代或元空间发生了大小调整，基于这种情况，一般建议在JVM参数中将 MetaspaceSize 和 MaxMetaspaceSize 设置成一样的值，并设置得比初始值要大，对于 8G 物理内存的机器来说，一般我会将这两个值都设置为 256M\r\n- `-Xss` 设置越小，说明一个线程栈里能分配的栈帧就越少，但是对 JVM 整体来说能开启的线程数会更多\r\n- 尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收\r\n\r\n## 内存调优案例\r\n\r\n![JVM 内存调优案例](static/JVM-内存模型-案例.png)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JVM-内存模型",
      "lvl1": "JVM 内存模型",
      "lvl2": "JVM 内存核心参数",
      "lvl3": "内存调优案例"
    },
    "frontmatter": {
      "title": "JVM-内存模型",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "JVM-常量池",
    "path": "/docs/architect/jvm/JVM-changliangchi.html",
    "url": "/docs/architect/jvm/JVM-changliangchi.html",
    "content": "---\r\ntitle: JVM-常量池\r\ndate: 2025/03/04\r\n---\r\n\r\n::: tip 介绍\r\n1. Class 常量池与运行时常量池\r\n2. 字符串常量池\r\n3. 八种基本类型的包装类和对象池\r\n:::\r\n\r\n## Class 常量池与运行时常量池\r\n\r\n- Class 常量池与运行时常量池（`javap -v Xxx.class` -> Constant pool）：常量池中主要存放字面量和符号引用\r\n\t- Class常量池可以理解为是Class文件中的资源仓库\r\n\t\t- Class文件中除了包含类的版本、字段、方法、接口等描述信息外， 还有一项信息就是常量池(constant pool table)，用于存放编译期生成的各种字面量(Literal)和符号引用(Symbolic References)\r\n\t- 字面量：就是指由字母、数字等构成的字符串或者数值常量\r\n\t\t- 字面量只可以右值出现，所谓右值是指等号右边的值，如：int a=1 这里的a为左值，1为右值\r\n\t- 符号引用：是编译原理中的概念，是相对于直接引用来说的\r\n\t\t- 主要包括了三类常量：类和接口的全限定名；字段的名称和描述符；方法的名称和描述符\r\n\t- 运行时常量池：这些常量池现在是静态信息，只有到运行时被加载到内存后，这些符号才有对应的内存地址信息，这些常量池一旦被装入内存就变成运行时常量池\r\n\t\t- 例如，compute()这个符号引用在运行时就会被转变为compute()方法具体代码在内存中的 地址，主要通过对象头里的类型指针去转换直接引用\r\n\r\n## 字符串常量池\r\n- 字符串常量池\r\n\t- 设计思想\r\n\t\t- 字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价，作为最基础的数据类型，大量频繁的创建字符串，极大程度地影响程序的性能\r\n\t\t- JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化\r\n\t\t\t- 为字符串开辟一个字符串常量池，类似于缓存区\r\n\t\t\t- 创建字符串常量时，首先查询字符串常量池是否存在该字符串\r\n\t\t\t- 存在该字符串，返回引用实例，不存在，实例化该字符串并放入池中\r\n\t- 三种字符串操作\r\n\t\t- 直接赋值字符串（指向常量池中的引用）：`String s = \"jxch\";`\r\n\t\t\t- 这种方式创建的字符串对象，只会在常量池中\r\n\t\t\t- 创建对象s的时候，JVM会先去常量池中通过 equals(key) 方法，判断是否有相同的对象\r\n\t\t\t\t- 如果有，则直接返回该对象在常量池中的引用\r\n\t\t\t\t- 如果没有，则会在常量池中创建一个新对象，再返回引用\r\n\t\t- `String s = new String(\"jxch\");` （指向内存中的对象引用）\r\n\t\t\t- 这种方式会保证字符串常量池和堆中都有这个对象，没有就创建，最后返回堆内存中的对象引用\r\n\t\t\t- 先检查字符串常量池中是否存在字符串\r\n\t\t\t\t- 不存在，先在字符串常量池里创建一个字符串对象；再去内存中创建一个字符串对象\r\n\t\t\t\t- 存在的话，就直接去堆内存中创建一个字符串对象\r\n\t\t\t- 最后，将内存中的引用返回\r\n\t\t- `intern` 方法是一个 native 的方法\r\n\t\t\t- 如果池已经包含一个等于此String对象的字符串（equals(oject)），则返回池中的字符串\r\n\t\t\t- 否则，将intern返回的引用指向当前字符串\r\n\t\t\t\t- 在 JDK 1.7 (及以上版本) 中，由于字符串池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象（字符串不存在时不再需要重新创建实例，可以直接指向堆上的实例）\r\n\t\t\t\t- jdk1.6版本需要将字符串复制到字符串常量池里\r\n\t- 常量池的位置\r\n\t\t- Jdk1.6及之前： 有永久代, 运行时常量池在永久代，运行时常量池包含字符串常量池\r\n\t\t- Jdk1.7：有永久代，但已经逐步“去永久代”，字符串常量池从永久代里的运行时常量池分离到堆里\r\n\t\t- Jdk1.8及之后： 无永久代，运行时常量池在元空间，字符串常量池里依然在堆里\r\n\t- 设计原理：类似 HashTable ，本质上是字符串对象的引用\r\n\r\n## 八种基本类型的包装类和对象池\r\n- 八种基本类型的包装类和对象池\r\n\t- java中基本类型的包装类的大部分都实现了常量池技术 (严格来说应该叫对象池，在堆上)\r\n\t- Byte,Short,Integer,Long,Character,Boolean （另外两种浮点数类型的包装类则没有实现对象池）\r\n\t- Byte,Short,Integer,Long,Character这5种整型的包装类也只是在对应值小于等于127时才可使用对象池\r\n\t\t- 即对象不负责创建和管理大于127的这些类的对象\r\n\t\t- 一般这种比较小的数用到的概率相对较大\r\n\r\n\r\n## 字符串常量池示例\r\n\r\n```java\r\nString s1 = new String(\"he\") + new String(\"llo\");\r\nString s2 = s1.intern();\r\n \r\nSystem.out.println(s1 == s2);\r\n// 在 JDK 1.6 下输出是 false，创建了 6 个对象\r\n// 在 JDK 1.7 及以上的版本输出是 true，创建了 5 个对象 \r\n// 当然我们这里没有考虑GC，但这些对象确实存在或存在过\r\n```\r\n\r\n![字符串常量池-JDK1.7+](static/JVM-常量池-字符串常量池-JDK1.7+.png)\r\n\r\n\r\n![字符串常量池-JDK1.6](static/JVM-常量池-字符串常量池-JDK1.6.png)\r\n\r\n```java\r\nString s0=\"zhuge\"; \r\nString s1=\"zhuge\"; \r\nString s2=\"zhu\" + \"ge\";\r\nSystem.out.println( s0==s1 ); //true \r\nSystem.out.println( s0==s2 ); //true\r\n\r\nString s0=\"zhuge\";\r\nString s1=new String(\"zhuge\");\r\nString s2=\"zhu\" + new String(\"ge\");\r\nSystem.out.println( s0==s1 ); // false \r\nSystem.out.println( s0==s2 )； // false \r\nSystem.out.println( s1==s2 ); // false\r\n\r\nString a = \"a1\";\r\nString b = \"a\" + 1;\r\nSystem.out.println(a == b); // true\r\nString a = \"atrue\";\r\nString b = \"a\" + \"true\";\r\nSystem.out.println(a == b); // true\r\nString a = \"a3.4\";\r\nString b = \"a\" + 3.4;\r\nSystem.out.println(a == b); // true\r\n\r\nString a = \"ab\"; \r\nString bb = \"b\"; \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // false 由于在字符串的\"+\"连接中，有字符串引用存在，而引用的值在程序编译期是无法确定的\r\n\r\nString a = \"ab\";\r\nfinal String bb = \"b\"; \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // true 对于final修饰的变量，它在编译时被解析为常量值的一个本地拷贝存储到自己的常量池中或嵌入到它的字节码流中\r\n\r\nprivate static String getBB() { return \"b\"; }\r\nString a = \"ab\";\r\nfinal String bb = getBB(); \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // false JVM对于字符串引用bb，它的值在编译期无法确定，只能在程序运行期调用方法后，将方法的返回值和\"a\"来动态连接并分配地址为b\r\n\r\nString str1 = new StringBuilder(\"ja\").append(\"va\").toString();\r\nSystem.out.println(str1 == str1.intern()); //false java是关键字，在JVM初始化的相关类里肯定早就放进字符串常量池了\r\n```\r\n\r\n::: info 注意\r\nString是不可变的\r\n:::\r\n\r\n```java\r\nString s = \"a\" + \"b\" + \"c\"; //就等价于String s = \"abc\";\r\nString a = \"a\";\r\nString b = \"b\";\r\nString c = \"c\";\r\nString s1 = a + b + c;\r\n\r\n// `s1` 这个就不一样了，可以通过观察其 `JVM` 指令码发现 `s1` 的 `+` 操作会变成如下操作\r\nStringBuilder temp = new StringBuilder(); \r\ntemp.append(a).append(b).append(c);\r\nString s = temp.toString();\r\n```\r\n\r\n## 包装类对象池示例\r\n\r\n```java\r\n //5种整形的包装类Byte,Short,Integer,Long,Character的对象，\r\n //在值小于127时可以使用对象池\r\n Integer i1 = 127; //这种调用底层实际是执行的Integer.valueOf(127)，里面用到了IntegerCache对象池 \r\n Integer i2 = 127;\r\n System.out.println(i1 == i2);//输出true\r\n \r\n //值大于127时，不会从对象池中取对象\r\n Integer i3 = 128;\r\n Integer i4 = 128;\r\n System.out.println(i3 == i4);//输出false\r\n \r\n //用new关键词新生成对象不会使用对象池\r\n Integer i5 = new Integer(127);\r\n Integer i6 = new Integer(127);\r\n System.out.println(i5 == i6);//输出false\r\n \r\n //Boolean类也实现了对象池技术\r\n Boolean bool1 = true;\r\n Boolean bool2 = true;\r\n System.out.println(bool1 == bool2);//输出true\r\n \r\n //浮点类型的包装类没有实现对象池技术\r\n Double d1 = 1.0;\r\n Double d2 = 1.0;\r\n System.out.println(d1 == d2);//输出false\r\n```\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JVM-常量池",
      "lvl1": "Class 常量池与运行时常量池",
      "lvl2": "字符串常量池",
      "lvl3": "八种基本类型的包装类和对象池",
      "lvl4": "字符串常量池示例",
      "lvl5": "包装类对象池示例"
    },
    "frontmatter": {
      "title": "JVM-常量池",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "1.基础",
    "path": "/docs/architect/kafka/Kafka-1.jichu.html",
    "url": "/docs/architect/kafka/Kafka-1.jichu.html",
    "content": "---\r\ntitle: 1.基础\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 核心组件\r\n- 配置文件\r\n- 基础命令\r\n- Topic\r\n- Kafka集群\r\n- Java客户端 & SpringBoot支持\r\n:::\r\n\r\n---\r\n## 核心组件\r\n\r\n\r\n| 名称            | 解释                                                                                                           |\r\n| ------------- | ------------------------------------------------------------------------------------------------------------ |\r\n| Broker        | 消息中间件处理节点，一个Kafka节点就是一个broker，一<br>个或者多个Broker可以组成一个Kafka集群                                                  |\r\n| Topic         | Kafka根据topic对消息进行归类，发布到Kafka集群的每条<br>消息都需要指定一个topic                                                          |\r\n| Producer      | 消息生产者，向Broker发送消息的客户端                                                                                        |\r\n| Consumer      | 消息消费者，从Broker读取消息的客户端                                                                                        |\r\n| ConsumerGroup | 每个Consumer属于一个特定的Consumer Group，一条消<br>息可以被多个不同的Consumer Group消费，但是一个<br>Consumer Group中只能有一个Consumer能够消费该消息 |\r\n| Partition     | 物理上的概念，一个topic可以分为多个partition，每个<br>partition内部消息是有序的                                                        |\r\n\r\n![核心组件](static/Kafka-基础-1.png)\r\n\r\n---\r\n## 配置文件\r\n\r\n- 配置：`server.properties`\r\n```properties\r\n#broker.id属性在kafka集群中必须要是唯一\r\nbroker.id=0\r\n#kafka部署的机器ip和提供服务的端口号\r\nlisteners=PLAINTEXT://192.168.65.60:9092\r\n#kafka的消息存储文件\r\nlog.dir=/usr/local/data/kafka‐logs\r\n#kafka连接zookeeper的地址\r\nzookeeper.connect=192.168.65.60:2181\r\n```\r\n- 默认配置\r\n\r\n| Property                   | Default                       | Description                                                                                                                                                      |\r\n| -------------------------- | ----------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |\r\n| broker.id                  | 0                             | 每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为<br>broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯<br>一的即可                                                                             |\r\n| log.dirs                   | /tmp/kafka-logs               | kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间<br>只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最<br>少partitions的路径下进行                                                                  |\r\n| listeners                  | PLAINTEXT://192.168.65.60:909 | server接受客户端连接的端口，ip配置kafka本机ip即可                                                                                                                                 |\r\n| zookeeper.connect          | localhost:2181                | zooKeeper连接字符串的格式为：hostname:port，此处hostname和<br>port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果<br>是集群，连接方式为 hostname1:port1, hostname2:port2, <br>hostname3:port3 |\r\n| log.retention.hours        | 168                           | 每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样                                                                                                                              |\r\n| num.partitions             | 1                             | 创建topic的默认分区数                                                                                                                                                    |\r\n| default.replication.factor | 1                             | 自动创建topic的默认副本数量，建议设置为大于等于2                                                                                                                                      |\r\n| min.insync.replicas        | 1                             | 当producer设置acks为-1时，min.insync.replicas指定replicas的最小<br>数目（必须确认每一个repica的写数据都是成功的），如果这个数目没<br>有达到，producer发送消息会产生异常                                              |\r\n| delete.topic.enable        | false                         | 是否允许删除主题                                                                                                                                                         |\r\n\r\n---\r\n## 基础命令\r\n\r\n- 启动：`kafka‐server‐start.sh ‐daemon server.properties`\r\n\t- ­`-daemon` 表示以后台进程运行，否则ssh客户端退出后，就会停止服务\r\n\t- 在启动kafka时会使用linux主机名关联的ip地址，所以需要把主机名和linux的ip映射配置到本地host里，用 `vim /etc/hosts`\r\n- 停止：`kafka‐server‐stop.sh`\r\n- 创建主题：当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创建\r\n\t- `kafka‐topics.sh ‐‐create ‐‐zookeeper 192.168.65.60:2181 ‐‐replication‐factor 1 ‐‐partitions 1 ‐‐topic test`\r\n\t- `kafka‐topics.sh ‐‐create ‐‐zookeeper 192.168.65.60:2181 ‐‐replication‐factor 1 ‐‐partitions 2 ‐‐topic test`\r\n\t- `kafka‐topics.sh ‐‐list ‐‐zookeeper 192.168.65.60:2181`\r\n- 查看Topic：`kafka‐topics.sh ‐‐describe ‐‐zookeeper 192.168.65.60:2181 ‐‐topic test`\r\n\t- 第一行是所有分区的概要信息，之后的每一行表示每一个pa",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础",
      "lvl1": "核心组件",
      "lvl2": "配置文件",
      "lvl3": "基础命令",
      "lvl4": "Topic",
      "lvl5": "Kafka集群",
      "lvl6": "Java客户端",
      "lvl7": "SpringBoot支持"
    },
    "frontmatter": {
      "title": "1.基础",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 4
  },
  {
    "title": "1.基础",
    "path": "/docs/architect/kafka/Kafka-1.jichu.html",
    "url": "/docs/architect/kafka/Kafka-1.jichu.html",
    "content": "rtition的信息\r\n\t- leader节点负责给定partition的所有读写请求\r\n\t- replicas 表示某个partition 在哪几个 broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出\r\n\t- isr 是replicas的一个子集，它只列出当前还存活着的，并且已同步备份了该partition的节点。leader的选举也是从ISR(in-sync replica)中进行的\r\n- 增加Topic的分区数量（目前不支持减少分区）：`kafka‐topics.sh ‐alter ‐‐partitions 3 ‐‐zookeeper 192.168.65.60:2181 ‐‐topic test`\r\n- 删除主题：`kafka‐topics.sh ‐‐delete ‐‐topic test ‐‐zookeeper 192.168.65.60:2181`\r\n- 发送消息：`kafka‐console‐producer.sh ‐‐broker‐list 192.168.65.60:9092 ‐‐topic test`\r\n- 消费消息：默认是消费最新的消息\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐topic test`\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐from‐beginning ‐‐topic test`\r\n- 消费多主题：`kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐whitelist \"test|test‐2\"`\r\n- 单播消费：只需让消费者在同一个消费组里即可\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐consumer‐property group.id=testGroup ‐‐topic test`\r\n- 多播消费：只要保证这些消费者属于不同的消费组即可\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐consumer‐property group.id=testGroup‐2 ‐‐topic test`\r\n- 生产消费集群消息\r\n\t- `kafka‐console‐producer.sh ‐‐broker‐list 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094 ‐‐topic my‐replicated‐topic`\r\n\t- `kafka‐console‐consumer.sh ‐‐bootstrap‐server 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094 ‐‐from‐beginning ‐‐topic my‐replicated‐topic`\r\n- 查看消费组名：`kafka‐consumer‐groups.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐list`\r\n- 查看消费组的消费偏移量：`kafka‐consumer‐groups.sh ‐‐bootstrap‐server 192.168.65.60:9092 ‐‐describe ‐‐group testGroup`\r\n\t- current-offset：当前消费组的已消费偏移量\r\n\t- log-end-offset：主题对应分区消息的结束偏移量(HW)\r\n\t- lag：当前消费组未消费的消息数\r\n---\r\n## Topic\r\n\r\n- 同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件\r\n\t- ![Topic](static/Kafka-基础-2.png)\r\n\t- Partition是一个有序的message序列，这些message按顺序添加到一个叫做commit log的文件中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message\r\n\t- 每个partition，都对应一个commit log文件。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的\r\n\t- kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响\r\n\t- 每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的。在kafka中，消费offset由consumer自己来维护；一般情况下我们按照顺序逐条消费commit log中的消息，当然可以通过指定offset来重复消费某些消息，或者跳过某些消息\r\n\t- 这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset\r\n- 对Topic下数据进行分区存储\r\n\t- commit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据\r\n\t- 提高并行度\r\n---\r\n## Kafka集群\r\n\r\n- kafka集群：一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量，只需要多启动几个broker实例即可\r\n\t- kafka将很多集群关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便\r\n- 集群消费\r\n\t- log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka集群支持配置一个partition备份的数量\r\n\t- 针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用\r\n\t- leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)。如果这个leader失效了，其中的一个follower将会自动的变成新的leader\r\n- Producers：生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round­-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多\r\n- Consumers：consumer group\r\n\t- queue 模式：consumer 位于同一个 consumer group 下\r\n\t- publish-subscribe 模式：consumer 有自己唯一的 consumer group\r\n\t- ![consumer group](static/Kafka-基础-3.png)\r\n- 消费顺序：一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序\r\n\t- Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性\r\n\t- 如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础",
      "lvl1": "核心组件",
      "lvl2": "配置文件",
      "lvl3": "基础命令",
      "lvl4": "Topic",
      "lvl5": "Kafka集群",
      "lvl6": "Java客户端",
      "lvl7": "SpringBoot支持"
    },
    "frontmatter": {
      "title": "1.基础",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 4
  },
  {
    "title": "1.基础",
    "path": "/docs/architect/kafka/Kafka-1.jichu.html",
    "url": "/docs/architect/kafka/Kafka-1.jichu.html",
    "content": "消费很少用\r\n\t- consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息\r\n---\r\n## Java客户端\r\n\r\n- 绑定Kafka服务器\r\n```java\r\nProperties props = new Properties();\r\nprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094\");\r\n// 生产者\r\nProducer<String, String> producer = new KafkaProducer<String, String>(props);\r\n// 消费者\r\nKafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);\r\n```\r\n- 生产者配置\r\n```java\r\n/* \r\n * 发出消息持久化机制参数\r\n * acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息\r\n * acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入，就可以继续发送下一条消息\r\n *          如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失\r\n * acks=‐1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志\r\n *                这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置\r\n */\r\nprops.put(ProducerConfig.ACKS_CONFIG, \"1\");\r\n// 发送失败重试次数，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，需要接收者做好消息接收的幂等性处理\r\nprops.put(ProducerConfig.RETRIES_CONFIG, 3);\r\n// 重试间隔设置，默认重试间隔100ms\r\nprops.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);\r\n// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB\r\nprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);\r\n// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去\r\nprops.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);\r\n/* \r\n * batch最大的延迟发送时间\r\n * 默认值是0：意思就是消息必须立即被发送，但这样会影响性能\r\n * 一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去\r\n * 如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长\r\n * \r\n *  消息 -> 本地缓冲区（32M）-> batch（16k）-> 发送（10ms batch不满也发送）\r\n */\r\nprops.put(ProducerConfig.LINGER_MS_CONFIG, 10);\r\n// 把发送的key和value从字符串序列化为字节数组\r\nprops.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\r\nprops.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\r\n```\r\n- 生产者发送消息：指定分区；不指定分区；同步；异步\r\n```java\r\n// 指定发送分区\r\nvar producerRecord = new ProducerRecord<String, String>(TOPIC_NAME, 0, key_json, value_json);\r\n// 未指定发送分区，具体发送的分区计算公式：hash(key) % partitionNum\r\nvar producerRecord = new ProducerRecord<String, String>(TOPIC_NAME, key_json, value_json);\r\n// 等待消息发送成功的同步阻塞方法\r\nRecordMetadata metadata = producer.send(producerRecord).get();\r\n// 异步回调方式发送消息\r\nproducer.send(producerRecord, new Callback() {\r\n\tpublic void onCompletion(RecordMetadata metadata, Exception exception) {\r\n\t\t// 处理异常\r\n\t}\r\n});\r\n// 关闭\r\nproducer.close();\r\n```\r\n- 消费配置\r\n```java\r\n// 消费分组名\r\nprops.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);\r\n// 是否自动提交offset，默认就是true\r\nprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\r\n// 自动提交offset的间隔时间\r\nprops.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\r\n/* \r\n * 当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费\r\n * latest(默认) ：只消费自己启动之后发送到主题的消息\r\n * earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于 consumer.seekToBeginning(每次都从头开始消费)\r\n */\r\nprops.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\r\n// consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，这个时间可以稍微短一点\r\nprops.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);\r\n// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒\r\nprops.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);\r\n// 一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点\r\nprops.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);\r\n// 如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费\r\nprops.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);\r\n// 把发送的key和value从字符串序列化为字节数组\r\nprops.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\nprops.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\n```\r\n- 消费者接收消息（topic）：指定分区；回溯（从头，指定offset）；拉取集合\r\n```java\r\n// 订阅Topic\r\nconsumer.subscribe(Arrays.asList(TOPIC_NAME));\r\n// 消费指定分区\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\n//",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础",
      "lvl1": "核心组件",
      "lvl2": "配置文件",
      "lvl3": "基础命令",
      "lvl4": "Topic",
      "lvl5": "Kafka集群",
      "lvl6": "Java客户端",
      "lvl7": "SpringBoot支持"
    },
    "frontmatter": {
      "title": "1.基础",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 4
  },
  {
    "title": "1.基础",
    "path": "/docs/architect/kafka/Kafka-1.jichu.html",
    "url": "/docs/architect/kafka/Kafka-1.jichu.html",
    "content": " 回溯消费（从头消费 - seekToBeginning）\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\nconsumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\n// 指定offset消费\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\nconsumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);\r\n// 从指定时间点开始消费 - 1小时前\r\nList<PartitionInfo> topicPartitions = consumer.partitionsFor(TOPIC_NAME);\r\nlong fetchDataTime = new Date().getTime() ‐ 1000 * 60 * 60;\r\nMap<TopicPartition, Long> map = new HashMap<>();\r\nfor (PartitionInfo par : topicPartitions) {\r\n\tmap.put(new TopicPartition(topicName, par.partition()), fetchDataTime);\r\n}\r\n// 遍历 value.offset(); 获取offset，然后指定offset消费\r\nMap<TopicPartition, OffsetAndTimestamp> parMap = consumer.offsetsForTimes(map);\r\n// 拉取消息集合\r\nConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\r\n```\r\n- 消费提交（offset）：同步；异步\r\n```java\r\n// 手动同步提交offset，当前线程会阻塞直到offset提交成功，一般使用同步提交，因为提交之后一般也没有什么逻辑代码了\r\nconsumer.commitSync();\r\n// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑\r\nconsumer.commitAsync(new OffsetCommitCallback() {\r\n\t@Override\r\n\tpublic void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception ex) {\r\n\t\t// 处理异常\r\n\t}\r\n});\r\n```\r\n---\r\n## SpringBoot支持\r\n\r\n- springboot配置application.yml\r\n```yml\r\nspring:\r\n\tkafka:\r\n\t\tbootstrap‐servers: 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094\r\n\t\tproducer:\r\n\t\t\tretries: 3\r\n\t\t\tbatch‐size: 16384\r\n\t\t\tbuffer‐memory: 33554432\r\n\t\t\tacks: 1\r\n\t\t\tkey‐serializer: org.apache.kafka.common.serialization.StringSerializer\r\n\t\t\tvalue‐serializer: org.apache.kafka.common.serialization.StringSerializer\r\n\t\tconsumer:\r\n\t\t\tgroup‐id: default‐group\r\n\t\t\tenable‐auto‐commit: false\r\n\t\t\tauto‐offset‐reset: earliest\r\n\t\t\tkey‐deserializer: xxx.StringDeserializer\r\n\t\t\tvalue‐deserializer: xxx.StringDeserializer\r\n\t\t\tlistener:\r\n\t\t\t\tack‐mode: manual_immediate\r\n```\r\n- ack‐mode\r\n\t- RECORD：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交\r\n\t- BATCH：当每一批poll()的数据被消费者监听器处理之后提交\r\n\t- TIME：当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交\r\n\t- COUNT：当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交\r\n\t- TIME | COUNT：有一个条件满足时提交\r\n\t- MANUAL：当每一批poll()的数据被消费者监听器处理之后, 手动调用Acknowledgment.acknowledge()后提交\r\n\t- MANUAL_IMMEDIATE：手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种（一次提交一条消息）\r\n- 生产者\r\n```java\r\n@Autowired\r\nprivate KafkaTemplate<String, String> kafkaTemplate;\r\nkafkaTemplate.send(TOPIC_NAME, 0, \"key\", \"this is a msg\");\r\n```\r\n- 消费者\r\n```java\r\n@KafkaListener(topics = \"my‐replicated‐topic\",groupId = \"zhugeGroup\")\r\npublic void listenZhugeGroup(ConsumerRecord<String, String> record, Acknowledgment ack) {\r\n\tString value = record.value();\r\n\tack.acknowledge();  //手动提交offset\r\n}\r\n\r\n// 配置多个消费组（再写一个消费组处理同一个topic）\r\n@KafkaListener(topics = \"my‐replicated‐topic\",groupId = \"tulingGroup\")\r\n\r\n// 配置多个topic，concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数\r\n@KafkaListener(groupId = \"testGroup\", topicPartitions = {\r\n\t@TopicPartition(topic = \"topic1\", partitions = {\"0\", \"1\"}),\r\n\t@TopicPartition(topic = \"topic2\", partitions = \"0\",\r\n\t\tpartitionOffsets = @PartitionOffset(partition = \"1\", initialOffset = \"100\"))\r\n},concurrency = \"6\")\r\n```\r\n---\r\n- Kafka事务\r\n```java\r\nProperties props = new Properties();\r\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\r\nprops.put(\"transactional.id\", \"my‐transactional‐id\");\r\nProducer<String, String> producer = new KafkaProducer<>(props, new StringSerializer(), new StringSerializer());\r\nproducer.initTransactions();      // 初始化事务\r\ntry {\r\n\tproducer.beginTransaction();  // 开启事务\r\n\tproducer.send(/*...*/);       // 发到不同的主题的不同分区\r\n\tproducer.commitTransaction(); // 提交事务\r\n} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {\r\n\tproducer.close();\r\n} catch (KafkaException e) {\r\n\tproducer.abortTransaction();  // 回滚事务\r\n}\r\nproducer.close();\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.基础",
      "lvl1": "核心组件",
      "lvl2": "配置文件",
      "lvl3": "基础命令",
      "lvl4": "Topic",
      "lvl5": "Kafka集群",
      "lvl6": "Java客户端",
      "lvl7": "SpringBoot支持"
    },
    "frontmatter": {
      "title": "1.基础",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 4,
    "contentParts": 4
  },
  {
    "title": "2.代码模板",
    "path": "/docs/architect/kafka/Kafka-2.daimamoban.html",
    "url": "/docs/architect/kafka/Kafka-2.daimamoban.html",
    "content": "---\r\ntitle: 2.代码模板\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 配置：`server.properties`\r\n- 绑定Kafka服务器\r\n- 生产者配置\r\n- 生产者发送消息\r\n- 消费配置\r\n- 消费者接收消息\r\n- 消费提交\r\n- springboot 集成\r\n    - ack‐mode\r\n    - 生产者 & 消费者\r\n- Kafka事务\r\n:::\r\n\r\n---\r\n\r\n## 配置：`server.properties`\r\n\r\n- 配置：`server.properties`\r\n```properties\r\n#broker.id属性在kafka集群中必须要是唯一\r\nbroker.id=0\r\n#kafka部署的机器ip和提供服务的端口号\r\nlisteners=PLAINTEXT://192.168.65.60:9092\r\n#kafka的消息存储文件\r\nlog.dir=/usr/local/data/kafka‐logs\r\n#kafka连接zookeeper的地址\r\nzookeeper.connect=192.168.65.60:2181\r\n```\r\n\r\n## 绑定Kafka服务器\r\n\r\n- 绑定Kafka服务器\r\n```java\r\nProperties props = new Properties();\r\nprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094\");\r\n// 生产者\r\nProducer<String, String> producer = new KafkaProducer<String, String>(props);\r\n// 消费者\r\nKafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);\r\n```\r\n\r\n## 生产者配置\r\n\r\n- 生产者配置\r\n```java\r\n/* \r\n * 发出消息持久化机制参数\r\n * acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息\r\n * acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入，就可以继续发送下一条消息\r\n *          如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失\r\n * acks=‐1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志\r\n *                这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置\r\n */\r\nprops.put(ProducerConfig.ACKS_CONFIG, \"1\");\r\n// 发送失败重试次数，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，需要接收者做好消息接收的幂等性处理\r\nprops.put(ProducerConfig.RETRIES_CONFIG, 3);\r\n// 重试间隔设置，默认重试间隔100ms\r\nprops.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 300);\r\n// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB\r\nprops.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);\r\n// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去\r\nprops.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);\r\n/* \r\n * batch最大的延迟发送时间\r\n * 默认值是0：意思就是消息必须立即被发送，但这样会影响性能\r\n * 一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去\r\n * 如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长\r\n * \r\n *  消息 -> 本地缓冲区（32M）-> batch（16k）-> 发送（10ms batch不满也发送）\r\n */\r\nprops.put(ProducerConfig.LINGER_MS_CONFIG, 10);\r\n// 把发送的key和value从字符串序列化为字节数组\r\nprops.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\r\nprops.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\r\n```\r\n\r\n## 生产者发送消息\r\n\r\n- 生产者发送消息：指定分区；不指定分区；同步；异步\r\n```java\r\n// 指定发送分区\r\nvar producerRecord = new ProducerRecord<String, String>(TOPIC_NAME, 0, key_json, value_json);\r\n// 未指定发送分区，具体发送的分区计算公式：hash(key) % partitionNum\r\nvar producerRecord = new ProducerRecord<String, String>(TOPIC_NAME, key_json, value_json);\r\n// 等待消息发送成功的同步阻塞方法\r\nRecordMetadata metadata = producer.send(producerRecord).get();\r\n// 异步回调方式发送消息\r\nproducer.send(producerRecord, new Callback() {\r\n\tpublic void onCompletion(RecordMetadata metadata, Exception exception) {\r\n\t\t// 处理异常\r\n\t}\r\n});\r\n// 关闭\r\nproducer.close();\r\n```\r\n\r\n## 消费配置\r\n\r\n- 消费配置\r\n```java\r\n// 消费分组名\r\nprops.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);\r\n// 是否自动提交offset，默认就是true\r\nprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\r\n// 自动提交offset的间隔时间\r\nprops.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, \"1000\");\r\n/* \r\n * 当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费\r\n * latest(默认) ：只消费自己启动之后发送到主题的消息\r\n * earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于 consumer.seekToBeginning(每次都从头开始消费)\r\n */\r\nprops.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\r\n// consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，这个时间可以稍微短一点\r\nprops.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);\r\n// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒\r\nprops.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10 * 1000);\r\n// 一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点\r\nprops.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);\r\n// 如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consume",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.代码模板",
      "lvl1": "配置：server.properties",
      "lvl2": "绑定Kafka服务器",
      "lvl3": "生产者配置",
      "lvl4": "生产者发送消息",
      "lvl5": "消费配置",
      "lvl6": "消费者接收消息",
      "lvl7": "消费提交",
      "lvl8": "springboot 集成",
      "lvl9": "Kafka事务"
    },
    "frontmatter": {
      "title": "2.代码模板",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "2.代码模板",
    "path": "/docs/architect/kafka/Kafka-2.daimamoban.html",
    "url": "/docs/architect/kafka/Kafka-2.daimamoban.html",
    "content": "r消费\r\nprops.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30 * 1000);\r\n// 把发送的key和value从字符串序列化为字节数组\r\nprops.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\nprops.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\r\n```\r\n\r\n## 消费者接收消息\r\n\r\n- 消费者接收消息（topic）：指定分区；回溯（从头，指定offset）；拉取集合\r\n```java\r\n// 订阅Topic\r\nconsumer.subscribe(Arrays.asList(TOPIC_NAME));\r\n// 消费指定分区\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\n// 回溯消费（从头消费 - seekToBeginning）\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\nconsumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\n// 指定offset消费\r\nconsumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME, 0)));\r\nconsumer.seek(new TopicPartition(TOPIC_NAME, 0), 10);\r\n// 从指定时间点开始消费 - 1小时前\r\nList<PartitionInfo> topicPartitions = consumer.partitionsFor(TOPIC_NAME);\r\nlong fetchDataTime = new Date().getTime() ‐ 1000 * 60 * 60;\r\nMap<TopicPartition, Long> map = new HashMap<>();\r\nfor (PartitionInfo par : topicPartitions) {\r\n\tmap.put(new TopicPartition(topicName, par.partition()), fetchDataTime);\r\n}\r\n// 遍历 value.offset(); 获取offset，然后指定offset消费\r\nMap<TopicPartition, OffsetAndTimestamp> parMap = consumer.offsetsForTimes(map);\r\n// 拉取消息集合\r\nConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\r\n```\r\n\r\n## 消费提交\r\n\r\n- 消费提交（offset）：同步；异步\r\n```java\r\n// 手动同步提交offset，当前线程会阻塞直到offset提交成功，一般使用同步提交，因为提交之后一般也没有什么逻辑代码了\r\nconsumer.commitSync();\r\n// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑\r\nconsumer.commitAsync(new OffsetCommitCallback() {\r\n\t@Override\r\n\tpublic void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception ex) {\r\n\t\t// 处理异常\r\n\t}\r\n});\r\n```\r\n---\r\n\r\n## springboot 集成\r\n\r\n- springboot配置application.yml\r\n```yml\r\nspring:\r\n\tkafka:\r\n\t\tbootstrap‐servers: 192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094\r\n\t\tproducer:\r\n\t\t\tretries: 3\r\n\t\t\tbatch‐size: 16384\r\n\t\t\tbuffer‐memory: 33554432\r\n\t\t\tacks: 1\r\n\t\t\tkey‐serializer: org.apache.kafka.common.serialization.StringSerializer\r\n\t\t\tvalue‐serializer: org.apache.kafka.common.serialization.StringSerializer\r\n\t\tconsumer:\r\n\t\t\tgroup‐id: default‐group\r\n\t\t\tenable‐auto‐commit: false\r\n\t\t\tauto‐offset‐reset: earliest\r\n\t\t\tkey‐deserializer: xxx.StringDeserializer\r\n\t\t\tvalue‐deserializer: xxx.StringDeserializer\r\n\t\t\tlistener:\r\n\t\t\t\tack‐mode: manual_immediate\r\n```\r\n\r\n### ack‐mode\r\n\r\n- ack‐mode\r\n\t- RECORD：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交\r\n\t- BATCH：当每一批poll()的数据被消费者监听器处理之后提交\r\n\t- TIME：当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交\r\n\t- COUNT：当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交\r\n\t- TIME | COUNT：有一个条件满足时提交\r\n\t- MANUAL：当每一批poll()的数据被消费者监听器处理之后, 手动调用Acknowledgment.acknowledge()后提交\r\n\t- MANUAL_IMMEDIATE：手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种（一次提交一条消息）\r\n\r\n### 生产者 & 消费者\r\n\r\n- 生产者\r\n```java\r\n@Autowired\r\nprivate KafkaTemplate<String, String> kafkaTemplate;\r\nkafkaTemplate.send(TOPIC_NAME, 0, \"key\", \"this is a msg\");\r\n```\r\n- 消费者\r\n```java\r\n@KafkaListener(topics = \"my‐replicated‐topic\",groupId = \"zhugeGroup\")\r\npublic void listenZhugeGroup(ConsumerRecord<String, String> record, Acknowledgment ack) {\r\n\tString value = record.value();\r\n\tack.acknowledge();  //手动提交offset\r\n}\r\n\r\n// 配置多个消费组（再写一个消费组处理同一个topic）\r\n@KafkaListener(topics = \"my‐replicated‐topic\",groupId = \"tulingGroup\")\r\n\r\n// 配置多个topic，concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数\r\n@KafkaListener(groupId = \"testGroup\", topicPartitions = {\r\n\t@TopicPartition(topic = \"topic1\", partitions = {\"0\", \"1\"}),\r\n\t@TopicPartition(topic = \"topic2\", partitions = \"0\",\r\n\t\tpartitionOffsets = @PartitionOffset(partition = \"1\", initialOffset = \"100\"))\r\n},concurrency = \"6\")\r\n```\r\n---\r\n\r\n## Kafka事务\r\n\r\n- Kafka事务\r\n```java\r\nProperties props = new Properties();\r\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\r\nprops.put(\"transactional.id\", \"my‐transactional‐id\");\r\nProducer<String, String> producer = new KafkaProducer<>(props, new StringSerializer(), new StringSerializer());\r\n\r\n// 初始化事务\r\nproducer.initTransactions();\r\ntry {\r\n\t// 开启事务\r\n\tproducer.beginTransaction();\r\n\t// 发到不同的主题的不同分区\r\n\tproducer.send(/*...*/);\r\n\r\n\t// 提交事务\r\n\tproducer.commitTransaction();\r\n} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {\r\n\tproducer.close();\r\n} catch (KafkaException e) {\r\n\t// 回滚事务\r\n\tproducer.abortTransaction();\r\n}\r\n// 关闭\r\nproducer.close();\r\n```\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.代码模板",
      "lvl1": "配置：server.properties",
      "lvl2": "绑定Kafka服务器",
      "lvl3": "生产者配置",
      "lvl4": "生产者发送消息",
      "lvl5": "消费配置",
      "lvl6": "消费者接收消息",
      "lvl7": "消费提交",
      "lvl8": "springboot 集成",
      "lvl9": "Kafka事务"
    },
    "frontmatter": {
      "title": "2.代码模板",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "3.设计原理",
    "path": "/docs/architect/kafka/Kafka-3.shejiyuanli.html",
    "url": "/docs/architect/kafka/Kafka-3.shejiyuanli.html",
    "content": "---\r\ntitle: 3.设计原理\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- Controller\r\n- Leader - Partition\r\n- Rebalance\r\n- 消息发布机制\r\n- HW与LEO\r\n- 日志分段\r\n- zookeeper\r\n:::\r\n\r\n---\r\n## Controller\r\n\r\n- Kafka核心总控制器Controller：在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态\r\n\t- 当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本\r\n\t- 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息\r\n\t- 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到\r\n- Controller选举机制\r\n\t- zookeeper临时节点的创建来选举controller：在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller\r\n\t- controller重新选举：当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker成为新的controller\r\n- 具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下\r\n\t- 监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker增减的变化\r\n\t- 监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作\r\n\t- 从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic所对应的Zookeeper中的/brokers/topics/\\[topic\\]节点添加PartitionModificationsListener，用来监听topic中的分区分配变化\r\n\t- 更新集群的元数据信息，同步到其他普通的broker节点中\r\n---\r\n## Leader - Partition\r\n\r\n- Partition副本选举Leader机制\r\n\t- controller感知到分区leader所在的broker挂了（controller监听了很多zk节点可以感知到broker存活）\r\n\t- controller会从ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR列表，可能是同步数据最多的副本)\r\n\t- 如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多\r\n- 副本进入ISR列表有两个条件\r\n\t- 必须能与zookeeper保持会话以及跟leader副本网络连通\r\n\t- 副本能复制leader上的所有写操作，并且不能落后太多\r\n\t\t- 与leader副本同步滞后的副本，是由 replica.lag.time.max.ms 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表\r\n- 消费者消费消息的offset记录机制\r\n\t- 每个consumer会定期将自己消费分区的offset提交给kafka内部topic：\\_\\_consumer_offsets\r\n\t\t- 提交过去的时候，key是consumerGroupId+topic+分区号，value就是当前offset的值\r\n\t\t- kafka会定期清理topic里的消息，最后就保留最新的那条数据\r\n\t- 因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发\r\n---\r\n## Rebalance\r\n\r\n- Rebalance分区分配策略（partition.assignment.strategy）：range（默认）、round-robin、sticky\r\n\t- range：按照分区序号排序，比如分区0~3给一个consumer，分区4~6给一个consumer，分区7~9给一个consumer\r\n\t- round-robin：轮询分配，比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer\r\n\t- sticky：与round-robin类似，但是在rebalance的时候，需要保证如下两个原则（当两者发生冲突时，第一个目标优先于第二个目标）\r\n\t\t- 分区的分配要尽可能均匀\r\n\t\t- 分区的分配尽可能与上次分配的保持相同\r\n- Rebalance机制：如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。比如consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他\r\n\t- rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进行rebanlance\r\n\t- rebalance过程中，消费者无法从kafka消费消息，这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生\r\n- 触发消费者rebalance\r\n\t- 消费组里的consumer增加或减少了\r\n\t- 动态给topic增加了分区\r\n\t- 消费组订阅了更多的topic\r\n- Rebalance过程：当有消费者加入消费组时，消费者、消费组及组协调器之间会经历以下几个阶段\r\n\t1. 选择组协调器（GroupCoordinator）：每个consumer group都会选择一个broker作为自己的组协调器coordinator，负责监控这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance\r\n\t\t- consumer group中的每个consumer启动时会向kafka集群中的某个节点发送FindCoordinatorRequest请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接\r\n\t\t- 组协调器选择方式：通过如下公式可以选出consumer消费的offset要提交到__consumer_offsets的哪个分区，这个分区le",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.设计原理",
      "lvl1": "Controller",
      "lvl2": "Leader - Partition",
      "lvl3": "Rebalance",
      "lvl4": "消息发布机制",
      "lvl5": "HW与LEO",
      "lvl6": "日志分段"
    },
    "frontmatter": {
      "title": "3.设计原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "3.设计原理",
    "path": "/docs/architect/kafka/Kafka-3.shejiyuanli.html",
    "url": "/docs/architect/kafka/Kafka-3.shejiyuanli.html",
    "content": "ader对应的broker就是这个consumer group的coordinator。说白了，leader分区所在的节点就是GroupCoordinator\r\n\t1. 加入消费组（JOIN GROUP），选择消费组协调器\r\n\t\t1. 在成功找到消费组所对应的 GroupCoordinator 之后就进入加入消费组的阶段，在此阶段的消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求，并处理响应。\r\n\t\t2. 然后GroupCoordinator 从一个consumer group中选择第一个加入group（第一个与GroupCoordinator连接的consumer）的consumer作为leader(消费组协调器)\r\n\t\t3. 把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案\r\n\t2. SYNC GROUP\r\n\t\t1. consumer leader通过给GroupCoordinator发送SyncGroupRequest\r\n\t\t2. 接着GroupCoordinator就把分区方案下发给各个consumer，他们会根据指定分区的leader broker进行网络连接以及消息消费\r\n\r\n![Rebalance](static/Kafka-设计原理-1.png)\r\n\r\n---\r\n## 消息发布机制\r\n\r\n- producer发布消息机制\r\n\t- 写入方式：producer 采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）\r\n\t- 消息路由：producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition\r\n\t\t1. 指定了 patition，则直接使用\r\n\t\t2. 指定 patition 但指定 key，通过对 key 的 value 进行 hash 选出一个 patition \r\n\t\t3. patition 和 key 都未指定，使用轮询选出一个 patition\r\n\t- 写入流程\r\n\t\t1. producer 先从 zookeeper 的 \"/brokers/.../state\" 节点找到该 partition 的 leader \r\n\t\t2. producer 将消息发送给该 leader \r\n\t\t3. leader 将消息写入本地 log \r\n\t\t4. followers 从 leader pull 消息，写入本地 log 后向leader 发送 ACK\r\n\t\t5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK\r\n\r\n![消息发布机制](static/Kafka-设计原理-2.png)\r\n\r\n---\r\n## HW与LEO\r\n\r\n- HW：HW俗称高水位，HighWatermark的缩写，取一个partition对应的ISR中最小的LEO(log-end-offset)作为HW，consumer最多只能消费到HW所在的位置。\r\n\t- 每个replica都有HW，leader和follower各自负责更新自己的HW的状态。\r\n\t- 对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，消息才能被consumer消费。\r\n\t- 这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。\r\n\t- 对于来自内部broker的读取请求，没有HW的限制\r\n- 当producer生产消息至broker后，ISR以及HW和LEO的流转过程\r\n\t- ![HW](static/Kafka-设计原理-3.png)\r\n- Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制，很好的均衡了确保数据不丢失以及吞吐率\r\n- 当 acks=1\r\n\t- ![acks=1](static/Kafka-设计原理-4.png)\r\n\r\n---\r\n## 日志分段\r\n\r\n- 日志分段存储：Kafka 一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，消息在分区内是分段(segment)存储，每个段的消息都存储在不一样的log文件里，这种特性方便old segment file快速被删除，kafka规定了一个段位的 log 文件最大为 1G，做这个限制目的是为了方便把 log 文件加载到内存去操作\r\n\t- 00000000000000000000.index：部分消息的offset索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件\r\n\t\t- 如果要定位消息的offset会先在这个文件里快速定位，再去log文件里找具体消息\r\n\t- 00000000000000000000.log：消息存储文件，主要存offset和消息体\r\n\t- 00000000000000000000.timeindex：息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件\r\n\t\t- 如果需要按照时间来定位消息的offset，会先在这个文件里查找\r\n\t- 文件名00000000000000000000就是表了这个日志段文件里包含的起始 Offset\r\n- log.segment.bytes：限定了每个日志段文件的大小，最大就是 1GB\r\n\t- 一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做log rolling，正在被写入的那个日志段文件，叫做 active log segment。\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.设计原理",
      "lvl1": "Controller",
      "lvl2": "Leader - Partition",
      "lvl3": "Rebalance",
      "lvl4": "消息发布机制",
      "lvl5": "HW与LEO",
      "lvl6": "日志分段"
    },
    "frontmatter": {
      "title": "3.设计原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "4.优化",
    "path": "/docs/architect/kafka/Kafka-4.youhua.html",
    "url": "/docs/architect/kafka/Kafka-4.youhua.html",
    "content": "---\r\ntitle: 4.优化\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 环境规划\r\n- 线上问题\r\n- Kafka事务\r\n- Kafka高性能原因\r\n:::\r\n\r\n---\r\n## 环境规划\r\n\r\n- Kafka可视化管理工具：kafka-manager\r\n- 线上环境规划\r\n\t- ![环境规划](static/Kafka-优化-1.png)\r\n- JVM参数设置：bin/kafka-start-server.sh 中的jvm设置\r\n\t- `export KAFKA_HEAP_OPTS=\"‐Xmx16G ‐Xms16G ‐Xmn10G ‐XX:MetaspaceSize=256M ‐XX:+UseG1GC ‐XX:MaxGCPauseMillis=50 ‐XX:G1HeapRegionSize=16M\"`\r\n\t- 这种大内存的情况一般都要用G1垃圾收集器，因为年轻代内存比较大，用G1可以设置GC最大停顿时间，不至于一次minor gc就花费太长时间，当然，因为像kafka，rocketmq，es这些中间件，写数据到磁盘会用到操作系统的page cache，所以JVM内存不宜分配过大，需要给操作系统的缓存留出几个G\r\n---\r\n## 线上问题\r\n\r\n- 消息丢失\r\n\t- 发送端：acks 设置\r\n\t- 消费端：如果消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但是此时你consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了\r\n- 重复消费：一般消费端都是要做消费幂等处理的\r\n\t- 发送端：发送消息如果配置了重试机制，比如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息\r\n\t- 消费端：如果消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理\r\n- 消息乱序\r\n\t- 如果发送端配置了重试机制，kafka不会等之前那条消息完全发送成功才去发送下一条消息，这样可能会出现，发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了\r\n\t\t- 是否一定要配置重试要根据业务情况而定。也可以用同步发送的模式去发消息，当然acks不能设置为0\r\n\t- kafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但是这种性能比较低\r\n\t\t- 可以在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列(可以搞多个)，一个内存队列开启一个线程顺序处理消息\r\n- 消息积压\r\n\t- 线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致broker积压大量未消费消息\r\n\t\t- 如果积压了上百万未消费消息需要紧急处理，可以修改消费端程序，让其将收到的消息快速转发到其他topic(可以设置很多分区)，然后再启动多个消费者同时消费新主题的不同分区\r\n\t- 由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息\r\n\t\t- 可以将这些消费不成功的消息转发到其它队列里去(类似死信队列)，后面再慢慢分析死信队列里的消息处理问题\r\n- 延时队列：消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费\r\n\t- 发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中（topic_1s，topic_5s，topic_10s，...topic_2h，这个一般不能支持任意时间段的延时）\r\n\t- 通过定时器进行轮训消费这些topic，查看消息是否到期，如果到期就把这个消息发送到具体业务处理的topic中\r\n\t- 队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，如果到了就转发，如果还没到这一次定时任务就可以提前结束了\r\n- 消息回溯：对之前已消费的消息重新消费\r\n\t- 如果某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费\r\n\t- 可以指定从多久之前的消息回溯消费，这种可以用consumer的offsetsForTimes、seek等方法指定从某个offset偏移的消息开始消费\r\n- 分区数与吞吐量：一般情况分区数跟集群机器数量相当就差不多了\r\n\t- `kafka‐producer‐perf‐test.sh ‐‐topic test ‐‐num‐records 1000000 ‐‐record‐size 1024 ‐‐throughput ‐1 ‐‐producer‐props bootstrap.servers=192.168.65.60:9092 acks=1`\r\n\t- 往test里发送一百万消息，每条设置1KB，throughput 用来进行限流控制，当设定的值小于 0 时不限流，当设定的值大于 0 时，当发送的吞吐量大于该值时就会被阻塞一段时间\r\n\t- 如果分区数设置过大，比如设置10000，可能会设置不成功，后台会报错\"java.io.IOException : Too many open files\"\r\n\t\t- `ulimit -n 65535` 调大文件描述符\r\n- 消息传递保障\r\n\t- at most once（消费者最多收到一次消息，0-1次）：acks = 0 可以实现\r\n\t- at least once（消费者至少收到一次消息，1-多次）：ack = all 可以实现\r\n\t- exactly once（消费者刚好收到一次消息）：at least once 加上消费者幂等性可以实现，还可以用kafka生产者的幂等性来实现\r\n\t\t- kafka生产者的幂等性：因为发送端重试导致的消息重复发送问题，kafka的幂等性可以保证重复发送的消息只接收一次\r\n\t\t\t- 只需在生产者加上参数 `props.put(\"enable.idempotence\", true)` 即可，默认是 false 不开启\r\n\t\t\t- 具体实现原理是，kafka每次发送消息会生成PID和Sequence Number，并将这两个属性一起发送给broker，broker会将PID和Sequence Number跟消息绑定一起存起来，下次如果生产者重发相同消息，broker会检查PID和Sequence Number，如果相同不会再接收\r\n\t\t\t\t- PID：每个新的 Producer 在初始化的时候会被分配一个唯一的 PID，这个PID 对用户完全是透明的。生产者如果重启则会生成新的PID\r\n\t\t\t\t- Sequence Number：对于每个 PID，该 Producer 发送到每个 Partition 的数据都有对应的序列号，这些序列号是从0开始单调递增的\r\n\t\t\t- 但是它只保证了生产者的幂等性，没保证消费者的幂等性，所以保险起见还是要再消费端考虑幂等性的问题\r\n---\r\n## Kafka事务\r\n\r\n- kafka的事务：保障一次发送多条消息的事务一致性（流式计算场景）\r\n\t- Kafka的事务不同于Rocketmq，Rocketmq是保障本地事务(比如数据库)与mq消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性(要么同时成功要么同时失败)\r\n\t- 一般在kafka的流式计算场景用得多一点，比如，kafka需要对一个topic里的消息做不同的流式计算处理，处理完分别发到不同的topic里，这些topic分别被不同的下游系统消费(比如hbase，redis，es等)，这种我们肯定希望系统发送到多个topic的数据保持事务一致性。Kafka要实现类似Rocketmq的分布式事务需要额外开发功能\r\n```java\r\nProperties props = new Properties();\r\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\r\nprops.put(\"transactional.id\", \"my‐transactional‐id\");\r\nProducer<String, String> producer = new KafkaProducer<>(props, new StringSerializer(), new StringSerializer());\r\n\r\n// 初始化事务\r\nproducer.initTransactions();\r\ntry {\r\n\t// 开启事务\r\n\tproducer.beginTransaction();\r\n\t// 发到不同的主题的不同分区\r\n\tproducer.send(/*...*/);\r\n\r\n\t// 提交事务\r\n\tproducer.commitTransaction();\r\n} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {\r\n\tproducer.close();\r\n} catch (KafkaException e) {\r\n\t// 回滚事务\r\n\tproducer.abortTransaction();\r\n}\r\n// 关闭\r\nproducer.close();\r\n```\r\n---\r\n## Kafka高性能原因\r\n\r\n- kafka高性能的原因\r\n\t- 磁盘顺序读写：kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾，不会写入文件中的某个位置(随机写)保证了磁盘顺序写\r\n\t- 读写数据的批量batch处理以及压缩传输\r\n\t- 数据传输的零拷贝\r\n\t\t- ![零拷贝](static/Kafka-优化-2.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.优化",
      "lvl1": "环境规划",
      "lvl2": "线上问题",
      "lvl3": "Kafka事务",
      "lvl4": "Kafka高性能原因"
    },
    "frontmatter": {
      "title": "4.优化",
      "date": "2025/07/03"
    },
    "type": "content"
  },
  {
    "title": "1.生态",
    "path": "/docs/architect/hadoop/Hadoop-1.shengtai.html",
    "url": "/docs/architect/hadoop/Hadoop-1.shengtai.html",
    "content": "---\r\ntitle: 1.生态\r\ndate: 2025/07/01\r\n---\r\n\r\n## Hadoop 背景\r\n\r\n其实最先被这些问题困惑的并不是电商，而是 google，他需面对的挑战一点也不会比电商小\r\n* 大量的网页怎么存储\r\n* 面对的数据和计算难题\r\n\r\n2003，2004 年 Google\r\n* GFS\r\n* MapReduce\r\n\r\n为了解决上面的两大难题，google 提出了自己的简介方案，当然这解决方案是闭源的，另外\r\n还提出了两篇论文，为大量数据的存储与计算问题提供了思路。\r\n\r\n---\r\n\r\n## Hadoop 生态\r\n[Hadoop 是 apache 下面的一套开源软件平台](http://hadoop.apache.org/)\r\n\r\nHadoop 的功能：利用服务器的集群，根据用户的业务逻辑对海里信息进行处理（存储与计算）\r\nHadoop 的核心组件:\r\n* HDFS(分布式文件系统)\r\n* MAPREDUCE(分布式运行系统)\r\n* YARN(运算资源调度系统)\r\n以上就是 hadoop 最核心的部分，可是随着时间的推移，hadoop 已经不只是这些技术了，它慢慢进化成了一个生态圈\r\n\r\n![Hadoop 生态](static/生态.png)\r\n\r\n---\r\n\r\n## Hadoop 起源\r\n* Hadoop 最初是由 Apache Lucene 项目的创始人 Doug Cutting 开发的文本搜索库。Hadoop 源自始于 2002 年的 Apache Nutch 项目——一个开源的网络搜索引擎并且也是 Lucene 项目的一部分\r\n* 2004 年 Nutch 项目也模仿 GFS 开发了自己的分布式文件系统 NDFS（Nutch Distributed File System），也就是 HDFS 的前身\r\n* 2005 年，Nutch 开源实现了谷歌的 MapReduce\r\n* 2006 年 2 月，Nutch 中的 NDFS 和 MapReduce 开始独立出来，成为 Lucene 项目的一个子项目，称为 Hadoop，同时，Doug Cutting 加盟雅虎\r\n* 2008 年 1 月，HADOOP 成为 Apache 顶级项目，迎来了它的快速发展期。\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.生态",
      "lvl1": "Hadoop 背景",
      "lvl2": "Hadoop 生态",
      "lvl3": "Hadoop 起源"
    },
    "frontmatter": {
      "title": "1.生态",
      "date": "2025/07/01"
    },
    "type": "content"
  },
  {
    "title": "10. YARN 资源调度器",
    "path": "/docs/architect/hadoop/Hadoop-10-YARNziyuandiaoduqi.html",
    "url": "/docs/architect/hadoop/Hadoop-10-YARNziyuandiaoduqi.html",
    "content": "---\r\ntitle: 10. YARN 资源调度器\r\ndate: 2025/07/02\r\n---\r\n\r\n配置 ([官方文档](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml)):\r\n`yarn.resourcemanager.scheduler.class` 默认: `org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler`\r\n\r\n---\r\n\r\n![YARN 资源调度器](static/YARN-QUEUE.png)\r\n\r\n1. FIFO 队列缺点: 大任务会耗时太长会导致小任务得不到及时的执行\r\n2. 分为大小任务两个队列，小任务在大任务执行时也能得到及时执行\r\n    * 缺点：如果只有大任务或只有小任务，会浪费掉一部分内存资源维护另一个用不到的队列\r\n    * Apache Hadoop 原生默认的队列类型\r\n3. 公平队列：在大任务执行过程中，如果加入了小任务，那么大任务会让出部分资源给小任务执行\r\n    * 缺点：小任务需要等待大任务让出资源，得不到及时执行\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "10. YARN 资源调度器"
    },
    "frontmatter": {
      "title": "10. YARN 资源调度器",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "11.优化",
    "path": "/docs/architect/hadoop/Hadoop-11-youhua.html",
    "url": "/docs/architect/hadoop/Hadoop-11-youhua.html",
    "content": "---\r\ntitle: 11.优化\r\ndate: 2025/07/02\r\n---\r\n\r\n## 参数调优\r\n**以下参数是在用户自己的 mr 应用程序中配置就可以生效**\r\n1. `mapreduce.map.memory.mb`: 一个 Map Task 可使用的资源上限（单位:MB），默认为 1024。如果 Map Task 实际使用的资源量超过该值，则会被强制杀死。\r\n2. `mapreduce.reduce.memory.mb`: 一个 Reduce Task 可使用的资源上限（单位:MB），默认为 1024。如果 Reduce Task 实际使用的资源量超过该值，则会被强制杀死。\r\n3. `mapreduce.map.cpu.vcores`: 每个 Map task 可使用的最多 cpu core 数目, 默认值: 1\r\n4. `mapreduce.reduce.cpu.vcores`: 每个 Reduce task 可使用的最多 cpu core 数目, 默认值: 1\r\n5. `mapreduce.map.java.opts`: Map Task 的 JVM 参数，你可以在此配置默认的 java heap size 等参数, e.g. \"-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc\" （@taskid@ 会被 Hadoop 框架自动换为相应的 taskid）, 默认值: \"\"\r\n6. `mapreduce.reduce.java.opts`: Reduce Task 的 JVM 参数，你可以在此配置默认的 java heap size 等参数, e.g. \"-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc\", 默认值: \"\"\r\n\r\n**应该在 yarn 启动之前就配置在服务器的配置文件中才能生效**\r\n1. `yarn.scheduler.minimum-allocation-mb`: 1024 给应用程序 container 分配的最小内存\r\n2. `yarn.scheduler.maximum-allocation-mb`: 8192 给应用程序 container 分配的最大内存\r\n3. `yarn.scheduler.minimum-allocation-vcores`: 1 最小核数\r\n4. `yarn.scheduler.maximum-allocation-vcores`: 32 最大核数\r\n5. `yarn.nodemanager.resource.memory-mb`: 8192 nodemanager resource 内存大小\r\n\r\n**shuffle 性能优化的关键参数，应在 yarn 启动之前就配置好**\r\n1. `mapreduce.task.io.sort.mb`: 100  shuffle 的环形缓冲区大小，默认 100m\r\n2. `mapreduce.map.sort.spill.percent`: 0.8  环形缓冲区溢出的阈值，默认 80%\r\n\r\n**可靠性相关**\r\n1. `mapreduce.map.speculative`: 是否为 Map Task 打开推测执行机制，默认为 false \r\n2. `mapreduce.reduce.speculative`: 是否为 Reduce Task 打开推测执行机制，默认为 false\r\n3. `mapreduce.job.user.classpath.first` & `mapreduce.task.classpath.user.precedence`：当同一个 class 同时出现在用户 jar 包和 hadoop jar 中时，优先使用哪个 jar 包中的 class，默认为 false，表示优先使用 hadoop jar 中的 class\r\n4. `mapreduce.input.fileinputformat.split.minsize`: FileInputFormat 做切片时的最小切片大小，\r\n5. `mapreduce.input.fileinputformat.split.maxsize`: FileInputFormat 做切片时的最大切片大小 (切片的默认大小就等于 blocksize，即 134217728)\r\n\r\n推测执行机制就是同时执行两台机器，选最先出结果的机器的结果，杀死另一台机器的任务，防止出现其中一台机器计算速度太慢的情况\r\n\r\n**压缩**\r\n* 如果是 IO 密集形任务，可以考虑开启压缩\r\n\r\n## 代码优化\r\n1. 输出的时候不要频繁创建对象\r\n```java\r\nfor(String word: words) {\r\n    context.write(new Text(word),new IntWritable(1));\r\n}\r\n// 改为\r\nText text = new Text(\"\");\r\nIntWritable count = new IntWritable(1);\r\nfor(String word: words) {\r\n    context.write(text.set(word), count);\r\n}\r\n```\r\n2. 尽量使用Combiner机制，减轻Reduce的压力: `job.setCombinerClass(XXReducer.class);`\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "11.优化",
      "lvl1": "参数调优",
      "lvl2": "代码优化"
    },
    "frontmatter": {
      "title": "11.优化",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "11.1. 数据压缩",
    "path": "/docs/architect/hadoop/Hadoop-11.1.shujuyasuo.html",
    "url": "/docs/architect/hadoop/Hadoop-11.1.shujuyasuo.html",
    "content": "---\r\ntitle: 11.1. 数据压缩\r\ndate: 2025/07/02\r\n---\r\n\r\n## 原则\r\nMapReduce 支持压缩，通过压缩算法对 mapper 或者 reducer 的最终数据结果进行压缩\r\n* 好处：减少了磁盘 io，提高了 MR 获取数据的速度，节省了磁盘空间\r\n* 坏处：压缩需要增加 cpu 的运算负担\r\n\r\n原则:\r\n* 运算密集的 job，少用压缩，尤其是中间数据\r\n* Io 密集的 job，可以用压缩，尤其是最终归档数据\r\n\r\n[官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Data_Compression)\r\n\r\n---\r\n\r\n## Mapper 输出压缩\r\n配置文档:\r\n* `mapreduce.map.output.compress=false`\r\n* `mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec`\r\n\r\n在代码中进行配置:\r\n```java\r\nconf.setBoolean(Job.MAP_OUTPUT_COMPRESS, true);\r\nconf.setClass(Job.MAP_OUTPUT_COMPRESS_CODEC, GzipCodec.class, CompressionCodec.class);\r\n```\r\n\r\n## Reduce 输出压缩\r\n配置文档:\r\n* `mapreduce.output.fileoutputformat.compress=false `\r\n* `mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec `\r\n* `mapreduce.output.fileoutputformat.compress.type=RECORD`\r\n\r\n在代码中进行配置:\r\n```java\r\nJob job = Job.getInstance(conf);\r\nFileOutputFormat.setCompressOutput(job, true);\r\nFileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);\r\n```\r\n\r\n---\r\n\r\n![支持的压缩类型](static/Compression.jpg)\r\n\r\n不建议使用配置文档的方式，不灵活，可以使用代码进行配置\r\n[配置文件官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "11.1. 数据压缩",
      "lvl1": "原则",
      "lvl2": "Mapper 输出压缩",
      "lvl3": "Reduce 输出压缩"
    },
    "frontmatter": {
      "title": "11.1. 数据压缩",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12. Hive 特点",
    "path": "/docs/architect/hadoop/Hadoop-12-Hive-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-12-Hive-tedian.html",
    "content": "---\r\ntitle: 12. Hive 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n\r\n## Hive 简介\r\nHive 是属于 Hadoop 的数据仓库工具，可以让使用者将结构化数据映射成一张张数据库的表，让用户能通过 SQL 来查询数据。用户出 SQL 命令给 hive，<font color=\"orange\">hive 把 SQL 语句转换成 MapReduce 查询分析存储在 hdfs 上的数据</font>。\r\n\r\n优点:\r\n* 直接使用 MapReuce 实现复杂查询比较复杂，而 Hive 提供 SQL 的语法，提高了开发的便捷程度\r\n* 直接使用 SQL 查询，减少了人员的学习成本，哪怕是数据库操作人员能很快上手\r\n* HIVE 提供很好的扩展性，方便用户增加功能\r\n\r\n## Hive 与传统数据库对比\r\n![Hive 与传统数据库对比](static/Hive-SQL-Compare.png)\r\n\r\n* **查询语言**: 由于 SQL 被广泛的应用在数据仓库中，因此，专门针对 Hive 的特性设计了类 SQL 的查询语言 HQL。熟悉 SQL 开发的开发者可以很方便的使用 Hive 进行开发。\r\n* **数据存储位置**: Hive 是建立在 Hadoop 之上的，所有 Hive 的数据都是存储在 HDFS 中的。而数据库则可以将数据保存在块设备或者本地文件系统中。\r\n* **数据格式**: Hive 中没有定义专门的数据格式，数据格式可以由用户指定，用户定义数据格式需要指定三个属性：**列分隔符**（通常为空格、”\\t”、”\\x001″）、**行分隔符**（”\\n”）以及**读取文件数据的方法**（Hive 中默认有三个文件格式 `TextFile`，`SequenceFile` 以及 `RCFile`）。由于在加载数据的过程中，不需要从用户数据格式到 Hive 定义的数据格式的转换，因此，**Hive 在加载的过程中不会对数据本身进行任何修改**，而只是将数据内容复制或者移动到相应的 HDFS 目录中。而在数据库中，不同的数据库有不同的存储引擎，定义了自己的数据格式。所有数据都会按照一定的组织存储，因此，数据库加载数据的过程会比较耗时。\r\n* **数据更新**: 由于 Hive 是针对数据仓库应用设计的，而数据仓库的内容是**读多写少**的。因此，**Hive 中不支持对数据的改写和添加**，所有的数据都是在加载的时候中确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO ... VALUES 添加数据，使用 UPDATE ... SET 修改数据。\r\n* **索引**: 之前已经说过，Hive 在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些 Key 建立索引。Hive 要访问数据中满足条件的特定值时，需要**暴力扫描整个数据**，因此访问延迟较高。由于 `MapReduce` 的引入， Hive 可以**并行访问数据**，因此即使没有索引，**对于大数据量的访问，Hive 仍然可以体现出优势**。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 **Hive 不适合在线数据查询**。\r\n* **执行**: Hive 中大多数查询的执行是通过 Hadoop 提供的 `MapReduce` 来实现的（类似 select * from tbl 的查询不需要 MapReduce）。而数据库通常有自己的执行引擎。\r\n* **执行延迟**: 之前提到，Hive 在查询数据的时候，**由于没有索引，需要扫描整个表，因此延迟较高**。另外一个导致 Hive 执行延迟高的因素是 MapReduce 框架。由于 **MapReduce 本身具有较高的延迟**，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，**当数据规模大到超过数据库的处理能力的时候，Hive 的并行计算显然能体现出优势**。\r\n* **可扩展性**: 由于 Hive 是建立在 Hadoop 之上的，因此 **Hive 的可扩展性是和 Hadoop 的可扩展性是一致的**。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle 在理论上的扩展能力也只有 100 台左右。\r\n* **数据规模**: 由于 Hive 建立在集群上并可以利用 MapReduce 进行并行计算，因此可以支持**很大规模的数据**；对应的，数据库可以支持的数据规模较小。\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12. Hive 特点",
      "lvl1": "Hive 简介",
      "lvl2": "Hive 与传统数据库对比"
    },
    "frontmatter": {
      "title": "12. Hive 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.1. Hive 窗口函数",
    "path": "/docs/architect/hadoop/Hadoop-12.1.Hivechuangkouhanshu.html",
    "url": "/docs/architect/hadoop/Hadoop-12.1.Hivechuangkouhanshu.html",
    "content": "---\r\ntitle: 12.1. Hive 窗口函数\r\ndate: 2025/07/02\r\n---\r\n\r\n```sql\r\nCREATE TABLE window_demo(cookieid STRING, createtime STRING, pv INT)\r\nROW FORMAT DELIMITED\r\nFIELDS TERMINATED BY ',';\r\n\r\nload data local inpath '/testdata/window' into table window_demo;\r\n```\r\n\r\n## SUM\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime) AS pv1, -- 默认为从起点到当前行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS pv2, --从起点到当前行，结果同 pv1\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS pv3, --当前行+往前 3 行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING) AS pv4, --当前行+往前 3 行+往后 1 行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS pv5 --当前行+往后所有行\r\nFROM test1;\r\n```\r\n\r\n* 如果不指定 `ROWS BETWEEN`, 默认统计窗口为从起点到当前行\r\n* 如果不指定 `ORDER BY`, 不仅分区内没有排序, 则将分组内所有值累加\r\n* `max()` 函数无论有没有 `order by` 都是计算整个分区的最大值\r\n\r\n关键是理解 `ROWS BETWEEN` 含义, 也叫做 window 子句：\r\n* `PRECEDING`：往前\r\n* `FOLLOWING`：往后\r\n* `CURRENT ROW`：当前行\r\n* `UNBOUNDED`：无边界\r\n* `UNBOUNDED PRECEDING`：表示从最前面的起点开始 \r\n* `UNBOUNDED FOLLOWING`：表示到最后面的终点\r\n\r\n## NTILE\r\n`NTILE(n)`，用于将分组数据按照顺序切分成 n 片，返回当前切片值，`NTILE` 不支持 `ROWS BETWEEN`\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nNTILE(2) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile1, --分组内将数据分成 2 片\r\nNTILE(3) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile2, --分组内将数据分成 3 片\r\nNTILE(4) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile3 --将所有数据分成 4 片\r\nFROM window_demo;\r\n```\r\n\r\n## ROW_NUMBER\r\n`ROW_NUMBER()` 从 1 开始，按照顺序，生成分组内记录的序列\r\n`ROW_NUMBER()` 的应用场景非常多，比如获取分组内排序第一的记录\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY pv desc) AS rn\r\nFROM window_demo;\r\n```\r\n\r\n## RANK DENSE_RANK\r\n`RANK()` 生成数据项在分组中的排名，排名相等会在名次中留下空位\r\n`DENSE_RANK()` 生成数据项在分组中的排名，排名相等会在名次中不会留下空位\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nRANK() OVER(PARTITION BY cookieid ORDER BY pv desc) AS rank1, \r\nDENSE_RANK() OVER(PARTITION BY cookieid ORDER BY pv desc) AS d_rank2, \r\nROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY pv DESC) AS rn3\r\nFROM window_demo\r\n```\r\n\r\n## CUME_DIST\r\n`cume_dist` 返回 小于等于 当前值的行数/分组内总行数\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nround(CUME_DIST() OVER(ORDER BY pv),2) AS cd1, \r\nround(CUME_DIST() OVER(PARTITION BY cookieid ORDER BY pv),2) AS cd2\r\nFROM window_demo;\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.1. Hive 窗口函数",
      "lvl1": "SUM",
      "lvl2": "NTILE",
      "lvl3": "ROW_NUMBER",
      "lvl4": "RANK DENSE_RANK",
      "lvl5": "CUME_DIST"
    },
    "frontmatter": {
      "title": "12.1. Hive 窗口函数",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.2. Hive 常用命令 dd 与 dmll",
    "path": "/docs/architect/hadoop/Hadoop-12.2.Hivechangyongminglingddyudmll.html",
    "url": "/docs/architect/hadoop/Hadoop-12.2.Hivechangyongminglingddyudmll.html",
    "content": "---\r\ntitle: 12.2. Hive 常用命令 dd 与 dmll\r\ndate: 2025/07/02\r\n---\r\n\r\n## 创建表\r\n```sql\r\nCREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name\r\n    [(col_name data_type [COMMENT col_comment], ...)]\r\n    [COMMENT table_comment]\r\n    [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]\r\n    [CLUSTERED BY (col_name, col_name, ...)\r\n    [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]\r\n    [ROW FORMAT row_format]\r\n    [STORED AS file_format]\r\n    [LOCATION hdfs_path]\r\n```\r\n\r\n### 创建内部表\r\n删除表的时候数据也会被删除\r\n\r\n```sql\r\ncreate table if not exists mytable(sid int ,sname string) \r\nrow format delimited\r\nfields terminated by ',' stored as textfile;\r\n\r\nshow tables;\r\n```\r\n\r\n上传数据: `hdfs dfs -put a /user/hive/warehouse/test.db/mytable/`\r\n`select * from mytable`\r\n\r\n### 创建外部表\r\n删除表的时候数据不会被删除\r\n\r\n```sql\r\ncreate external table mytable_ext(sid int ,sname string)\r\nrow format delimited\r\nfields terminated by ',' location '/dbdata'\r\n\r\nshow tables;\r\nselect * from mytable_ext;\r\n```\r\n\r\n### 创建分区表\r\n```sql\r\ncreate table person_p(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited fields\r\nterminated by ','stored as textfile;\r\n\r\nload data local inpath '/testdata/a' into table person_p partition(sex='nan');\r\nload data local inpath '/testdata/a' into table person_p partition(sex='nv');\r\n\r\nshow tables;\r\nselect * from person_p;\r\n```\r\n\r\n### 创建动态分区表\r\n```sql\r\nset hive.exec.dynamic.partition.mode=nonstrict;\r\n\r\ncreate table person_p2(sid int ,sname string) partitioned by(sex string) row format delimited\r\nfields terminated by ','stored as textfile;\r\n\r\ninsert into person_p2 partition(sex) select sid,sname,sex from person_p;\r\n\r\nshow tables;\r\nselect * from person_p2;\r\n```\r\n\r\n## 修改表\r\n```sql\r\nALTER TABLE table_name ADD [IF NOT EXISTS] partition_spec [ LOCATION 'location1' ] partition_spec [ LOCATION 'location2' ] ...\r\npartition_spec:\r\n: PARTITION (partition_col = partition_col_value, partition_col = partiton_col_value, ...)\r\n\r\nALTER TABLE table_name DROP partition_spec, partition_spec,...\r\n```\r\n\r\n### 增加分区\r\n```sql\r\ncreate table person_p3(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited\r\nfields terminated by ','stored as textfile;\r\n\r\nalter table person_p3 add partition(sex='1') partition(sex='2');\r\n\r\nload data local inpath '/testdata/a' into table person_p3 partition(sex='1');\r\nload data local inpath '/testdata/a' into table person_p3 partition(sex='2');\r\n\r\nshow tables;\r\nselect * from person_p3;\r\n```\r\n\r\n### 删除分区\r\n```sql\r\nalter table person_p3 drop partition(sex='2')\r\n```\r\n\r\n###  重命名表\r\n```sql\r\nALTER TABLE person_p3 RENAME TO person_p4;\r\n```\r\n\r\n### 新增列\r\nADD 是代表新增一字段，字段位置在所有列后面(partition 列前)，REPLACE 则是表示替换表中所有字段。\r\n```sql\r\nALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...\r\n```\r\n\r\n```sql\r\ncreate table person_p5(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited\r\nfields terminated by \r\n\r\nAlter table person_p5 add COLUMNS (age int);\r\ndesc person_p5;\r\n\r\nAlter table person_p5 REPLACE COLUMNS (age2 int);\r\ndesc person_p5;\r\n```\r\n\r\n### 修改列\r\n```sql\r\nALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type\r\n[COMMENT col_comment] [FIRST|AFTER column_name]\r\n```\r\n\r\n```sql\r\nalter table person_p5 change column age2 age2 string;\r\n\r\ndesc person_p5;\r\n```\r\n\r\n## 显示命令\r\n```sql\r\nshow tablese;\r\nshow databasese;\r\nshow partitions table_namee;\r\nshow functionse;\r\ndesc extended table_name;\r\ndesc formatted table_name;\r\n```\r\n\r\n## Load 操作\r\n```sql\r\nLOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO\r\nTABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]\r\n```\r\n\r\n## Insert\r\n```sql\r\nINSERT INTO TABLE VALUES(XX,YY,ZZ);\r\n\r\nINSERT OVERWRITE [INTO] TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)]\r\nselect_statement1 \r\n```\r\n\r\n## SELECT\r\n```sql\r\nSELECT [ALL | DISTINCT] select_expr, select_expr, ... FROM table_reference\r\n[WHERE where_condition]\r\n[GROUP BY col_list [HAVING condition]]\r\n[CLUSTER BY col_list\r\n| [DISTRIBUTE BY col_list] [SORT BY| ORDER BY col_list]\r\n]\r\n[LIMIT number]\r\n```\r\n\r\n1. `order by` 会对输入做全局排序，因此只有一个 reducer，会导致当输入规模较大时，需要较长的计算时间。\r\n2. `sort by` 不是全局排序，其在数据进入 reducer 前完成排序。因此，如果用 `sort by` 进行排序，并且设置 `mapred.reduce.tasks>1`，则 `sort by` 只保证每个 reducer 的输出有序，**不保证全局有序**。\r\n3. `distribute by`(字段) 根据指定的字段将数据分到不同的 reducer，且分发算法是 **hash 散列**。\r\n4. `Cluster by`(字段) 除了具有 `Distribute by` 的功能外，还会对该字段进行**排序**。\r\n\r\n因此，如果分桶和 sort 字段是同一个时，此时，`cluster by = distribute by + sort by`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.2. Hive 常用命令 dd 与 dmll",
      "lvl1": "创建表",
      "lvl2": "修改表",
      "lvl3": "显示命令",
      "lvl4": "Load 操作",
      "lvl5": "Insert",
      "lvl6": "SELECT"
    },
    "frontmatter": {
      "title": "12.2. Hive 常用命令 dd 与 dmll",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.3. Hive 分桶",
    "path": "/docs/architect/hadoop/Hadoop-12.3.Hivefentong.html",
    "url": "/docs/architect/hadoop/Hadoop-12.3.Hivefentong.html",
    "content": "---\r\ntitle: 12.3. Hive 分桶\r\ndate: 2025/07/02\r\n---\r\n\r\n## 创建桶表\r\n```sql\r\nset hive.enforce.bucketing=true;\r\nset mapreduce.job.reduces=4;\r\n\r\ndrop table person_buck;\r\n\r\ncreate table person_buck(sid int ,sname string)\r\npartitioned by(sex string)\r\nclustered by(sid)\r\nsorted by(sid DESC)\r\ninto 4 buckets\r\nrow format delimited\r\nfields terminated by ',';\r\n\r\ninsert into person_buck partition(sex) select sid,sname,sex from person_p;\r\n```\r\n\r\n## 桶表抽样查询\r\n```sql\r\nselect * from table_name tablesample(bucket X out of Y on field);\r\n\r\nselect * from person_buck tablesample(bucket 1 out of 2 on sid);\r\n```\r\n\r\n* X 表示从哪个桶中开始抽取\r\n* Y 表示相隔多少个桶再次抽取\r\n    * Y 必须为分桶数量的倍数或者因子，比如分桶数为 6，Y 为 6，则表示只从桶中抽取 1 个 bucket 的数据；若 Y 为 3，则表示从桶中抽取 6/3 (2)个 bucket 的数据\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.3. Hive 分桶",
      "lvl1": "创建桶表",
      "lvl2": "桶表抽样查询"
    },
    "frontmatter": {
      "title": "12.3. Hive 分桶",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
    "path": "/docs/architect/hadoop/Hadoop-12.4.HiveDemodaxiaoxiezhuanhuanUDFzidingyihanshu.html",
    "url": "/docs/architect/hadoop/Hadoop-12.4.HiveDemodaxiaoxiezhuanhuanUDFzidingyihanshu.html",
    "content": "---\r\ntitle: 12.4. Hive Demo 大小写转换 UDF 自定义函数\r\ndate: 2025/07/02\r\n---\r\n\r\n## pom.xml\r\n```xml\r\n<dependency>\r\n    <groupId>org.apache.hive</groupId>\r\n    <artifactId>hive-exec</artifactId>\r\n</dependency>\r\n```\r\n\r\n## Lower.java\r\n```java\r\npublic final class Lower extends UDF {\r\n    public Text evaluate(final Text s){\r\n        if(s==null){return null;}\r\n        return new Text(s.toString().toLowerCase());\r\n    }\r\n}\r\n```\r\n\r\n## 测试\r\n将代码打成 jar 包上传到服务器\r\n\r\n```sql\r\nadd JAR /path/to/udf.jar\r\n\r\ncreate temporary function tolowercase as 'cn.enjoy.hive.Lower'\r\n\r\nselect tolowercase(\"AAA\");\r\nselect sid,tolowercase(sname),sex from person_p;\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
      "lvl1": "pom.xml",
      "lvl2": "Lower.java",
      "lvl3": "测试"
    },
    "frontmatter": {
      "title": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.5.1. Hive 不支援 10 验证类型",
    "path": "/docs/architect/hadoop/Hadoop-12.5.1.Hivebuzhiyuan10yanzhengleixing.html",
    "url": "/docs/architect/hadoop/Hadoop-12.5.1.Hivebuzhiyuan10yanzhengleixing.html",
    "content": "---\r\ntitle: 12.5.1. Hive 不支援 10 验证类型\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger\r\n- 报错：PSQLException: 不支援 10 验证类型。请核对您已经组态 pg_hba.conf 文件包含客户端的IP位址或网路区段，以及驱动程序所支援的验证架构模式已被支援\r\n:::\r\n\r\n原因：驱动不兼容（需要更新驱动版本）\r\n\r\n1. 去官网或者使用Maven下载新的驱动jar包\r\n2. 添加到 hive/lib 目录中\r\n3. 将目录中旧的驱动jar包移出 hive/lib 目录\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.5.1. Hive 不支援 10 验证类型"
    },
    "frontmatter": {
      "title": "12.5.1. Hive 不支援 10 验证类型",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.5.2. Hive WstxParsingException",
    "path": "/docs/architect/hadoop/Hadoop-12.5.2.HiveWstxParsingException.html",
    "url": "/docs/architect/hadoop/Hadoop-12.5.2.HiveWstxParsingException.html",
    "content": "---\r\ntitle: 12.5.2. Hive WstxParsingException\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger\r\n- Hive-WstxParsingException: Illegal character entity: expansion character\r\n:::\r\n\r\n`hive-site.xml` 文件第 3215 行左右有一个特殊字符 (`&#8;`)，删掉它:\r\n\r\n```xml\r\n214      <description>\r\n3215       Ensures commands with OVERWRITE (such as INSERT OVERWRITE) acquire Exclusive      locks for&#8;transactional tables.  This ensures that inserts (w/o overwrite) runni     ng concurrently\r\n3216       are not hidden by the INSERT OVERWRITE.\r\n3217     </description>\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.5.2. Hive WstxParsingException"
    },
    "frontmatter": {
      "title": "12.5.2. Hive WstxParsingException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13. HBase 特点",
    "path": "/docs/architect/hadoop/Hadoop-13-HBase-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-13-HBase-tedian.html",
    "content": "---\r\ntitle: 13. HBase 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n## HBase 列式数据库简介\r\nHBase 是一个开源的非关系型分布式数据库（NoSql） 原型是 Google 的 BigTable 论文，受到了该论文思想的启发，目前作为Hadoop 的子项目来开发维护。它介于 nosql 和 RDBMS 之间，仅能通过主键(row key)和主键的 range 来检索数据，可通过 hive 支持来实现多表 join 等复杂操作。\r\n\r\n## HBase 特点\r\n\r\n* **海量存储**: Hbase 适合存储 PB 级别的海量数据，在 PB 级别的数据以及采用廉价 PC 存储的情况下，能在几十到百毫秒内返回数据。这与 Hbase 的极易扩展性息息相关。正式因为 Hbase 良好的扩展性，才为海量数据的存储提供了便利。\r\n* **列式存储**: 这里的列式存储其实说的是列族（ColumnFamily）存储，Hbase 是根据列族来存储数据的。列族下面可以有非常多的列，列族在创建表的时候就必须指定。\r\n* **极易扩展**: Hbase 的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer）的扩展，一个是基于存储的扩展（HDFS）。通过横向添加RegionSever 的机器，进行水平扩展，提升 Hbase 上层的处理能力，提升 Hbsae 服务更多 Region 的能力。\r\n* **高并发**: 由于目前大部分使用 Hbase 的架构，都是采用的廉价 PC，因此单个 IO 的延迟其实并不小，一般在几十到上百 ms 之间。这里说的高并发，主要是在并发的情况下，Hbase 的单个 IO 延迟下降并不多。能获得高并发、低延迟的服务。\r\n* **稀疏**: 稀疏主要是针对 Hbase 列的灵活性，在列族中，你可以指定任意多的列，在列数据为空的情况下，是不会占用存储空间的。\r\n\r\n适用场景:\r\n* 持久化存储大量数据（TB、PB）\r\n* 对扩展伸缩性有要求\r\n* 需要良好的随机读写性能\r\n* 简单的业务 KV 查询(不支持复杂的查询比如表关联等)\r\n* 能够同时处理结构化和非结构化的数据\r\n* 订单流水、交易记录、需要记录历史版本的数据等\r\n\r\n不适用场景:\r\n* 几千、几百万那种还不如使用 RDBMS\r\n* 需要类型列\r\n* 需要跨行事务，目前 HBase 只支持单行事务\r\n* SQL 查询\r\n\r\n## HBase 数据模型\r\n<table>\r\n    <tr>\r\n        <th>Row Key</th>\r\n        <th>Time Stamp</th>\r\n        <th>CF1</th>\r\n        <th>CF2</th>\r\n        <th>CF3</th>\r\n    </tr>\r\n    <tr>\r\n        <td rowspan=\"3\">rk00001</td>\r\n        <td>t1</td>\r\n        <td></td>\r\n        <td>CF2:q1=val1</td>\r\n        <td>CF3:q2=val2</td>\r\n    </tr>\r\n    <tr>\r\n        <td>t2</td>\r\n        <td></td>\r\n        <td></td>\r\n        <td></td>\r\n    </tr>\r\n    <tr>\r\n        <td>t3</td>\r\n        <td>CF1:q3=val3</td>\r\n        <td></td>\r\n        <td></td>\r\n    </tr>\r\n</table>\r\n\r\n* ROW KEY\r\n    * 决定一行数据\r\n    * 按照字典顺序排序的\r\n    * ROW KEY 只能存储 64k 的字节数据\r\n* Column Family 列族 & qualifier 列\r\n    * HBase 表中的每个列都归属于某个列族，列族必须作为表模式(schema)定义的一部分预先给出。`create 'test', 'course'`\r\n    * 列名以列族作为前缀， 每个“列族”都可以有多个列成员(column) ； 如 `course:math`,`course:english`, 新的列族成员（列）可以随后按需、动态加入；\r\n    * 权限控制、存储以及调优都是在列族层面进行的；\r\n    * HBase 把同一列族里面的数据存储在同一目录下，由几个文件保存\r\n* Timestamp 时间戳\r\n    * 在HBase 每个 cell 存储单元对同一份数据有多个版本，根据唯一的时间戳来区分每个版本之间的差异，不同版本的数据按照时间倒序排序，最新的数据版本排在最前面\r\n    * 时间戳的类型是 64 位整型\r\n    * 时间戳可以由HBase(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间\r\n    * 时间戳也可以由客户显式赋值\r\n* Cell 单元格\r\n    * 由行和列的坐标交叉决定\r\n    * 单元格是有版本的\r\n    * 单元格的内容是未解析的字节数组\r\n    * 由`{rowkey，column(=<family> +<qualifier>)，version}`唯一确定的单元\r\n    * Cell 中的数据是没有类型的，全部是二进制字节码形式存储\r\n\r\n## HBase 架构\r\n![HBase 架构](static/HBase.png)\r\n\r\n* **Client**: 包含了访问 Hbase 的接口，另外 Client 还维护了对应的 cache 来加速 HBase 的访问，比如 cache 的.META.元数据的信息\r\n* **Zookeeper**: HBase 通过 Zookeeper 来做 master 的高可用、RegionServer 的监控、元数据的入口以及集群配置的维护等工作\r\n    * 通过 Zoopkeeper 来保证集群中只有1个 master 在运行，如果 master 异常，会通过竞争机制\r\n    * 产生新的 master 提供服务\r\n    * 通过 Zoopkeeper 来监控 RegionServer 的状态，当 RegionSevrer 有异常的时候，通过回调的形式通知 Master RegionServer 上下线的信息\r\n    * 通过 Zoopkeeper 存储元数据的统一入口地址\r\n* **HMaster**: \r\n    * 为 RegionServer 分配 Region\r\n    * 维护整个集群的负载均衡\r\n    * 维护集群的元数据信息\r\n    * 发现失效的 Region，并将失效的 Region 分配到正常的 RegionServer 上\r\n    * 当 RegionSever 失效的时候，协调对应 Hlog 的拆分\r\n* **HregionServer**: 直接对接用户的读写请求，是真正的“干活”的节点\r\n    * 管理 master 为其分配的 Region\r\n    * 处理来自客户端的读写请求\r\n    * 负责和底层 HDFS 的交互，存储数据到 HDFS\r\n    * 负责 Region 变大以后的拆分\r\n    * 负责 Storefile 的合并工作\r\n* **HDFS**: 为 Hbase 提供最终的底层数据存储服务，同时为 HBase 提供高可用（Hlog 存储在 HDFS）的支持\r\n    * 提供元数据和表数据的底层分布式存储服务\r\n    * 数据多副本，保证的高可靠和高可用性\r\n\r\n## HBase 中的角色\r\n\r\n* **HMaster**\r\n    * 监控 RegionServer\r\n    * 处理 RegionServer 故障转移\r\n    * 处理元数据的变更\r\n    * 处理 region 的分配或转移\r\n    * 在空闲时间进行数据的负载均衡\r\n    * 通过 Zookeeper 发布自己的位置给客户端\r\n* **RegionServer**\r\n    * 负责存储 HBase 的实际数据\r\n    * 处理分配给它的 Region\r\n    * 刷新缓存到 HDFS\r\n    * 维护 Hlog\r\n    * 执行压缩\r\n    * 负责处理 Region 分片\r\n* **Write-Ahead logs (WAL)**\r\n    * HBase 的修改记录，当对 HBase 读写数据的时候，数据不是直接写进磁盘，它会在内存中保留一段时间（时间以及数据量阈值可以设定）。但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入内存中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。\r\n* **Region**\r\n    * Hbase 表的分片，HBase 表会根据 RowKey 值被切分成不同的 region 存储在 RegionServer 中，在一个 RegionServer 中可以有多个不同的 region\r\n* **Store**\r\n    * HFile 存储在 Store 中，一个 Store 对应 HBase 表中的一个列族(列簇， ColumnFamily)\r\n* **MemStore**\r\n    * 顾名思义，就是内存存储，位于内存中，用来保存当前的数据操作，所以当数据保存在 WAL 中之后，RegsionServer 会在内存中存储键值对\r\n* **HFile**\r\n    * 这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。StoreFile 是以 HFile 的形式存储在 HDFS 的\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13. HBase 特点",
      "lvl1": "HBase 列式数据库简介",
      "lvl2": "HBase 特点",
      "lvl3": "HBase 数据模型",
      "lvl4": "HBase 架构",
      "lvl5": "HBase 中的角色"
    },
    "frontmatter": {
      "title": "13. HBase 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.1. HBase 常用命令",
    "path": "/docs/architect/hadoop/Hadoop-13.1.HBasechangyongmingling.html",
    "url": "/docs/architect/hadoop/Hadoop-13.1.HBasechangyongmingling.html",
    "content": "---\r\ntitle: 13.1. HBase 常用命令\r\ndate: 2025/07/02\r\n---\r\n\r\n`hbase shell` 进入shell\r\n`help` 命令查看帮助文档\r\n`list` 命令查看数据库中的表\r\n\r\n## 创建表\r\n创建 person 表，包含 info, data 两个列族\r\n然后查看表结构\r\n```sql\r\ncreate 'person', 'info', 'data'\r\ndescribe 'person'\r\n```\r\n\r\n## 插入数据\r\n```sql\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加name 列标示符，值为zhangsan\r\nput 'person', 'rk0001', 'info:name', 'zhangsan'\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加gender 列标示符，值为female\r\nput 'person', 'rk0001', 'info:gender', 'female'\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加age 列标示符，值为20\r\nput 'person', 'rk0001', 'info:age', 20\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族data 中添加pic 列标示符，值为picture\r\nput 'person', 'rk0001', 'data:pic', 'picture'\r\n```\r\n\r\n## 查询数据\r\n`get` 适用于获取单个记录或少量记录的场景，`scan` 适用于获取大量记录的场景\r\n```sql\r\n-- 获取person 表中row key 为rk0001 的所有信息\r\nget 'person', 'rk0001'\r\n\r\n-- 获取person 表中row key 为rk0001，info 列族的所有信息\r\nget 'person', 'rk0001', 'info'\r\n\r\n-- 获取person 表中row key 为rk0001，info 列族的name、age 列标示符的信息\r\nget 'person', 'rk0001', 'info:name', 'info:age'\r\n\r\n-- 获取person 表中row key 为rk0001，info、data 列族的信息\r\nget 'person', 'rk0001', 'info', 'data'\r\n\r\nget 'person', 'rk0001', {COLUMN => ['info', 'data']}\r\nget 'person', 'rk0001', {COLUMN => ['info:name', 'data:pic']}\r\n\r\n-- 获取person 表中row key 为rk0001，列族为info，版本号最新5 个的信息\r\nget 'person', 'rk0001', {COLUMN => 'info', VERSIONS => 5}\r\n\r\nget 'person', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5}\r\nget 'person', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5, TIMERANGE => [1567491377530,1567491377590]}\r\n\r\n-- 获取person 表中row key 为rk0001，cell 的值为zhangsan 的信息\r\nget 'person', 'rk0001', {FILTER => \"ValueFilter(=, 'binary:zhangsan')\"}\r\n\r\n-- 获取person 表中row key 为rk0001，列标示符中含有a 的信息\r\nget 'person', 'rk0001', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\r\n\r\nput 'person', 'rk0002', 'info:name', 'fanbingbing'\r\nput 'person', 'rk0002', 'info:gender', 'female'\r\nput 'person', 'rk0002', 'info:nationality', '中国'\r\nget 'person', 'rk0002', {FILTER => \"ValueFilter(=, 'binary:中国')\"}\r\n\r\n-- 查询person 表中的所有信息\r\nscan 'person'\r\n\r\n-- 查询person 表中列族为info 的信息\r\nscan 'person', {COLUMNS => 'info'}\r\n\r\n-- 查询person 表中列族为info 和data 的信息\r\nscan 'person', {COLUMNS => ['info', 'data']}\r\nscan 'person', {COLUMNS => ['info:name', 'data:pic']}\r\n\r\n-- 查询person 表中列族为info、列标示符为name 的信息\r\nscan 'person', {COLUMNS => 'info:name'}\r\n\r\n-- 查询person 表中列族为info、列标示符为name 的信息,并且版本最新的5 个\r\nscan 'person', {COLUMNS => 'info:name', VERSIONS => 5}\r\n\r\n-- 查询person 表中列族为info 和data 且列标示符中含有a 字符的信息\r\nscan 'person', {COLUMNS => ['info', 'data'], FILTER => \"(QualifierFilter(=,'substring:a'))\"}\r\n\r\n-- 查询person 表中列族为info，rk 范围是[rk0001, rk0003)的数据\r\nscan 'person', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}\r\n\r\n-- 查询person 表中row key 以rk 字符开头的\r\nscan 'person',{FILTER=>\"PrefixFilter('rk')\"}\r\n\r\n-- 查询person 表中指定范围的数据\r\nscan 'person', {TIMERANGE => [1392368783980, 1392380169184]}\r\n```\r\n\r\n## 删除数据\r\n```sql\r\n-- 删除person 表row key 为rk0001，列标示符为info:name 的数据\r\ndelete 'person', 'rk0001', 'info:name'\r\n\r\n-- 删除person 表row key 为rk0001，列标示符为info:name，timestamp 为1392383705316 的数据\r\ndelete 'person', 'rk0001', 'info:name', 1392383705316\r\n\r\n-- 清空person 表中的数据\r\ntruncate 'person'\r\n```\r\n\r\n## 修改表结构\r\n```sql\r\n-- 首先停用person 表\r\ndisable 'person'\r\n\r\n-- 添加两个列族f1 和f2\r\nalter 'person', NAME => 'f1'\r\nalter 'person', NAME => 'f2'\r\n\r\n-- 删除一个列族\r\nalter 'person', NAME => 'f1', METHOD => 'delete'\r\nalter 'person', 'delete' => 'f1'\r\n\r\n-- 添加列族f1 同时删除列族f2\r\nalter 'person', {NAME => 'f1'}, {NAME => 'f2', METHOD => 'delete'}\r\n\r\n-- 将person 表的f1 列族版本号改为5\r\nalter 'person', NAME => 'info', VERSIONS => 5\r\n\r\n-- 启用表\r\nenable 'person'\r\n```\r\n\r\n## 删除表\r\n```sql\r\ndisable 'person'\r\ndrop 'person'\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.1. HBase 常用命令",
      "lvl1": "创建表",
      "lvl2": "插入数据",
      "lvl3": "查询数据",
      "lvl4": "删除数据",
      "lvl5": "修改表结构",
      "lvl6": "删除表"
    },
    "frontmatter": {
      "title": "13.1. HBase 常用命令",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.2. HBase 优化",
    "path": "/docs/architect/hadoop/Hadoop-13.2.HBaseyouhua.html",
    "url": "/docs/architect/hadoop/Hadoop-13.2.HBaseyouhua.html",
    "content": "---\r\ntitle: 13.2. HBase 优化\r\ndate: 2025/07/02\r\n---\r\n\r\n* [13.3. HBase 设计优化 rowkey](./Hadoop-13.3.HBase设计优化rowkey.md)\r\n* 代码优化\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setInMemory(true)` 将表放到 RegionServer 的缓存中，**保证在读取的时候被 cache 命中**\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setMaxVersions(int maxVersions)` **设置表中数据的最大版本**，如果只需要保存最新版本的数据，那么可以设置 `setMaxVersions(1)`\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setTimeToLive(int timeToLive)` **设置表中数据的存储生命期，过期数据将自动被删除**，例如如果只需要存储最近两天的数据，那么可以设置 `setTimeToLive(2 * 24 * 60 * 60)`\r\n* `hdfs-site.xml`: **HDFS 副本数的调整**\r\n    * `dfs.replication`: 如果数据量巨大，且不是非常之重要，可以调整为2~3，如果数据非常之重要，可以调整为3~5\r\n    * `dfs.datanode.max.transfer.threads`: HBase 一般都会同一时间操作大量的文件，根据集群的数量和规模以及数据动作，设置为 4096 或者更高。默认值：4096\r\n* `mapred-site.xml`: **优化数据的写入效率, 减少写入时间 (压缩)**\r\n    * `mapreduce.map.output.compress`: 修改为 `true`\r\n    * `mapreduce.map.output.compress.codec`: 修改为 `org.apache.hadoop.io.compress.GzipCodec` 或者其他压缩方式\r\n* `hbase-site.xml`\r\n    * `hbase.regionserver.handler.count`: 默认值为 30，用于指定 **RPC 监听的数量**，可以根据客户端的请求数进行调整，读写请求较多时，增加此值\r\n    * `hbase.hregion.max.filesize`: 默认值10737418240(10GB)，如果需要运行 HBase 的 MR 任务，可以减小此值，因为**一个 region 对应一个 map 任务**，如果单个 region 过大，会导致 map 任务执行时间过长。该值的意思就是，如果 HFile 的大小达到这个数值，则这个 region 会被切分为两个 Hfile\r\n    * `hbase.client.write.buffer`: 用于指定 HBase 客户端缓存，**增大该值可以减少 RPC 调用次数，但是会消耗更多内存**。一般我们需要设定一定的缓存大小，以达到减少 RPC 次数的目的\r\n    * `hbase.client.scanner.caching`: 用于指定 `scan.next` 方法**获取的默认行数，值越大，消耗内存越大**\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.2. HBase 优化"
    },
    "frontmatter": {
      "title": "13.2. HBase 优化",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.3. HBase 设计优化 rowkey",
    "path": "/docs/architect/hadoop/Hadoop-13.3.HBaseshejiyouhuarowkey.html",
    "url": "/docs/architect/hadoop/Hadoop-13.3.HBaseshejiyouhuarowkey.html",
    "content": "---\r\ntitle: 13.3. HBase 设计优化 rowkey\r\ndate: 2025/07/02\r\n---\r\n\r\n## 性能上考虑\r\n一条数据的唯一标识就是 rowkey，而这行数据最终存储到哪一个分区里面，取决于分区({% post_link architect/Hadoop/HBase-预分区 %})，如果从性能上考虑 rowkey 优化，应该考虑的是让数据均匀的分布在所有的 region 中，**防止数据的倾斜**。\r\n\r\n设计方案:\r\n1. 使用**随机数**, **hash** 等\r\n2. **字符串反转** 10001, 10002 反转成为 10001, 20001\r\n3. **拼接字符串** XX0001 -> 1000XX0001\r\n\r\n## 业务上考虑\r\n\r\n### 列族数目\r\n一个列族和一个 Store 对于，如果经常需要跨列族查询，对应就是需要从多个 Store 中取数据，这样对性能开销挺大，建议**创建表的时候不要太多列族，一般 2-3 个为主**。**基本信息**放到一个列族，**扩展信息**放到一个列族，如果还有另外的**不常用的附件信息**放到第三个列族。\r\n\r\n### 行键设置\r\n\r\n**根据查询要求设置 key**:\r\n* 手机号-日期: \r\n    * `18229955555-20190919`\r\n    * `18229955555-20190920`\r\n* 日期-姓名缩写-类别: 姓名缩写长度需要保持一致 (填充和截断)\r\n    * `20150230-lisi-category`\r\n    * `20150230-zs__-category`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.3. HBase 设计优化 rowkey",
      "lvl1": "性能上考虑",
      "lvl2": "业务上考虑"
    },
    "frontmatter": {
      "title": "13.3. HBase 设计优化 rowkey",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.4. HBase 预分区",
    "path": "/docs/architect/hadoop/Hadoop-13.4.HBaseyufenqu.html",
    "url": "/docs/architect/hadoop/Hadoop-13.4.HBaseyufenqu.html",
    "content": "---\r\ntitle: 13.4. HBase 预分区\r\ndate: 2025/07/02\r\n---\r\n\r\n在默认情况下，在使用 hbase 创建表的时候会自动创建一个 region 分区，所有 hbase 的客户端的数据都写到这个 region 分区里面，一直到 region 足够大的时候才进行切分。每一个 region 维护着 startRow 与 endRowKey，如果加入的数据符合某个 region 维护的 rowKey范围，则该数据交给这个 region 维护, 根据这个特性，我们可以根据以后要插入 hbase 的数据进行一个预估，**将数据大致估算好，提前进行分区，用于提升 hbase 的性能**。\r\n\r\n可以在 `http://hadoop01:16010/`(主节点) 查看分区情况\r\n\r\n## 预分区\r\n* 手动预分区: `create 'p1','info','partition1',SPLITS => ['1000','2000','3000','4000']`\r\n* 16进制分区: `create 'p2','info','partition2',{NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'}`\r\n* 代码分区: 创建表的时候指定分区\r\n    ```java\r\n    public class SplitReginTest {\r\n        private Configuration conf = null;\r\n        private Connection conn = null;\r\n\r\n        @Before\r\n        public void init() throws Exception {\r\n            conf = HBaseConfiguration.create();\r\n            conf.set(\"hbase.zookeeper.quorum\",\"hadoop01:2181,hadoop02:2182,hadoop03:2183\");\r\n            conn = ConnectionFactory.createConnection(conf);\r\n        }\r\n\r\n        @Test\r\n        public void testCreateTable() throws Exception {\r\n            Admin admin = conn.getAdmin();\r\n\r\n            HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(\"split_p\"));\r\n            HColumnDescriptor hcd1 = new HColumnDescriptor(\"base_info\");\r\n            htd.addFamily(hcd1);\r\n\r\n            byte[][] splitKeys = new byte[4][];\r\n            splitKeys[0] = Bytes.toBytes(\"1000\");\r\n            splitKeys[1] = Bytes.toBytes(\"2000\");\r\n            splitKeys[2] = Bytes.toBytes(\"3000\");\r\n            splitKeys[3] = Bytes.toBytes(\"4000\");\r\n\r\n            admin.createTable(htd,splitKeys);\r\n\r\n            admin.close();\r\n            conn.close();\r\n        }\r\n    }\r\n    ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.4. HBase 预分区",
      "lvl1": "预分区"
    },
    "frontmatter": {
      "title": "13.4. HBase 预分区",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.5.1. HBase Demo Java API 常用操作",
    "path": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "url": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "content": "---\r\ntitle: 13.5.1. HBase Demo Java API 常用操作\r\ndate: 2025/07/02\r\n---\r\n\r\n## pom.xml\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.apache.hbase</groupId>\r\n            <artifactId>hbase-server</artifactId>\r\n            <version>2.5.4</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hbase</groupId>\r\n            <artifactId>hbase-client</artifactId>\r\n            <version>2.5.4</version>\r\n        </dependency>\r\n```\r\n\r\n## 获得连接\r\n```java\r\nprivate Configuration conf = null;\r\nprivate Connection conn = null;\r\n\r\n    @Before\r\n    public void init() throws Exception {\r\n        conf = HBaseConfiguration.create();\r\n        conf.set(\"hbase.zookeeper.quorum\", \"hadoop01:2181,hadoop02:2182,hadoop03:2183\");\r\n        conn = ConnectionFactory.createConnection(conf);\r\n    }\r\n```\r\n\r\n## 建表\r\n```java\r\n    @Test\r\n    public void testCreateTable() throws Exception {\r\n        // 获取一个表管理器\r\n        Admin admin = conn.getAdmin();\r\n\r\n        // 构造一个表描述器，并指定表名\r\n        HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 构造一个列族描述器，并指定列族名\r\n        HColumnDescriptor hcd1 = new HColumnDescriptor(\"base_info\");\r\n        // 构造第二个列族描述器，并指定列族名\r\n        HColumnDescriptor hcd2 = new HColumnDescriptor(\"extra_info\");\r\n\r\n        // 将列族描述器添加到表描述器中\r\n        htd.addFamily(hcd1).addFamily(hcd2);\r\n        admin.createTable(htd);\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 删除表\r\n```java\r\n    @Test\r\n    public void testDrop() throws Exception {\r\n        Admin admin = conn.getAdmin();\r\n\r\n        admin.disableTable(TableName.valueOf(\"t_person_info\"));\r\n        admin.deleteTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 修改表结构\r\n```java\r\n    @Test\r\n    public void testModify() throws Exception {\r\n        Admin admin = conn.getAdmin();\r\n\r\n        // 修改已有的ColumnFamily\r\n        HTableDescriptor table = admin.getTableDescriptor(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 添加新的ColumnFamily\r\n        table.addFamily(new HColumnDescriptor(\"other_info\"));\r\n        admin.modifyTable(TableName.valueOf(\"t_person_info\"), table);\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 插入/修改数据\r\n```java\r\n    @Test\r\n    public void testPut() throws Exception {\r\n        Table table = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        ArrayList<Put> puts = new ArrayList<Put>();\r\n        // 构建一个put 对象（kv），指定其行键\r\n        Put put01 = new Put(Bytes.toBytes(\"user001\"));\r\n        put01.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhangsan\"));\r\n        Put put02 = new Put(\"user001\".getBytes());\r\n        put02.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"password\"),Bytes.toBytes(\"123456\"));\r\n        Put put03 = new Put(\"user002\".getBytes());\r\n        put03.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"lisi\"));\r\n        put03.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put04 = new Put(\"zhang_sh_01\".getBytes());\r\n        put04.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang01\"));\r\n        put04.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put05 = new Put(\"zhang_sh_02\".getBytes());\r\n        put05.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang02\"));\r\n        put05.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put06 = new Put(\"liu_sh_01\".getBytes());\r\n        put06.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"liu01\"));\r\n        put06.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put07 = new Put(\"zhang_bj_01\".getBytes());\r\n        put07.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang03\"));\r\n        put07.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put08 = new Put(\"zhang_bj_01\".getBytes());\r\n        put08.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang04\"));\r\n        put08.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n\r\n        puts.add(put01);\r\n        puts.add(put02);\r\n        puts.add(put03);\r\n        puts.add(put04);\r\n        puts.add(put05);\r\n        puts.add(put06);\r\n        puts.add(put07);\r\n        puts.add(put08);\r\n        table.put(puts);\r\n\r\n        table.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## get 查询\r\n```java\r\n    @Test\r\n    public void testGet() throws Exception {\r\n        Table table = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 构造一个get 查询参数对象，指定要get 的是哪一行\r\n        Get get = new Get(\"user001\".getBytes());\r\n        Result result = table.get(get);\r\n\r\n        CellScanner cellScanner = result.cellScanner();\r\n        while (cellScanner.advance()) {\r\n            Cell current = cellScanner.current();\r\n            byte[] familyArray = current.getFamilyArray();\r\n            byte[] qualifierArray = current.getQualifierArray();\r\n            byte[] valueArray = current.getValueArray();\r\n            System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n            System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n            System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n        }\r\n\r\n        table.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 删除表中数据\r\n```java\r\n    @Test\r\n    public void testDel() throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.5.1. HBase Demo Java API 常用操作",
      "lvl1": "pom.xml",
      "lvl2": "获得连接",
      "lvl3": "建表",
      "lvl4": "删除表",
      "lvl5": "修改表结构",
      "lvl6": "插入/修改数据",
      "lvl7": "get 查询",
      "lvl8": "删除表中数据",
      "lvl9": "scan 查询",
      "lvl10": "过滤查询"
    },
    "frontmatter": {
      "title": "13.5.1. HBase Demo Java API 常用操作",
      "date": "2025/07/02"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "13.5.1. HBase Demo Java API 常用操作",
    "path": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "url": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "content": "(\"t_person_info\"));\r\n\r\n        Delete delete = new Delete(\"user001\".getBytes());\r\n        delete.addColumn(\"base_info\".getBytes(), \"password\".getBytes());\r\n\r\n        t_person_info.delete(delete);\r\n\r\n        t_person_info.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## scan 查询\r\n```java\r\n    @Test\r\n    public void testScan() throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n        Scan scan = new Scan(Bytes.toBytes(\"liu_sh_01\"), Bytes.toBytes(\"zhang_bj_01\" + \"\\000\"));\r\n        ResultScanner scanner = t_person_info.getScanner(scan);\r\n        Iterator<Result> iter = scanner.iterator();\r\n        while (iter.hasNext()) {\r\n            Result result = iter.next();\r\n            CellScanner cellScanner = result.cellScanner();\r\n            while (cellScanner.advance()) {\r\n                Cell current = cellScanner.current();\r\n                byte[] familyArray = current.getFamilyArray();\r\n                byte[] valueArray = current.getValueArray();\r\n                byte[] qualifierArray = current.getQualifierArray();\r\n                byte[] rowArray = current.getRowArray();\r\n                System.out.println(new String(rowArray, current.getRowOffset(),current.getRowLength()));\r\n                System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n                System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n                System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n            }\r\n            System.out.println(\"-----------------------\");\r\n        }\r\n    }\r\n```\r\n\r\n## 过滤查询\r\n```java\r\n    @Test\r\n    public void testFilter() throws Exception {\r\n        // 针对行键的前缀过滤器\r\n        Filter pf = new PrefixFilter(Bytes.toBytes(\"liu\"));\r\n        testScan(pf);\r\n\r\n        // 行过滤器\r\n        RowFilter rf1 = new RowFilter(CompareOp.LESS, new BinaryComparator(Bytes.toBytes(\"user002\")));\r\n        RowFilter rf2 = new RowFilter(CompareOp.EQUAL, new SubstringComparator(\"00\"));\r\n        testScan(rf1);\r\n        System.out.println(\"**********\");\r\n        testScan(rf2);\r\n\r\n        // 针对指定一个列的 value 来过滤\r\n        SingleColumnValueFilter scvf = new SingleColumnValueFilter(\"base_info\".getBytes(),\"password\".getBytes(), CompareOp.EQUAL, \"123456\".getBytes());\r\n        scvf.setFilterIfMissing(true); // 如果指定的列缺失，则也过滤掉\r\n        testScan(scvf);\r\n\r\n        ByteArrayComparable comparator1 = new RegexStringComparator(\"^zhang\");\r\n        ByteArrayComparable comparator2 = new SubstringComparator(\"ang\");\r\n        SingleColumnValueFilter scvf = new SingleColumnValueFilter(\"base_info\".getBytes(),\r\n        \"username\".getBytes(), CompareOp.EQUAL, comparator2);\r\n        testScan(scvf);\r\n\r\n        // 针对列族名的过滤器返回结果中只会包含满足条件的列族中的数据\r\n        FamilyFilter ff1 = new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(\"inf\")));\r\n        FamilyFilter ff2 = new FamilyFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"base\")));\r\n        testScan(ff1);\r\n\r\n        // 针对列名的过滤器返回结果中只会包含满足条件的列的数据\r\n        QualifierFilter qf = new QualifierFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(\"password\")));\r\n        QualifierFilter qf2 = new QualifierFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"us\")));\r\n        testScan(qf);\r\n\r\n        // 跟 SingleColumnValueFilter 结果不同，只返回符合条件的该column\r\n        ColumnPrefixFilter cf = new ColumnPrefixFilter(\"passw\".getBytes());\r\n        testScan(cf);\r\n\r\n        byte[][] prefixes = new byte[][]{ Bytes.toBytes(\"username\"),Bytes.toBytes(\"password\") };\r\n        MultipleColumnPrefixFilter mcf = new MultipleColumnPrefixFilter(prefixes);\r\n        testScan(mcf);\r\n\r\n        FamilyFilter ff2 = new FamilyFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"base\")));\r\n        ColumnPrefixFilter cf = new ColumnPrefixFilter(\"passw\".getBytes());\r\n        FilterList filterList = new FilterList(Operator.MUST_PASS_ALL);\r\n        filterList.addFilter(ff2);\r\n        filterList.addFilter(cf);\r\n        testScan(filterList);\r\n    }\r\n```\r\n\r\n```java\r\n    private void testScan(Filter filter) throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n        Scan scan = new Scan();\r\n        scan.setFilter(filter);\r\n        ResultScanner scanner = t_person_info.getScanner(scan);\r\n        Iterator<Result> iter = scanner.iterator();\r\n        while (iter.hasNext()) {\r\n            Result result = iter.next();\r\n            CellScanner cellScanner = result.cellScanner();\r\n            while (cellScanner.advance()) {\r\n                Cell current = cellScanner.current();\r\n                byte[] familyArray = current.getFamilyArray();\r\n                byte[] valueArray = current.getValueArray();\r\n                byte[] qualifierArray = current.getQualifierArray();\r\n                byte[] rowArray = current.getRowArray();\r\n                System.out.println(new String(rowArray, current.getRowOffset(),current.getRowLength()));\r\n                System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n                System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n                System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n            }\r\n            System.out.println(\"-----------------------\");\r\n        }\r\n    }\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.5.1. HBase Demo Java API 常用操作",
      "lvl1": "pom.xml",
      "lvl2": "获得连接",
      "lvl3": "建表",
      "lvl4": "删除表",
      "lvl5": "修改表结构",
      "lvl6": "插入/修改数据",
      "lvl7": "get 查询",
      "lvl8": "删除表中数据",
      "lvl9": "scan 查询",
      "lvl10": "过滤查询"
    },
    "frontmatter": {
      "title": "13.5.1. HBase Demo Java API 常用操作",
      "date": "2025/07/02"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "13.6.1. HBase ServerNotRunningYetException",
    "path": "/docs/architect/hadoop/Hadoop-13.6.1.HBaseServerNotRunningYetException.html",
    "url": "/docs/architect/hadoop/Hadoop-13.6.1.HBaseServerNotRunningYetException.html",
    "content": "---\r\ntitle: 13.6.1. HBase ServerNotRunningYetException\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger ServerNotRunningYetException\r\n- HBase ServerNotRunningYetException: Server is not running yet\r\n:::\r\n\r\n`hbase-site.xml` 中添加:\r\n```xml\r\n  <property>\r\n    <name>hbase.wal.provider</name>\r\n    <value>filesystem</value>\r\n  </property>\r\n```\r\n\r\n重启 HBase 即可\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.6.1. HBase ServerNotRunningYetException"
    },
    "frontmatter": {
      "title": "13.6.1. HBase ServerNotRunningYetException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.6.2. HBase No Hbase Master Found",
    "path": "/docs/architect/hadoop/Hadoop-13.6.2.HBaseNoHbaseMasterFound.html",
    "url": "/docs/architect/hadoop/Hadoop-13.6.2.HBaseNoHbaseMasterFound.html",
    "content": "---\r\ntitle: 13.6.2. HBase No Hbase Master Found\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger\r\n- HBase-stop-hbase.sh: no hbase master found\r\n:::\r\n\r\n1. `hbase-env.sh` 中添加: `export HBASE_PID_DIR=/var/hbase/pids`\r\n2. `jps` 查看 hbase 相关的 pid, 然后 `kill -9` 结束进程\r\n3. `start-hbase.sh` 启动 hbase\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.6.2. HBase No Hbase Master Found"
    },
    "frontmatter": {
      "title": "13.6.2. HBase No Hbase Master Found",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14. Sqoop 特点",
    "path": "/docs/architect/hadoop/Hadoop-14-Sqoop-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-14-Sqoop-tedian.html",
    "content": "---\r\ntitle: 14. Sqoop 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n## Sqoop 简介\r\nSqoop 是 apache 旗下的工具，用于实现结构型数据（如关系数据库）和 Hadoop 之间进行数据迁移的工具, 可以讲关系型数据库中的数据导入到 Hadoop 的 HDFS 中，同样也完全可以把 HDFS 的数据导入到关系型数据库里面\r\n* 导入数据：MySQL, Oracle 导入数据到 Hadoop 的 HDFS, HIVE, HBASE 等数据存储系统\r\n* 导出数据：从 Hadoop 的文件系统中导出数据到关系数据库\r\n\r\n![Sqoop](static/sqoop.png)\r\n\r\n## Sqoop 原理\r\nSqoop 把导入或导出命令翻译成 `mapreduce` 代码来实现, 在翻译出的 `mapreduce` 中，其实只是对 `inputformat` 和 `outputformat` 进行了定制\r\n\r\n---\r\n\r\n<font color=\"red\">该项目已于 2021-06 终止, 并移入 Apache Attic</font>\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14. Sqoop 特点",
      "lvl1": "Sqoop 简介",
      "lvl2": "Sqoop 原理"
    },
    "frontmatter": {
      "title": "14. Sqoop 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.1. Sqoop 导入数据到 HBase",
    "path": "/docs/architect/hadoop/Hadoop-14.1.SqoopdaorushujudaoHBase.html",
    "url": "/docs/architect/hadoop/Hadoop-14.1.SqoopdaorushujudaoHBase.html",
    "content": "---\r\ntitle: 14.1. Sqoop 导入数据到 HBase\r\ndate: 2025/07/02\r\n---\r\n\r\n1. 创建 HBase 表: `create 'hbase_person','info'`\r\n2. 导入数据到 HBase\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --columns \"pid,name,sex\" \\\r\n        --column-family \"info\" \\\r\n        --hbase-create-table \\\r\n        --hbase-row-key \"pid\" \\\r\n        --hbase-table \"hbase_person\" \\\r\n        --num-mappers 1 \\\r\n        --split-by pid\r\n    ```\r\n3. `scan 'hbase_person'`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.1. Sqoop 导入数据到 HBase"
    },
    "frontmatter": {
      "title": "14.1. Sqoop 导入数据到 HBase",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.2. Sqoop Hive 与 Mysql 互导",
    "path": "/docs/architect/hadoop/Hadoop-14.2.SqoopHiveyuMysqlhudao.html",
    "url": "/docs/architect/hadoop/Hadoop-14.2.SqoopHiveyuMysqlhudao.html",
    "content": "---\r\ntitle: 14.2. Sqoop Hive 与 Mysql 互导\r\ndate: 2025/07/02\r\n---\r\n\r\n* 导入数据到 HIVE\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --num-mappers 1 \\\r\n        --hive-import \\\r\n        --fields-terminated-by \",\" \\\r\n        --hive-overwrite \\\r\n        --hive-table person_hive\r\n    ```\r\n* hive/hdfs 导入数据到 mysql\r\n    ```bash\r\n    sqoop export \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person2 \\\r\n        --export-dir /user/hive/warehouse/person_hive \\\r\n        --m 1\r\n    ```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.2. Sqoop Hive 与 Mysql 互导"
    },
    "frontmatter": {
      "title": "14.2. Sqoop Hive 与 Mysql 互导",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.3. Sqoop Mysql 导入 HDFS",
    "path": "/docs/architect/hadoop/Hadoop-14.3.SqoopMysqldaoruHDFS.html",
    "url": "/docs/architect/hadoop/Hadoop-14.3.SqoopMysqldaoruHDFS.html",
    "content": "---\r\ntitle: 14.3. Sqoop Mysql 导入 HDFS\r\ndate: 2025/07/02\r\n---\r\n\r\n1. Mysql 测试数据\r\n    ```sql\r\n    create database sqooptest;\r\n    Use sqooptest\r\n    create table person(pid int primary key auto_increment, name varchar(20), sex varchar(20));\r\n    insert into person(name, sex) values('james', 'Male');\r\n    insert into person(name, sex) values('lison', 'Female');\r\n    ```\r\n2. 全量导入\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\"\r\n\r\n    hadoop fs -cat /user/person/part-m-00000\r\n    ```\r\n3. 带查询条件导入: `$CONDITIONS` 不能省略, 要链接 sqoop 默认的条件\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\" \\\r\n        --query 'select name,sex from person where pid <=1 and $CONDITIONS;'\r\n\r\n    hadoop fs -cat /user/person/part-m-00000\r\n    ```\r\n4. 导入特定列\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\" \\\r\n        --columns pid,sex \\\r\n        --table person\r\n    ```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.3. Sqoop Mysql 导入 HDFS"
    },
    "frontmatter": {
      "title": "14.3. Sqoop Mysql 导入 HDFS",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.1. Demo 单词统计",
    "path": "/docs/architect/hadoop/Hadoop-15.1.Demodancitongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.1.Demodancitongji.html",
    "content": "---\r\ntitle: 15.1. Demo 单词统计\r\ndate: 2025/07/02\r\n---\r\n\r\n导入 `hadoop` 和 `hadoop.mapreduce` 包下的类\r\n\r\n## WCMapper.java\r\n```java\r\n// 泛型分别是：输入的键值类型; 输出的键值类型 \r\npublic class WCMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\r\n\r\n    @Override\r\n    protected void map(LongWritable key, @NotNull Text value, Context context) throws IOException, InterruptedException {\r\n        String line = value.toString();\r\n        String[] words = line.split(\" \");\r\n        for (String word : words) {\r\n            context.write(new Text(word), new IntWritable(1));\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n\r\n## WCReducer.java\r\n```java\r\n// 泛型分别是：输入的键值类型; 输出的键值类型 \r\npublic class WCReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\r\n\r\n    @Override\r\n    protected void reduce(Text key, @NotNull Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\r\n        int count = 0;\r\n        for (IntWritable v : values) {\r\n            count += v.get();\r\n        }\r\n        context.write(key, new IntWritable(count));\r\n    }\r\n\r\n}\r\n```\r\n\r\n## WCJob.java\r\n```java\r\npublic class WCJob {\r\n\r\n    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n\r\n        job.setJarByClass(WCJob.class);\r\n\r\n        job.setMapperClass(WCMapper.class);\r\n        job.setReducerClass(WCReducer.class);\r\n        \r\n//        Mapper 输出键值类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n\r\n//        Reducer 输出键值类型\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n\r\n//         前期准备, 在 Hadoop /wc/input 目录中上传进待分析的文件\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\"));\r\n\r\n//        等待执行完并检查是否执行成功\r\n        System.exit(job.waitForCompletion(true)? 0:-1);\r\n    }\r\n\r\n}\r\n```\r\n\r\n## pom.xml\r\n```xml\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-jar-plugin</artifactId>\r\n                <version>3.3.0</version>\r\n                <configuration>\r\n                    <archive>\r\n                        <manifest>\r\n                            <addClasspath>true</addClasspath>\r\n                            <classpathPrefix>lib/</classpathPrefix>\r\n                            <mainClass>org.jxch.study.hadoop.mr.wc.WCJob</mainClass>\r\n                        </manifest>\r\n                    </archive>\r\n                </configuration>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 运行\r\n编译 jar 包: `mvn package -Dmaven.test.skip=true -f pom.xml`\r\n将 jar 包上传到 Hadoop 服务器之后，执行命令: `hadoop jar /home/jxch/study-hadoop-1.0-SNAPSHOT.jar `\r\n\r\n跑完后，检查运行结果:\r\n* `hadoop fs -ls /wc/output`\r\n* `hadoop fs -cat /wc/output/part-r-00000`\r\n\r\n---\r\n\r\n## 依赖包\r\n```xml\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-common</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-hdfs</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-client</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>junit</groupId>\r\n            <artifactId>junit</artifactId>\r\n            <version>4.13.2</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-api</artifactId>\r\n            <version>2.0.7</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-simple</artifactId>\r\n            <version>2.0.7</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.projectlombok</groupId>\r\n            <artifactId>lombok</artifactId>\r\n            <version>1.18.26</version>\r\n            <scope>provided</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.jetbrains</groupId>\r\n            <artifactId>annotations</artifactId>\r\n            <version>RELEASE</version>\r\n            <scope>compile</scope>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.1. Demo 单词统计",
      "lvl1": "WCMapper.java",
      "lvl2": "WCReducer.java",
      "lvl3": "WCJob.java",
      "lvl4": "pom.xml",
      "lvl5": "运行",
      "lvl6": "依赖包"
    },
    "frontmatter": {
      "title": "15.1. Demo 单词统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.2. Demo 单词分组排序统计",
    "path": "/docs/architect/hadoop/Hadoop-15.2.Demodancifenzupaixutongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.2.Demodancifenzupaixutongji.html",
    "content": "---\r\ntitle: 15.2. Demo 单词分组排序统计\r\ndate: 2025/07/02\r\n---\r\n\r\n先进行单词统计: [15.Demo单词统计](./Hadoop-15.Demo单词统计.md)\r\n\r\n## 排序\r\n利用对Mapper输出的Key的自动排序进行排序\r\n\r\n```java\r\npublic class WCSortMapper extends Mapper<LongWritable, Text, DescIntWritable, Text> {\r\n    @Override\r\n    protected void map(LongWritable key, @NotNull Text value, @NotNull Context context) throws IOException, InterruptedException {\r\n        String line = value.toString();\r\n        String[] words = line.split(\"\\t\");\r\n        if (words.length == 2) {\r\n            context.write(new DescIntWritable(Integer.parseInt(words[1])), new Text(words[0]));\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n```java\r\npublic class WCSortReducer extends Reducer<DescIntWritable, Text, Text, IntWritable> {\r\n    @Override\r\n    protected void reduce(DescIntWritable key, @NotNull Iterable<Text> values, Context context) throws IOException, InterruptedException {\r\n        for (Text word : values) {\r\n            context.write(word, key);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n```java\r\npublic class DescIntWritable extends IntWritable {\r\n\r\n    public DescIntWritable() {\r\n    }\r\n\r\n    public DescIntWritable(int value) {\r\n        super(value);\r\n    }\r\n\r\n    @Override\r\n    public int compareTo(IntWritable o) {\r\n        return -super.compareTo(o);\r\n    }\r\n}\r\n```\r\n\r\n## 分组\r\n\r\n```java\r\npublic class WCPartitioner extends Partitioner<DescIntWritable, Text> {\r\n\r\n    @Override\r\n    public int getPartition(DescIntWritable descIntWritable, @NotNull Text text, int numPartitions) {\r\n        return text.toString().contains(\"jxch\") ? 0 : 1;\r\n    }\r\n\r\n}\r\n```\r\n\r\n## Job\r\n先完成单词统计的任务，然后在此基础上进行分组排序\r\n```java\r\npublic class WCSortJob {\r\n    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {\r\n        Job job = Job.getInstance(new Configuration());\r\n\r\n        job.setJarByClass(WCSortJob.class);\r\n\r\n        job.setMapperClass(WCMapper.class);\r\n        job.setReducerClass(WCReducer.class);\r\n\r\n//        Mapper 输出键值类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n\r\n//        Reducer 输出键值类型\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\"));\r\n\r\n//        等待执行完并检查是否执行成功\r\n        if (job.waitForCompletion(true)) {\r\n            Job sortJob = Job.getInstance(new Configuration());\r\n\r\n            sortJob.setJarByClass(WCSortJob.class);\r\n            sortJob.setMapperClass(WCSortMapper.class);\r\n            sortJob.setReducerClass(WCSortReducer.class);\r\n            sortJob.setMapOutputKeyClass(DescIntWritable.class);\r\n            sortJob.setMapOutputValueClass(Text.class);\r\n            sortJob.setOutputKeyClass(Text.class);\r\n            sortJob.setOutputValueClass(IntWritable.class);\r\n            sortJob.setInputFormatClass(TextInputFormat.class);\r\n            sortJob.setOutputFormatClass(TextOutputFormat.class);\r\n            sortJob.setPartitionerClass(WCPartitioner.class);\r\n            sortJob.setNumReduceTasks(2);\r\n\r\n            FileInputFormat.setInputPaths(sortJob, new Path(\"/wc/output\"));\r\n            FileOutputFormat.setOutputPath(sortJob, new Path(\"/wc/output_sort\"));\r\n\r\n            System.exit(sortJob.waitForCompletion(true)? 0:-1);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n## pom.xml\r\n```xml\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-jar-plugin</artifactId>\r\n                <version>3.3.0</version>\r\n                <configuration>\r\n                    <archive>\r\n                        <manifest>\r\n                            <addClasspath>true</addClasspath>\r\n                            <classpathPrefix>lib/</classpathPrefix>\r\n                            <mainClass>org.jxch.study.hadoop.mr.wc.sort.WCSortJob</mainClass>\r\n                        </manifest>\r\n                    </archive>\r\n                </configuration>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 运行\r\n编译 jar 包: `mvn package -Dmaven.test.skip=true -f pom.xml`\r\n将 jar 包上传到 Hadoop 服务器之后，执行命令: `hadoop jar /home/jxch/study-hadoop-1.1-SNAPSHOT.jar `\r\n\r\n跑完后，检查运行结果:\r\n* `hadoop fs -ls /wc/output_sort`\r\n* `hadoop fs -cat /wc/output_sort/part-r-00000`\r\n* `hadoop fs -cat /wc/output_sort/part-r-00001`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.2. Demo 单词分组排序统计",
      "lvl1": "排序",
      "lvl2": "分组",
      "lvl3": "Job",
      "lvl4": "pom.xml",
      "lvl5": "运行"
    },
    "frontmatter": {
      "title": "15.2. Demo 单词分组排序统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.3. Demo 倒排索引-文章单词统计",
    "path": "/docs/architect/hadoop/Hadoop-15.3.Demodaopaisuoyin-wenzhangdancitongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.3.Demodaopaisuoyin-wenzhangdancitongji.html",
    "content": "---\r\ntitle: 15.3. Demo 倒排索引-文章单词统计\r\ndate: 2025/07/02\r\n---\r\n\r\n## 思路 (倒推法)\r\n\r\n第二步:\r\n* Reduce\r\n    * key:单词\r\n    * values[] 文章--次数\r\n* Map \r\n    * key: 单词\r\n    * value: 文章--次数\r\n\r\n第一步:\r\n* Reduce\r\n    * key: 单词--文档位置 \r\n    * value: 单词次数\r\n* Map\r\n    * key: 单词--文档位置 \r\n    * value: 1\r\n\r\n---\r\n\r\n## JAVA 代码\r\n\r\n### IndexStepOne.java\r\n```java\r\npublic class IndexStepOne {\r\n    public static class IndexStepOneMapper extends Mapper<LongWritable, Text, Text, IntWritable>{\r\n        Text k = new Text();\r\n        IntWritable v = new IntWritable(1);\r\n\r\n        @Override\r\n        protected void map(LongWritable key, Text value,Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] words = line.split(\" \");\r\n            FileSplit Split = (FileSplit)context.getInputSplit();\r\n            String filename = Split.getPath().getName();\r\n            //输出 key :单词--文件名 value:1\r\n            for(String word : words){\r\n                k.set(word +\"--\"+ filename);\r\n                context.write(k, v);\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class IndexStepOneReducer extends Reducer<Text, IntWritable, Text, IntWritable>{\r\n        IntWritable v = new IntWritable();\r\n\r\n        @Override\r\n        protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\r\n            int count = 0;\r\n            for(IntWritable value : values){\r\n                count += value.get();\r\n            }\r\n            v.set(count);\r\n            context.write(key, v);\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(IndexStepOne.class);\r\n        job.setMapperClass(IndexStepOneMapper.class);\r\n        job.setReducerClass(IndexStepOneReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n        //这里可以进行 combiner 组件的设置\r\n        job.setCombinerClass(IndexStepOneReducer.class);\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:/index/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:/index/output-1\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n### IndexStepTwo.java\r\n```java\r\npublic class IndexStepTwo {\r\n    public static class IndexStepTwoMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        Text k = new Text();\r\n        Text v = new Text();\r\n        \r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] fields = line.split(\"\\t\");\r\n            String word_file = fields[0];\r\n            String count = fields[1];\r\n            String[] split = word_file.split(\"--\");\r\n            String word = split[0];\r\n            String file = split[1];\r\n            k.set(word);\r\n            v.set(file+\"--\"+count);\r\n            context.write(k, v);\r\n        }\r\n    }\r\n\r\n    public static class IndexStepTwoReducer extends Reducer<Text, Text, Text, Text>{\r\n        Text v = new Text();\r\n\r\n        @Override\r\n        protected void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for (Text value : values) {\r\n                sBuffer.append(value.toString()).append(\" \");\r\n            }\r\n            v.set(sBuffer.toString());\r\n            context.write(key, v);\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(IndexStepTwo.class);\r\n        //告诉程序，我们的程序所用的 mapper 类和 reducer 类是什么\r\n        job.setMapperClass(IndexStepTwoMapper.class);\r\n        job.setReducerClass(IndexStepTwoReducer.class);\r\n        //告诉框架，我们程序输出的数据类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        //这里可以进行 combiner 组件的设置\r\n        job.setCombinerClass(IndexStepTwoReducer.class);\r\n        //告诉框架，我们要处理的数据文件在那个路劲下\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:/index/output-1\"));\r\n        //告诉框架，我们的处理结果要输出到什么地方\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:/index/output-2\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.3. Demo 倒排索引-文章单词统计",
      "lvl1": "思路 (倒推法)",
      "lvl2": "JAVA 代码"
    },
    "frontmatter": {
      "title": "15.3. Demo 倒排索引-文章单词统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.4. Demo 共同好友",
    "path": "/docs/architect/hadoop/Hadoop-15.4.Demogongtonghaoyou.html",
    "url": "/docs/architect/hadoop/Hadoop-15.4.Demogongtonghaoyou.html",
    "content": "---\r\ntitle: 15.4. Demo 共同好友\r\ndate: 2025/07/02\r\n---\r\n\r\n## 思路\r\n原数据:\r\n```text\r\nA:B,C,D,F,E,O\r\nB:A,C,E,K\r\nC:F,A,D,I\r\nD:A,E,F,L\r\nE:B,C,D,M,L\r\nF:A,s,C,D,E,O,M\r\nG:A,C,D,E,F\r\nH:A,C,D,E,O\r\nI:A,O\r\nJ:B,O\r\nK:A,C,D\r\nL:D,E,F\r\nM:E,F,G\r\nO:A,H,I,J\r\n```\r\n\r\n1. 先找出一个用户是哪些用户的共同好友（比如 C 是哪些用户的共同好友，以上题目中的 C 是用户 A,B,E,F,G,H,K 的共同好友，所以 AB 的共同好友为 C，AE 的共同好友为 C，以此类推。。。）\r\n2. 经过第一步推算，得到 AE 的 共同好友还有 D，最后将 AE 的共同好友合并得到 C,D，这只是举个例子，他们的共同好友还有很多，即将两两用户作为 key，好友作为 value，以此类推，因此需要写两个 mapreduce\r\n\r\n## JAVA 代码\r\n### FriendsStepOne.java\r\n```java\r\npublic class FriendsStepOne {\r\n    public static class FriendsStepOneMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] splits = line.split(\":\");\r\n            String person = splits[0];\r\n            String[] friends = splits[1].split(\",\");\r\n            for(String fString :friends){\r\n                context.write(new Text(fString), new Text(person));\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class FriendsStepOneReducer extends Reducer<Text, Text, Text, Text>{\r\n        @Override\r\n        protected void reduce(Text friend, Iterable<Text> persons, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for(Text pText :persons){\r\n                sBuffer.append(pText).append(\"-\");\r\n            }\r\n            context.write(friend, new Text(sBuffer.toString()));\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(FriendsStepOne.class);\r\n        job.setMapperClass(FriendsStepOneMapper.class);\r\n        job.setReducerClass(FriendsStepOneReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:\\\\friends\\\\input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:\\\\friends\\\\output-1\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n### FriendsStepTwo.java\r\n```java\r\npublic class FriendsStepTwo {\r\n    public static class FriendsStepTwoMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] splits = line.split(\"\\t\");\r\n            String friend = splits[0];\r\n            String[] persons = splits[1].split(\"-\");\r\n            Arrays.sort(persons);\r\n            for (int i = 0; i < persons.length-1; i++) {\r\n                for (int j = i+1; j < persons.length; j++) {\r\n                    context.write(new Text(persons[i]+\"-\"+persons[j]), new Text(friend));\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class FriendsStepTwoReducer extends Reducer<Text, Text, Text, Text>{\r\n        @Override\r\n        protected void reduce(Text person_pair, Iterable<Text> friends, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for(Text fText : friends){\r\n                sBuffer.append(fText).append(\" \");\r\n            }\r\n            context.write(person_pair, new Text(sBuffer.toString()));\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(FriendsStepTwo.class);\r\n        job.setMapperClass(FriendsStepTwoMapper.class);\r\n        job.setReducerClass(FriendsStepTwoReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:\\\\friends\\\\output-1\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:\\\\friends\\\\output-2\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.4. Demo 共同好友",
      "lvl1": "思路",
      "lvl2": "JAVA 代码"
    },
    "frontmatter": {
      "title": "15.4. Demo 共同好友",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.5. Demo 自定义 InputFileFormat",
    "path": "/docs/architect/hadoop/Hadoop-15.5.DemozidingyiInputFileFormat.html",
    "url": "/docs/architect/hadoop/Hadoop-15.5.DemozidingyiInputFileFormat.html",
    "content": "---\r\ntitle: 15.5. Demo 自定义 InputFileFormat\r\ndate: 2025/07/02\r\n---\r\n\r\n以 excel 的文件举例\r\n\r\n## pom.xml\r\n```xml\r\n<dependency>\r\n    <groupId>net.sourceforge.jexcelapi</groupId>\r\n    <artifactId>jxl</artifactId>\r\n    <version>2.6.12</version>\r\n</dependency>\r\n```\r\n\r\n## ExcelInputFormat.java\r\n```java\r\npublic class ExcelFileInputFormat extends FileInputFormat<IntWritable,Text> {\r\n    @Override\r\n    protected boolean isSplitable(JobContext context, Path filename) {\r\n        return false;\r\n    }\r\n    public RecordReader<IntWritable, Text> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {\r\n        return new ExcelRecordReader();\r\n    }\r\n}\r\n```\r\n\r\n## ExcelRecordReader.java\r\n```java\r\npublic class ExcelRecordReader extends RecordReader<IntWritable,Text> {\r\n    private int rows;\r\n    private int current = -1;\r\n    private Sheet sheet;\r\n    private Workbook workbook;\r\n    \r\n    @Override\r\n    public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {\r\n        FileSplit filesplit = (FileSplit) split;\r\n        Configuration conf= context.getConfiguration();\r\n        Path filePath =filesplit.getPath();\r\n        FileSystem fs=filePath.getFileSystem(conf);\r\n        FSDataInputStream inputStream = fs.open(filePath);\r\n        try {\r\n            workbook = Workbook.getWorkbook(inputStream);\r\n            sheet = workbook.getSheets()[0];\r\n            rows = sheet.getRows();\r\n        } catch (BiffException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public boolean nextKeyValue() throws IOException, InterruptedException {\r\n        if(current<rows-1) {\r\n            current++;\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n\r\n    @Override\r\n    public IntWritable getCurrentKey() throws IOException, InterruptedException {\r\n        return new IntWritable(current);\r\n    }\r\n\r\n    @Override\r\n    public Text getCurrentValue() throws IOException, InterruptedException {\r\n        StringBuffer sb = new StringBuffer(\"\");\r\n        for(int i=0; i<sheet.getColumns(); i++){\r\n            Cell cell = sheet.getCell(i, current);\r\n            sb.append(cell.getContents() + \" \");\r\n        }\r\n        return new Text(sb.toString());\r\n    }\r\n\r\n    @Override\r\n    public float getProgress() throws IOException, InterruptedException {\r\n        return current/rows;\r\n    }\r\n\r\n    @Override\r\n    public void close() throws IOException {\r\n        workbook.close();\r\n    }\r\n}\r\n```\r\n\r\n## ExcelMapper.java\r\n```java\r\npublic class ExcelMapper extends Mapper<IntWritable,Text,IntWritable,Text> {\r\n    @Override\r\n    protected void map(IntWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n        super.map(key, value, context);\r\n    }\r\n}\r\n```\r\n\r\n## ExcelJob.java\r\n```java\r\npublic class ExcelJob {\r\n    public static void main(String[] args) throws Exception{\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(ExcelJob.class);\r\n        job.setMapperClass(ExcelMapper.class);\r\n        job.setMapOutputKeyClass(IntWritable.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setInputFormatClass(ExcelFileInputFormat.class);\r\n        //不需要Reduce\r\n        job.setNumReduceTasks(0);\r\n        //指定文件得读取位置\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/excel\"));\r\n        //指定文件得输出位置\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/excelout\"));\r\n\r\n        System.exit(job.waitForCompletion(true) ? 0 : -1);\r\n    }\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.5. Demo 自定义 InputFileFormat",
      "lvl1": "pom.xml",
      "lvl2": "ExcelInputFormat.java",
      "lvl3": "ExcelRecordReader.java",
      "lvl4": "ExcelMapper.java",
      "lvl5": "ExcelJob.java"
    },
    "frontmatter": {
      "title": "15.5. Demo 自定义 InputFileFormat",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.6. Demo 自定义 OutputFileFormat",
    "path": "/docs/architect/hadoop/Hadoop-15.6.DemozidingyiOutputFileFormat.html",
    "url": "/docs/architect/hadoop/Hadoop-15.6.DemozidingyiOutputFileFormat.html",
    "content": "---\r\ntitle: 15.6. Demo 自定义 OutputFileFormat\r\ndate: 2025/07/02\r\n---\r\n\r\n如果单词是老师人名，放到一个目录，否则放到另外一个目录\r\n\r\n## TeacherOutPutFormat.java\r\n```java\r\npublic class TeacherOutPutFormat extends FileOutputFormat<Text,NullWritable> {\r\n    \r\n    public RecordWriter<Text,NullWritable> getRecordWriter(TaskAttemptContext job) throws IOException, InterruptedException {\r\n        FileSystem fs = FileSystem.get(job.getConfiguration());\r\n        Path teacherPath = new Path(\"/wc/excelteacher/excelteacher.txt\");\r\n        Path otherPath = new Path(\"/wc/excelother/excelother.txt\");\r\n        FSDataOutputStream teacherOut = fs.create(teacherPath);\r\n        FSDataOutputStream otherOut = fs.create(otherPath);\r\n        return new TeacherRecordWriter(teacherOut,otherOut);\r\n    }\r\n\r\n    static class TeacherRecordWriter extends RecordWriter<Text,NullWritable> {\r\n        FSDataOutputStream teacherOut;\r\n        FSDataOutputStream otherOut;\r\n        \r\n        public TeacherRecordWriter(FSDataOutputStream teacherOut, FSDataOutputStream otherOut) {\r\n            this.teacherOut = teacherOut;\r\n            this.otherOut = otherOut;\r\n        }\r\n\r\n        public void write(Text key, NullWritable value) throws IOException, InterruptedException {\r\n            String keyStr = key.toString()+\"\\n\";\r\n            if(keyStr.contains(\":teacher\")){\r\n                String resultKey = keyStr.replace(\":teacher\", \"\");\r\n                teacherOut.write(resultKey.getBytes());\r\n            }else {\r\n                otherOut.write(keyStr.getBytes());\r\n            }\r\n        }\r\n\r\n        public void close(TaskAttemptContext context) throws IOException, InterruptedException {\r\n            if(teacherOut !=null) {\r\n                teacherOut.close();\r\n            }\r\n            if(otherOut !=null) {\r\n                otherOut.close();\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n## ExcelMapper.java\r\n```java\r\npublic class ExcelMapper extends Mapper<IntWritable,Text,Text,NullWritable> {\r\n    private List<String> teachers = null;\r\n    \r\n    @Override\r\n    protected void map(IntWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n        String[] words = value.toString().split(\" \");\r\n        for(String word :words) {\r\n            if(teachers.contains(word)) {\r\n                word = word+\":teacher\";\r\n            }\r\n            context.write(new Text(word),NullWritable.get());\r\n        }\r\n    }\r\n\r\n    @Override\r\n    protected void setup(Context context) throws IOException, InterruptedException {\r\n        teachers = new ArrayList<String>();\r\n        teachers.add(\"deer\");\r\n        teachers.add(\"james\");\r\n        teachers.add(\"peter\");\r\n        teachers.add(\"lison\");\r\n        teachers.add(\"king\");\r\n        teachers.add(\"mark\");\r\n    }\r\n}\r\n```\r\n\r\n## ExcelJob.java\r\n```java\r\npublic class ExcelJob {\r\n    public static void main(String[] args) throws Exception{\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(ExcelJob.class);\r\n        job.setMapperClass(ExcelMapper.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(NullWritable.class);\r\n        job.setInputFormatClass(ExcelFileInputFormat.class);\r\n        job.setOutputFormatClass(TeacherOutPutFormat.class);\r\n        //不需要Reduce\r\n        job.setNumReduceTasks(0);\r\n        //指定文件得读取位置\r\n        FileInputFormat.setInputPaths(job,new Path(\"D:\\\\wc\\\\excel\"));\r\n        //指定文件得输出位置 还有success文件需要输出 \r\n        FileOutputFormat.setOutputPath(job,new Path(\"D:\\\\wc\\\\excelout\"));\r\n\r\n        System.exit(job.waitForCompletion(true) ? 0 : -1);\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.6. Demo 自定义 OutputFileFormat",
      "lvl1": "TeacherOutPutFormat.java",
      "lvl2": "ExcelMapper.java",
      "lvl3": "ExcelJob.java"
    },
    "frontmatter": {
      "title": "15.6. Demo 自定义 OutputFileFormat",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.7. Demo 文件操作 FileSystem",
    "path": "/docs/architect/hadoop/Hadoop-15.7.DemowenjiancaozuoFileSystem.html",
    "url": "/docs/architect/hadoop/Hadoop-15.7.DemowenjiancaozuoFileSystem.html",
    "content": "---\r\ntitle: 15.7. Demo 文件操作 FileSystem \r\ndate: 2025/07/02\r\n---\r\n\r\n\r\n## FSTest.java\r\n```java\r\n/**\r\n * 需要安装Hadoop程序, 并配置环境变量(HADOOP_HOME)\r\n * 不配置也可以使用部分功能\r\n * 配置本地的hosts文件, 对应hadoop01的ip地址\r\n */\r\n@Slf4j\r\npublic class FSTest {\r\n\r\n    public static FileSystem fileSystem;\r\n\r\n\r\n    @Before\r\n    public void init() throws URISyntaxException, IOException, InterruptedException {\r\n        fileSystem = FileSystem.get(new URI(\"hdfs://hadoop01:9000\"), new Configuration(), \"root\");\r\n    }\r\n\r\n    @After\r\n    public void close() throws IOException {\r\n        fileSystem.close();\r\n    }\r\n\r\n    //显示根目录下文件\r\n    @Test\r\n    public void showRootFiles() throws Exception {\r\n        RemoteIterator<LocatedFileStatus> files = fileSystem.listFiles(new Path(\"/\"), false);\r\n        while (files.hasNext()) {\r\n            LocatedFileStatus fileStatus = files.next();\r\n            Path path = fileStatus.getPath();\r\n            String name = path.getName();\r\n            log.info(\"{} -> {}\", path, name);\r\n        }\r\n    }\r\n\r\n    //测试上传文件\r\n    @Test\r\n    public void testCopyFromLocalFile() throws Exception {\r\n        Path src = new Path(\"E:\\\\work\\\\test.txt\");\r\n        Path dst = new Path(\"/\");\r\n        fileSystem.copyFromLocalFile(src, dst);\r\n    }\r\n\r\n    //测试删除文件\r\n    @Test\r\n    public void testDelete() throws Exception {\r\n        Path dst = new Path(\"/test.txt\");\r\n        fileSystem.delete(dst, true);\r\n    }\r\n\r\n    //测试使用流的方式上传\r\n    @Test\r\n    public void testUploadUseStream() throws Exception {\r\n        FileInputStream fis = new FileInputStream(\"E:\\\\work\\\\test.txt\");\r\n        Path path = new Path(\"/test.txt\");\r\n        FSDataOutputStream fos = fileSystem.create(path);\r\n        IOUtils.copy(fis, fos);\r\n    }\r\n\r\n    //测试下载文件\r\n    @Test\r\n    public void testCopyToLocalFile() throws Exception {\r\n//        这种方式只有配置了HADOOP_HOME之后才能使用\r\n//        fileSystem.copyToLocalFile(new Path(\"/test.txt\"), new Path(\"E:\\\\work\\\\test2.txt\"));\r\n\r\n//        使用Java默认的方式 (RawLocalFileSystem)\r\n        fileSystem.copyToLocalFile(false, new Path(\"/test.txt\"), new Path(\"E:\\\\work\\\\test2.txt\"), true);\r\n    }\r\n}\r\n```\r\n\r\n\r\n## pom.xml\r\n```xml\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-common</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-hdfs</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-client</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>junit</groupId>\r\n            <artifactId>junit</artifactId>\r\n            <version>4.13.2</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-api</artifactId>\r\n            <version>2.0.7</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-simple</artifactId>\r\n            <version>2.0.7</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.projectlombok</groupId>\r\n            <artifactId>lombok</artifactId>\r\n            <version>1.18.26</version>\r\n            <scope>provided</scope>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.7. Demo 文件操作 FileSystem",
      "lvl1": "FSTest.java",
      "lvl2": "pom.xml"
    },
    "frontmatter": {
      "title": "15.7. Demo 文件操作 FileSystem",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "16.1. 启动时没有启动 datanode",
    "path": "/docs/architect/hadoop/Hadoop-16.1.qidongshimeiyouqidongdatanode.html",
    "url": "/docs/architect/hadoop/Hadoop-16.1.qidongshimeiyouqidongdatanode.html",
    "content": "---\r\ntitle: 16.1. 启动时没有启动 datanode\r\ndate: 2025/07/02\r\n---\r\n\r\n原因:\r\n在第一次格式化`dfs`后，启动并使用了`hadoop`，后来又重新执行了格式化命令 `hdfs namenode -format`，这时`namenode`的`clusterID`会重新生成，而`datanode`的`clusterID` 保持不变。\r\n\r\n解决方法:\r\n1. 删除目录，重新格式化\r\n2. 将`name/current`下的`VERSION`中的`clusterID`复制到`data/current`下的`VERSION`中，覆盖掉原来的`clusterID`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "16.1. 启动时没有启动 datanode"
    },
    "frontmatter": {
      "title": "16.1. 启动时没有启动 datanode",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "16.2. ClassNotFoundException",
    "path": "/docs/architect/hadoop/Hadoop-16.2.ClassNotFoundException.html",
    "url": "/docs/architect/hadoop/Hadoop-16.2.ClassNotFoundException.html",
    "content": "---\r\ntitle: 16.2. ClassNotFoundException\r\ndate: 2025/07/02\r\n---\r\n\r\n1. 输入命令 `hadoop classpath`, 将结果复制下来\r\n2. `mapred-site.xml` 中加入:\r\n```xml\r\n  <property>\r\n     <name>mapreduce.application.classpath</name>\r\n     <value>刚才复制的值</value>\r\n   </property>\r\n```\r\n1. `yarn-site.xml` 中加入:\r\n```xml\r\n  <property>\r\n     <name>yarn.application.classpath</name>\r\n     <value>刚才复制的值</value>\r\n   </property>\r\n\r\n```\r\n4. 重启 hadoop 集群\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "16.2. ClassNotFoundException"
    },
    "frontmatter": {
      "title": "16.2. ClassNotFoundException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "17.1. 常用命令 fs",
    "path": "/docs/architect/hadoop/Hadoop-17.1.changyongminglingfs.html",
    "url": "/docs/architect/hadoop/Hadoop-17.1.changyongminglingfs.html",
    "content": "---\r\ntitle: 17.1. 常用命令 fs\r\ndate: 2025/07/02\r\n---\r\n\r\n|命令|作用|\r\n|-|-|\r\n|`hadoop fs -help`|帮助命令|\r\n|`hadoop fs -ls /`|显示目录信息|\r\n|`hadoop fs -ls hdfs://hadoop01:9000/`|显示目录信息(使用Nn节点)|\r\n|`hadoop fs -mkdir -p /path1/path2/path3`|创建目录|\r\n|`hadoop fs -moveFromLocal /file/a.txt /path1/path2`|从本地剪切粘贴到hdfs|\r\n|`hadoop fs -appendToFile  b.txt /file/a.txt`|追加文件|\r\n|`hadoop fs -cat /a.txt`|显示文件|\r\n|`hadoop fs -chmod 666 /file/a.txt`|改权限|\r\n|`hadoop fs -chown root:root /file/a.txt`|改组和拥有者|\r\n|`hadoop fs -chgrp group /file/a.txt`|改组|\r\n|`hadoop fs -copyFromLocal ./b.txt /`|拷贝文件到HDFS (上传)|\r\n|`hadoop fs -copyToLocal /b.txt /c.txt`|拷贝HDFS文件到本地 (下载)|\r\n|`hadoop fs -cp /aa.txt /bbb.txt`|复制|\r\n|`hadoop fs -mv /aa.txt /bbb.txt`|移动|\r\n|`hadoop fs -get /aa.txt`|下载|\r\n|`hadoop fs -put aa.txt /file`|上传|\r\n|`hadoop fs -getmerge /file bb.txt`|合并下载某个目录中的多个文件|\r\n|`hadoop fs -rmdir /file1/file2`|删除空目录|\r\n|`hadoop fs -rm -r /d.txt`|删除文件或文件夹|\r\n|`hadoop fs -df -h /`|统计文件系统可用空间|\r\n|`hadoop fs -du -s -h /file`|统计文件夹大小|\r\n|`hadoop fs -count /file`|统计文件夹节点数量|\r\n|`hadoop fs -setrep 3 /aa.txt`|设置副本数量|\r\n|`hdfs dfsadmin -report`|查看集群状态|\r\n\r\n---\r\n[官方文档](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html)\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "17.1. 常用命令 fs"
    },
    "frontmatter": {
      "title": "17.1. 常用命令 fs",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "2.节点",
    "path": "/docs/architect/hadoop/Hadoop-2.jiedian.html",
    "url": "/docs/architect/hadoop/Hadoop-2.jiedian.html",
    "content": "---\r\ntitle: 2.节点\r\ndate: 2025/07/02\r\n---\r\n\r\n* NN: NameNode fdfs 节点的 leader\r\n* DN: DataNode fdfs 的数据节点\r\n* SNN SecondaryNameNode fdfs 节点的镜像复制节点\r\n* RM: resoucemanager yarn 资源管理器的主节点\r\n* NM: nodemanager yarn 资源管理器的从节点\r\n* JN: JournalNode 日志节点\r\n\r\n---\r\n\r\n* ZKFC: DFSZKFailoverController Zookeeper 高可用控制\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.节点"
    },
    "frontmatter": {
      "title": "2.节点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "3. HDFS 读写文件流程",
    "path": "/docs/architect/hadoop/Hadoop-3.HDFSduxiewenjianliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-3.HDFSduxiewenjianliucheng.html",
    "content": "---\r\ntitle: 3. HDFS 读写文件流程\r\ndate: 2025/07/02\r\n---\r\n\r\n## HDFS 特点\r\n\r\n1. hdfs 里的文件是分块（block）存储的，默认大小是 128M\r\n2. hdfs 使用统一的抽象目录树管理文件，客户端不需要关心具体的文件分块\r\n    * 例如：hdfs://hadoop01:port/path1/path2/file\r\n3. 抽象目录树以及分块的信息由 namenode 节点管理\r\n4. 具体的 block 存储在每一个节点上，并且每一个 block 可以有多个副本（dfs.replication）\r\n5. Hdfs 适合设计成一次写入多次读取的情况，不支持修改\r\n\r\n## HDFS 写文件流程\r\n\r\n![HDFS 写文件流程](static/HDFS-W.png)\r\n\r\n举例来说，现在要上传一个 hadoop.jar 文件, 200M（按默认得配置应该分成两个 block [128,72]）\r\n对应命令是： `hadoop fs put hadoop.jar /`\r\n\r\n1. 客户端使用 FIleSystem 上传\r\n2. FIleSystem 与 namenode 进行通信，nn 会检查自己维护得目录树，判断当前目录是否存在\r\n3. 当 namenode 正确返回后，客户端再向 namenode 请求上传第一个 block, namenode 确认 datanode 的状态，把健康的 datanode 集合返回给客户端，客户端会根据返回的 datanode 集合挑选一个进行连接\r\n4. 客户端对每一个用于传输的节点都建立 pipeline 管道，并对传输第一个 block 块的数据（每次传输的并不是一整个 block 块，而是一个 packet，默认大小为 64K，64K 的 packet 中每次传输 512b 的数据时（一个 chunk）会进行一次校验）所以你可以把 packet 又理解成 chunk的集合\r\n5. 每个 datenode 写完个 block 后再返回确认信息\r\n6. 所有写完了，关闭输出流\r\n7. 整个完成后最后通知 namdenode 完成数据上传\r\n\r\n\r\n## HDFS 读文件流程\r\n\r\n![HDFS 写文件流程](static/HDFS-R.png)\r\n\r\n`hadoop fs get /hadoop.jar`\r\n\r\n1. client 访问 NameNode，查询元数据信息，获得这个文件的数据块位置列表，返回输入流对象。\r\n2. 就近挑选一台 datanode 服务器，请求建立输入流\r\n3. DataNode 向输入流中中写数据，以 packet 为单位\r\n4. 关闭输入流\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3. HDFS 读写文件流程",
      "lvl1": "HDFS 特点",
      "lvl2": "HDFS 写文件流程",
      "lvl3": "HDFS 读文件流程"
    },
    "frontmatter": {
      "title": "3. HDFS 读写文件流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "4.元数据管理 edits fsimage",
    "path": "/docs/architect/hadoop/Hadoop-4.yuanshujuguanli-edits_fsimage.html",
    "url": "/docs/architect/hadoop/Hadoop-4.yuanshujuguanli-edits_fsimage.html",
    "content": "---\r\ntitle: 4.元数据管理 edits fsimage\r\ndate: 2025/07/02\r\n---\r\n\r\n## 元数据的存储形式\r\nhdfs 的读写流程都离不开 namenode，在 namenode 中维护了文件、文件块的信息，这些信息统统称之为元数据\r\n\r\n元数据在 hdfs 中有 3 种存在形式 (<font color=\"red\">内存的数据 = fsimage + edits 文件</font>)\r\n1. 存在内存中，这个最全的元数据\r\n2. fsimage 磁盘元数据镜像文件\r\n3. 最新的操作日志文件\r\n\r\n查看存储结构:\r\n* `cd /soft/data/tmp/dfs/name/current`\r\n* `hdfs oev -i edits_0000000000000001913-0000000000000001959 -o edits.xml`\r\n* `hdfs oiv -i fsimage_0000000000000001972 -p XML -o fsimage.xml`\r\n\r\n## checkpoint\r\n当达到某个条件后，secondary namenode 会把 namenode 上保存的 edits 和最新的 fsimage 下载到本地，并把这些 edits 和 fsimage 进行合并，产生新的 fsimage，这整个过程把他称作 <font color=\"red\">checkpoint</font> ([官方文档](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml))\r\n\r\ncheckpoint 的条件配置 (hdfs-site.xml):\r\n```properties\r\n#检查触发条件是否满足的频率，60 秒\r\ndfs.namenode.checkpoint.check.period=60 \r\n\r\n# 以下两个参数做checkpoint 操作时，代表 secondary namenode 的本地工作目录\r\ndfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary\r\ndfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir} \r\n\r\n#最大重试次数\r\ndfs.namenode.checkpoint.max-retries=3 \r\n#两次 checkpoint 之间的时间间隔 3600 秒\r\ndfs.namenode.checkpoint.period=3600 \r\n#两次 checkpoint 之间最大的操作记录\r\ndfs.namenode.checkpoint.txns=1000000 \r\n```\r\n\r\n## checkpoint 工作机制\r\n\r\n![checkpoint 工作机制](static/checkpoint.png)\r\n\r\n1. SecondaryNameNode 会定时的和 NameNode 通信，请求其停止使用 edits 文件，暂时将新的写操作写到一个新的文件 edits.new 上，这个操作是瞬时完成的，上层的写日志函数完全感觉不到差别\r\n2. econdaryNameNode 通过 HTTP 的 get 方法从 NameNode 上获取到 fsimage 和 edits 文件，SecondaryNameNode 将 fsimage 文件载入内存中，逐一执行 edits 文件中的事务，创建新的合并后的 fsimage 文件，<font color=\"red\">使得内存中的 fsimage 保存最新</font>。\r\n3. SecondaryNameNode 执行完 2 之后，会通过 post 方法将新的 fsimage 文件发送到 NameNode 节点上\r\n4. NameNode 将从 SecondaryNameNode 接收到的新的 fsimage 文件保存为.ckpt 文件\r\n5. NameNode 重新命名 fsimage.ckpt 为 fsimage 替换旧的 fsimage 文件，同时将 edits.new 替换为 edits 文件，<font color=\"red\">通过这个过程 edits 文件就变小了</font>。\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.元数据管理 edits fsimage",
      "lvl1": "元数据的存储形式",
      "lvl2": "checkpoint",
      "lvl3": "checkpoint 工作机制"
    },
    "frontmatter": {
      "title": "4.元数据管理 edits fsimage",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "5. mapreduce 工作机制",
    "path": "/docs/architect/hadoop/Hadoop-5.mapreducegongzuojizhi.html",
    "url": "/docs/architect/hadoop/Hadoop-5.mapreducegongzuojizhi.html",
    "content": "---\r\ntitle: 5. mapreduce 工作机制\r\ndate: 2025/07/02\r\n---\r\n\r\n一个完整的 mapreduce 程序在分布式运行时有三类实例进程：\r\n1. MRAppMaster：负责整个程序的过程调度及状态协调\r\n2. MapTask：负责 map 阶段的整个数据处理流程\r\n3. ReduceTask：负责 reduce 阶段的整个数据处理流程\r\n\r\n---\r\n流程:\r\n1. 一个 mr 程序启动的时候，最先启动的是 MRAppMaster，MRAppMaster 启动后根据本次 job 的描述信息，计算出需要的 maptask 实例数量，然后向集群申请机器启动相应数量的 maptask 进程（这里先理解成一个文件一个 maptask）\r\n2. maptask 进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：\r\n    1. 利用客户指定的 inputformat 来获取数据，形成输入 K，V 对\r\n    2. 将输入 KV 对传递给客户定义的 `map()` 方法，做逻辑运算，并将 `map()` 方法输出的 KV 对收集到缓存\r\n    3. 将缓存中的 KV 对按照 K 分区排序后不断溢写到磁盘文件\r\n3. MRAppMaster 监控到所有 maptask 进程任务完成之后，会根据客户指定的参数启动相应数量的 reducetask 进程，并告知 reducetask 进程要处理的数据范围（数据分区）\r\n4. Reducetask 进程启动之后，根据 MRAppMaster 告知的待处理数据所在位置，从若干台 maptask 运行所在机器上获取到若干个 maptask 输出结果文件，并在本地进行重新归并排序，然后按照相同 key 的 KV 为一个组，调用客户定义的 `reduce()` 方法进行逻辑运算，并收集运算输出的结果 KV，然后调用客户指定的 outputformat 将结果数据输出到外部存储\r\n\r\n---\r\n\r\n{% mermaid %}\r\ngraph TD\r\n    M -.->|开启两个MapTask| C1\r\n    M -.->|所有maptask进程完成后<br>开启两个ReduceTask<br>告知数据所在位置| R1\r\n    M(MRAppMaster) --> A(input dir)\r\n    A --> B1([1.txt])\r\n    A --> B2([2.txt])\r\n    B1 --InputFormat<br>TextInputFormat--> C1([MapTask1])\r\n    B2 --InputFormat<br>TextInputFormat--> C2([MapTask2])\r\n    M -.->|开启两个MapTask| C2\r\n    C1 --Mapper.map-->D1([context.write])\r\n    C2 --Mapper.map-->D2([context.write])\r\n    D1 --> E1(内存缓存-环形缓冲区)\r\n    D2 --> E2(内存缓存-环形缓冲区)\r\n    E1 --按照KEY分区排序<br>写入磁盘--> F1(溢出文件1) \r\n    E1 --按照KEY分区排序<br>写入磁盘--> F2(溢出文件2) \r\n    E2 --按照KEY分区排序<br>写入磁盘--> F3(溢出文件3) \r\n    E2 --按照KEY分区排序<br>写入磁盘--> F4(溢出文件4)\r\n    F1 --> H1([Shuffle流程])\r\n    F2 --> H1([Shuffle流程])\r\n    F3 --> H2([Shuffle流程])\r\n    F4 --> H2([Shuffle流程])\r\n    H1 -.-> F5(所有客户机的数据)\r\n    H2 -.-> F5\r\n    F5 --从客户机获取溢出文件<br>key.hashcode%2=0--> R1([ReduceTask1])\r\n    F5 --从客户机获取溢出文件<br>key.hashcode%2=1--> R2([ReduceTask2])\r\n    M -.->|所有maptask进程完成后<br>开启两个ReduceTask<br>告知数据所在位置| R2\r\n    R1 --归并排序分组<br>Reducer.reduce--> G1([context.write])\r\n    R2 --归并排序分组<br>Reducer.reduce--> G2([context.write])\r\n    G1 --OutputFormat<br>TextOutputFormat--> P1(part-r-00000)\r\n    G2 --OutputFormat<br>TextOutputFormat--> P2(part-r-00001)\r\n{% endmermaid %}\r\n\r\n---\r\n\r\n关于Shuffle流程: [6.提交任务流程与Shuffle流程](./Hadoop-6.提交任务流程与Shuffle流程.md)\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5. mapreduce 工作机制"
    },
    "frontmatter": {
      "title": "5. mapreduce 工作机制",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "6.提交任务流程与 Shuffle 流程",
    "path": "/docs/architect/hadoop/Hadoop-6.tijiaorenwuliuchengyuShuffleliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-6.tijiaorenwuliuchengyuShuffleliucheng.html",
    "content": "---\r\ntitle: 6.提交任务流程与 Shuffle 流程\r\ndate: 2025/07/02\r\n---\r\n\r\n\r\nshuffle 并不是个组件，而是 mr 处理流程中的一个子过程，它过程开始于 maptask 把数据写入环形缓存一直到数据到 reduce 之间的整个过程\r\n\r\n![Shuffle 流程](static/shuffle.png)\r\n\r\n1. maptask 收集我们的 `map()` 方法输出的 kv 对，放到内存缓冲区中\r\n2. 从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件\r\n3. 多个溢出文件会被合并成大的溢出文件\r\n4. <font color=\"orange\">在溢出过程中，及合并 Combine 的过程中，都要调用 partitoner 进行分组和针对 key 进行排序 (compare)</font>\r\n5. reducetask 根据自己的分区号，去各个 maptask 机器上取相应的结果分区数据\r\n6. reducetask 会取到同一个分区的来自不同 maptask 的结果文件，<font color=\"orange\">reducetask 会将这些文件再进行合并（归并排序）</font>\r\n7. 合并成大文件后，shuffle 的过程也就结束了，后面进入 reducetask 的逻辑运算过程（从文件中取出一个个的键值对 group，调用用户自定义的 `reduce()`方法）\r\n8. 缓冲区的大小可以通过参数调整, 参数：`mapreduce.task.io.sort.mb` 默认 100M\r\n\r\n---\r\n[官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "6.提交任务流程与 Shuffle 流程"
    },
    "frontmatter": {
      "title": "6.提交任务流程与 Shuffle 流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "7.切片逻辑",
    "path": "/docs/architect/hadoop/Hadoop-7-qiepianluoji.html",
    "url": "/docs/architect/hadoop/Hadoop-7-qiepianluoji.html",
    "content": "---\r\ntitle: 7.切片逻辑\r\ndate: 2025/07/02\r\n---\r\n\r\n默认切片的大小与 hdfs 的 block 的 size 相等\r\n切片大小: `Math.max(minSize, Math.min(maxSize, blockSize))`\r\n* `mapreduce.input.fileinputformat.split.minsize` 默认值 `1`\r\n* `mapreduce.input.fileinputformat.split.maxsize` 默认值 `Long.MAX_VALUE`\r\n\r\n切片规则: `剩余长度 / splitsize < 1.1`\r\n\r\n---\r\n\r\n流程:\r\n\r\n{% mermaid %}\r\ngraph TD\r\n    A(input.txt) --> F([FileInputFormat])\r\n    F --> J([Jobsubmit])\r\n    J -.->|剩余/splitsize<1.1| S1([切片1])\r\n    J -.->|剩余/splitsize<1.1| S2([切片2])\r\n    S1 --写入文件--> JS(job.split)\r\n    S2 --写入文件--> JS(job.split)\r\n    JS --MrAppMaster--> M1([MapTask1])\r\n    JS --MrAppMaster--> M2([MapTask2])\r\n{% endmermaid %}\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "7.切片逻辑"
    },
    "frontmatter": {
      "title": "7.切片逻辑",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "8.YARN流程",
    "path": "/docs/architect/hadoop/Hadoop-8-YARNliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-8-YARNliucheng.html",
    "content": "---\r\ntitle: 8.YARN流程\r\ndate: 2025/07/02\r\n---\r\n\r\nYARN 是运算资源调度系统，他只做运算资源的分配和调度，不参与用户程序内部的具体工作，所以 YARN 可以作为一个通用的资源调度平台\r\n\r\n在 Hadoop1.x 的时候其实是没有 YRAN，当初的 MapReduce 由两个组件组成\r\n* Job Tracker: 相当于 RM + MrAppMaster\r\n* Task Tracker: 相当于 NM + Task(MapTask, ReduceTask)\r\n\r\n---\r\n\r\n![YARN 流程](static/YARN.png)\r\n\r\n1. 客户端程序向 ResourceManager 提交应用并请求一个 ApplicationMaster 实例\r\n2. ResourceManager 找到一个可以运行一个 Container 的 NodeManager，并在这个 Container 中启动 ApplicationMaster 实例\r\n3. ApplicationMaster 向 ResourceManager 进行注册 ，注册之后客户端就可以查询 ResourceManager 获得自己 ApplicationMaster 的详细信息 ，以后就可以和自己的 ApplicationMaster 直接交互了（这个时候，客户端主动和 ApplicationMaster 交互，应用先向 ApplicationMaster 发送一个满足自己需求的资源请求）\r\n4. 在平常的操作过程中，ApplicationMaster 根据协议向 ResourceManager 发送资源请求\r\n5. 当 Container 被成功分配后，ApplicationMaster 通过向 NodeManager 发送信息来启动 Container，信息包含了能够让 Container 和 ApplicationMaster 交互所需要的资料\r\n6. 应用程序的代码以 task 形式在启动的 Container 中运行，并把运行的进度、状态等信息通过协议发送给 ApplicationMaster\r\n7. 在应用程序运行期间，提交应用的客户端主动和 ApplicationMaster 交流获得应用的运行状态、进度更新等信息\r\n8. 一旦应用程序执行完成并且所有相关工作也已经完成，ApplicationMaster 向 ResourceManager 取消注册然后关闭，用到所有的 Container 也归还给系统\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "8.YARN流程"
    },
    "frontmatter": {
      "title": "8.YARN流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "9. mapreduce YARN 流程",
    "path": "/docs/architect/hadoop/Hadoop-9-mapreduce-YARNliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-9-mapreduce-YARNliucheng.html",
    "content": "---\r\ntitle: 9. mapreduce YARN 流程\r\ndate: 2025/07/02\r\n---\r\n\r\n![mapreduce-YARN流程](static/YARN-MR.png)\r\n\r\n1. 应用申请运行RM的JOB\r\n2. RM返回JOBID以及提交资源的目录\r\n3. 应用提交相关文件到资源目录\r\n4. 通知RM, JOB资源提交完毕\r\n5. RM初始任务TASK, 加入调度队列\r\n6. 空闲NM领取任务\r\n7. NM根据任务信息创建Container (并且从资源目录获取JOB资源)\r\n8. 应用发送指令启动NM的MrAppMaster\r\n9. MrAppMaster向RM请求运算节点\r\n10. MrAppMaster向请求回来的运算节点中启动MapTask\r\n11. MrAppMaster向请求回来的运算节点中启动ReduceTask\r\n12. JOB执行完成后, MrAppMaster向RM注销自己\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "9. mapreduce YARN 流程"
    },
    "frontmatter": {
      "title": "9. mapreduce YARN 流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "Redis-持久化",
    "path": "/docs/architect/redis/Redis-chijiuhua.html",
    "url": "/docs/architect/redis/Redis-chijiuhua.html",
    "content": "---\r\ntitle: Redis-持久化\r\ndate: 2025/03/05\r\n---\r\n\r\n::: tip 介绍\r\n1. RDB：dump.rdb （二进制文件）\r\n2. AOF（append-only file）：appendonly.aof（resp协议格式）\r\n3. 混合持久化：RDB+AOF\r\n4. 数据备份策略\r\n:::\r\n\r\n## RDB: dump.rdb\r\n\r\n- RDB：dump.rdb （二进制文件）\r\n\t- 配置文件：`bgsave` 方式\r\n\t\t- `save 60 1000`  关闭RDB只需要将所有的 `save` 保存策略注释掉即可\r\n\t\t\t- 60 秒内有至少有 1000 个键被改动， 则进行一次 RDB 持久化\r\n\t- 命令：覆盖原有 rdb 快照文件\r\n\t\t- `save`：同步\r\n\t\t- `bgsave`：异步，写时复制 - COW机制\r\n\t\t\t- `bgsave` 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据\r\n\t\t\t\t- 在生成子进程执行调用fork函数时会有短暂阻塞\r\n\t\t\t- 如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。然后，`bgsave` 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据\r\n\r\n::: danger 缺点\r\n宕机后，服务器将丢失最近写入、且仍未保存到快照中的数据\r\n:::\r\n\r\n## AOF: appendonly.aof\r\n\r\n- AOF（append-only file）：appendonly.aof（resp协议格式）\r\n\t- 将修改的每一条指令记录进文件appendonly.aof中（先写入os cache，每隔一段时间fsync到磁盘）\r\n\t- 命令：`bgrewriteaof`  （fork出一个子进程去做）\r\n\t- 配置文件\r\n\r\n|配置文件|介绍|\r\n|-|-|\r\n|`appendonly yes`|开启AOF模式|\r\n|`appendfsync always`|每条命令都fsync一次，拉低性能|\r\n|`appendfsync everysec`|每秒fsync一次，推荐，缺点是宕机后会丢失1秒的数据，但可以从数据库恢复|\r\n|`appendfsync no`|让操作系统决定fsync的时机，快但不安全|\r\n|`auto‐aof‐rewrite‐min‐size 64mb`|AOF文件超过64M时，重写AOF文件（整合命令）|\r\n|`auto‐aof‐rewrite‐percentage 100`|自上一次重写后文件大小增长了100%则再次触发重写|\r\n\r\n::: warning 缺点\r\n体积大，恢复慢\r\n:::\r\n\r\n## 混合持久化\r\n\r\n- 混合持久化：RDB+AOF\r\n\t- 配置文件（必须先开启AOF）：`aof‐use‐rdb‐preamble yes`\r\n\t- 将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令（生成RDB过程中产生的命令）存在一起，都写入新的AOF文件\r\n\t- 新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换\r\n\r\n::: info 优点\r\n在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可以完全替代之前的AOF 全量文件重放，因此重启效率大幅得到提升\r\n:::\r\n\r\n![混合持久化](static/Redis-持久化-appendonly.aof.png)\r\n\r\n## 数据备份策略\r\n\r\n- 数据备份策略：\r\n\t1. 写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份\r\n\t2. 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份\r\n\t3. 每次copy备份的时候，删除一些旧备份\r\n\t4. 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Redis-持久化",
      "lvl1": "RDB: dump.rdb",
      "lvl2": "AOF: appendonly.aof",
      "lvl3": "混合持久化",
      "lvl4": "数据备份策略"
    },
    "frontmatter": {
      "title": "Redis-持久化",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "---\r\ntitle: Zookeeper-特性\r\ndate: 2025/06/16\r\n---\r\n\r\n:::tip\r\n- CP架构\r\n- 常见命令\r\n- 数据结构\r\n- 监听通知机制\r\n- 节点特性\r\n- ACL权限控制\r\n- 集群\r\n- 四字命令\r\n- Leader 选举原理\r\n- 数据同步流程\r\n:::\r\n\r\n---\r\n## CP架构\r\n\r\n- CAP 理论指出对于一个分布式计算系统来说，不可能同时满足以下三点\r\n\t- 一致性：在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性，等同于所有节点访问同一份最新的数据副本。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态\r\n\t- 可用性：每次请求都能获取到正确的响应，但是不保证获取的数据为最新数据\r\n\t- 分区容错性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供服务，除非是整个网络环境都发生了故障\r\n- 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项\r\n\t- P 是必须的，因此只能在 CP 和 AP 中选择，zookeeper 保证的是 CP\r\n- BASE 理论：BASE 是 Basically Available(基本可用)、Soft-state(软状态) 和 Eventually Consistent(最终一致性) 三个短语的缩写\r\n\t- 基本可用：在分布式系统出现故障，允许损失部分可用性（服务降级、页面降级）\r\n\t- 软状态：允许分布式系统出现中间状态。而且中间状态不影响系统的可用性。这里的中间状态是指不同的 data replication（数据备份节点）之间的数据更新可以出现延时的最终一致性\r\n\t- 最终一致性：data replications 经过一段时间达到一致性\r\n- Zookeeper 写入是强一致性，读取是顺序一致性（版本号）\r\n- ZooKeeper本质上是一个分布式的小文件存储系统（Zookeeper=文件系统+监听机制）\r\n\t- 是一个基于观察者模式设计的分布式服务管理框架\r\n\r\n---\r\n## 常见命令\r\n\r\n- ls 查看当前 znode 的子节点 \\[可监听\\]\r\n\t- -w: 监听子节点变化\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t- -R: 表示递归的获取\r\n- create 创建节点\r\n\t- -s : 创建有序节点\r\n\t- -e : 创建临时节点\r\n\t- -c : 创建一个容器节点\r\n\t- \\[-t ttl\\] : 创建一个TTL节点， -t 时间（单位毫秒）\r\n\t- data : 节点的数据，可选，如果不使用时，节点数据就为null\r\n\t- acl : 访问控制\r\n- get 获取节点数据信息\r\n\t-  -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t-  -w: 监听节点变化\r\n- set 设置节点数据\r\n\t- -s: 表示节点为顺序节点\r\n\t- -v: 指定版本号\r\n- getAcl 获取节点的访问控制信息\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n- setAcl 设置节点的访问控制列表\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t- -v: 指定版本号\r\n\t- -R: 递归的设置\r\n- stat 查看节点状态信息\r\n- delete  删除某一节点，只能删除无子节点的节点\r\n\t- -v: 表示节点版本号\r\n- deleteall 递归的删除某一节点及其子节点\r\n- setquota 对节点增加限制\r\n\t- -n: 表示子节点的最大个数\r\n\t- -b: 数据值的最大长度，-1表示无限制\r\n\r\n---\r\n## 数据结构\r\n\r\n- ZooKeeper的数据模型是层次模型，层次模型常见于文件系统。层次模型和key-value模型是两种主流的数据模型。ZooKeeper使用文件系统模型主要基于以下两点考虑\r\n\t- 文件系统的树形结构便于表达数据之间的层次关系\r\n\t- 文件系统的树形结构便于为不同的应用分配独立的命名空间 ( namespace ) \r\n- ZooKeeper的层次模型称作Data Tree，Data Tree的每个节点叫作Znode\r\n\t- 每一个 ZNode 默认能够存储 1MB 的数据\r\n\t- 每个 ZNode 都可以通过其路径唯一标识\r\n\t- 每个节点都有一个版本(version)，版本从0开始计数\r\n\t- ![Zookeeper 节点](static/Zookeeper-特性-节点.png)\r\n- 节点分类\r\n\t- 持久节点 (PERSISTENT): 这样的znode在创建之后即使发生ZooKeeper集群宕机或者client宕机也不会丢失\r\n\t- 临时节点 (EPHEMERAL ): client宕机或者client在指定的timeout时间内没有给ZooKeeper集群发消息，这样的znode就会消失\r\n\t- 持久顺序节点 (PERSISTENT_SEQUENTIAL): znode除了具备持久性znode的特点之外，名字具备顺序性\r\n\t- 临时顺序节点 (EPHEMERAL_SEQUENTIAL): znode除了具备临时性znode的特点之外，名字具备顺序性\r\n\t- Container节点 (3.5.3版本新增)：Container容器节点，当容器中没有任何子节点，该容器节点会被zk定期删除（定时任务默认60s 检查一次)\r\n\t\t- 和持久节点的区别是 ZK 服务端启动后，会有一个单独的线程去扫描，所有的容器节点，当发现容器节点的子节点数量为 0 时，会自动删除该节点\r\n\t\t- 可以用于 leader 或者锁的场景中\r\n\t- TTL节点:  带过期时间节点，默认禁用\r\n\t\t- 在zoo.cfg中添加 `extendedTypesEnabled=true `开启\r\n\t\t- ttl 不能用于临时节点\r\n- 节点状态信息\r\n\t- cZxid ：Znode创建的事务id\r\n\t- ctime：节点创建时的时间戳\r\n\t- mZxid ：Znode被修改的事务id，即每次对znode的修改都会更新mZxid\r\n\t\t- 对于zk来说，每次的变化都会产生一个唯一的事务id，zxid（ZooKeeper Transaction Id）\r\n\t\t- 通过zxid，可以确定更新操作的先后顺序\r\n\t\t- 如果zxid1小于zxid2，说明zxid1操作先于zxid2发生\r\n\t\t- zxid对于整个zk都是唯一的，即使操作的是不同的znode\r\n\t- pZxid: 表示该节点的子节点列表最后一次修改的事务ID\r\n\t\t- 只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid\r\n\t\t\t- 添加子节点或删除子节点就会影响子节点列表\r\n\t\t\t- 但是修改子节点的数据内容则不影响该ID\r\n\t- mtime：节点最新一次更新发生时的时间戳\r\n\t- cversion ：子节点的版本号\r\n\t\t- 当znode",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "的子节点有变化时，cversion 的值就会增加1\r\n\t- dataVersion：数据版本号\r\n\t\t- 每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据）\r\n\t\t- 可有效避免了数据更新时出现的先后顺序问题\r\n\t- ephemeralOwner\r\n\t\t- 如果该节点为临时节点, ephemeralOwner值表示与该节点绑定的session id\r\n\t\t\t- 在client和server通信之前,首先需要建立连接,该连接称为session\r\n\t\t\t- 连接建立后,如果发生连接超时、授权失败,或者显式关闭连接,连接便处于closed状态, 此时session结束\r\n\t\t- 如果不是, ephemeralOwner值为0 (持久节点)\r\n\t- dataLength： 数据的长度\r\n\t- numChildren：子节点的数量（只统计直接子节点的数量）\r\n\r\n---\r\n## 监听通知机制\r\n\r\n- watcher 机制\r\n\t- 一个Watch事件是一个一次性的触发器\r\n\t\t- 当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们\r\n\t- Zookeeper采用了 Watcher机制实现数据的发布订阅功能\r\n\t\t- 多个订阅者可同时监听某一特定主题对象，当该主题对象的自身状态发生变化时例如节点内容改变、节点下的子节点列表改变等，会实时、主动通知所有订阅者\r\n\t- watcher机制事件上与观察者模式类似，也可看作是一种观察者模式在分布式场景下的实现方式\r\n- watcher 的过程\r\n\t- 客户端向服务端注册watcher\r\n\t- 服务端事件发生触发watcher\r\n\t- 客户端回调watcher得到触发事件情况\r\n- Zookeeper中的watch机制，必须客户端先去服务端注册监听，这样事件发送才会触发监听，通知给客户端\r\n- 支持的事件类型\r\n\t- None: 连接建立事件\r\n\t- NodeCreated： 节点创建 \r\n\t- NodeDeleted： 节点删除 \r\n\t- NodeDataChanged：节点数据变化\r\n\t- NodeChildrenChanged：子节点列表变化 \r\n\t- DataWatchRemoved：节点监听被移除 \r\n\t- ChildWatchRemoved：子节点监听被移除\r\n- 特性\r\n\t- 一次性触发：watcher是一次性的，一旦被触发就会移除，再次使用时需要重新注册\r\n\t- 客户端顺序回调：watcher回调是顺序串行执行的，只有回调后客户端才能看到最新的数据状态。一个watcher回调逻辑不应该太多，以免影响别的watcher执行\r\n\t- 轻量级：WatchEvent是最小的通信单位，结构上只包含通知状态、事件类型和节点路径，并不会告诉数据节点变化前后的具体内容\r\n\t- 时效性：watcher只有在当前session彻底失效时才会无效，若在session有效期内快速重连成功，则watcher依然存在，仍可接收到通知\r\n- 使用场景\r\n\t- master-worker 机制\r\n\t- 基于版本号的条件更新\r\n\t\t- ![Zookeeper 更新](static/Zookeeper-特性-更新.png)\r\n\r\n---\r\n## 节点特性\r\n\r\n- 同一级节点 key 名称是唯一的\r\n- 创建节点时，必须要带上全路径\r\n- session 关闭，临时节点清除\r\n- 自动创建顺序节点\r\n- watch 机制，监听节点变化\r\n\t- 监听事件被单次触发后，事件就失效了\r\n- 永久性 Watch（`addWatch [‐m mode] path`）：是Zookeeper 3.6.0版本新增的功能\r\n\t- 在被触发之后，仍然保留，可以继续监听ZNode上的变更\r\n\t- 针对指定节点添加事件监听，支持两种模式\r\n\t\t- PERSISTENT，持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件\r\n\t\t- PERSISTENT_RECURSIVE，持久化递归订阅，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件\r\n- delete 命令只能一层一层删除\r\n- deleteall 命令递归删除\r\n- 应用场景：适用于存储和协同相关的关键数据，不适合用于大数据量存储\r\n\t- 注册中心 \r\n\t- 数据发布/订阅（常用于实现配置中心） \r\n\t\t- 数据量小的KV\r\n\t\t- 数据内容在运行时会发生动态变化\r\n\t\t- 集群机器共享，配置一致\r\n\t\t- 推拉结合\r\n\t\t\t- 服务端会推给注册了监控节点的客户端 Watcher 事件通知\r\n\t\t\t- 客户端获得通知后，然后主动到服务端拉取最新的数据\r\n\t- 统一集群管理\r\n\t- 负载均衡\r\n\t- 命名服务\r\n\t- 分布式协调/通知\r\n\t- 集群管理\r\n\t- Master选举\r\n\t- 分布式锁\r\n\t- 分布式队列\r\n\r\n---\r\n## ACL权限控制\r\n\r\n- zookeeper 的 ACL（Access Control List，访问控制表）权限可以针对节点设置相关读写等权限\r\n- zookeeper 的 acl 通过 `[scheme:id:permissions]` 来构成权限列表\r\n\t- scheme：授权的模式，代表采用的某种权限机制\r\n\t\t- 包括 world、auth、digest、ip、super 几种\r\n\t- id：授权对象，代表允许访问的用户\r\n\t\t- 如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段\r\n\t\t- 而如果使用 Digest 或 Super 方式，则对应于一个用户名\r\n\t\t- 如果是 World 模式，是授权系统中所有的用户\r\n\t- permissions：授权的权限，权限组合字符串，由 cdrwa 组成，其中每个字母代表支持不同权限\r\n\t\t- 创建权限 create(c)、删除权限 delete(d)、读权限 read(r)、写权限 write(w)、管理权限admin(a)。\r\n\r\n| 模式     | 描述                                        |\r\n| ------ | ----------------------------------------- |\r\n| world  | 授权对象只有一个anyone，代表登录到服务器的所有客户端都能对该节点执行某种权限 |\r\n| ip     | 对连接的客户端使用IP地址认证方式进行认证                     |\r\n| auth   | 使用以添加认证的用户进行认证                            |\r\n| digest | 使用用户:密码方式验证                               |\r\n\r\n| 权限类型   | ACL简写 | 描述              |\r\n| ------ | ----- | --------------- |\r\n| read   | r     | 读取节点及显示子节点列表的权限 |\r\n| write  | w     | 设置节点数据的权限       |\r\n| create | c     | 创建子节点的权限        |\r\n| delete | d     | 删除子节点的权限        |\r\n| admin  | a     | 设置该节点ACL权限的权限   |\r\n\r\n| 授权命令    |",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": " 用法                   | 描述             |\r\n| ------- | -------------------- | -------------- |\r\n| getAcl  | getAcl path          | 读取节点的ACL       |\r\n| setAcl  | setAcl path acl      | 设置节点的ACL       |\r\n| create  | create path data acl | 创建节点时设置ACL     |\r\n| addAuth | addAuth scheme auth  | 添加认证用户，类似于登录操作 |\r\n- setAcl\r\n\t- `set Acl /name world:anyone:cdwa`\r\n- auth授权模式\r\n\t- 创建用户 `addauth digest fox:123456`\r\n\t- `setAcl /name auth:fox:123456:cdrwa`\r\n\t- 密码加密\r\n\t\t- `echo -n fox:123456 | openssl dgst -binary -sha1 | openssl base64`\r\n\t\t- `setAcl /name auth:fox:ZsWwgmtnTnx1usRF1voHFJAYGQU=:cdrwa`\r\n- digest授权模式\r\n\t- `setAcl /tuling/fox digest:fox:ZsWwgmtnTnx1usRF1voHFJAYGQU=:cdrwa`\r\n- IP授权模式\r\n\t- `setAcl /node-ip ip:192.168.109.128:cdwra`\r\n\t- `create /node-ip data ip:192.168.109.128:cdwra`\r\n\t\t- 多个指定IP可以通过逗号分隔\r\n\t\t\t- `setAcl /node-ip ip:IP1:rw,ip:IP2:a`\r\n- Super 超级管理员模式\r\n\t- 这是一种特殊的Digest模式， 在Super模式下超级管理员用户可以对Zookeeper上的节点进行任何的操作\r\n\t- 需要在启动脚本上通过添加JVM 参数开启\r\n\t\t- `-Dzookeeper.DigestAuthenticationProvider.superDigest=admin:<base64encoded(SHA1(123456))`\r\n\r\n---\r\n## 集群\r\n\r\n- 集群角色\r\n\t- Leader： 领导者\r\n\t\t- 事务请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性\r\n\t\t- 集群内部各个服务器的调度者\r\n\t\t- 对于create、setData、delete等有写操作的请求，则要统一转发给leader处理，leader需要决定编号、执行操作，这个过程称为事务\r\n\t- Follower：跟随者\r\n\t\t- 处理客户端非事务（读操作）请求（可以直接响应）\r\n\t\t- 转发事务请求给 Leader\r\n\t\t- 参与集群 Leader 选举投票\r\n\t- Observer：观察者\r\n\t\t- 对于非事务请求可以独立处理（读操作）\r\n\t\t- 对于事务性请求会转发给 leader 处理\r\n\t\t- Observer 节点接收来自 leader 的 inform 信息，更新自己的本地存储\r\n\t\t- 不参与提交和选举投票\r\n\t\t- 在不影响集群事务处理能力的前提下提升集群的非事务处理能力\r\n\t\t- Observer 应用场景\r\n\t\t\t- 提升集群的读性能\r\n\t\t\t- 跨数据中心部署\r\n\t\t\t\t- 比如需要部署一个北京和香港两地都可以使用的zookeeper集群服务，并且要求北京和香港客户的读请求延迟都很低。解决方案就是把香港的节点都设置为observer\r\n- 集群架构\r\n\t- ![Zookeeper 集群](static/Zookeeper-特性-集群.png)\r\n\t- leader节点可以处理读写请求\r\n\t- follower只可以处理读请求\r\n\t- follower在接到写请求时会把写请求转发给leader来处理\r\n- Zookeeper数据一致性保证\r\n\t- 全局可线性化 (Linearizable) 写入：先到达leader的写请求会被先处理，leader决定写请求的执行顺序\r\n\t- 客户端FIFO顺序：来自给定客户端的请求按照发送顺序执行\r\n- 集群搭建\r\n\t- 修改zoo.cfg配置，添加server节点配置：`server.A=B:C:D`\r\n\t\t- `dataDir=/data/zookeeper`\r\n\t\t- `server.1=192.168.65.156:2888:3888`\r\n\t\t- A 是一个数字，表示这个是第几号服务器\r\n\t\t\t- 集群模式下配置一个文件 myid，这个文件在 dataDir 目录下，这个文件里面有一个数据 就是 A 的值，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个server\r\n\t\t- B 是这个服务器的地址\r\n\t\t- C 是这个服务器Follower与集群中的Leader服务器交换信息的端口\r\n\t\t- D 是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader\r\n\t\t\t- 而这个端口就是用来执行选举时服务器相互通信的端口\r\n\t- 创建 myid 文件，配置服务器编号\r\n\t- 启动 zookeeper server 集群 `bin/zkServer.sh start`\r\n\r\n---\r\n## 四字命令\r\n\r\n- zookeeper 支持某些特定的四字命令与其交互，用户获取 zookeeper 服务的当前状态及相关信息\r\n\t- 用户在客户端可以通过 telenet 或者 nc（netcat） 向 zookeeper 提交相应的命令\r\n- 开启四字命令\r\n\t- 在 zoo.cfg 文件里加入配置项让这些指令放行\r\n\t\t- `4lw.commands.whitelist=*`\r\n\t- 在 zk 的启动脚本 zkServer.sh 中新增放行指令（添加ＶＭ环境变量）\r\n\t\t- `ZOOMAIN=\"-Dzookeeper.4lw.commands.whitelist=* ${ZOOMAIN}\"`\r\n- `echo [command] | nc [ip] [port]`\r\n\t- stat 命令用于查看 zk 的状态信息\r\n\t\t- `echo stat | nc 192.168.65.156 2181`\r\n\r\n| 四字命令 | 功能描述                                                                        |\r\n| ---- | --------------------------------------------------------------------------- |\r\n| conf | 3.3.0版本引入的。打印出服务相关配置的详细信息。                                                  |\r\n| cons | 3.3.0版本引入的。列出所有连接到这台服务器的客户端全部连接/会话详细信息。包括\"接受/发送\"的包数量、会话id、操作延迟、最后的操作执行等等信息。 |\r\n| crst | 3.3.0版本引入的。重置所有连接的连接和会话统计信息。                                                |\r\n| dump | 列出那些比较重要的会话和临时节点。这个命令只能在leader节点上有用。                                        |\r\n| envi | 打印出服务环境的详细信息。                                                               |\r\n| reqs | 列出未经处理的请求                                                                   |\r\n| ruok | 测试服务是否处于正确状态。如果确实如此，那么服务返回\"imok\"，否则不做任何相应。                                  |\r\n| stat | 输出关于性能和连接的客户端的列表。                                                           |\r\n| srst | 重置服务器的统计。                                                                   |\r\n| srvr | 3.3.0版本引入的。列出连接服务器的详细信息                                                     |\r\n| wchs | 3.3.0版本引入的。列出服务器watch的",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "详细信息。                                                 |\r\n| wchc | 3.3.0版本引入的。通过session列出服务器watch的详细信息，它的输出是一个与watch相关的会话的列表。                  |\r\n| wchp | 3.3.0版本引入的。通过路径列出服务器watch的详细信息。它输出一个与session相关的路径。                          |\r\n| mntr | 3.4.0版本引入的。输出可用于检测集群健康状态的变量列表                                               |\r\n\r\n---\r\n## Leader 选举原理\r\n\r\n- zookeeper 的 leader 选举存在两个阶段\r\n\t- 一个是服务器启动时 leader 选举\r\n\t- 另一个是运行过程中 leader 服务器宕机\r\n- 重要的参数\r\n\t- 服务器 ID(myid)：编号越大在选举算法中权重越大\r\n\t- 事务 ID(zxid)：值越大说明数据越新，权重越大\r\n\t- 逻辑时钟(epoch-logicalclock)：同一轮投票过程中的逻辑时钟值是相同的，每投完一次值会增加\r\n- 选举状态\r\n\t- LOOKING: 竞选状态\r\n\t- FOLLOWING: 随从状态，同步 leader 状态，参与投票 \r\n\t- OBSERVING: 观察状态，同步 leader 状态，不参与投票 \r\n\t- LEADING: 领导者状态\r\n- 服务器启动时的 leader 选举\r\n\t- 每个节点启动的时候都 LOOKING 观望状态，接下来就开始进行选举主流程\r\n\t\t- 第一台服务器 server1启动时，无法进行 leader 选举\r\n\t\t- 当第二台服务器 server2 启动时，两台机器可以相互通信，进入 leader 选举过程\r\n\t- ![Zookeeper 选举](static/Zookeeper-特性-选举.png)\r\n\t\t1. 每台 server 发出一个投票\r\n\t\t\t1. 由于是初始情况，server1 和 server2 都将自己作为 leader 服务器进行投票\r\n\t\t\t2. 每次投票包含所推举的服务器myid、zxid、epoch，使用（myid，zxid）表示\r\n\t\t\t3. 此时 server1 投票为（1,0），server2 投票为（2,0），然后将各自投票发送给集群中其他机器\r\n\t\t2. 接收来自各个服务器的投票\r\n\t\t\t1. 集群中的每个服务器收到投票后，首先判断该投票的有效性\r\n\t\t\t2. 如检查是否是本轮投票（epoch）、是否来自 LOOKING 状态的服务器\r\n\t\t3. 分别处理投票\r\n\t\t\t1. 针对每一次投票，服务器都需要将其他服务器的投票和自己的投票进行对比\r\n\t\t\t\t1. 优先比较 epoch\r\n\t\t\t\t2. 检查 zxid，zxid 比较大的服务器优先作为 leader\r\n\t\t\t\t3. 如果 zxid 相同，那么就比较 myid，myid 较大的服务器作为 leader 服务器\r\n\t\t4. 统计投票\r\n\t\t\t1. 每次投票后，服务器统计投票信息，判断是否有过半机器接收到相同的投票信息\r\n\t\t\t2. server1、server2 都统计出集群中有两台机器接受了（2,0）的投票信息，此时已经选出了 server2 为 leader 节点\r\n\t\t5. 改变服务器状态\r\n\t\t\t1. 一旦确定了 leader，每个服务器响应更新自己的状态\r\n\t\t\t2. 如果是 follower，那么就变更为 FOLLOWING，如果是 Leader，变更为 LEADING\r\n\t\t\t3. 此时 server3继续启动，直接加入变更自己为 FOLLOWING\r\n- 运行过程中的 leader 选举：当集群中 leader 服务器出现宕机或者不可用情况时，整个集群无法对外提供服务，进入新一轮的 leader 选举\r\n\t1. 变更状态：leader 挂后，其他非 Oberver服务器将自身服务器状态变更为 LOOKING\r\n\t2. 每个 server 发出一个投票：在运行期间，每个服务器上 zxid 可能不同\r\n\t3. 处理投票：规则同启动过程\r\n\t4. 统计投票：与启动过程相同\r\n\t5. 改变服务器状态：与启动过程相同\r\n\r\n---\r\n## 数据同步流程\r\n\r\n- 在 Zookeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性\r\n- ZAB 协议分为两部分：消息广播；崩溃恢复\r\n- 消息广播\r\n\t- ![Zookeeper 事务](static/Zookeeper-特性-事务.png)\r\n\t- Zookeeper 使用单一的主进程 Leader 来接收和处理客户端所有事务请求\r\n\t- 并采用 ZAB 协议的原子广播协议，将事务请求以 Proposal 提议广播到所有 Follower 节点\r\n\t- 当集群中有过半的Follower 服务器进行正确的 ACK 反馈\r\n\t\t- 那么Leader就会再次向所有的 Follower 服务器发送commit 消息，将此次提案进行提交\r\n\t- 这个过程可以简称为 2pc 事务提交\r\n\t- 注意 Observer 节点只负责同步 Leader 数据，不参与 2PC 数据同步过程\r\n- 崩溃恢复\r\n\t- 在正常情况消息下广播能运行良好，但是一旦 Leader 服务器出现崩溃，或者由于网络原理导致 Leader 服务器失去了与过半 Follower 的通信，那么就会进入崩溃恢复模式\r\n\t- 需要选举出一个新的 Leader 服务器\r\n\t- 在这个过程中可能会出现两种数据不一致性的隐患，需要 ZAB 协议的特性进行避免\r\n\t\t- Leader 服务器将消息 commit 发出后，立即崩溃\r\n\t\t- Leader 服务器刚提出 proposal 后，立即崩溃\r\n\t- ZAB 协议的恢复模式使用了以下策略\r\n\t\t- 选举 zxid 最大的节点作为新的 leader\r\n\t\t- 新 leader 将事务日志中尚未提交的消息进行处理\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 4,
    "contentParts": 4
  },
  {
    "title": "1. 基础",
    "path": "/docs/architect/rocketmq/RocketMQ-1.jichu.html",
    "url": "/docs/architect/rocketmq/RocketMQ-1.jichu.html",
    "content": "---\r\ntitle: 1. 基础\r\ndate: 2025/07/03\r\n---\r\n\r\n\r\n- RocketMQ 集群架构 \r\n\t- ![](static/RocketMQ-基础-1.png)\r\n\t- Producer：消息生产者集群。通常是业务系统中的一个功能模块。 \r\n\t- Consumer：消息消费者集群。通常也是业务系统中的一个功能模块。\r\n\t- Broker：实际处理消息存储、转发等服务的核心组件。\r\n\t- NameServer : 提供轻量级的Broker路由服务。 管理Broker\r\n\t\t- 所以我们要启动RocketMQ服务，需要先启动NameServer。\r\n\t- Topic：区分消息的种类；\r\n\t\t- 一个发送者可以发送消息给一个或者多个Topic\r\n\t\t- 一个消息的接收者可以订阅一个或者多个Topic消息\r\n\t- Message Queue：相当于是Topic的分区；用于并行发送和接收消息\r\n\t- 这种主从结构是只做数据备份，没有容灾功能\r\n- Dledger 高可用集群：基于Raft协议\r\n\t- 修改conf/dleger下的配置文件\r\n- 系统参数调优\r\n\t- 配置RocketMQ的JVM内存大小 `runbroker.sh`\r\n\t\t- `-XX:+UseG1GC` 使用G1垃圾回收器\r\n\t\t- `-XX:G1HeapRegionSize=16m` 将G1的region块大小设为16M\r\n\t\t- `-XX:G1ReservePercent` 在G1的老年代中预留25%空闲内存\r\n\t\t- `-XX:InitiatingHeapOccupancyPercent=30` 当堆内存的使用率达到30%之后就会启动G1垃圾回收器尝试回收垃圾\r\n\t- RocketMQ的其他一些核心参数\r\n\t\t- `sendMessageThreadPoolNums=16` RocketMQ内部用来发送消息的线程池的线程数量是16个\r\n\t- Linux内核参数定制\r\n\t\t- ulimit，需要进行大量的网络通信和磁盘IO\r\n\t\t- vm.extra_free_kbytes，告诉VM在后台回收（kswapd）启动的阈值与直接回收（通过分配进程）的阈值之间保留额外的可用内存。RocketMQ使用此参数来避免内存分配中的长延迟\r\n\t\t- vm.min_free_kbytes，如果将其设置为低于1024KB，将会巧妙的将系统破坏，并且系统在高负载下容易出现死锁\r\n\t\t- vm.max_map_count，限制一个进程可能具有的最大内存映射区域数。RocketMQ将使用mmap加载CommitLog和ConsumeQueue，因此建议将为此参数设置较大的值\r\n\t\t- vm.swappiness，定义内核交换内存页面的积极程度。较高的值会增加攻击性，较低的值会减少交换量。建议将值设置为10来避免交换延迟\r\n\t\t- File descriptor limits，RocketMQ需要为文件（CommitLog和ConsumeQueue）和网络连接打开文件描述符。我们建议设置文件描述符的值为655350\r\n\t\t\t- `/proc/sys/vm`\r\n\t\t- 另外，RocketMQ的bin目录下有个`os.sh`里面设置了RocketMQ建议的系统内核参数\r\n- RocketMQ消息转发模型\r\n\t- ![](static/RocketMQ-基础-2.png)\r\n\t- 消息模型（Message Model） \r\n\t\t- RocketMQ 主要由 Producer、Broker、Consumer 三部分组成\r\n\t\t- Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息\r\n\t\t- Broker 在实际部署过程中对应一台服务器\r\n\t\t\t- 每个 Broker 可以存储多个Topic的消息，每个Topic 的消息也可以分片存储于不同的 Broker\r\n\t\t- Message Queue 用于存储消息的物理地址\r\n\t\t\t- 每个Topic中的消息地址存储于多个 Message Queue 中\r\n\t\t- ConsumerGroup 由多个Consumer 实例构成\r\n\t- 消息生产者（Producer） \r\n\t\t- 一个消息生产者会把业务应用系统里产生的消息发送到broker服务器\r\n\t\t- 同步发送、异步发送、顺序发送、单向发送\r\n\t\t\t- 同步和异步方式均需要Broker返回确认信息，单向发送不需要\r\n\t\t-  生产者中，会把同一类Producer组成一个集合，叫做生产者组\r\n\t\t\t- 同一组的Producer被认为是发送同一类消息且发送逻辑一致\r\n\t- 消息消费者（Consumer） \r\n\t\t-  负责消费消息，一般是后台系统负责异步消费\r\n\t\t- 一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序\r\n\t\t- 拉取式消费\r\n\t\t\t- 拉取式消费的应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、主动权由应用控制。一旦获取了批量消息，应用就会启动消费过程\r\n\t\t- 推动式消费\r\n\t\t\t- 推动式消费模式下Broker收到数据后会主动推送给消费端，该消费模式一般实时性较高\r\n\t\t-  消费者同样会把同一类Consumer组成一个集合，叫做消费者组\r\n\t\t\t- 这类Consumer通常消费同一类消息且消费逻辑一致\r\n\t\t\t- 消费者组使得在消息消费方面，实现负载均衡和容错的目标变得非常容易\r\n\t\t\t- 消费者组的消费者实例必须订阅完全相同的Topic\r\n\t\t- 集群消费模式下,  相同Consumer Group的每个Consumer实例平均分摊消息\r\n\t\t- 广播消费模式下，相同Consumer Group的每个Consumer实例都接收全量的消息\r\n\t- 主题（Topic）\r\n\t\t- 表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位\r\n\t\t-  Topic只是一个逻辑概念，并不实际保存消息\r\n\t\t- 同一个Topic下的消息，会分片保存到不同的Broker上，而每一个分片单位，就叫做MessageQueue\r\n\t\t- MessageQueue是一个具有FIFO特性的队列结构，生产者发送消息与消费者消费消息的最小单位\r\n\t- 代理服务器（Broker Server） \r\n\t\t- 消息中转角色，负责存储消息、转发消息\r\n\t\t\t- 负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备\r\n\t\t\t- 也存储消息相关的元数据，包括消费者组、消费进度偏移和主题和队列消息等\r\n\t\t- Broker Server是RocketMQ真正的业务核心，包含了多个重要的子模块\r\n\t\t\t- Remoting Module：整个Broker的实体，负责处理来自clients端的请求\r\n\t\t\t- Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息\r\n\t\t\t- Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能\r\n\t\t\t- HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步\r\n\t\t\t- Index Service：根据特定的Message key对投递到Broker的消息进行索引服务\r\n\t\t- RocketMQ中有两种Broker架构模式\r\n\t\t\t- 普通集群\r\n\t\t\t\t- 这种集群模式下会给每个节点分配一个固定的角色\r\n\t\t\t\t- master负责响应客户端的请求，并存储消息\r\n\t\t\t\t- slave则只负责对master的消息进行同步保存，并响应部分客户端的读请求\r\n\t\t\t\t- 消息同步方式分为同步同步和异步同步\r\n\t\t\t\t- 这种集群模式下各个节点的角色无法进行切换\r\n\t\t\t\t\t- 也就是说，master节点挂了，这一组Broker就不可用了\r\n\t\t\t- Dledger高可用集群\r\n\t\t\t\t- 集群会随机选出一个节点作为master\r\n\t\t\t\t\t- 当master节点挂了后，会从slave中自动选出一个节点升级成为master\r\n\t\t\t\t- 完成master节点往slave节点的消息同步\r\n\t- 名字服务（Name Server） \r\n\t\t- 名称服务充当路由消息的提供者\r\n\t\t- Broker Server会在启动时向所有的Name Server注册自己的服务信息\r\n\t\t\t- 后续通过心跳请求的方式保证这个服务信息的实时性\r\n\t\t- 生产者或消费者能够通过名字服务查找各主题相应的Broker IP列表\r\n\t\t- 多个Namesrv实例组成集群，但相互独立，没有信息交换\r\n\t\t\t-  这种特性也就意味着NameServer中任意的节点挂了，只要有一台服务节点正常，整个路由服务就不会有影响\r\n\t- 消息（Message） \r\n\t\t- 消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题Topic\r\n\t\t- RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key\r\n\t\t\t- 系统提供了通过Message ID和Key查询消息的功能\r\n\t\t- 并且Message上有一个为消息设置的标志，Tag标签\r\n\t\t\t- 用于同一主题下区分不同类型的消息\r\n\t\t\t- 来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1. 基础"
    },
    "frontmatter": {
      "title": "1. 基础",
      "date": "2025/07/03"
    },
    "type": "content"
  },
  {
    "title": "2.消息类型&ACL",
    "path": "/docs/architect/rocketmq/RocketMQ-2.xiaoxileixing_ACL.html",
    "url": "/docs/architect/rocketmq/RocketMQ-2.xiaoxileixing_ACL.html",
    "content": "---\r\ntitle: 2.消息类型&ACL\r\ndate: 2025/07/03\r\n---\r\n\r\n- 消息类型\r\n- ACL 权限控制 \r\n\r\n---\r\n## 消息类型\r\n\r\n- 顺序消息 \r\n\t- 保证的是消息的局部有序，而不是全局有序\r\n\t- 消息发送者会采取Round Robin轮询方式把消息发送到不同的 MessageQueue (分区队列)\r\n\t\t- 消费者消费的时候也从多个MessageQueue上拉取消息，这种情况下消息是不能保证顺序的\r\n\t\t- 而只有当一组有序的消息发送到同一个MessageQueue上时，才能利用MessageQueue先进先出的特性保证这一组消息有序\r\n\t\t- MessageListenerConcurrently这个消息监听器则不会锁队列，每次都是从多个Message中取一批数据（默认不超过32条）。因此也无法保证消息有序\r\n\t- 消费者会从多个消息队列上去拿消息\r\n\t\t- 这时虽然每个消息队列上的消息是有序的，但是多个队列之间的消息仍然是乱序的\r\n\t\t- 消费者端要保证消息有序，就需要按队列一个一个来取消息，即取完一个队列的消息后，再去取下一个队列的消息\r\n\t\t- 而给consumer注入的MessageListenerOrderly对象，在RocketMQ内部就会通过锁队列的方式保证消息是一个一个队列来取的\r\n- 广播消息 \r\n- 延迟消息：`Message#setDelayTimeLevel`\r\n\t- 在调用producer.send方法后，消息并不会立即发送出去，而是会等一段时间再发送出去\r\n\t- 只支持18个固定的延迟级别（18种消息队列）\r\n- 批量消息 \r\n\t- 将多条消息合并成一个批量消息，一次发送出去\r\n\t- 如果批量消息大于1MB就不要用一个批次发送，而要拆分成多个批次消息发送\r\n\t\t- 实际最大的限制是4MB\r\n\t- 这些消息应该有相同的Topic，相同的waitStoreMsgOK\r\n\t- 而且不能是延迟消息、事务消息等\r\n- 过滤消息\r\n\t- 可以使用Message的Tag属性来简单快速的过滤信息\r\n\t- 一个应用可以就用一个Topic，而应用中的不同业务就用TAG来区分\r\n\t- 可以使用SQL表达式来对消息进行过滤：`MessageSelector#bySql`\r\n\t\t- 只有推模式的消费者可以使用SQL过滤\r\n- 事务消息\r\n\t- `TransactionMQProducer -> TransactionListener`\r\n\t- 事务消息只保证消息发送者的本地事务与发消息这两个操作的原子性\r\n\t\t- 但是并不保证消费者本地事务的原子性\r\n\t- 事务消息不支持延迟消息和批量消息\r\n\t- 默认将单个消息的检查次数限制为 15 次 `transactionCheckMax`\r\n\t\t- 超过则 Broker 将丢弃此消息，默认情况下同时打印错误日志 `AbstractTransactionCheckListener`\r\n\t- 事务消息将在 Broker 配置文件中的参数 transactionMsgTimeout 这样的特定时间长度之后被检查\r\n\t\t- 用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制\r\n\t\t\t- 该参数优先于 transactionMsgTimeout 参数\r\n\t- 事务性消息可能不止一次被检查或消费\r\n\t- 提交给用户的目标主题消息可能会失败，目前这依日志的记录而定\r\n\t\t- 如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制\r\n\t- 事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享\r\n\t\t- 事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者\r\n\t- 事务消息的实现机制\r\n\t\t- ![](static/RocketMQ-消息类型-ACL-1.png)\r\n\t\t\t- 在发送消息时，会将消息转为一个half半消息，并存入RocketMQ内部的一个 RMQ_SYS_TRANS_HALF_TOPIC 这个Topic，这样对消费者是不可见的\r\n\t\t\t- 再经过一系列事务检查通过后，再将消息转存到目标Topic，这样对消费者就可见了\r\n\t- 事务消息的作用\r\n\t\t- 事务消息只保证了分布式事务的一半\r\n\t\t- 对于复杂的分布式事务，RocketMQ提供的事务消息也是目前业内最佳的降级方案\r\n\r\n---\r\n## ACL 权限控制 \r\n\r\n- 权限控制（ACL）主要为RocketMQ提供Topic资源级别的用户访问控制\r\n- 用户在使用RocketMQ权限控制时，可以在Client客户端通过 RPCHook注入AccessKey和SecretKey签名\r\n\t- 同时，将对应的权限控制属性（包括Topic访问权限、IP白名单和AccessKey和SecretKey签名等）设置在`$ROCKETMQ_HOME/conf/plain_acl.yml`的配置文件中\r\n- Broker端对AccessKey所拥有的权限进行校验，校验不过，抛出异常\r\n- Broker端要在broker.conf中打开acl的标志\r\n\t- 这个配置文件是热加载的，也就是说要修改配置时，只要修改配置文件就可以了，不用重启Broker服务\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.消息类型&ACL",
      "lvl1": "消息类型",
      "lvl2": "ACL 权限控制"
    },
    "frontmatter": {
      "title": "2.消息类型&ACL",
      "date": "2025/07/03"
    },
    "type": "content"
  },
  {
    "title": "3.代码示例",
    "path": "/docs/architect/rocketmq/RocketMQ-3.daimashili.html",
    "url": "/docs/architect/rocketmq/RocketMQ-3.daimashili.html",
    "content": "---\r\ntitle: 3.代码示例\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 消息发送者的固定步骤\r\n\t- 同步发送消息\r\n\t- 异步发送消息\r\n\t- 单向发送消息：只管把消息发出去\r\n- 消息消费者的固定步骤\r\n\t- 拉模式\r\n\t\t- DefaultMQPullConsumerImpl 这个消费者类已标记为过期\r\n\t\t- 替换的类是 DefaultLitePullConsumerImpl\r\n\t- 推模式\r\n- 顺序消息\r\n- 广播消息\r\n- 延迟消息\r\n- 批量消息\r\n- 过滤消息\r\n- 事务消息\r\n- ACL 权限控制 \r\n- SpringBoot 整合 RocketMQ \r\n:::\r\n\r\n---\r\n## 消息发送者的固定步骤 \r\n\r\n1. 创建消息生产者producer，并制定生产者组名 \r\n2. 指定Nameserver地址\r\n3. 启动producer \r\n4. 创建消息对象，指定主题Topic、Tag和消息体 \r\n5. 发送消息：同步发送、异步发送以及单向发送\r\n6. 关闭生产者producer\r\n\r\n```java\r\nDefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage msg = new Message(\"TopicTest\",\"TagA\",\"OrderID188\", \r\n\t\"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\r\n// 同步发送消息\r\nSendResult sendResult = producer.send(msg);\r\n// 异步发送消息\r\nproducer.setRetryTimesWhenSendAsyncFailed(3);\r\nproducer.send(msg, new SendCallback() { });\r\n// 单向发送消息\r\nproducer.sendOneway(msg);\r\nproducer.shutdown();\r\n```\r\n\r\n---\r\n## 消息消费者的固定步骤\r\n \r\n1. 创建消费者Consumer，制定消费者组名 \r\n2. 指定Nameserver地址\r\n3. 订阅主题Topic和Tag \r\n4. 设置回调函数，处理消息\r\n\t- 拉模式；推模式（推模式也是由拉模式封装出来的）\r\n5. 启动消费者consumer\r\n\r\n```java\r\n// 拉模式\r\nDefaultMQPullConsumer consumer = new DefaultMQPullConsumer(\"group_name\");\r\nconsumer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nconsumer.start();\r\nSet<MessageQueue> mqs = consumer.fetchSubscribeMessageQueues(\"TopicTest\");\r\nfor (MessageQueue mq : mqs) {\r\n\t// 从每个 MQ 中拉消息，指定 offset 和 maxNums\r\n\tPullResult pullResult = consumer.pullBlockIfNotFound(mq, null, 0, 32);\r\n\t// 该 MQ 中下一个消息的 offset\r\n\tlong offset = pullResult.getNextBeginOffset()\r\n\tswitch (pullResult.getPullStatus()) {\r\n\t\t// 如果该 MQ 中的消息没取完，应该继续取\r\n\t}\r\n}\r\nconsumer.shutdown();\r\n```\r\n```java\r\n// 订阅-拉模式\r\nDefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(\"lite_pull_consumer\");\r\nlitePullConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);\r\nlitePullConsumer.subscribe(\"TopicTest\", \"*\");\r\nlitePullConsumer.start();\r\nwhile (running) {\r\n\tList<MessageExt> messageExts = litePullConsumer.poll();\r\n}\r\nlitePullConsumer.shutdown();\r\n```\r\n```java\r\n// 分派-拉模式\r\nDefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer(\"group_name\");\r\nlitePullConsumer.setAutoCommit(false);\r\nlitePullConsumer.start();\r\nCollection<MessageQueue> mqSet = litePullConsumer.fetchMessageQueues(\"TopicTest\");\r\nList<MessageQueue> list = new ArrayList<>(mqSet);\r\n// list -add-> assignList\r\nList<MessageQueue> assignList = new ArrayList<>();\r\nlitePullConsumer.assign(assignList);\r\nlitePullConsumer.seek(assignList.get(0), 10);\r\nwhile (running) {\r\n\tList<MessageExt> messageExts = litePullConsumer.poll();\r\n\tlitePullConsumer.commitSync();\r\n}\r\n\r\nlitePullConsumer.shutdown();\r\n```\r\n```java\r\n// 推模式\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_JODIE_1\");\r\nconsumer.setNamesrvAddr(\"worker1:9876\");\r\nconsumer.subscribe(\"TopicTest\", \"*\");\r\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);\r\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\r\n\t@Override\r\n\tpublic ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, \r\n\t\t\tConsumeConcurrentlyContext context) {\r\n\t\t// 消费 msgs 之后确认已经消费完毕\r\n\t\treturn ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\r\n\t}\r\n};\r\nconsumer.start();\r\n```\r\n\r\n---\r\n## 顺序消息 \r\n\r\n```java\r\n// 生产者\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage msg = new Message(\"OrderTopicTest\", \"order_\" + orderId, \"KEY\" + orderId,\r\n\t (\"order_\"+orderId+\" step \" + j).getBytes(RemotingHelper.DEFAULT_CHARSET));\r\nSendResult sendResult = producer.send(msg, new MessageQueueSelector() {\r\n\t@Override\r\n\tpublic MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {\r\n\t\t// 根据传入的 arg (即 producer#send 的第二个参数，orderId) 选一个 MessageQueue\r\n\t\treturn mqs.get(index);\r\n\t}\r\n}, orderId);\r\nproducer.shutdown();\r\n```\r\n```java\r\n// 消费者\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group_name\");\r\nconsumer.setNamesrvAddr(\"localhost:9876\");\r\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);\r\nconsumer.subscribe(\"OrderTopicTest\", \"*\");\r\n// 需要使用 MessageListenerOrderly 保证顺序性，而不是 MessageListenerConcurrently\r\nconsumer.registerMessageListener(new MessageListenerOrderly() {\r\n\t@Override\r\n\tpublic ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs, \r\n\t\t\tConsumeOrderlyContext context) {\r\n\t\tcontext.setAutoCommit(true);\r\n\t\t// 消费 msgs 后确认消费完毕\r\n\t\treturn ConsumeOrderlyStatus.SUCCESS;\r\n\t}\r\n});\r\n\r\nconsumer.start();\r\n```\r\n\r\n---\r\n## 广播消息\r\n\r\n```java\r\n// 消费者\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group_name\");\r\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);\r\nconsumer.setMessageModel(MessageModel.BROADCASTING);\r\nconsumer.subscribe(\"TopicTest\", \"*\");\r\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\r\n\t@Override\r\n\tpublic ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\r\n\t\t\tConsumeConcurrentlyContext context) {\r\n\t\t// 消费 msgs 后确认消费完毕\r\n\t\treturn ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\r\n\t}\r\n});\r\nconsumer.start();\r\n```\r\n\r\n---\r\n## 延迟消息 \r\n\r\n```java\r\n// 生产者\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage message = new Message(\"TestTopic\", (\"Hello scheduled message \").g",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.代码示例",
      "lvl1": "消息发送者的固定步骤",
      "lvl2": "消息消费者的固定步骤",
      "lvl3": "顺序消息",
      "lvl4": "广播消息",
      "lvl5": "延迟消息",
      "lvl6": "批量消息",
      "lvl7": "过滤消息",
      "lvl8": "事务消息",
      "lvl9": "ACL 权限控制",
      "lvl10": "SpringBoot 整合 RocketMQ"
    },
    "frontmatter": {
      "title": "3.代码示例",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "3.代码示例",
    "path": "/docs/architect/rocketmq/RocketMQ-3.daimashili.html",
    "url": "/docs/architect/rocketmq/RocketMQ-3.daimashili.html",
    "content": "etBytes());\r\nmessage.setDelayTimeLevel(3);\r\nproducer.send(message);\r\nproducer.shutdown();\r\n```\r\n\r\n---\r\n## 批量消息 \r\n\r\n```java\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nproducer.send(List<Message> messages);\r\nproducer.shutdown();\r\n```\r\n\r\n---\r\n## 过滤消息 \r\n\r\n```java\r\n// tag-生产者\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage msg = new Message(\"TagFilterTest\", \"TagA\", \r\n\t \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\r\nSendResult sendResult = producer.send(msg);\r\nproducer.shutdown();\r\n\r\n// tag-消费者\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group_name\");\r\nconsumer.subscribe(\"TagFilterTest\", \"TagA || TagC\");\r\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\r\n\t@Override\r\n\tpublic ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\r\n\t\t\tConsumeConcurrentlyContext context) {\r\n\t\t// 消费 msgs 后确认消费完毕\r\n\t\treturn ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\r\n\t}\r\n});\r\nconsumer.start();\r\n```\r\n```java\r\n// sql-生产者\r\nDefaultMQProducer producer = new DefaultMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"192.168.232.128:9876\");\r\nproducer.start();\r\nMessage msg = new Message(\"SqlFilterTest\",\"TagA\",\r\n\t(\"Hello RocketMQ\").getBytes(RemotingHelper.DEFAULT_CHARSET));\r\nmsg.putUserProperty(\"a\", String.valueOf(i));\r\nSendResult sendResult = producer.send(msg);\r\nproducer.shutdown();\r\n\r\n// sql-消费者\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group_name\");\r\nconsumer.subscribe(\"SqlFilterTest\",\r\n\tMessageSelector.bySql(\"(TAGS is not null and TAGS in ('TagA', 'TagB'))\" +\r\n\t\"and (a is not null and a between 0 and 3)\"));\r\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\r\n\t@Override\r\n\tpublic ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\r\n\t\t\tConsumeConcurrentlyContext context) {\r\n\t\t// 消费 msgs 后确认消费完毕\r\n\t\treturn ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\r\n\t}\r\n});\r\nconsumer.start();\r\n```\r\n\r\n---\r\n## 事务消息 \r\n\r\n```java\r\npublic class TransactionListenerImpl implements TransactionListener {\r\n\t@Override\r\n\tpublic LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\r\n\t\t// COMMIT_MESSAGE ROLLBACK_MESSAGE UNKNOW\r\n\t\tmsg.getTransactionId(); // 事务ID\r\n\t\treturn LocalTransactionState.COMMIT_MESSAGE;\r\n\t}\r\n\t@Override\r\n\tpublic LocalTransactionState checkLocalTransaction(MessageExt msg) {\r\n\t\t// COMMIT_MESSAGE ROLLBACK_MESSAGE UNKNOW\r\n\t\tmsg.getTransactionId(); // 事务ID\r\n\t\treturn LocalTransactionState.COMMIT_MESSAGE;\r\n\t}\r\n}\r\n```\r\n```java\r\nTransactionListener transactionListener = new TransactionListenerImpl();\r\nTransactionMQProducer producer = new TransactionMQProducer(\"group_name\");\r\nproducer.setNamesrvAddr(\"127.0.0.1:9876\");\r\nproducer.setExecutorService(executorService);\r\nproducer.setTransactionListener(transactionListener);\r\nproducer.start();\r\nMessage msg = new Message(\"TopicTest\", \"TagA\", \"KEY\", \r\n\t(\"Hello RocketMQ \").getBytes(RemotingHelper.DEFAULT_CHARSET));\r\nSendResult sendResult = producer.sendMessageInTransaction(msg, null);\r\nproducer.shutdown();\r\n```\r\n\r\n---\r\n## ACL 权限控制 \r\n- `<artifactId>rocketmq-acl</artifactId>`\r\n- `broker.conf -> aclEnable=true`\r\n- `plan_acl.yml`\r\n```yaml\r\n#全局白名单，不受ACL控制 \r\n#通常需要将主从架构中的所有节点加进来 \r\nglobalWhiteRemoteAddresses:\r\n- 10.10.103.*\r\n- 192.168.0.*\r\n\r\naccounts:\r\n#第一个账户\r\n- accessKey: RocketMQ\r\n  secretKey: 12345678 \r\n  whiteRemoteAddress: \r\n  admin: false \r\n  defaultTopicPerm: DENY #默认Topic访问策略是拒绝 \r\n  defaultGroupPerm: SUB #默认Group访问策略是只允许订阅 \r\n  topicPerms:\r\n  - topicA=DENY #topicA拒绝\r\n  - topicB=PUB|SUB #topicB允许发布和订阅消息\r\n  - topicC=SUB #topicC只允许订阅\r\n  groupPerms:\r\n  # the group should convert to retry topic\r\n  - groupA=DENY\r\n  - groupB=PUB|SUB\r\n  - groupC=SUB\r\n#第二个账户，只要是来自192.168.1.*的IP，就可以访问所有资源 \r\n- accessKey: rocketmq2\r\n  secretKey: 12345678 \r\n  whiteRemoteAddress: 192.168.1.*\r\n  # if it is admin, it could access all resources \r\n  admin: true\r\n```\r\n\r\n---\r\n## SpringBoot 整合 RocketMQ \r\n\r\n```properties\r\n#NameServer地址 \r\nrocketmq.name-server=192.168.232.128:9876 \r\n#默认的消息生产者组 \r\nrocketmq.producer.group=springBootGroup\r\n```\r\n```java\r\n// 生产者\r\n@Component\r\npublic class SpringProducer {\r\n\t@Resource\r\n\tprivate RocketMQTemplate rocketMQTemplate;\r\n\t// 发送普通消息\r\n\tpublic void sendMessage(String topic,String msg){\r\n\t\tthis.rocketMQTemplate.convertAndSend(topic,msg);\r\n\t}\r\n\t// 发送事务消息\r\n\tpublic void sendMessageInTransaction(String topic,String msg) {\r\n\t\tString destination =topic + \":\" + \"TagA\";\r\n\t\tMessage<String> message = MessageBuilder.withPayload(msg).build();\r\n\t\tSendResult sendResult = rocketMQTemplate.sendMessageInTransaction(\r\n\t\t\tdestination, message, destination);\r\n\t}\r\n}\r\n// 事务消息监听器\r\n@RocketMQTransactionListener(rocketMQTemplateBeanName = \"rocketMQTemplate\")\r\npublic class MyTransactionImpl implements RocketMQLocalTransactionListener{\r\n\t@Override\r\n\tpublic RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) {\r\n\t\t// COMMIT ROLLBACK UNKNOWN\r\n\t\t// SpringBoot 的消息对象中，并没有 transactionId 这个属性\r\n\t\treturn RocketMQLocalTransactionState.COMMIT;\r\n\t}\r\n\t@Override\r\n\tpublic RocketMQLocalTransactionState checkLocalTransaction(Message msg){\r\n\t\t// COMMIT ROLLBACK UNKNOWN\r\n\t\treturn RocketMQLocalTransactionState.COMMIT;\r\n\t}\r\n}\r\n// 消费者\r\n@Component\r\n@RocketMQMessageListener(consumerGroup = \"MyConsumerGroup\", topic = \"TestTopic\")\r\npublic class SpringConsumer implements RocketMQListener<String> {\r\n    @Override\r\n    public void onMessage(String message) { \r\n        System.out.println(\"Received message : \"+ message);\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3.代码示例",
      "lvl1": "消息发送者的固定步骤",
      "lvl2": "消息消费者的固定步骤",
      "lvl3": "顺序消息",
      "lvl4": "广播消息",
      "lvl5": "延迟消息",
      "lvl6": "批量消息",
      "lvl7": "过滤消息",
      "lvl8": "事务消息",
      "lvl9": "ACL 权限控制",
      "lvl10": "SpringBoot 整合 RocketMQ"
    },
    "frontmatter": {
      "title": "3.代码示例",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "---\r\ntitle: 4.核心原理\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 读队列与写队列\r\n- 消息持久化\r\n- 过期文件删除\r\n- 高效文件写\r\n\t- 零拷贝\r\n\t- 顺序写\r\n\t- 刷盘机制\r\n- 消息主从复制\r\n- 负载均衡\r\n- 消息重试\r\n- 死信队列\r\n- 消息幂等\r\n- Dledger 集群\r\n\t- 选举\r\n\t- 消息同步\r\n:::\r\n\r\n---\r\n## 读队列与写队列\r\n\r\n- 通常在运行时，都需要设置读队列=写队列\r\n- 读写分离\r\n\t- 写队列会真实的创建对应的存储文件，负责消息写入\r\n\t- 读队列会记录Consumer的Offset，负责消息读取\r\n-  在往写队列里写Message时，会同步写入到一个对应的读队列中\r\n\t- ![](static/RocketMQ-核心原理-1.png)\r\n- 如果写队列大于读队列，就会有一部分写队列无法写入到读队列中，这一部分的消息就无法被读取，就会造成消息丢失（消息存入了，但是读不出来）\r\n- 如果写队列小于读队列，那就有一部分读队列里是没有消息写入的。如果有一个消费者被分配的是这些没有消息的读队列，那这些消费者就无法消费消息，造成消费者空转，极大的浪费性能\r\n- 对Topic的MessageQueue进行缩减的时候，可以考虑将读写队列设置为不一致\r\n\t- 例如原来四个队列，现在要缩减成两个队列\r\n\t- 如果立即缩减读写队列，那么被缩减的MessageQueue上没有被消费的消息，就会丢失\r\n\t- 这时，可以先缩减写队列，待空出来的读队列上的消息都被消费完了之后，再来缩减读队列，这样就可以比较平稳的实现队列缩减了\r\n\r\n---\r\n## 消息持久化\r\n\r\n- RocketMQ消息直接采用磁盘文件保存消息，默认路径在`${user_home}/store`目录（`broker.conf`）\r\n- 存储文件主要分为三个部分\r\n\t- CommitLog：存储消息的元数据\r\n\t\t- 所有消息都会顺序存入到CommitLog文件当中\r\n\t\t- CommitLog由多个文件组成，每个文件固定大小1G\r\n\t\t- 以第一条消息的偏移量为文件名\r\n\t- ConsumerQueue：存储消息在CommitLog的索引\r\n\t\t- 一个MessageQueue一个文件\r\n\t\t- 记录当前MessageQueue被哪些消费者组消费到了哪一条CommitLog\r\n\t- IndexFile\r\n\t\t- 为了消息查询提供了一种通过key或时间区间来查询消息的方法\r\n\t\t- 这通过IndexFile来查找消息的方法不影响发送与消费消息的主流程\r\n\t- CommitLog文件和ConsumeQueue文件都是以偏移量命名\r\n- 还有几个辅助的存储文件\r\n\t- checkpoint：数据存盘检查点\r\n\t\t- 里面主要记录commitlog文件、ConsumeQueue文件以及IndexFile文件最后一次刷盘的时间戳\r\n\t- `config/*.json`：这些文件是将RocketMQ的一些关键配置信息进行存盘保存\r\n\t\t- 例如Topic配置、消费者组配置、消费者组消息偏移量Offset 等等一些信息\r\n\t- abort：这个文件是RocketMQ用来判断程序是否正常关闭的一个标识文件\r\n\t\t- 正常情况下，会在启动时创建，而关闭服务时删除\r\n\t\t- 但是如果遇到一些服务器宕机，这个abort文件就不会删除\r\n\t\t- 因此RocketMQ就可以判断上一次服务是非正常关闭的，后续就会做一些数据恢复的操作\r\n- 整体的消息存储结构\r\n\t- ![](static/RocketMQ-核心原理-2.png)\r\n- CommitLog文件存储所有消息实体\r\n\t- 所有生产者发过来的消息，都会无差别的依次存储到Commitlog文件当中\r\n\t\t- 这样的好处是可以减少查找目标文件的时间，让消息以最快的速度落盘\r\n\t\t- 对比Kafka存文件时，需要寻找消息所属的Partition文件，再完成写入，当Topic比较多时，这样的Partition寻址就会浪费比较多的时间，所以Kafka不太适合多Topic的场景\r\n\t\t- 而RocketMQ的这种快速落盘的方式在多Topic场景下，优势就比较明显\r\n\t-  文件结构：CommitLog的文件大小是固定的，但是其中存储的每个消息单元长度是不固定的\r\n\t\t- 所以RocketMQ在每次存CommitLog文件时，都会去检查当前CommitLog文件空间是否足够\r\n\t\t\t- 如果不够的话，就重新创建一个CommitLog文件\r\n\t\t\t- 文件名为当前消息的偏移量\r\n- ConsumeQueue文件主要是加速消费者的消息索引\r\n\t- 他的每个文件夹对应RocketMQ中的一个MessageQueue\r\n\t\t- 文件夹下的文件记录了每个MessageQueue中的消息在CommitLog文件当中的偏移量\r\n\t\t- 这样，消费者通过ComsumeQueue文件，就可以快速找到CommitLog文件中感兴趣的消息记录\r\n\t\t- 而消费者在ConsumeQueue文件当中的消费进度，会保存在`config/consumerOffset.json`文件当中\r\n\t- 文件结构：每个ConsumeQueue文件固定由30万个固定大小20byte的数据块组成，数据块的内容包括\r\n\t\t- msgPhyOffset (8byte，消息在文件中的起始位置)\r\n\t\t- msgSize (4byte，消息在文件中占用的长度)\r\n\t\t- msgTagCode (8byte，消息的tag的Hash值)\r\n- IndexFile文件主要是辅助消息检索\r\n\t- 消费者进行消息消费时，通过ConsumeQueue文件就足够完成消息检索了，但是如果要按照MeessageId或者MessageKey来检索文件，比如RocketMQ管理控制台的消息轨迹功能，ConsumeQueue文件就不够用了\r\n\t- 他的文件名比较特殊，不是以消息偏移量命名，而是用的时间命名\r\n\t- 文件结构：也是一个固定大小的文件\r\n\t\t- indexHeader (固定40byte)\r\n\t\t- slot (固定500W个，每个固定20byte)\r\n\t\t- index (最多`500W*4`个，每个固定20byte) \r\n\r\n---\r\n## 过期文件删除\r\n\r\n- 判断过期文件：唯一标准就是非当前写文件的保留时间（`broker.conf -> fileReservedTime`）\r\n\t- 如果超过了一定的保留时间，那么这些文件都会被认为是过期文件，随时可以删除\r\n\t- 并不关心文件当中的消息是否被消费过\r\n\t\t- 所以，RocketMQ的消息堆积也是有时间限度的\r\n- 删除过期文件\r\n\t- 内部有一个定时任务，对文件进行扫描，并且触发文件删除的操作\r\n\t\t- `broker.conf -> deleteWhen`，默认是凌晨四点\r\n\t- 还会检查服务器的磁盘空间是否足够，如果磁盘空间的使用率达到一定的阈值，也会触发过期文件删除\r\n\t\t- broker的",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 5
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "磁盘空间不要少于4\r\n\r\n---\r\n## 高效文件写\r\n\r\n### 零拷贝\r\n\r\n- 所谓的零拷贝技术，其实并不是不拷贝，而是要尽量减少CPU拷贝\r\n- 引入DMA拷贝之后，在读写请求的过程中，CPU不再需要参与具体的工作\r\n\t- DMA可以独立完成数据在系统内部的复制\r\n\t- 但是，数据复制过程中，依然需要借助数据总进线\r\n\t\t- 当系统内的IO操作过多时，还是会占用过多的数据总线，造成总线冲突，最终还是会影响数据读写性能\r\n- 为了避免DMA总线冲突对性能的影响，后来又引入了Channel通道的方式\r\n\t- Channel，是一个完全独立的处理器，专门负责IO操作\r\n\t- 既然是处理器，Channel就有自己的IO指令，与CPU无关，他也更适合大型的IO操作，性能更高\r\n- mmap：`FileChannel#map`\r\n\t- mmap机制适合操作小文件，如果文件太大，映射信息也会过大，容易造成很多问题\r\n\t- 通常mmap机制建议的映射文件大小不要超过2G\r\n\t- RocketMQ的CommitLog文件保持在1G固定大小，也是为了方便文件映射\r\n\t- ![](static/RocketMQ-核心原理-3.png)\r\n- sendFile：`FileChannel#transferTo`\r\n\t- 在拷贝过程中，并不直接拷贝文件的内容，而是只拷贝一个带有文件位置和长度等信息的文件描述符FD\r\n\t\t- 这样就大大减少了需要传递的数据\r\n\t- 而真实的数据内容，会交由DMA控制器，从页缓存中打包异步发送到socket中\r\n\t- sendfile机制在内核态直接完成了数据的复制，不需要用户态的参与，所以这种机制的传输效率是非常稳定的\r\n\t- sendfile机制非常适合大数据的复制转移\r\n\t- ![](static/RocketMQ-核心原理-4.png)\r\n\r\n### 顺序写\r\n\r\n- 在磁盘中提前申请一块连续的磁盘空间\r\n\t- 每次写数据时，就可以避免这些寻址操作，直接在之前写入的地址后面接着写就行\r\n- 顺序写的性能基本能够达到内存级别\r\n\r\n### 刷盘机制\r\n\r\n- 在操作系统层面\r\n\t- 当应用程序写入一个文件时，文件内容并不会直接写入到硬件当中，而是会先写入到操作系统中的一个缓存PageCache中\r\n\t\t- PageCache缓存以4K大小为单位，缓存文件的具体内容\r\n\t\t- 这些写入到PageCache中的文件，在应用程序看来，是已经完全落盘保存好了的\r\n\t\t- 但是，本质上，PageCache依然是内存状态，所以一断电就会丢失\r\n\t\t- 因此，需要将内存状态的数据写入到磁盘当中，这样数据才能真正完成持久化，断电也不会丢失\r\n\t\t\t- 这个过程就称为刷盘\r\n\t- PageCache是源源不断产生的，操作系统只会在某些特定的时刻将PageCache写入到磁盘\r\n\t\t- 正常关机时\r\n\t\t- 当 Dirty Page (脏页) 的比例达到一定的阈值时（对于有数据修改的PageCache，会标记为Dirty状态）\r\n\t- 可以通过/proc/meminfo文件查看到Page Cache的状态\r\n\t- fsync：可以让应用程序完成PageCache的强制刷盘\r\n-  RocketMQ对于何时进行刷盘，也设计了两种刷盘机制，同步刷盘和异步刷盘 \r\n\t- `broker.conf -> flushDiskType`\r\n\t- ![](static/RocketMQ-核心原理-5.png)\r\n\t- 同步刷盘：在返回写成功状态时，消息已经被写入磁盘\r\n\t\t- 消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘\r\n\t\t-  然后等待刷盘完成\r\n\t\t- 刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态\r\n\t- 异步刷盘：在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE\r\n\t\t- 写操作的返回快，吞吐量大\r\n\t\t- 当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入\r\n\t- 同步刷盘机制会更频繁的调用fsync，所以吞吐量相比异步刷盘会降低，但是数据的安全性会得到提高\r\n\r\n---\r\n## 消息主从复制 \r\n\r\n- 同步复制：等Master和Slave都写入消息成功后才反馈给客户端写入成功的状态\r\n\t- 如果Master节点故障，Slave上有全部的数据备份，这样容易恢复数据\r\n\t- 但是同步复制会增大数据写入的延迟，降低系统的吞吐量\r\n- 异步复制：只要master写入消息成功，就反馈给客户端写入成功的状态\r\n\t- 然后再异步的将消息复制给Slave节点\r\n\t- 系统拥有较低的延迟和较高的吞吐量\r\n\t- 但是如果master节点故障，而有些数据没有完成复制，就会造成数据丢失\r\n- `broker.conf -> brokerRole`\r\n\t- ASYNC_MASTER、 SYNC_MASTER、SLAVE\r\n\r\n---\r\n## 负载均衡\r\n\r\n- Producer 负载均衡 \r\n\t- ![](static/RocketMQ-核心原理-6.png)\r\n\t- Producer发送消息时，默认会轮询目标Topic下的所有MessageQueue，并采用递增取模的方式往不同的MessageQueue上发送消息，以达到让消息平均落在不同的queue上的目的\r\n\t- 由于MessageQueue是分布在不同的Broker上的，所以消息也会发送到不同的broker上\r\n\t- 同时生产者在发送消息时，可以指定一个MessageQueueSelector\r\n\t\t- 通过这个对象来将消息发送到自己指定的MessageQueue上\r\n\t\t- 这样可以保证消息局部有序\r\n- Consumer负载均衡： Consumer也是以MessageQueue为单位来进行负载均衡\r\n\t- 集群模式 \r\n\t\t- 每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可\r\n\t\t- RocketMQ采用主动拉取的方式拉取并消费消息\r\n\t\t\t- 在拉取的时候需要明确指定拉取哪一条message queue\r\n\t\t- 每当实例的数量有变更，都会触发一次所有实例的负载均衡\r\n\t\t\t- 这时候会按照queue的数量和实例的数量平均分配queue给每个实例\r\n\t\t- 每次分配时，都会将MessageQueue和消费者ID进行排序后，再用不同的分配算法进行分配\r\n\t\t- 内置的分配的算法共有六种，分别对应AllocateMessageQueueStrategy下的六种实现类\r\n\t\t\t- 可以在consumer中直接set来指定。默认情况下使用的是最简单的平均分配策略\r\n\t- 广播模式\r\n\t\t- 每一条消息都会投递给订阅了Topic的所有消费者实例，所以也就没有消息分配这一说\r\n\t\t- 在实现上，就是在Consumer分配Queue时，所有Consumer都分到所有的Queue\r\n\t\t- 实现",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 5
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "的关键是将消费者的消费偏移量不再保存到broker当中\r\n\t\t\t- 而是保存到客户端当中，由客户端自行维护自己的消费偏移量\r\n- 集群模式分配算法\r\n\t- AllocateMachineRoomNearby： 将同机房的Consumer和Broker优先分配在一起\r\n\t\t- 可以通过一个machineRoomResolver对象来定制Consumer和Broker的机房解析规则\r\n\t\t- 然后还需要引入另外一个分配策略来对同机房的Broker和Consumer进行分配\r\n\t\t\t- 一般也就用简单的平均分配策略或者轮询分配策略\r\n\t- AllocateMessageQueueAveragely（默认）：平均分配。将所有MessageQueue平均分给每一个消费者\r\n\t- AllocateMessageQueueAveragelyByCircle： 轮询分配。轮流的给一个消费者分配一个MessageQueue\r\n\t- AllocateMessageQueueByConfig： 不分配，直接指定一个messageQueue列表\r\n\t\t- 类似于广播模式，直接指定所有队列\r\n\t- AllocateMessageQueueByMachineRoom：按逻辑机房的概念进行分配\r\n\t\t- 又是对BrokerName和ConsumerIdc有定制化的配置\r\n\t- AllocateMessageQueueConsistentHash：一致性哈希策略\r\n\t\t- 只需要指定一个虚拟节点数，是用的一个哈希环的算法\r\n\t\t- 虚拟节点是为了让Hash数据在换上分布更为均匀\r\n\r\n---\r\n## 消息重试\r\n\r\n- 集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置 \r\n\t- `MessageListener#consume`\r\n\t- 返回 Action.ReconsumeLater（推荐） 消息重试\r\n\t- 返回 Action.CommitMessage 消费失败后不重试\r\n\t- 返回 null\r\n\t- 抛出异常\r\n- 处理重试消息\r\n\t- 重试的消息会进入一个 “%RETRY%”+ConsumeGroup 的队列中\r\n\t- 默认允许每条消息最多重试16次\r\n\t\t- 这个重试时间跟延迟消息的延迟级别是对应的\r\n\t\t- 不过取的是延迟级别的后16级别\r\n\t- `consumer#setMaxReconsumeTimes` 定制重试次数\r\n\t\t- 当定制的重试次数超过16次后，消息的重试时间间隔均为2小时\r\n\t- 如果消息重试16次后仍然失败，消息将不再投递。转为进入死信队列\r\n\t- 一条消息无论重试多少次，这些重试消息的MessageId始终都是一样的\r\n\t\t- 在4.9.1版本中，每次重试MessageId都会重建\r\n\t- 配置覆盖\r\n\t\t- 消息最大重试次数的设置对相同GroupID下的所有Consumer实例有效\r\n\t\t- 并且最后启动的Consumer会覆盖之前启动的Consumer的配置\r\n\r\n---\r\n## 死信队列\r\n\r\n- 如果消息重试16次（`consumer#setMaxReconsumeTimes`）后仍然失败，消息将不再投递。转为进入死信队列\r\n- 死信队列的名称是 %DLQ%+ConsumGroup\r\n- 死信队列的特征\r\n\t- 一个死信队列对应一个ConsumGroup，而不是对应某个消费者实例\r\n\t- 如果一个ConsumeGroup没有产生死信队列，RocketMQ就不会为其创建相应的死信队列\r\n\t- 一个死信队列包含了这个ConsumeGroup里的所有死信消息，而不区分该消息属于哪个Topic\r\n\t- 死信队列中的消息不会再被消费者正常消费\r\n\t- 死信队列的有效期跟正常消息相同。默认3天（`broker.conf -> fileReservedTime`）\r\n\t\t- 超过这个最长时间的消息都会被删除，而不管消息是否消费过\r\n- 一般需要人工去查看死信队列中的消息，对错误原因进行排查\r\n\t- 然后对死信消息进行处理，比如转发到正常的Topic重新进行消费，或者丢弃\r\n- 默认创建出来的死信队列，他里面的消息是无法读取的，在控制台和消费者中都无法读取\r\n\t- 这些默认的死信队列，他们的权限 perm 被设置成了 2:禁读\r\n\t\t- 权限有三种：2:禁读，4:禁写，6:可读可写\r\n\t- 需要手动将死信队列的权限配置成 6，才能被消费\r\n\r\n---\r\n## 消息幂等\r\n\r\n- 在MQ系统中，对于消息幂等有三种实现语义\r\n\t- at most once 最多一次：每条消息最多只会被消费一次\r\n\t- at least once 至少一次：每条消息至少会被消费一次\r\n\t- exactly once 刚刚好一次：每条消息都只会确定的消费一次\r\n- RocketMQ 只能保证 at least once，保证不了 exactly once\r\n\t- 所以，使用RocketMQ时，需要由业务系统自行保证消息的幂等性\r\n- 消息重复\r\n\t- 发送时消息重复\r\n\t\t- 当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败\r\n\t\t- 此时生产者意识到消息发送失败并尝试再次发送消息\r\n\t\t- 消费者后续会收到两条内容相同并且 Message ID 也相同的消息\r\n\t- 投递时消息重复\r\n\t\t- 消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断\r\n\t\t- 为了保证消息至少被消费一次，消息队列 RocketMQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息\r\n\t\t- 消费者后续会收到两条内容相同并且 Message ID 也相同的消息\r\n\t- 负载均衡时消息重复：网络抖动、Broker 重启以及订阅方应用重启\r\n\t\t- 当消息队列 RocketMQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息\r\n- 处理方式：要在业务上自行来保证消息消费的幂等性\r\n\t- RocketMQ的每条消息都有一个唯一的 MessageId，这个参数在多次投递的过程中是不会改变的\r\n\t- 业务上可以用这个MessageId来作为判断幂等的关键依据\r\n\t- 但是，这个MessageId是无法保证全局唯一的，也会有冲突的情况\r\n\t- 所以在一些对幂等性要求严格的场景，最好是使用业务上唯一的一个标识比较靠谱\r\n\t- 而这个业务标识可以使用Message的Key来进行传递\r\n\r\n---\r\n## Dledger 集群\r\n\r\n- 高可用集群：基于Raft，在RocketMQ的主从集群基础上，增加了自动选举的功能\r\n- Dledger集群主要包含两个功能\r\n\t- 从集群中选举产生master节点\r\n\t- 优化master节点往slave节点的消息同步机制\r\n\r\n### 选举\r\n\r\n- Dledger是使用Raft算法来进行节点选举\r\n\t- 节点有三个状态，Leader，follower 和 candidate (候选人)\r\n\t\t- 正常运行的情况下",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 5
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "，集群中会有一个leader，其他都是follower\r\n\t\t- follower只响应Leader和Candidate的请求\r\n\t\t- 客户端的请求全部由Leader处理\r\n\t\t\t- 即使有客户端请求到了一个follower，也会将请求转发到leader\r\n\t- 选举流程\r\n\t\t- 集群刚启动时，每个节点都是follower状态\r\n\t\t- 之后集群内部会发送一个timeout信号\r\n\t\t- 所有follower就转成candidate去拉取选票，获得大多数选票的节点选为leader，其他候选人转为follower\r\n\t\t- 如果一个timeout信号发出时，没有选出leader，将会重新开始一次新的选举\r\n\t- 心跳\r\n\t\t- Leader节点会往其他节点发送心跳信号，确认他的leader状态\r\n\t\t- 然后follower会启动定时器，如果在指定时间内没有收到Leader的心跳，就会转为Candidate状态\r\n\t\t- 然后向其他成员发起投票请求，如果收到半数以上成员的投票，则Candidate会晋升为Leader\r\n\t\t\t- 然后leader也有可能会退化成follower\r\n- 在Raft协议中，会将时间分为一些任意时间长度的时间片段，叫做term\r\n\t- ![](static/RocketMQ-核心原理-7.png)\r\n\t- term会使用一个全局唯一，连续递增的编号作为标识，也就是起到了一个逻辑时钟的作用\r\n\t- 在每一个term时间片里，都会进行新的选举，每一个Candidate都会努力争取成为leader\r\n\t\t- 获得票数最多的节点就会被选举为Leader\r\n\t- 被选为Leader的这个节点，在一个term时间片里就会保持leader状态\r\n\t\t- 保证在同一时间段内，集群中只会有一个Leader\r\n\t- 在某些情况下，选票可能会被各个节点瓜分，形成不了多数派，那这个term可能直到结束都没有leader\r\n\t\t- 直到下一个term再重新发起选举，这也就没有了Zookeeper中的脑裂问题\r\n\t- 在每次重新选举的过程中， leader也有可能会退化成为follower\r\n\t\t- 也就是说，在这个集群中， leader节点是会不断变化的\r\n- 每次选举的过程中，每个节点都会存储当前term编号，并在节点之间进行交流时，都会带上自己的term编号\r\n\t- 如果一个节点发现他的编号比另外一个小，那么他就会将自己的编号更新为较大的那一个\r\n\t- 如果leader或者candidate发现自己的编号不是最新的，他就会自动转成follower\r\n\t- 如果接收到的请求term编号小于自己的编号，term将会拒绝执行\r\n-  在选举过程中，Raft协议会通过心跳机制发起leader选举\r\n\t- 节点都是从follower状态开始的，如果收到了来自leader或者candidate的心跳RPC请求，那他就会保持follower状态，避免争抢成为candidate\r\n\t- leader会往其他节点发送心跳信号，来确认自己的地位\r\n\t- 如果follower一段时间(两个timeout信号)内没有收到Leader的心跳信号，他就会认为leader挂了，发起新一轮选举\r\n-  选举开始后，每个follower会增加自己当前的term，并将自己转为candidate\r\n\t- 然后向其他节点发起投票请求，请求时会带上自己的编号和term，也就是说都会默认投自己一票\r\n\t- 之后candidate状态可能会发生以下三种变化\r\n\t\t- 赢得选举，成为leader\r\n\t\t\t- 如果它在一个term内收到了大多数的选票，将会在接下的剩余term时间内称为leader\r\n\t\t\t- 然后就可以通过发送心跳确立自己的地位\r\n\t\t\t- 每一个server在一个term内只能投一张选票，并且按照先到先得的原则投出\r\n\t\t- 其他节点成为leader\r\n\t\t\t- 在等待投票时，可能会收到其他server发出心跳信号，说明其他leader已经产生了\r\n\t\t\t- 这时通过比较自己的term编号和RPC过来的term编号\r\n\t\t\t\t- 如果比对方大，说明leader的term过期了，就会拒绝该RPC,并继续保持候选人身份\r\n\t\t\t\t- 如果对方编号不比自己小,则承认对方的地位,转为follower\r\n\t\t- 选票被瓜分,选举失败\r\n\t\t\t- 如果没有candidate获取大多数选票, 则没有leader产生\r\n\t\t\t- candidate们等待超时后发起另一轮选举\r\n\t\t\t- 为了防止下一次选票还被瓜分, raft采用随机electiontimeout(随机休眠时间)的机制防止选票被持续瓜分\r\n\t\t\t- 通过将timeout随机设为一段区间上的某个值, 因此很大概率会有某个candidate率先超时然后赢得大部分选票\r\n- 所以以三个节点的集群为例，选举过程会是这样的\r\n\t- 集群启动时，三个节点都是follower，发起投票后，三个节点都会给自己投票。这样一轮投票下来，三个节点的term都是1，是一样的，这样是选举不出Leader的\r\n\t- 当一轮投票选举不出Leader后，三个节点会进入随机休眠，例如A休眠1秒，B休眠3秒，C休眠2秒\r\n\t- 一秒后，A节点醒来，会把自己的term加一票，投为2。然后2秒时，C节点醒来，发现A的term已经是2，比自己的1大，就会承认A是Leader，把自己的term也更新为2。实际上这个时候，A已经获得了集群中的多数票，2票，A就会被选举成Leader。这样，一般经过很短的几轮选举，就会选举出一个Leader来\r\n\t- 到3秒时，B节点会醒来，他也同样会承认A的term最大，他是Leader，自己的term也会更新为2。这样集群中的所有Candidate就都确定成了leader和follower\r\n\t- 然后在一个任期内，A会不断发心跳给另外两个节点。当A挂了后，另外的节点没有收到A的心跳，就会都转化成Candidate状态，重新发起选举\r\n\r\n### 消息同步\r\n\r\nDledger还会采用Raft协议进行多副本的消息同步：\r\n- 使用Dledger集群后，数据主从同步会分为两个阶段，一个是uncommitted阶段，一个是commited阶段\r\n- Leader Broker上的Dledger收到一条数据后，会标记为uncommitted状态，然后他通过自己的DledgerServer组件把这个uncommitted数据发给Follower Broker的DledgerServer组件\r\n- 接着Follower Broker的DledgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的Dledger。然后如果Leader Broker收到超过半数的Follower Broker返回的ack之后，就会把消息标记为committed状态\r\n-  再接下来， Leader Broker上的DledgerServer就",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 4,
    "contentParts": 5
  },
  {
    "title": "4.核心原理",
    "path": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "url": "/docs/architect/rocketmq/RocketMQ-4.hexinyuanli.html",
    "content": "会发送committed消息给Follower Broker上的DledgerServer，让他们把消息也标记为committed状态。这样，就基于Raft协议完成了两阶段的数据同步\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.核心原理",
      "lvl1": "读队列与写队列",
      "lvl2": "消息持久化",
      "lvl3": "过期文件删除",
      "lvl4": "高效文件写",
      "lvl5": "消息主从复制",
      "lvl6": "负载均衡",
      "lvl7": "消息重试",
      "lvl8": "死信队列",
      "lvl9": "消息幂等",
      "lvl10": "Dledger 集群"
    },
    "frontmatter": {
      "title": "4.核心原理",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 5,
    "contentParts": 5
  },
  {
    "title": "5.整体架构",
    "path": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "url": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "content": "---\r\ntitle: 5.整体架构\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- NameServer的结构\r\n- Broker的结构\r\n- Netty服务注册框架\r\n- RocketMQ的同步结果推送与异步结果推送\r\n- Broker心跳注册过程\r\n- Producer发送消息过程\r\n- Consumer拉取消息过程\r\n- 文件存储\r\n- 延迟消息\r\n- 长轮询机制\r\n:::\r\n\r\n---\r\n## NameServer的结构\r\n\r\n- NameServer的核心作用\r\n\t- 一是维护Broker的服务地址并进行及时的更新\r\n\t- 二是给Producer和Consumer提供服务获取Broker列表\r\n- NameServer的启动入口为NamesrvStartup类的main方法\r\n- 整个NameServer的核心就是一个NamesrvController对象\r\n\r\n![](static/RocketMQ-整体架构-1.png)\r\n\r\n---\r\n## Broker的结构\r\n\r\n- Broker是整个RocketMQ的业务核心，所有消息存储、转发这些最为重要的业务都是在Broker中进行处理的\r\n- Broker启动的入口在BrokerStartup这个类的main方法\r\n- 重点也是围绕一个BrokerController对象\r\n- 在BrokerStartup.createBrokerController方法中可以看到Broker的几个核心配置\r\n\t- BrokerConfig \r\n\t- NettyServerConfig  ：Netty服务端占用了10911端口。同样也可以在配置文件中覆盖\r\n\t- NettyClientConfig  \r\n\t- MessageStoreConfig\r\n\r\n![](static/RocketMQ-整体架构-2.png)\r\n\r\n---\r\n## Netty服务注册框架\r\n\r\n- RocketMQ使用Netty框架提供了一套基于服务码的服务注册机制，让各种不同的组件都可以按照自己的需求，注册自己的服务方法\r\n- Netty的所有远程通信功能都由remoting模块实现。RemotingServer模块里包含了RPC的服务端RemotingServer以及客户端RemotingClient\r\n- RocketMQ基于Netty保持客户端与服务端的长连接Channel\r\n- 所有的请求都封装成RemotingCommand对象。而每个处理消息的服务逻辑，会封装成一个NettyRequestProcessor对象\r\n- 服务端和客户端都维护了一个processorTable，这是个HashMap，key是服务码requestCode，value是对应的运行单元\r\n\t- Pair<NettyRequestProcessor, ExecutorService>  类型，包含了处理逻辑Prcessor和执行线程池ExecutorService\r\n- 服务端的注册BrokerController.registerProcessor() ，客户端的服务注册见MQClientAPIImpl。NameServer则会注册一个大的DefaultRequestProcessor，统一处理所有的服务\r\n- 服务注册流程：\r\n\r\n![](static/RocketMQ-整体架构-3.png)\r\n\r\n- NameServer会维护Broker的路由列表，并对路由列表进行实时更新\r\n- BrokerController.this.registerBrokerAll方法会发起向NameServer注册心跳。启动时会立即注册，同时也会启动一个线程池，以10秒延迟，默认30秒的间隔持续向NameServer发送心跳\r\n-  BrokerController.this.registerBrokerAll这个方法就是注册心跳的入口\r\n- 然后，在NameServer中也会启动一个定时任务，扫描不活动的Broker。具体观察NamesrvController.initialize方法\r\n\r\n![](static/RocketMQ-整体架构-4.png)\r\n\r\n---\r\n## RocketMQ的同步结果推送与异步结果推送\r\n\r\n- RocketMQ的RemotingServer服务端，会维护一个responseTable，这是一个线程同步的Map结构。 key为请求的ID，value是异步的消息结果 ConcurrentMap<Integer  , ResponseFuture>\r\n- 处理同步请求(NettyRemotingAbstract#invokeSyncImpl)时，处理的结果会存入responseTable，通过ResponseFuture提供一定的服务端异步处理支持，提升服务端的吞吐量。 请求返回后，立即从responseTable中移除请求记录\r\n-  处理异步请求(NettyRemotingAbstract#invokeAsyncImpl)时，处理的结果依然会存入responsTable，等待客户端后续再来请求结果。但是他保存的依然是一个ResponseFuture，也就是在客户端请求结果时再去获取真正的结果\r\n\t- 另外，在RemotingServer启动时，会启动一个定时的线程任务，不断扫描responseTable，将其中过期的response清除掉\r\n\r\n---\r\n## Producer发送消息过程 \r\n\r\n- Producer有两种\r\n\t- 普通发送者：DefaultMQProducer。只负责发送消息，发送完消息，就可以停止了\r\n\t\t- DefaultMQProducer只需要构建一个Netty客户端，往Broker发送消息就行了\r\n\t\t- 异步回调只是在Producer接收到Broker的响应后自行调整流程，不需要提供Netty服务\r\n\t- 事务消息发送者： TransactionMQProducer。支持事务消息机制。需要在事务消息过程中提供事务状态确认的服务，这就要求事务消息发送者虽然是一个客户端，但是也要完成整个事务消息的确认机制后才能退出\r\n\t\t- TransactionMQProducer由于需要在事务消息机制中给Broker提供状态确认服务，所以在发送消息的同时，还需要保持连接，提供服务\r\n\t\t- TransactionMQProducer的启动过程中，会往RemotingClient中注册相应的Processor，这样RemotingServer和RemotingClient之间就可以通过channel进行双向的服务请求了\r\n- 整个Producer的流程，大致分两个步骤\r\n\t- start方法，进行一大堆的准备工作\r\n\t- 各种各样的send方法，进行消息发送\r\n- 重点关注以下几个问题\r\n\t- Producer的核心启动流程以及两种消息发送者的区别\r\n\t\t- 所有Producer的启动过程，最终都会调用DefaultMQProducerImpl#start方法\r\n\t\t\t- 在start方法中的通过一个mQClientFactory对象，启动生产者的一大堆重要服务\r\n\t\t- 所有客户端的启动流程是固定的，不同客户端的区别只是在于他们在启动前注册的一些信息不同\r\n\t\t\t- 生产者注册到producerTable，消费者注册到consumerTable，管理控制端注册到adminExtTable\r\n\t- Producer如何管理Borker路由信息\r\n\t\t- Producer需要拉取Broker列表，然后跟Broker建立连接等等很多核心的流程，其实都是在发送消息时建立的。因为在启动时，还不知道要拉取哪个Topic的Broker列表呢\r\n\t\t- 对NameServer的地址管理，则是散布在启动和发送的多个过程当中，并且NameServer地址可以通过一个Http服务来获取\r\n\t\t- Send方法中，首先需要获得Topic的路由信息。这会从本地缓存中获取，如果本地缓存中没有，就从NameServer中去申请 DefaultMQProducerImpl#tryToFindTopicPublishIn",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.整体架构",
      "lvl1": "NameServer的结构",
      "lvl2": "Broker的结构",
      "lvl3": "Netty服务注册框架",
      "lvl4": "RocketMQ的同步结果推送与异步结果推送",
      "lvl5": "Producer发送消息过程",
      "lvl6": "Consumer拉取消息过程",
      "lvl7": "文件存储",
      "lvl8": "延迟消息",
      "lvl9": "长轮询机制"
    },
    "frontmatter": {
      "title": "5.整体架构",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 3
  },
  {
    "title": "5.整体架构",
    "path": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "url": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "content": "fo 方法\r\n\t\t- ![](static/RocketMQ-整体架构-5.png)\r\n\t- Producer的负载均衡\r\n\t\t- Producer在获取路由信息后，会选出一个MessageQueue去发送消息\r\n\t\t- 这个选MessageQueue的方法就是一个索引自增然后取模的方式\r\n\t\t- 然后根据MessageQueue再找所在的Broker，往Broker发送请求\r\n\t- 在发送Netty请求时，如何制定Broker\r\n\t\t- 实际上是指定的MessageQueue，而不是Topic。Topic只是用来找MessageQueue\r\n\r\n---\r\n## Consumer拉取消息过程 \r\n\r\n- 消费者也是有两种，推模式消费者（用的最多）和拉模式消费者\r\n- 消费者组之间有集群模式和广播模式两种消费模式\r\n- 消费者端的负载均衡的原理。即消费者是如何绑定消费队列的，哪些消费策略到底是如何落地的\r\n- 在推模式的消费者中，MessageListenerConcurrently 和MessageListenerOrderly这两种消息监听器的处理逻辑到底有什么不同，为什么后者能保持消息顺序\r\n-  DefaultMQPushConsumer.start作为入口。最终消费者的启动过程，跟生产者一样，也交由了mQClientFactory\r\n\t- pullMessageService主要处理拉取消息服务；rebalanceService主要处理客户端的负载均衡\r\n- 客户端负载均衡策略\r\n\t- 在消费者示例的start方法中，启动RebalanceService，这个是客户端进行负载均衡策略的启动服务。他只负责根据负载均衡策略获取当前客户端分配到的MessageQueue\r\n\t- 五种负载策略，可以由Consumer的allocateMessageQueueStrategy属性来选择\r\n\t\t- 这个属性可以在DefaultMQPushConsumer的构造方法当中指定。默认是AllocateMessageQueueAveragely策略\r\n\t\t- 最常用的是AllocateMessageQueueAveragely平均分配和AllocateMessageQueueAveragelyByCircle平均轮询分配\r\n\t\t\t- 平均分配是把MessageQueue按组内的消费者个数平均分配\r\n\t\t\t- 平均轮询分配就是把MessageQueue按组内的消费者一个一个轮询分配\r\n- 并发消费与顺序消费的过程\r\n\t- 消费的过程依然是在DefaultMQPushConsumerImpl的 consumeMessageService中\r\n\t- 他有两个子类ConsumeMessageConcurrentlyService和ConsumeMessageOrderlyService\r\n\t- 最主要的差别是ConsumeMessageOrderlyService会在消费前把队列锁起来，优先保证拉取同一个队列里的消息\r\n\t- 消费过程的入口在DefaultMQPushConsumerImpl的pullMessage中定义的PullCallback中\r\n- RocketMQ消息消费方式分别为集群模式、广播模式\r\n- 消息队列负载由RebalanceService线程默认每隔20s进行一次消息队列负载\r\n\t- 根据当前消费者组内消费者个数与主题队列数量按照某一种负载算法进行队列分配\r\n\t- 分配原则为同一个消费者可以分配多个消息消费队列\r\n\t- 同一个消息消费队列同一个时间只会分配给一个消费者\r\n- 消息拉取由PullMessageService线程根据RebalanceService线程创建的拉取任务进行拉取\r\n\t- 默认每次拉取一批消息(可以由业务指定，默认是1)，提交给消费者消费线程后继续下一次消息拉取\r\n\t- 如果消息消费过慢产生消息堆积会触发消息消费拉取流控\r\n- 并发消息消费指消费线程池中的线程可以并发对同一个消息队列的消息进行消费\r\n\t- 消费成功后，取出消息队列中最小的消息偏移量作为消息消费进度偏移量存储在于消息消费进度存储文件中\r\n\t- 集群模式消息消费进度存储在Broker（消息服务器）\r\n\t- 广播模式消息消费进度存储在消费者端\r\n- RocketMQ不支持任意精度的定时调度消息，只支持自定义的消息延迟级别\r\n\t- 可通过在broker配置文件中设置messageDelayLevel\r\n- 顺序消息一般使用集群模式，是指对消息消费者内的线程池中的线程对消息消费队列只能串行消费\r\n\t- 与并发消息消费最本质的区别是消息消费时必须成功锁定消息消费队列\r\n\t- 在Broker端会存储消息消费队列的锁占用情况\r\n- 拉模式核心服务类： PullMessageService\r\n\t- PullRequest里有messageQueue和processQueue，其中messageQueue负责拉取消息，拉取到后，将消息存入processQueue，进行处理。 存入后就可以清空messageQueue，继续拉取了\r\n\t- ![](static/RocketMQ-整体架构-6.png)\r\n\r\n---\r\n## 文件存储\r\n\r\n- Broker接收到消息后是如何把消息进行存储的\r\n- 最终存储的文件\r\n\t- commitLog：消息存储目录\r\n\t- config：运行期间一些配置信息\r\n\t- consumerqueue：消息消费队列存储目录\r\n\t- index：消息索引文件存储目录 \r\n\t- abort：如果存在改文件寿命Broker非正常关闭 \r\n\t- checkpoint：文件检查点，存储CommitLog文件最后一次刷盘时间戳、 consumerquueue最后一次刷盘时间，index索引文件最后一次刷盘时间戳\r\n- messageStore就是负责消息存储的核心组件\r\n- 消息存储的入口在：DefaultMessageStore.putMessage\r\n- commitLog写入\r\n\t- CommitLog的doAppend方法就是Broker写入消息的实际入口\r\n\t- 这个方法最终会把消息追加到MappedFile映射的一块内存里，并没有直接写入磁盘\r\n\t- 写入消息的过程是串行的，一次只会允许一个线程写入\r\n- 分发ConsumeQueue和IndexFile\r\n\t- 当CommitLog写入一条消息后，在DefaultMessageStore的start方法中，会启动一个后台线程reputMessageService每隔1毫秒就会去拉取CommitLog中最新更新的一批消息，然后分别转发到ComsumeQueue和IndexFile里去\r\n\t- 如果服务异常宕机，会造成CommitLog和ConsumeQueue、IndexFile文件不一致，有消息写入CommitLog后，没有分发到索引文件，这样消息就丢失了\r\n\t- DefaultMappedStore的load方法提供了恢复索引文件的方法，入口在load方法\r\n- 文件同步刷盘与异步刷盘：CommitLog.submitFlushRequest\r\n\t- 同步刷盘也是使用异步机制实现的\r\n\t\t- 刷盘是一个很重的操作，所以，RocketMQ即便是同步刷盘，也要对刷盘次数精打细算\r\n\t\t\t- 单条消息，那么直接将commitlog刷盘即可\r\n\t\t\t- 批量消息，RockeMQ会先收集这一批次消息的刷盘请求，再进行一次统一的刷盘操作\r\n\t\t\t- 一",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.整体架构",
      "lvl1": "NameServer的结构",
      "lvl2": "Broker的结构",
      "lvl3": "Netty服务注册框架",
      "lvl4": "RocketMQ的同步结果推送与异步结果推送",
      "lvl5": "Producer发送消息过程",
      "lvl6": "Consumer拉取消息过程",
      "lvl7": "文件存储",
      "lvl8": "延迟消息",
      "lvl9": "长轮询机制"
    },
    "frontmatter": {
      "title": "5.整体架构",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 3
  },
  {
    "title": "5.整体架构",
    "path": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "url": "/docs/architect/rocketmq/RocketMQ-5.zhengtijiagou.html",
    "content": "批消息有可能会跨两个commitlog文件，所以在刷盘时，要严格计算commitlog文件的刷盘次数\r\n\t- 异步刷盘\r\n\t\t- 通过RocketMQ自己实现的一个CountDownLatch2提供了线程阻塞，使用CAS来驱动CountDownLatch2的countDown操作\r\n\t\t- 每来一个消息就启动一次CAS，成功后，调用一次countDown\r\n\t\t- 这个CountDownLatch2在CountDownLatch的基础上，增加实现了reset功能，实现了对象的重用\r\n\t- TransientStorePoolEnable。如果开启了堆外内存，会在启动时申请一个跟CommitLog文件大小一致的堆外内存，这部分内存就可以确保不会被交换到虚拟内存中\r\n- CommigLog主从复制：CommitLog.submitReplicaRequest\r\n\t- RocketMQ整体是基于Netty实现的网络请求，而在主从复制这一块，却放弃了Netty框架，转而使用更轻量级的Java的NIO来构建\r\n\t-  在主要的HAService中，会在启动过程中启动三个守护进程\r\n\t\t- 其中与Master相关的是acceptSocketService和groupTransferService\r\n\t\t\t- acceptSocketService主要负责维护Master与Slave之间的TCP连接\r\n\t\t\t- groupTransferService主要与主从同步复制有关\r\n\t\t- 而slave相关的则是haClient\r\n- 过期文件删除：DefaultMessageStore.addScheduleTask -> DefaultMessageStore.this.cleanFilesPeriodically\r\n\t- Broker会启动后台线程，每60秒，检查CommitLog、ConsumeQueue文件\r\n\t\t- 然后对超过72小时的数据进行删除\r\n\t\t- 默认情况下， RocketMQ只会保存3天内的数据\r\n\t\t- 可以通过fileReservedTime来配置\r\n\t- 他删除时，并不会检查消息是否被消费了\r\n- 整个文件存储的核心入口在DefaultMessageStore的start方法中\r\n\r\n![](static/RocketMQ-整体架构-7.png)\r\n\r\n---\r\n## 延迟消息\r\n\r\n- 延迟消息的核心使用方法就是在Message中设定一个MessageDelayLevel参数，对应18个延迟级别\r\n- 然后Broker中会创建一个默认的Schedule_Topic主题，这个主题下有18个队列，对应18个延迟级别\r\n- 消息发过来之后，会先把消息存入Schedule_Topic主题中对应的队列\r\n\t- 等延迟时间到了，再转发到目标队列，推送给消费者进行消费\r\n- 延迟消息的处理入口在scheduleMessageService， 他会在broker启动时也一起加载\r\n- 消息写入：CommitLog.putMessage\r\n\t- 在CommitLog写入消息时，会判断消息的延迟级别，然后修改Message的Topic和Queue，达到转储Message的目的\r\n- 消息转储到目标Topic：scheduleMessageService\r\n\t- 这个服务只在master节点上启动，而在slave节点上会主动关闭这个服务\r\n\t-  由于RocketMQ的主从节点支持切换，所以就需要考虑这个服务的幂等性\r\n\t\t- 在节点切换为slave时就要关闭服务，切换为master时就要启动服务\r\n\t\t- 即便节点多次切换为master，服务也只启动一次：通过一个CAS操作来保证服务的启动状态\r\n\t\t-  这个CAS操作还保证了在后面，同一时间只有一个DeliverDelayedMessageTimerTask执行\r\n\t- ScheduleMessageService会每隔1秒钟执行一个executeOnTimeup任务，将消息从延迟队列中写入正常Topic中：ScheduleMessageService -> DeliverDelayedMessageTimerTask.executeOnTimeup\r\n\r\n![](static/RocketMQ-整体架构-8.png)\r\n\r\n---\r\n## 长轮询机制\r\n\r\n- RocketMQ对消息消费者提供了Push推模式和Pull拉模式两种消费模式\r\n\t- 但是这两种消费模式的本质其实都是Pull拉模式\r\n\t- Push模式可以认为是一种定时的Pull机制\r\n- 长轮询机制简单来说，就是当Broker接收到Consumer的Pull请求时，判断如果没有对应的消息，不用直接给Consumer响应 (给响应也是个空的，没意义)，而是就将这个Pull请求给缓存起来\r\n\t- 当Producer发送消息过来时，增加一个步骤去检查是否有对应的已缓存的Pull请求，如果有，就及时将请求从缓存中拉取出来，并将消息通知给Consumer\r\n\r\n![](static/RocketMQ-整体架构-9.png)\r\n\r\n---\r\n\r\n![](static/RocketMQ-整体架构-10.png)\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5.整体架构",
      "lvl1": "NameServer的结构",
      "lvl2": "Broker的结构",
      "lvl3": "Netty服务注册框架",
      "lvl4": "RocketMQ的同步结果推送与异步结果推送",
      "lvl5": "Producer发送消息过程",
      "lvl6": "Consumer拉取消息过程",
      "lvl7": "文件存储",
      "lvl8": "延迟消息",
      "lvl9": "长轮询机制"
    },
    "frontmatter": {
      "title": "5.整体架构",
      "date": "2025/07/03"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 3
  },
  {
    "title": "6.常见问题",
    "path": "/docs/architect/rocketmq/RocketMQ-6.changjianwenti.html",
    "url": "/docs/architect/rocketmq/RocketMQ-6.changjianwenti.html",
    "content": "---\r\ntitle: 6.常见问题\r\ndate: 2025/07/03\r\n---\r\n\r\n:::tip\r\n- 消息零丢失\r\n- 消息顺序\r\n- 消息积压\r\n- 消息轨迹\r\n:::\r\n\r\n---\r\n## 消息零丢失\r\n\r\n- 哪些环节会有丢消息的可能\r\n\t- ![](static/RocketMQ-常见问题-1.png)\r\n\t- 1，2，4 三个场景都是跨网络的，而跨网络就肯定会有丢消息的可能\r\n\t- 通常MQ存盘时都会先写入操作系统的缓存page cache中，然后再由操作系统异步的将消息写入硬盘\r\n\t\t- 这个中间有个时间差，就可能会造成消息丢失\r\n\t\t- 如果服务挂了，缓存中还没有来得及写入硬盘的消息就会丢失\r\n- 生产者使用事务消息机制保证消息零丢失\r\n\t- ![事务消息](static/RocketMQ-常见问题-2.png)\r\n\t- half 消息\r\n\t\t- 这个half消息是在订单系统进行下单操作前发送，并且对下游服务的消费者是不可见的\r\n\t\t- 这个消息的作用更多的体现在确认RocketMQ的服务是否正常\r\n\t\t- half 消息如果写入失败了，可以在下单时给订单一个状态标记，然后等待MQ服务正常后再进行补偿操作，等MQ服务正常后重新下单通知下游服务\r\n\t- 订单系统写数据库失败\r\n\t\t- 可以另外找个地方把订单消息先缓存起来\r\n\t\t- 然后给RocketMQ返回一个UNKNOWN状态\r\n\t\t\t- 这样RocketMQ就会过一段时间来回查事务状态\r\n\t\t- 可以在回查事务状态时再尝试把订单数据写入数据库，如果数据库这时候已经恢复了，那就能完整正常的下单，再继续后面的业务\r\n\t- half消息写入成功后RocketMQ挂了\r\n\t\t- 未知状态的事务状态回查是由RocketMQ的Broker主动发起的\r\n\t\t- 等RocketMQ恢复后，只要存储的消息没有丢失，RocketMQ就会再次继续状态回查的流程\r\n\t- 下单成功后如何优雅的等待支付成功\r\n\t\t- 可以用事务消息的状态回查机制来替代定时的任务\r\n\t\t- 在下单时，给Broker返回一个UNKNOWN的未知状态\r\n\t\t- 在状态回查的方法中去查询订单的支付状态\r\n\t\t- 我们只需要配置RocketMQ中的事务消息回查次数(默认15次)和事务回查间隔时间(messageDelayLevel)\r\n\t- 事务消息机制的作用\r\n\t\t- 保证的是订单系统下单和发消息这两个事件的事务一致性\r\n\t\t- 而对下游服务的事务并没有保证\r\n- RocketMQ配置同步刷盘+Dledger主从架构保证MQ主从同步时不会丢消息\r\n\t- 同步刷盘\r\n\t- Dledger的文件同步：基于Raft协议\r\n\t\t- ![Dledger的文件同步](static/RocketMQ-常见问题-3.png)\r\n\t\t- Dledger会通过两阶段提交的方式保证文件在主从之间成功同步\r\n\t\t\t- uncommitted阶段\r\n\t\t\t\t- Leader Broker上的Dledger收到一条数据后，会标记为uncommitted状态\r\n\t\t\t\t- 然后他通过自己的DledgerServer组件把这个uncommitted数据发给Follower Broker的DledgerServer组件\r\n\t\t\t\t- 接着Follower Broker的DledgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的Dledger\r\n\t\t\t- commited阶段\r\n\t\t\t\t- 如果Leader Broker收到超过半数的Follower Broker返回的ack之后，就会把消息标记为committed状态\r\n\t\t\t\t- 再接下来， Leader Broker上的DledgerServer就会发送committed消息给Follower Broker上的DledgerServer\r\n\t\t\t\t- 让他们把消息也标记为committed状态\r\n- 消费者端不要使用异步消费机制\r\n\t- 正常情况下，消费者端都是需要先处理本地事务，然后再给MQ一个ACK响应，这时MQ就会修改Offset，将消息标记为已消费，从而不再往其他消费者推送消息\r\n\t- 所以在Broker的这种重新推送机制下，消息是不会在传输过程中丢失的\r\n\t- 但是如果在开启异步消费线程后，直接返回 `ConsumeConcurrentlyStatus.CONSUME_SUCCESS`\r\n\t\t- 那么一旦消费失败，这个消息就丢失了\r\n- RocketMQ特有的问题，NameServer挂了如何保证消息不丢失\r\n\t- NameServer在RocketMQ中，是扮演的一个路由中心的角色，提供到Broker的路由功能\r\n\t- 集群中任意多的节点挂掉，都不会影响他提供的路由功能\r\n\t- 如果集群中所有的NameServer节点都挂了，生产者和消费者立即就无法工作了\r\n\t\t- RocketMQ相当于整个服务都不可用了，那他本身肯定无法给我们保证消息不丢失了\r\n\t- 降级方案\r\n\t\t- 可以暂存到其他地方，然后起一个线程定时的扫描这些失败的订单消息，尝试往RocketMQ发送\r\n- 这整套的消息零丢失方案，在各个环节都大量的降低了系统的处理性能以及吞吐量\r\n\t- 要根据实际的业务情况来考虑\r\n\t- 在有些对消息可靠性要求没有那么高的场景\r\n\t\t- 在生产者端就可以采用其他一些更简单的方案来提升吞吐\r\n\t\t- 而采用定时对账、补偿的机制来提高消息的可靠性\r\n\r\n---\r\n## 消息顺序\r\n\r\n- 全局有序：整个MQ系统的所有消息严格按照队列先入先出顺序进行消费\r\n\t- 通常意义下，全局有序都可以压缩成局部有序的问题\r\n- 局部有序：只保证一部分关键消息的消费顺序\r\n\t- 在大部分的MQ业务场景，我们只需要能够保证局部有序就可以了\r\n- 通常情况下，发送者发送消息时，会通过MessageQueue轮询的方式保证消息尽量均匀的分布到所有的MessageQueue上，而消费者也就同样需要从多个MessageQueue上消费消息\r\n\t- MessageQueue是RocketMQ存储消息的最小单元，他们之间的消息都是互相隔离的，在这种情况下，是无法保证消息全局有序的\r\n\t\t- 通常所谓的保证Topic全局消息有序的方式，就是将Topic配置成只有一个MessageQueue队列(默认是4个)\r\n\t\t- 对整个Topic的消息吞吐影响是非常大的，如果这样用，基本上就没有用MQ的必要了\r\n\t-  而对于局部有序的要求，只需要将有序的一组消息都存入同一个MessageQueue里，这样MessageQueue的FIFO设计天生就可以保证这一组消息的有序\r\n\t\t- RocketMQ中，可以在发送者发送消息时指定一个MessageSelector对象，让这个对象来决定消息发入哪一个MessageQueue。这样就可以保证一组有序的消息能够发到同一个MessageQueue里\r\n\r\n---\r\n## 消息积压\r\n\r\n- 如何确定RocketMQ有大量的消息积压\r\n\t- 在正常情况下，使用MQ都会要尽量保证他的消息生产速度和消费速度整体上是平衡的\r\n\t- 但是如果部分消费者系统出现故障，就会造成大量的消息积累\r\n\t- 使用web控制台，就能直接看到消息的积压情况\r\n\t- 也可以通过mqadmin指令在后台检查各个Topic的消息延迟情况\r\n\t- RocketMQ也会在他的 ${storePathRootDir}/config目录下落地一系列的json文件，也可以用来跟踪消息积压情况\r\n- 如何处理大量积压的消息\r\n\t- 如果Topic下的MessageQueue配置得是足够多的，那每个Consumer实际上会分配多个MessageQueue来进行消费\r\n\t\t- 可以简单的通过增加Consumer的服务节点数量来加快消息的消费，等积压消息消费完了，再恢复成正常情况\r\n\t\t- 最极限的情况是把Consumer的节点个数设置成跟MessageQueue的个数相同\r\n\t\t\t- 再继续增加Consumer的服务节点就没有用了\r\n\t- 如果Topic下的MessageQueue配置得不够多的话：可以创建一个新的Topic，配置足够多的MessageQueue\r\n\t\t- 然后把所有消费者节点的目标Topic转向新的Topic，并紧急上线一组新的消费者，只负责消费旧Topic中的消息，并转储到新的Topic中，这个速度是可以很快的\r\n\t\t- 然后在新的Topic上，就可以通过增加消费者个数来提高消费速度了。之后再根据情况恢复成正常情况\r\n- 如果RocketMQ原本是采用的普通方式搭建主从架构，而现在想要中途改为使用Dledger高可用集群\r\n\t- 这时候如果不想历史消息丢失，就需要先将消息进行对齐，也就是要消费者把所有的消息都消费完，再来切换主从架构\r\n\t- 因为Dledger集群会接管RocketMQ原有的CommitLog日志，所以切换主从架构时，如果有消息没有消费完，这些消息是存在旧的CommitLog中的，就无法再进行消费了\r\n\t\t- 这个场景下也是需要尽快的处理掉积压的消息\r\n\r\n---\r\n## 消息轨迹\r\n\r\n- `broker.conf -> traceTopicEnable=true`\r\n- 消息轨迹数据存储 \r\n\t- 默认情况下，消息轨迹数据是存于一个系统级别的 Topic (RMQ_SYS_TRACE_TOPIC)\r\n\t\t- 这个Topic在Broker节点启动时，会自动创建出来\r\n\t\t- 也支持客户端自定义轨迹数据存储的 Topic\r\n- 在客户端的两个核心对象 DefaultMQProducer 和 DefaultMQPushConsumer 的构造函数中，都有两个可选的参数来打开消息轨迹存储\r\n\t- enableMsgTrace：是否打开消息轨迹。默认是false\r\n\t- customizedTraceTopic：配置将消息轨迹数据存储到用户指定的Topic\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "6.常见问题",
      "lvl1": "消息零丢失",
      "lvl2": "消息顺序",
      "lvl3": "消息积压",
      "lvl4": "消息轨迹"
    },
    "frontmatter": {
      "title": "6.常见问题",
      "date": "2025/07/03"
    },
    "type": "content"
  },
  {
    "title": "2025-03",
    "path": "/docs/diary/2025/2025-03.html",
    "url": "/docs/diary/2025/2025-03.html",
    "content": "---\r\ntitle: 2025-03\r\npassword: b593bf97f44387eb6fdc629acef2d138\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## 2025-03-08\r\n\r\n- 优化博客站点\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2025-03",
      "lvl1": "2025-03-08"
    },
    "frontmatter": {
      "title": "2025-03",
      "password": "b593bf97f44387eb6fdc629acef2d138",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "边缘填充算法",
    "path": "/docs/it/jisuanjituxingxue/bianyuantianchongsuanfa.html",
    "url": "/docs/it/jisuanjituxingxue/bianyuantianchongsuanfa.html",
    "content": "---\r\ntitle: 边缘填充算法\r\ndate: 2025/03/08\r\n---\r\n\r\n## 填充原理\r\n边缘填充算法是先求出多边形的每条边与扫描线的交点，然后**将交点右侧的所有像素颜色全部取为补色（或反色**）。按任意顺序处理完多边形的所有边后，就完成了多边形的填充任务。边缘填充算法利用了图像处理中的求“补”或求“反”的概念，对于黑白图像，求补就是把RGB(1,1,1)（白色）的像素置为RGB(0,0,0)（黑色），反之亦然；对于彩色图像，求补就是将背景色置为填充色，反之亦然。求补的一条基本性质是**一个像素求补两次就恢复为原色**。**如果多边形内部的像素被求补偶数次，保持原色，如果被求补奇数次，显示填充色。**\r\n\r\n## 填充过程\r\n假定边的顺序为E0、E1、E2、E3、E4、E5和E6。这里，边的顺序并不影响填充结果，只是方便编写循环结构而已。\r\n\r\n\r\n![边缘填充算法](static/边缘填充算法.png)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "边缘填充算法",
      "lvl1": "填充原理",
      "lvl2": "填充过程"
    },
    "frontmatter": {
      "title": "边缘填充算法",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "期权交易策略",
    "path": "/docs/trader/options/qiquanjiaoyicelue.html",
    "url": "/docs/trader/options/qiquanjiaoyicelue.html",
    "content": "---\r\ntitle: 期权交易策略\r\ndate: 2025/03/06\r\n---\r\n\r\n## 单向策略\r\n\r\n::: tip\r\n|评估|Long Call|Long Put|Short Call|Short Put|\r\n|-|-|-|-|-|\r\n|预期|上涨|下跌|微涨/不变|微跌/不变/有买入意愿|\r\n|场景|看涨|看跌|赚权利金|赚权利金/低价买入|\r\n|权利|按行权价买入|按行权价卖出|-|-|\r\n|义务|-|-|按行权价卖出|按行权价买入|\r\n|成本|权利金|权利金|保证金|保证金|\r\n|收益|涨幅 - 权利金|跌幅 - 权利金|权利金 - (市价 - 行权价)|权利金 - (行权价 - 市价)|\r\n|亏损|损失权利金|损失权利金|越涨越亏|越跌越亏 （最低为0）|\r\n|风险|风险低；收益无限|风险低；收益高|风险无限；收益低|风险高；收益低|\r\n\r\n::: danger\r\n1. 卖方的最大成本取决于市场的波动性，虽然表格中用“保证金”表示，但实际计算中，卖方承担的亏损可能远超保证金。\r\n:::\r\n\r\n\r\n- 买入看涨期权：Long Call\r\n  - 预期：标的资产价格将上涨\r\n  - 权利：买方有权利在期权到期时按行权价买入标的资产，但没有义务。\r\n  - 成本：买方需要支付权利金。\r\n  - 收益：潜在收益是无限的（标的资产价格上涨越多，收益越大）。\r\n  - 风险：风险有限，最大损失是支付的权利金。\r\n- 买入看跌期权：Long Put\r\n  - 预期：标的资产价格将下跌\r\n  - 权利：买方有权利在期权到期时按行权价卖出标的资产，但没有义务。\r\n  - 成本：买方需要支付权利金。\r\n  - 收益：潜在收益有限，但标的资产价格跌得越多，收益越大（最低价格为0）。\r\n  - 风险：风险有限，最大损失是支付的权利金。\r\n- 卖出看涨期权：Short Call\r\n  - 预期：标的资产价格不会上涨太多或保持不变\r\n  - 义务：卖方有义务按行权价卖出标的资产给买方（如果买方行权）。\r\n  - 收益：收益有限，最大收益是收到的权利金。\r\n  - 风险：风险无限（标的资产价格上涨越多，卖方亏损越大）。\r\n- 卖出看跌期权：Short Put\r\n  - 预期：标的资产价格不会大幅下跌或保持不变\r\n  - 义务：卖方有义务按行权价买入标的资产（如果买方行权）。\r\n  - 收益：收益有限，最大收益是收到的权利金。\r\n  - 风险：风险很高（标的资产价格下跌越多，卖方亏损越大，但跌幅有限，最低为0）。\r\n\r\n\r\n## 价差策略\r\n\r\n::: tip\r\n|评估|Bull Spread|Bear Spread|\r\n|-|-|-|\r\n|预期|温和上涨|温和下跌|\r\n|场景|在看涨市场中降低成本|在看跌市场中降低成本|\r\n|收益|行权价差 - 净权利金|行权价差 - 净权利金|\r\n|成本|净权利金|净权利金|\r\n|亏损|净权利金|净权利金|\r\n|风险|风险低；收益低|风险低；收益低|\r\n|构成|买入较低行权价的看涨期权 <br/> 卖出较高行权价的看涨期权|买入较高行权价的看跌期权 <br/> 卖出较低行权价的看跌期权|\r\n\r\n::: info\r\n1. 如果标的价格超出价格区间以外，那么期权的权利与义务会互相抵消，所以限制了最大收益，同时也限制了最大亏损\r\n2. Bull Spread 和 Bear Spread 都是低风险、低收益的策略，适合温和的市场走势，而非剧烈波动\r\n:::\r\n\r\n- 牛市价差：Bull Spread\r\n  - 预期：适用于看涨市场，收益和风险都有限\r\n  - 构成：\r\n    - 买入较低行权价的看涨期权（成本较高）\r\n    - 卖出较高行权价的看涨期权（获得权利金）\r\n  - 收益风险：\r\n    - 最大收益：两行权价差 - 净支出\r\n    - 最大亏损：净支出（买入权利金 - 卖出权利金）\r\n- 熊市价差：Bear Spread\r\n  - 预期：适用于看跌市场，收益和风险都有限\r\n  - 构成：\r\n    - 买入较高行权价的看跌期权（成本较高）\r\n    - 卖出较低行权价的看跌期权（获得权利金）\r\n  - 收益风险：\r\n    - 最大收益：两行权价差 - 净支出\r\n    - 最大亏损：净支出（买入权利金 - 卖出权利金）\r\n\r\n\r\n### 跨式策略\r\n\r\n::: tip\r\n|评估|Long Straddle|Long Strangle|Short Straddle|Short Strangle|\r\n|-|-|-|-|-|\r\n|预期|大幅波动|大幅波动|||\r\n|场景|重大事件前|重大事件前|||\r\n|收益|波幅 - 净权利金|波幅 - 净权利金|||\r\n|成本|净权利金|净权利金|||\r\n|亏损|净权利金|净权利金|||\r\n|风险|风险低；收益高|风险低；收益高；成本低|||\r\n|构成|买入相同行权价的看涨期权 <br/> 买入相同行权价的看跌期权|买入较高行权价的看涨期权 <br/> 买入较低行权价的看跌期权|||\r\n:::\r\n\r\n\r\n\r\n\r\n### 复杂价差策略\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "期权交易策略",
      "lvl1": "单向策略",
      "lvl2": "价差策略"
    },
    "frontmatter": {
      "title": "期权交易策略",
      "date": "2025/03/06"
    },
    "type": "content"
  },
  {
    "title": "期权交易策略收益图表",
    "path": "/docs/trader/options/qiquanjiaoyicelueshouyitubiao.html",
    "url": "/docs/trader/options/qiquanjiaoyicelueshouyitubiao.html",
    "content": "---\r\ntitle: 期权交易策略收益图表\r\ndate: 2025/03/08\r\n---\r\n\r\n<iframe src=\"/html/OptionsStrategy.html\" style=\"width:100%; height: 1000px\"></iframe>\r\n\r\n<a href=\"/html/OptionsStrategy.html\" target=\"_blank\">全屏展示</a>\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "期权交易策略收益图表"
    },
    "frontmatter": {
      "title": "期权交易策略收益图表",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "实盘日记 - 2025 年",
    "path": "/docs/trading_journal/diary/2025.html",
    "url": "/docs/trading_journal/diary/2025.html",
    "content": "---\r\ntitle: 实盘日记 - 2025 年\r\ndate: 2025/03/19\r\n---\r\n\r\n## 2025/3/19 TQQQ CALL\r\n\r\n:::info\r\n- 策略类型：看涨期权（短期反弹博弈）\r\n- 期权类型：买入TQQQ Call期权\r\n- 行权价：61-62美元附近\r\n- 到期日：2-4周\r\n- 仓位：500美元以内\r\n- 止盈目标：EMA20（68美元附近）\r\n- 止损位：57美元以下\r\n\r\n|情境|股价目标|期权预估价值|盈亏金额|盈亏百分比|\r\n|-|-|-|-|-|\r\n|止盈|68美元|约6.2美元|盈利740美元|+148%|\t\t\t\t\r\n|止损|57美元|约0.8美元|亏损340美元|-68%|\r\n\r\n盈亏比大于2，属于较好的盈亏比\r\n:::\r\n\r\n预计收益计算（止盈情境）：假设未来1-2周内TQQQ上涨到EMA20附近（约68美元）\r\n- 行权价：62美元\r\n- 股价上涨到：68美元\r\n- 期权的内在价值 = 股票价格 – 行权价格 = 68 – 62 = 6美元\r\n- 期权买入成本：2.5美元/张\r\n- 期权到期时预估的价值：6美元（内在价值）+ 0.2美元左右的时间价值估计（由于临近到期，时间价值不多）= 约6.2美元\r\n- 每张期权盈利 = 6.2美元 - 2.5美元 = 3.7美元\r\n- 2张期权总盈利 = 3.7美元 × 2张 × 100股 = 740美元\r\n\r\n止盈情境下的收益率：\r\n- 总盈利 = 740美元\r\n- 总成本 = 500美元\r\n- 净利润 = 740美元\r\n- 盈利比例 = (740 ÷ 500) × 100% = 148%\r\n\r\n预计亏损计算（止损情境）：假设未来几天内TQQQ下跌到57美元以下\r\n- 行权价：62美元（看涨期权）\r\n- 跌破支撑位到57美元甚至更低，此时期权变为深度价外，价值快速缩水。\r\n- 假设跌破57美元时，看涨期权的价值大幅缩水到0.8美元左右（甚至更低），此时及时止损：\r\n- 每张期权亏损 = 买入成本 - 期权剩余价值 = 2.5美元 - 0.8美元 = 1.7美元\r\n- 2张期权总亏损 = 1.7美元 × 2张 × 100股 = 340美元\r\n\r\n止损情境下的亏损率：\r\n- 总亏损 = 340美元\r\n- 总成本 = 500美元\r\n- 亏损比例 = (340 ÷ 500) × 100% = 68%\r\n\r\n盈亏比评估：盈亏比大于2，属于较好的盈亏比\r\n- 盈利情境预期盈利 = 740美元\r\n- 亏损情境预期亏损 = 340美元\r\n- 盈亏比 = 740 ÷ 340 ≈ 2.18\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "实盘日记 - 2025 年",
      "lvl1": "2025/3/19 TQQQ CALL"
    },
    "frontmatter": {
      "title": "实盘日记 - 2025 年",
      "date": "2025/03/19"
    },
    "type": "content"
  }
]