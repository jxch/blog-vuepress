[
  {
    "title": "Java 根据 Getter 方法获取字段及注解值",
    "path": "/blogs/bianmabiji/JavagenjuGetterfangfahuoquziduanjizhujiezhi.html",
    "url": "/blogs/bianmabiji/JavagenjuGetterfangfahuoquziduanjizhujiezhi.html",
    "content": "---\r\ntitle: Java 根据 Getter 方法获取字段及注解值\r\ndate: 2025/04/12\r\ntags:\r\n - Java\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```java\r\n@FunctionalInterface\r\npublic interface SIFunction<T, R> extends Function<T, R>, Serializable {}\r\n```\r\n\r\n```java\r\npublic class FieldUtil {\r\n\r\n    public static <T, R> String getFieldNameByGetter(SIFunction<T, R> func) {\r\n        try {\r\n            SerializedLambda serializedLambda = getSerializedLambda(func);\r\n            String getterMethodName = serializedLambda.getImplMethodName();\r\n            return methodToFieldName(getterMethodName);\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(\"获取字段名失败\", e);\r\n        }\r\n    }\r\n\r\n    private static SerializedLambda getSerializedLambda(Serializable lambda) throws Exception {\r\n        // 通过反射调用writeReplace方法获取SerializedLambda\r\n        Method writeReplace = lambda.getClass().getDeclaredMethod(\"writeReplace\");\r\n        writeReplace.setAccessible(true);\r\n        return (SerializedLambda) writeReplace.invoke(lambda);\r\n    }\r\n\r\n    private static String methodToFieldName(String getterMethodName) {\r\n        String fieldName;\r\n        if (getterMethodName.startsWith(\"get\")) {\r\n            fieldName = getterMethodName.substring(3);\r\n        } else if (getterMethodName.startsWith(\"is\")) {\r\n            fieldName = getterMethodName.substring(2);\r\n        } else {\r\n            throw new IllegalArgumentException(\"无效的getter方法名称: \" + getterMethodName);\r\n        }\r\n        // 将首字母转小写\r\n        return fieldName.substring(0, 1).toLowerCase(Locale.ROOT) + fieldName.substring(1);\r\n    }\r\n\r\n    public static <T, R> Field getFieldByGetter(SIFunction<T, R> getter, Class<T> clazz) {\r\n        try {\r\n            return clazz.getDeclaredField(getFieldNameByGetter(getter));\r\n        } catch (NoSuchFieldException e) {\r\n            throw new RuntimeException(\"字段不存在\", e);\r\n        }\r\n    }\r\n\r\n    public static <T, R, A extends Annotation> String getAnnotationValueByGetter(SIFunction<T, R> getter, Class<T> clazz, Class<A> annotationClass) {\r\n        try {\r\n            // 获取字段名\r\n            String fieldName = getFieldNameByGetter(getter);\r\n\r\n            // 获取字段对象\r\n            Field field = clazz.getDeclaredField(fieldName);\r\n\r\n            // 获取字段上的注解\r\n            A annotation = field.getAnnotation(annotationClass);\r\n\r\n            // 如果注解存在，返回其 value 属性值\r\n            if (annotation != null) {\r\n                // 使用反射获取注解的 value 属性值\r\n                Method valueMethod = annotationClass.getMethod(\"value\");\r\n                return (String) valueMethod.invoke(annotation);\r\n            } else {\r\n                throw new RuntimeException(\"字段没有指定的注解: \" + fieldName);\r\n            }\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(\"获取注解值失败\", e);\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Java 根据 Getter 方法获取字段及注解值"
    },
    "frontmatter": {
      "title": "Java 根据 Getter 方法获取字段及注解值",
      "date": "2025/04/12",
      "tags": [
        "Java"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Java 获取接口泛型类型",
    "path": "/blogs/bianmabiji/Javahuoqujiekoufanxingleixing.html",
    "url": "/blogs/bianmabiji/Javahuoqujiekoufanxingleixing.html",
    "content": "---\r\ntitle: Java 获取接口泛型类型\r\ndate: 2025/04/12\r\ntags:\r\n - Java\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```java\r\n    @SuppressWarnings(\"unchecked\")\r\n    public Class<S> getTypeClass() {\r\n        Class<?> clazz = this.getClass();\r\n        Type result = InterfaceUtils.findParameterizedType(clazz, ProjectTypeServiceGetter.class);\r\n        if (result != null) {\r\n            ParameterizedType pt = (ParameterizedType) result;\r\n            // 获取第一个泛型参数，它对应 S\r\n            Type sType = pt.getActualTypeArguments()[0];\r\n            if (sType instanceof Class) {\r\n                return (Class<S>) sType;\r\n            } else if (sType instanceof ParameterizedType) {\r\n                // 处理嵌套泛型情况\r\n                return (Class<S>) ((ParameterizedType) sType).getRawType();\r\n            }\r\n        }\r\n        throw new IllegalStateException(\"无法获取泛型类型 S 的 Class 对象\");\r\n    }\r\n```\r\n\r\n\r\n```java\r\npublic class InterfaceUtils {\r\n\r\n    /**\r\n     * 获取指定类实现的所有接口，包括父类实现的接口以及接口之间的继承关系。\r\n     *\r\n     * @param clazz 要查找接口的类\r\n     * @return 包含所有接口的集合\r\n     */\r\n    public static Set<Class<?>> getAllInterfaces(Class<?> clazz) {\r\n        Set<Class<?>> interfaces = new HashSet<>();\r\n        // 遍历类的继承层次结构\r\n        while (clazz != null) {\r\n            // 获取当前类直接实现的接口\r\n            Class<?>[] directInterfaces = clazz.getInterfaces();\r\n            for (Class<?> intf : directInterfaces) {\r\n                collectInterfaces(intf, interfaces);\r\n            }\r\n            clazz = clazz.getSuperclass();\r\n        }\r\n        return interfaces;\r\n    }\r\n\r\n    /**\r\n     * 递归地将接口及其扩展的接口加入到集合中。\r\n     *\r\n     * @param intf       当前的接口\r\n     * @param interfaces 用来保存所有接口的集合\r\n     */\r\n    private static void collectInterfaces(Class<?> intf, Set<Class<?>> interfaces) {\r\n        if (interfaces.add(intf)) {\r\n            // 获取接口可能扩展的其他接口\r\n            for (Class<?> superInterface : intf.getInterfaces()) {\r\n                collectInterfaces(superInterface, interfaces);\r\n            }\r\n        }\r\n    }\r\n\r\n    public static Type findParameterizedType(Type clazz, Class<?> targetType) {\r\n        if (clazz instanceof ParameterizedType) {\r\n            ParameterizedType pt = (ParameterizedType) clazz;\r\n            // 如果直接匹配目标接口\r\n            if (targetType.equals(pt.getRawType())) {\r\n                return pt;\r\n            }\r\n            // 检查该参数化类型的原始类型的接口\r\n            return findParameterizedType(pt.getRawType(), targetType);\r\n        } else if (clazz instanceof Class) {\r\n            Class<?> currentClass = (Class<?>) clazz;\r\n\r\n            // 检查当前类所有直接实现的接口\r\n            for (Type intf : currentClass.getGenericInterfaces()) {\r\n                Type result = findParameterizedType(intf, targetType);\r\n                if (result != null) {\r\n                    return result;\r\n                }\r\n            }\r\n            // 检查父类\r\n            Type superClass = currentClass.getGenericSuperclass();\r\n            if (superClass != null) {\r\n                return findParameterizedType(superClass, targetType);\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Java 获取接口泛型类型"
    },
    "frontmatter": {
      "title": "Java 获取接口泛型类型",
      "date": "2025/04/12",
      "tags": [
        "Java"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "MAVEN 上传到中心仓库",
    "path": "/blogs/bianmabiji/MAVENshangchuandaozhongxincangku.html",
    "url": "/blogs/bianmabiji/MAVENshangchuandaozhongxincangku.html",
    "content": "---\r\ntitle: MAVEN 上传到中心仓库\r\ndate: 2025/03/05\r\ntags:\r\n - MAVEN\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n1. 注册中心仓库账户：[central.sonatype.com](https://central.sonatype.com)\r\n2. 使用 GPG 生成密钥并上传到公钥服务器\r\n3. 配置 Maven 的 Setting.xml 文件\r\n4. pom.xml 文件模板\r\n5. 发布到中心仓库\r\n:::\r\n\r\n## 注册中心仓库账户 \r\n\r\n1. 注册中心仓库的账户：[central.sonatype.com](https://central.sonatype.com)\r\n2. 使用 Github 登录，可以自动获得命名空间 -> 有效的 groupId\r\n3. Generate User Token  ->  自动生成 maven setting.xml 的 server 配置项（修改 id 为 central）\r\n\r\n## GPG\r\n\r\n```powershell\r\n# 安装GPG\r\nwinget install GnuPG.Gpg4win\r\n\r\n# 生成密钥\r\ngpg --full-generate-key\r\n\r\n# 上传公钥到GPG公钥服务器\r\ngpg --keyserver pgp.mit.edu --send-keys <KEY_ID>\r\ngpg --keyserver keyserver.ubuntu.com --send-keys <KEY_ID>\r\n\r\n# 导出公钥\r\ngpg --armor --export <KEY_ID> > public_key_1.asc\r\n# 导出私钥\r\ngpg --armor --export-secret-keys <KEY_ID> > private_key_2.asc\r\n```\r\n\r\n## Maven Setting.xml\r\n\r\n```xml\r\n\t<servers>\r\n\t\t<server>\r\n\t\t\t<id>central</id>\r\n\t\t\t<username>${username}</username>\r\n\t\t\t<password>${token}</password>\r\n\t\t</server>\r\n    </servers>\r\n\r\n\t<profiles>\r\n\t\t<profile>\r\n\t\t\t<id>gpg-profile</id>\r\n\t\t\t<properties>\r\n\t\t\t\t<gpg.keyname> ${KEY_ID} </gpg.keyname>\r\n\t\t\t\t<gpg.passphrase><![CDATA[password]]></gpg.passphrase>\r\n\t\t\t</properties>\r\n\t\t</profile>\r\n\t</profiles>\r\n\t<activeProfiles>\r\n\t\t<activeProfile>gpg-profile</activeProfile>\r\n\t</activeProfiles>\r\n```\r\n\r\n## pom.xml\r\n\r\n```xml\r\n    <groupId>io.github.jxch</groupId>\r\n    <artifactId>capital-py4j-spring-boot-starter</artifactId>\r\n    <version>3.2.5-alpha.1</version>\r\n    <name>capital-py4j-spring-boot-starter</name>\r\n    <description>py4j本地执行引擎与springboot的无缝集成</description>\r\n    <url>https://github.com/jxch-capital/capital-py4j-spring-boot-starter</url>\r\n\r\n    <properties>\r\n        <maven.compiler.source>21</maven.compiler.source>\r\n        <maven.compiler.target>21</maven.compiler.target>\r\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\r\n        <lombok.version>1.18.32</lombok.version>\r\n        <hutool.version>5.8.27</hutool.version>\r\n        <maven-source-plugin.version>3.3.1</maven-source-plugin.version>\r\n        <maven-javadoc-plugin.version>3.6.3</maven-javadoc-plugin.version>\r\n        <maven-gpg-plugin.version>3.2.4</maven-gpg-plugin.version>\r\n        <maven-release-plugin.version>3.0.1</maven-release-plugin.version>\r\n        <central-publishing-maven-plugin.version>0.4.0</central-publishing-maven-plugin.version>\r\n    </properties>\r\n\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-source-plugin</artifactId>\r\n                <version>${maven-source-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>attach-sources</id>\r\n                        <goals>\r\n                            <goal>jar-no-fork</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-javadoc-plugin</artifactId>\r\n                <version>${maven-javadoc-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>attach-javadocs</id>\r\n                        <goals>\r\n                            <goal>jar</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.sonatype.central</groupId>\r\n                <artifactId>central-publishing-maven-plugin</artifactId>\r\n                <version>${central-publishing-maven-plugin.version}</version>\r\n                <extensions>true</extensions>\r\n                <configuration>\r\n                    <publishingServerId>central</publishingServerId>\r\n                    <tokenAuth>true</tokenAuth>\r\n                    <autoPublish>true</autoPublish>\r\n                    <waitUntil>published</waitUntil>\r\n                </configuration>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-release-plugin</artifactId>\r\n                <version>${maven-release-plugin.version}</version>\r\n                <configuration>\r\n                    <goals>deploy nexus-staging:release</goals>\r\n                    <autoVersionSubmodules>true</autoVersionSubmodules>\r\n                    <useReleaseProfile>false</useReleaseProfile>\r\n                    <releaseProfiles>release</releaseProfiles>\r\n                </configuration>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-gpg-plugin</artifactId>\r\n                <version>${maven-gpg-plugin.version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <id>sign-artifacts</id>\r\n                        <phase>verify</phase>\r\n                        <goals>\r\n                            <goal>sign</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n\r\n    <licenses>\r\n        <license>\r\n            <name>The Apache Software License, Version 2.0</name>\r\n            <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>\r\n            <distribution>repo</distribution>\r\n        </license>\r\n    </licenses>\r\n\r\n    <scm>\r\n        <connection>scm:git:git://github.com/jxch-capital/capital-py4j-spring-boot-starter.git</connection>\r\n        <developerConnection>scm:git:ssh://github.com:jxch-capital/capital-py4j-spring-boot-starter.git</developerConnection>\r\n        <url>${developer_github_project_url}</url>\r\n    </scm>\r\n\r\n    <developers>\r\n        <developer>\r\n            <id>${developer_id}</id>\r\n            <name>${developer_name}</name>\r\n            <email>${developer_email}</email>\r\n            <url>${developer_github_url}</url>\r\n        </developer>\r\n    </developers>\r\n\r\n    <distributionManagement>\r\n        <snapshotRepository>\r\n            <id>central</id>\r\n            <url>https://s01.oss.sonatype.org/content/repositories/snapshots</url>\r\n        </snapshotRepository>\r\n        <repository>\r\n            <id>central</id>\r\n            <url>https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/</url>\r\n        </repository>\r\n    </distributionManagement>\r\n```\r\n\r\n## 发布\r\n\r\n```shell\r\nmvn deploy -f pom.xml\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MAVEN 上传到中心仓库",
      "lvl1": "注册中心仓库账户",
      "lvl2": "GPG",
      "lvl3": "Maven Setting.xml",
      "lvl4": "pom.xml",
      "lvl5": "发布"
    },
    "frontmatter": {
      "title": "MAVEN 上传到中心仓库",
      "date": "2025/03/05",
      "tags": [
        "MAVEN"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 实现 Chrome 环境隔离的多开方案",
    "path": "/blogs/bianmabiji/PowerShellshixianChromehuanjinggelideduokaifangan.html",
    "url": "/blogs/bianmabiji/PowerShellshixianChromehuanjinggelideduokaifangan.html",
    "content": "---\r\ntitle: PowerShell 实现 Chrome 环境隔离的多开方案\r\ndate: 2025/07/01\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n- 下载地址：[https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/chromej.ps1](https://raw.githubusercontent.com/jxch/shell/refs/heads/main/powershell/chromej.ps1)\r\n:::\r\n\r\n使用示例：\r\n```powershell\r\n    chromej.ps1 1 2 --disable-web-security --incognito\r\n        # 启动/多开 1、2 两个 profile，并传递原生参数\r\n\r\n    chromej.ps1 dev -a -u \"https://example.com\" --disable-gpu\r\n        # 激活已开的 dev profile，或未开则以指定网址和参数新开\r\n\r\n    chromej.ps1 1 -Delete -y\r\n        # 强制删除 1 号 profile 目录，无需确认\r\n\r\n    chromej.ps1 --disable-software-rasterizer -sc\r\n        # 启动 Chrome 并显示完整命令行\r\n\r\n    chromej.ps1 -s\r\n        # 静默启动 Chrome 本体\r\n\r\n    chromej.ps1 1 2 3 -Activate -ShowCmd -Silent\r\n        # 激活/多开 1、2、3，命令行输出，静默执行\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 实现 Chrome 环境隔离的多开方案"
    },
    "frontmatter": {
      "title": "PowerShell 实现 Chrome 环境隔离的多开方案",
      "date": "2025/07/01",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 目录栈",
    "path": "/blogs/bianmabiji/PowerShellmuluzhan.html",
    "url": "/blogs/bianmabiji/PowerShellmuluzhan.html",
    "content": "---\r\ntitle: PowerShell 目录栈\r\ndate: 2025/04/23\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n如果只是在脚本里临时切换目录，使用 `Push-Location / Pop-Location` 更优雅\r\n:::\r\n\r\n```powershell\r\ntry {\r\n    Push-Location path/to/dir\r\n    # todo ...\r\n}\r\nfinally {\r\n    Pop-Location\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 目录栈"
    },
    "frontmatter": {
      "title": "PowerShell 目录栈",
      "date": "2025/04/23",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "PowerShell 设置定时任务",
    "path": "/blogs/bianmabiji/PowerShellshezhidingshirenwu.html",
    "url": "/blogs/bianmabiji/PowerShellshezhidingshirenwu.html",
    "content": "---\r\ntitle: PowerShell 设置定时任务\r\ndate: 2025/03/05\r\ntags:\r\n - PowerShell\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n1. 注册任务\r\n2. 注销任务\r\n\r\n---\r\n\r\n[使用VBS保持PS脚本的静默执行](./VBS静默执行PS脚本.md)\r\n:::\r\n\r\n\r\n## 注册任务\r\n\r\n```powershell\r\n# 使用vbs脚本的好处是可以保持静默执行\r\n$Action = New-ScheduledTaskAction -Execute \"wscript.exe\" -Argument \"D:\\personal-folder\\app\\powershell\\wallpaper-kline.vbs\"\r\n\r\n# 设置开机执行一次\r\n$Trigger1 = New-ScheduledTaskTrigger -AtStartup\r\n# 设置每小时执行一次\r\n$Trigger2 = New-ScheduledTaskTrigger -Once -At (Get-Date).Date -RepetitionInterval (New-TimeSpan -Hours 1)\r\n\r\n# 注册任务\r\n$Settings = New-ScheduledTaskSettingsSet -AllowStartIfOnBatteries -DontStopIfGoingOnBatteries -StartWhenAvailable -RunOnlyIfNetworkAvailable\r\nRegister-ScheduledTask -Action $Action -Trigger $Trigger1,$Trigger2 -TaskName \"wallpaper-kline-task\" -Description \"wallpaper-kline.vbs\"  -Settings $Settings\r\n```\r\n\r\n## 注销任务\r\n\r\n```powershell\r\nUnregister-ScheduledTask -TaskName \"wallpaper-kline-task\" -Confirm:$false\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "PowerShell 设置定时任务",
      "lvl1": "注册任务",
      "lvl2": "注销任务"
    },
    "frontmatter": {
      "title": "PowerShell 设置定时任务",
      "date": "2025/03/05",
      "tags": [
        "PowerShell"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Python 导出最简项目依赖",
    "path": "/blogs/bianmabiji/PYdaochuzuijianxiangmuyilai.html",
    "url": "/blogs/bianmabiji/PYdaochuzuijianxiangmuyilai.html",
    "content": "---\r\ntitle: Python 导出最简项目依赖\r\ndate: 2025/03/05\r\ntags:\r\n - Python\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n::: tip\r\n使用 `pipreqs` 导出项目依赖\r\n:::\r\n\r\n## 导出依赖\r\n\r\n```shell\r\n# 安装 pipreqs\r\npip install pipreqs\r\n\r\n# 导出项目依赖到 requirements.txt\r\npipreqs ./ --encoding=utf-8\r\n\r\n# 覆盖 requirements.txt\r\npipreqs ./ --encoding=utf-8 --force\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Python 导出最简项目依赖",
      "lvl1": "导出依赖"
    },
    "frontmatter": {
      "title": "Python 导出最简项目依赖",
      "date": "2025/03/05",
      "tags": [
        "Python"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "shlink 部署及 openfeign 调用",
    "path": "/blogs/bianmabiji/shlinkbushujiopenfeigndiaoyong.html",
    "url": "/blogs/bianmabiji/shlinkbushujiopenfeigndiaoyong.html",
    "content": "---\r\ntitle: shlink 部署及 openfeign 调用\r\ndate: 2025/04/16\r\ntags:\r\n - shlink\r\n - openfeign\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## shlink 部署\r\n\r\n```yml\r\nservices:\r\n  shlink:\r\n    image: shlinkio/shlink:latest\r\n    ports:\r\n      - \"28881:8080\"\r\n    environment:\r\n      - SHLINK_SHORT_CODES_LENGTH=5\r\n      - INITIAL_API_KEY=cda4282f-27a5-4a93-bb8a-47234309628f\r\n      - DB_DRIVER=mysql\r\n      - DB_HOST=mysql_host\r\n      - DB_PORT=3306\r\n      - DB_NAME=shlink\r\n      - DB_USER=shlink\r\n      - DB_PASSWORD=662caa92-1f0e-40f5-9656-2147c76a4f73\r\n```\r\n\r\n## openfeign\r\n\r\n```java\r\n@FeignClient(name = CloudName.SHLINK, path = \"/rest/v3\",\r\n        fallbackFactory = ShlinkClientFallbackFactory.class,\r\n        configuration = ShlinkHeaderConfig.class)\r\npublic interface ShlinkClient {\r\n    @PostMapping(\"/short-urls\")\r\n    ShortUrlRes shortUrls(@RequestBody ShortUrlParam param);\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Builder\r\n@NoArgsConstructor\r\n@AllArgsConstructor\r\n@Accessors(chain = true)\r\npublic class ShortUrlParam {\r\n    private String longUrl;\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Builder\r\n@NoArgsConstructor\r\n@AllArgsConstructor\r\n@Accessors(chain = true)\r\npublic class ShortUrlRes {\r\n    private String shortUrl;\r\n    private String shortCode;\r\n    private String longUrl;\r\n    @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ssXXX\")\r\n    private Date dateCreated;\r\n    private String domain;\r\n    private String title;\r\n    private Boolean crawlable;\r\n    private Boolean forwardQuery;\r\n    private Boolean hasRedirectRules;\r\n}\r\n```\r\n\r\n```java\r\n@RequiredArgsConstructor\r\npublic class ShlinkHeaderConfig {\r\n    private final ShlinkConfig shlinkConfig;\r\n    @Bean\r\n    public RequestInterceptor requestInterceptor() {\r\n        return requestTemplate -> requestTemplate.header(\"X-Api-Key\", shlinkConfig.getApiKey());\r\n    }\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConfigurationProperties(prefix = \"app.shlink\")\r\npublic class ShlinkConfig {\r\n    private String apiKey;\r\n}\r\n```\r\n\r\n```yml\r\napp:\r\n  shlink:\r\n    api-key: cda4282f-27a5-4a93-bb8a-47234309628f\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "shlink 部署及 openfeign 调用",
      "lvl1": "shlink 部署",
      "lvl2": "openfeign"
    },
    "frontmatter": {
      "title": "shlink 部署及 openfeign 调用",
      "date": "2025/04/16",
      "tags": [
        "shlink",
        "openfeign"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 Starter 自定义环境变量",
    "path": "/blogs/bianmabiji/SpringBoot2Starterzidingyihuanjingbianliang.html",
    "url": "/blogs/bianmabiji/SpringBoot2Starterzidingyihuanjingbianliang.html",
    "content": "---\r\ntitle: SpringBoot2 Starter 自定义环境变量\r\ndate: 2025/04/12\r\ntags:\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n```\r\nMETA-INF\r\n  - application-referenced.yml\r\n  - spring.factories\r\n```\r\n\r\nspring.factories\r\n```prop\r\norg.springframework.boot.env.EnvironmentPostProcessor=package.path.CommonEnvironmentPostProcessor\r\n```\r\n\r\n```java\r\npublic class CommonEnvironmentPostProcessor implements EnvironmentPostProcessor {\r\n    private static final String PROPERTY_SOURCE_NAME = CommonEnvironmentPostProcessor.class.getSimpleName();\r\n\r\n    @Override\r\n    public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) {\r\n        YamlPropertySourceLoader loader = new YamlPropertySourceLoader();\r\n        Resource resource = new ClassPathResource(\"META-INF/application-referenced.yml\");\r\n\r\n        if (resource.exists()) {\r\n            try {\r\n                PropertySource<?> yamlProps = loader.load(PROPERTY_SOURCE_NAME, resource).get(0);\r\n                environment.getPropertySources().addLast(yamlProps);  // 注意：使用 `.addLast()`，确保主项目配置优先\r\n            } catch (IOException e) {\r\n                throw new IllegalStateException(\"Failed to load YAML file: \" + resource.getFilename(), e);\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 Starter 自定义环境变量"
    },
    "frontmatter": {
      "title": "SpringBoot2 Starter 自定义环境变量",
      "date": "2025/04/12",
      "tags": [
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 实现 SpringCache 集成多个 CacheManager",
    "path": "/blogs/bianmabiji/SpringBoot2shixianSpringCachejichengduogeCacheManager.html",
    "url": "/blogs/bianmabiji/SpringBoot2shixianSpringCachejichengduogeCacheManager.html",
    "content": "---\r\ntitle: SpringBoot2 实现 SpringCache 集成多个 CacheManager\r\ndate: 2025/04/29\r\ntags:\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n- 通过 `CachingConfigurerSupport` 指定全局默认的主 `CacheManager`\r\n- `@Cacheable` 等 SpringCache 注解可以通过 `cacheManager` 属性指定自定义的 `CacheManager`\r\n:::\r\n\r\n```java\r\n@Configuration\r\n@EnableCaching\r\npublic class CacheConfig extends CachingConfigurerSupport {\r\n    private final CacheManager cacheManager;\r\n\r\n    public CacheConfig(@Qualifier(RedisCacheConfig.REDIS_CACHE_NAME) CacheManager cacheManager) {\r\n        this.cacheManager = cacheManager;\r\n    }\r\n\r\n    @Override\r\n    public CacheManager cacheManager() {\r\n        return cacheManager;\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConditionalOnClass(name = \"com.github.benmanes.caffeine.cache.Caffeine\")\r\npublic class LocalCacheConfig {\r\n    public static final String LOCAL_CACHE_MANAGER = \"caffeineCacheManager\";\r\n    @Value(\"${app.cache.ttl-seconds:3600}\")\r\n    private Long ttlSeconds;\r\n    @Value(\"${app.cache.maximum:5000}\")\r\n    private Integer maximum;\r\n\r\n    @Bean(LOCAL_CACHE_MANAGER)\r\n    public CaffeineCacheManager caffeineCacheManager() {\r\n        CaffeineCacheManager cacheManager = new CaffeineCacheManager();\r\n        cacheManager.setCaffeine(Caffeine.newBuilder()\r\n                .expireAfterWrite(ttlSeconds, TimeUnit.SECONDS)\r\n                .maximumSize(maximum));\r\n        return cacheManager;\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n@Data\r\n@Configuration\r\n@ConditionalOnClass(name = \"org.springframework.data.redis.cache.RedisCacheManager\")\r\npublic class RedisCacheConfig {\r\n    public static final String REDIS_CACHE_NAME = \"cacheManager\";\r\n    @Value(\"${app.cache.ttl-seconds:3600}\")\r\n    private Long ttlSeconds;\r\n\r\n    @Bean\r\n    @ConditionalOnMissingBean(RedisCacheConfiguration.class)\r\n    public RedisCacheConfiguration redisCacheConfiguration() {\r\n        return RedisCacheConfiguration.defaultCacheConfig()\r\n                .entryTtl(Duration.ofSeconds(ttlSeconds))\r\n                .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()))\r\n                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));\r\n    }\r\n\r\n    @Primary\r\n    @Bean(REDIS_CACHE_NAME)\r\n    public CacheManager cacheManager(RedisConnectionFactory connectionFactory, RedisCacheConfiguration config) {\r\n        return RedisCacheManager.builder(connectionFactory)\r\n                .cacheDefaults(config)\r\n                .build();\r\n    }\r\n\r\n}\r\n```\r\n\r\n```yml\r\napp:\r\n  cache:\r\n    ttl-seconds: 3600\r\n    maximum: 5000\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 实现 SpringCache 集成多个 CacheManager"
    },
    "frontmatter": {
      "title": "SpringBoot2 实现 SpringCache 集成多个 CacheManager",
      "date": "2025/04/29",
      "tags": [
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
    "path": "/blogs/bianmabiji/SpringBoot2jichengZipkinheSleuthshixianlianluzhuizong.html",
    "url": "/blogs/bianmabiji/SpringBoot2jichengZipkinheSleuthshixianlianluzhuizong.html",
    "content": "---\r\ntitle: SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪\r\ndate: 2025/04/22\r\ntags:\r\n - SpringBoot\r\n - Zipkin\r\n - Sleuth\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>2.7.9</version>\r\n        <relativePath/>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-sleuth</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-sleuth-zipkin</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-openfeign</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-loadbalancer</artifactId>\r\n        </dependency>\r\n```\r\n\r\n## 配置\r\n\r\n:::tip\r\n- 关闭 sleuth 组件自动注入的链路日志信息：`spring.sleuth.default-logging-pattern-enabled: false`\r\n- logback 自定义链路日志：`%X{traceId:-} %X{spanId:-}`\r\n- logback 中自定义的默认就可以上传到 ELK，而 sleuth 默认输出的则默认上传不到 ELK\r\n- ELK 搭建见：[ELK 部署](../运维手册/ELK部署.md)\r\n:::\r\n\r\n```yml\r\nspring:\r\n  sleuth:\r\n    default-logging-pattern-enabled: false\r\n    jdbc:\r\n      datasource-proxy:\r\n        query:\r\n          enable-logging: true\r\n        slow-query:\r\n          enable-logging: true\r\n      p6spy:\r\n        enable-logging: true\r\n    sampler:\r\n      probability: 1.0\r\n      rate: 100\r\n  zipkin:\r\n    base-url: http://zipkin:port\r\n    sender:\r\n      type: web\r\n```\r\n\r\n## 标签\r\n\r\n:::info\r\n- 多环境公用一个Zipkin的时候，可以使用打标签的方式进行环境隔离\r\n- Zipkin 查询语句：`tagQuery=env=dev`\r\n:::\r\n\r\n```java\r\n@Configuration\r\npublic class ZipkinTracingConfig {\r\n    @Value(\"${spring.profiles.active:unknown}\")  // 读取当前环境\r\n    private String activeProfile;\r\n\r\n    @Bean\r\n    public SpanHandler spanHandler() {\r\n        return new SpanHandler() {\r\n            @Override\r\n            public boolean end(TraceContext context, MutableSpan span, Cause cause) {\r\n                span.tag(\"env\", activeProfile); // 给 Zipkin 添加环境信息\r\n                return true;\r\n            }\r\n        };\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
      "lvl1": "依赖",
      "lvl2": "配置",
      "lvl3": "标签"
    },
    "frontmatter": {
      "title": "SpringBoot2 集成 Zipkin 和 Sleuth 实现链路追踪",
      "date": "2025/04/22",
      "tags": [
        "SpringBoot",
        "Zipkin",
        "Sleuth"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot3 集成 GraalVM 云原生",
    "path": "/blogs/bianmabiji/SpringBoot3jichengGraalVMyunyuansheng.html",
    "url": "/blogs/bianmabiji/SpringBoot3jichengGraalVMyunyuansheng.html",
    "content": "---\r\ntitle: SpringBoot3 集成 GraalVM 云原生\r\ndate: 2025/04/18\r\ntags:\r\n - GraalVM\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n:::info\r\nSpringBoot 版本必须在 3.4.4 之上\r\n:::\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>3.4.4</version>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n    <build>\r\n        <finalName>image-name</finalName>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.graalvm.buildtools</groupId>\r\n                <artifactId>native-maven-plugin</artifactId>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n                <version>3.4.4</version>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 构建发布\r\n\r\n```shell\r\nmvn clean -Pnative spring-boot:build-image -f pom.xml\r\ndocker tag image-name:{version} jxch/image-name:latest\r\ndocker push jxch/image-name:latest\r\n```\r\n\r\n## 兼容性\r\n\r\n### 反射声明配置\r\n\r\n需要声明哪些类被反射过（尤其是被JSON序列化的类）\r\n\r\n```java\r\n@Configuration\r\n@RegisterReflectionForBinding({\r\n        CPunchCardNormal.class, CPunchCardState.class, UserConfig.class, User.class\r\n})\r\npublic class NativeReflectionConfig {\r\n}\r\n```\r\n\r\n### 静态资源声明配置\r\n\r\n声明用到了哪些 resources 目录下的静态资源文件\r\n\r\n```java\r\n@Configuration\r\n@ImportRuntimeHints(NativeRuntimeHints.class)\r\npublic class NativeRuntimeHints implements RuntimeHintsRegistrar {\r\n    @Override\r\n    public void registerHints(RuntimeHints hints, ClassLoader classLoader) {\r\n        hints.resources().registerPattern(\"xxx.json\");\r\n    }\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot3 集成 GraalVM 云原生",
      "lvl1": "依赖",
      "lvl2": "构建发布",
      "lvl3": "兼容性"
    },
    "frontmatter": {
      "title": "SpringBoot3 集成 GraalVM 云原生",
      "date": "2025/04/18",
      "tags": [
        "GraalVM",
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 Dockerfile 健康检查",
    "path": "/blogs/bianmabiji/SpringBootjichengDockerfilejiankangjiancha.html",
    "url": "/blogs/bianmabiji/SpringBootjichengDockerfilejiankangjiancha.html",
    "content": "---\r\ntitle: SpringBoot 集成 Dockerfile 健康检查\r\ndate: 2025/04/23\r\ntags:\r\n - Docker\r\n - SpringBoot\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n:::info\r\n健康检查成功后，容器才视为启动成功，包括 docker swarm 的 update 也是这样，可以利用这个特性实现集群的不停机更新\r\n:::\r\n\r\n## HEALTHCHECK\r\n\r\n```dockerfile\r\nENV ACTUATOR_PORT=13011\r\nENV ACTUATOR_USER=admin\r\nENV ACTUATOR_PASS=123456\r\n\r\nHEALTHCHECK --interval=30s --timeout=10s --start-period=300s CMD curl -f -u $ACTUATOR_USER:$ACTUATOR_PASS http://127.0.0.1:$ACTUATOR_PORT/actuator/health || exit 1\r\n\r\nENTRYPOINT [...]\r\n```\r\n\r\n## 依赖\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-actuator</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-security</artifactId>\r\n        </dependency>\r\n```\r\n\r\n## 配置\r\n\r\n```yml\r\nmanagement:\r\n  server:\r\n    port: 13011\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: '*'\r\n\r\nspring:\r\n  security:\r\n    user:\r\n      name: admin\r\n      password: 123456\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 Dockerfile 健康检查",
      "lvl1": "HEALTHCHECK",
      "lvl2": "依赖",
      "lvl3": "配置"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 Dockerfile 健康检查",
      "date": "2025/04/23",
      "tags": [
        "Docker",
        "SpringBoot"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
    "path": "/blogs/bianmabiji/VaadinjichengSpringBoot3jiGraalVMyunyuansheng.html",
    "url": "/blogs/bianmabiji/VaadinjichengSpringBoot3jiGraalVMyunyuansheng.html",
    "content": "---\r\ntitle: Vaadin 集成 SpringBoot3 及 GraalVM 云原生\r\ndate: 2025/04/18\r\ntags:\r\n - GraalVM\r\n - SpringBoot\r\n - Vaadin\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 依赖\r\n\r\n:::info\r\n- SpringBoot 版本必须在 3.4.4 之上\r\n- Vaadin 版本必须在 24.7.2 之上\r\n:::\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>3.4.4</version>\r\n    </parent>\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.vaadin</groupId>\r\n            <artifactId>vaadin-spring-boot-starter</artifactId>\r\n            <version>24.7.2</version>\r\n        </dependency>\r\n```\r\n\r\n```xml\r\n    <build>\r\n        <finalName>image-name</finalName>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.graalvm.buildtools</groupId>\r\n                <artifactId>native-maven-plugin</artifactId>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n                <version>3.4.4</version>\r\n            </plugin>\r\n            <plugin>\r\n                <groupId>com.vaadin</groupId>\r\n                <artifactId>vaadin-maven-plugin</artifactId>\r\n                <version>24.7.2</version>\r\n                <executions>\r\n                    <execution>\r\n                        <goals>\r\n                            <goal>prepare-frontend</goal>\r\n                            <goal>build-frontend</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 兼容性\r\n\r\n:::info\r\nVaadin 组件中用到过的所有类都必须声明反射\r\n\r\n其他兼容性（静态资源、反射等）参见 [SpringBoot3集成GraalVM云原生](./SpringBoot3集成GraalVM云原生.md)\r\n:::\r\n\r\n## view\r\n\r\n```java\r\n@Route(\"clock\")\r\npublic class ClockView extends VerticalLayout {\r\n    public ClockView(){\r\n        // todo 在构造方法中编写这个页面（可以通过构造方法参数直接注入 SpringBean）\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
      "lvl1": "依赖",
      "lvl2": "兼容性",
      "lvl3": "view"
    },
    "frontmatter": {
      "title": "Vaadin 集成 SpringBoot3 及 GraalVM 云原生",
      "date": "2025/04/18",
      "tags": [
        "GraalVM",
        "SpringBoot",
        "Vaadin"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "VBS 静默执行 PowerShell 脚本",
    "path": "/blogs/bianmabiji/VBSjingmozhixingPSjiaoben.html",
    "url": "/blogs/bianmabiji/VBSjingmozhixingPSjiaoben.html",
    "content": "---\r\ntitle: VBS 静默执行 PowerShell 脚本\r\ndate: 2025/03/05\r\ntags:\r\n - VBS\r\ncategories:\r\n - 编码笔记\r\n---\r\n\r\n## 创建 VBS 脚本\r\n\r\n```powershell\r\nSet WshShell = CreateObject(\"WScript.Shell\")\r\nWshShell.Run \"powershell.exe -WindowStyle Hidden -File D:\\personal-folder\\app\\powershell\\wallpaper-kline.ps1\", 0\r\nSet WshShell = Nothing\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "VBS 静默执行 PowerShell 脚本",
      "lvl1": "创建 VBS 脚本"
    },
    "frontmatter": {
      "title": "VBS 静默执行 PowerShell 脚本",
      "date": "2025/03/05",
      "tags": [
        "VBS"
      ],
      "categories": [
        "编码笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "AMD 架构上运行 ARM 架构的 Docker 容器",
    "path": "/blogs/yunweishouce/AMDjiagoushangyunxingARMjiagoudeDockerrongqi.html",
    "url": "/blogs/yunweishouce/AMDjiagoushangyunxingARMjiagoudeDockerrongqi.html",
    "content": "---\r\ntitle: AMD 架构上运行 ARM 架构的 Docker 容器\r\ndate: 2025/05/06\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n安装 QEMU binfmt 支持：\r\n```bash\r\ndocker run --privileged --rm tonistiigi/binfmt --install all\r\n```\r\n\r\n测试：\r\n```bash\r\ndocker run --rm --platform linux/arm64/v8 arm64v8/alpine uname -m\r\n```\r\n\r\n:::tip\r\n- QEMU 是一个开源的硬件虚拟化工具，可以在 x86_64 主机上模拟 ARM64（aarch64）环境，从而让 Docker 能“假装”自己是 ARM 机器，运行 ARM 容器镜像。\r\n- QEMU 虚拟化会大大降低运行速度（比真实 ARM 机子慢很多），只适合测试和编译。\r\n- 某些复杂场景（如需内核特性、特殊指令集等）可能不完全兼容。\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "AMD 架构上运行 ARM 架构的 Docker 容器"
    },
    "frontmatter": {
      "title": "AMD 架构上运行 ARM 架构的 Docker 容器",
      "date": "2025/05/06",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Cloudflared 防 DNS 污染",
    "path": "/blogs/yunweishouce/CloudflaredfangDNSwuran.html",
    "url": "/blogs/yunweishouce/CloudflaredfangDNSwuran.html",
    "content": "---\r\ntitle: Cloudflared 防 DNS 污染\r\ndate: 2025/06/29\r\ntags:\r\n - DNS\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n- 下载：[https://github.com/cloudflare/cloudflared/releases](https://github.com/cloudflare/cloudflared/releases)\r\n- 启动命令：`cloudflared proxy-dns`\r\n- win11 安装：`winget install Cloudflare.cloudflared`，然后把 `C:\\Program Files (x86)\\cloudflared` 设进环境变量 path\r\n- win11 开机自启\r\n  - NSSM方式参考：[WIN使用NSSM管理Service](./WIN使用NSSM管理Service.md)\r\n  - VBS方式：\r\n    - 启动脚本参考：[VBS静默执行PS脚本](../编码笔记/VBS静默执行PS脚本.md)\r\n    - 脚本放入 `win + r` 输入 `shell:startup` 回车后出现的文件夹中\r\n:::\r\n\r\n## 以 Ubuntu - arm64 为例\r\n\r\n### 安装\r\n```shell\r\n# 下载\r\nwget https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-arm64.deb\r\n\r\n# 安装\r\ndpkg -i cloudflared-linux-arm64.deb\r\n\r\n# 启动\r\ncloudflared proxy-dns\r\n```\r\n\r\n### 部署\r\n设为 service\r\n```shell\r\n# 查看路径\r\nwhich cloudflared\r\n# 编辑配置文件\r\nvi /etc/systemd/system/cloudflared-proxy-dns.service\r\n# 启动 service\r\nsystemctl daemon-reload\r\nsystemctl enable --now cloudflared-proxy-dns\r\nsystemctl status cloudflared-proxy-dns\r\n```\r\n\r\n`cloudflared-proxy-dns.service` 配置文件：\r\n\r\n```shell \r\n[Unit]\r\nDescription=cloudflared DNS over HTTPS Proxy\r\nAfter=network.target\r\n\r\n[Service]\r\nType=simple\r\nUser=nobody\r\nCapabilityBoundingSet=CAP_NET_BIND_SERVICE\r\nAmbientCapabilities=CAP_NET_BIND_SERVICE\r\nExecStart=/usr/local/bin/cloudflared proxy-dns\r\nRestart=on-failure\r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Cloudflared 防 DNS 污染",
      "lvl1": "以 Ubuntu - arm64 为例"
    },
    "frontmatter": {
      "title": "Cloudflared 防 DNS 污染",
      "date": "2025/06/29",
      "tags": [
        "DNS"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "dnsmasq 部署",
    "path": "/blogs/yunweishouce/dnsmasqbushu.html",
    "url": "/blogs/yunweishouce/dnsmasqbushu.html",
    "content": "---\r\ntitle: dnsmasq 部署\r\ndate: 2025/03/05\r\ntags:\r\n - dnsmasq\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n1. 使用 docker 部署，docker-compose.yml 文件\r\n2. 配置文件，dnsmasq.conf 文件\r\n:::\r\n\r\n## docker-compose.yml\r\n\r\n```yml\r\nservices:\r\n  dns-server:\r\n    image: jpillora/dnsmasq\r\n    container_name: dns-server\r\n    restart: unless-stopped\r\n    environment:\r\n      - TZ=Asia/Shanghai\r\n      - HTTP_USER=username\r\n      - HTTP_PASS=password\r\n    ports:\r\n      - \"53:53/udp\"\r\n      - \"5380:8080\"\r\n    volumes:\r\n      - \"./dns/dnsmasq.conf:/etc/dnsmasq.conf\"\r\n```\r\n\r\n## dnsmasq.conf\r\n\r\n```shell\r\n# 服务器上游DNS服务器地址\r\nresolv-file=/etc/resolv.conf\r\n# 默认缓存条数150，这里增加到1000\r\ncache-size=1000\r\n# 重启后清空缓存\r\nclear-on-reload\r\n\r\n# DNS 服务器\r\nserver=8.8.4.4\r\nserver=8.8.8.8\r\nserver=4.2.2.1\r\nserver=4.2.2.2\r\nserver=114.114.114.114\r\n\r\n# 自定义域名\r\naddress=/example.com/192.168.1.10\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "dnsmasq 部署",
      "lvl1": "docker-compose.yml",
      "lvl2": "dnsmasq.conf"
    },
    "frontmatter": {
      "title": "dnsmasq 部署",
      "date": "2025/03/05",
      "tags": [
        "dnsmasq"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker Registry2 镜像仓库清理",
    "path": "/blogs/yunweishouce/DockerRegistry2jingxiangcangkuqingli.html",
    "url": "/blogs/yunweishouce/DockerRegistry2jingxiangcangkuqingli.html",
    "content": "---\r\ntitle: Docker Registry2 镜像仓库清理\r\ndate: 2025/04/23\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::info\r\n1. 必须在配置文件中允许删除镜像：`/etc/docker/registry/config.yml`\r\n2. 手动删除镜像：`/var/lib/registry/docker/registry/v2/repositories/`\r\n3. 清理镜像：`registry garbage-collect /etc/docker/registry/config.yml`\r\n:::\r\n\r\n```yml\r\n# /etc/docker/registry/config.yml\r\nstorage:\r\n  delete:\r\n    enabled: true\r\n```\r\n\r\n```bash\r\ncd /var/lib/registry/docker/registry/v2/repositories/\r\nrm -rf ./<要删除的镜像>\r\n\r\nregistry garbage-collect /etc/docker/registry/config.yml\r\n```\r\n\r\n```bash\r\n# 检查清理效果\r\ndf -h\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker Registry2 镜像仓库清理"
    },
    "frontmatter": {
      "title": "Docker Registry2 镜像仓库清理",
      "date": "2025/04/23",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker Swarm 将服务部署到指定标签的节点上",
    "path": "/blogs/yunweishouce/DockerSwarmjiangfuwubushudaozhidingbiaoqiandejiedianshang.html",
    "url": "/blogs/yunweishouce/DockerSwarmjiangfuwubushudaozhidingbiaoqiandejiedianshang.html",
    "content": "---\r\ntitle: Docker Swarm 将服务部署到指定标签的节点上\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip \r\n1. 给节点打标签\r\n2. 给服务加约束\r\n:::\r\n\r\n```shell\r\n# 给节点打标签\r\ndocker node update --label-add memory=high NODE_ID\r\n\r\n# 给服务添加约束，他就会自动调度到特定标签的节点上\r\ndocker service update --constraint-add 'node.labels.memory == high' SERVICE_ID\r\n```\r\n\r\n```shell\r\n# 查看节点上的标签\r\ndocker node inspect <node_id> --format '{{json .Spec.Labels}}'\r\n```\r\n\r\n```shell\r\n# 使该节点不接受任务调度，但是仍然可以通过该节点的端口访问集群中的服务\r\ndocker node update --availability drain <node_id>\r\n```\r\n\r\n```yml\r\nservices:\r\n  app:\r\n    image: app-images\r\n    deploy:\r\n      placement:\r\n        constraints:\r\n          - node.labels.memory == high\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker Swarm 将服务部署到指定标签的节点上"
    },
    "frontmatter": {
      "title": "Docker Swarm 将服务部署到指定标签的节点上",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker 容器启动时提示内存太小",
    "path": "/blogs/yunweishouce/Dockerrongqiqidongshitishinacuntaixiao.html",
    "url": "/blogs/yunweishouce/Dockerrongqiqidongshitishinacuntaixiao.html",
    "content": "---\r\ntitle: Docker 容器启动时提示内存太小\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: danger 类似的报错信息\r\n`Maximum number of memory map areas per process (vm.max_map_count) 262144 is too low, recommended value: 1048575, you can change it with sysctl.`\r\n:::\r\n\r\n## 解决方案\r\n\r\n:::: code-group\r\n::: code-group-item LINUX\r\n```bash\r\nsysctl -w vm.max_map_count=1048575\r\n```\r\n:::\r\n::: code-group-item WINDOWS\r\n```powershell\r\nwsl -d docker-desktop sh -c \"sysctl -w vm.max_map_count=1048575\"\r\n```\r\n:::\r\n::::\r\n\r\n::: info \r\n1. 提示应该设置多少就设置多少\r\n2. 然后重启docker服务即可\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker 容器启动时提示内存太小",
      "lvl1": "解决方案"
    },
    "frontmatter": {
      "title": "Docker 容器启动时提示内存太小",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Docker 清理",
    "path": "/blogs/yunweishouce/Dockerqingli.html",
    "url": "/blogs/yunweishouce/Dockerqingli.html",
    "content": "---\r\ntitle: Docker 清理\r\ndate: 2025/03/05\r\ntags:\r\n - Docker\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n通常可以直接使用 `docker system prune --all -f` 命令进行深度清理并且无需手动确认\r\n:::\r\n\r\n|命令|作用|\r\n|-|-|\r\n|`docker container prune`|容器清理|\r\n|`docker image prune`|镜像清理|\r\n|`docker volume prune`|数据卷清理|\r\n|`docker builder prune`|缓存清理|\r\n|`docker system prune`|一键清理|\r\n|`docker system prune -a`|深度清理|\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Docker 清理"
    },
    "frontmatter": {
      "title": "Docker 清理",
      "date": "2025/03/05",
      "tags": [
        "Docker"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "ELK 部署",
    "path": "/blogs/yunweishouce/ELKbushu.html",
    "url": "/blogs/yunweishouce/ELKbushu.html",
    "content": "---\r\ntitle: ELK 部署\r\ndate: 2025/04/16\r\ntags:\r\n - elasticsearch\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## docker-compose.yml\r\n\r\n```yml\r\nservices:\r\n  elasticsearch: \r\n    image: elasticsearch:8.16.1\r\n    restart: always\r\n    environment:\r\n      - discovery.type=single-node \r\n      - xpack.security.enabled=true\r\n    volumes:\r\n      - /mnt/nexus3/es_data:/usr/share/elasticsearch/data \r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  kibana: \r\n    image: kibana:8.16.1 \r\n    ports:\r\n      - \"12563:5601\"\r\n    environment:\r\n      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\r\n      - XPACK_SECURITY_ENABLED=true\r\n      - ELASTICSEARCH_USERNAME=kibana_system\r\n      - ELASTICSEARCH_PASSWORD=\"3UGDvTkAmzhprC5*9PUw\"\r\n    depends_on:\r\n      - elasticsearch\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  zipkin:\r\n    image: bitnami/zipkin:3\r\n    ports:\r\n      - \"12411:9411\"\r\n    environment:\r\n      - STORAGE_TYPE=elasticsearch\r\n      - ES_HOSTS=elasticsearch:9200\r\n      - ES_USERNAME=elastic\r\n      - ES_PASSWORD=rC4hG9mR9DUC109=DeS8\r\n    depends_on:\r\n      - elasticsearch\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n  logstash:\r\n    image: bitnami/logstash:8.17.0\r\n    ports: \r\n      - \"5044:8080\"\r\n    volumes:\r\n      - ./logstash.conf:/opt/bitnami/logstash/pipeline/logstash.conf\r\n    logging:\r\n      driver: \"json-file\"\r\n      options:\r\n        max-size: \"50m\"\r\n        max-file: \"3\"\r\n```\r\n\r\n## logstash.conf\r\n\r\n```config\r\ninput {\r\n  tcp {\r\n    port => 8080 \r\n    codec => json_lines \r\n  }\r\n}\r\n\r\n\r\noutput {\r\n  elasticsearch {\r\n    hosts => [\"http://elasticsearch:9200\"] \r\n    user => \"elastic\"\r\n    password => \"rC4hG9mR9DUC109=DeS8\"\r\n    index => \"logs-%{+YYYY.MM.dd}\"\r\n    ssl => false \r\n  }\r\n}\r\n```\r\n\r\n## 设置密码\r\n\r\n```bash\r\n# 进入 elasticsearch 容器内部\r\ndocker exec -it <elasticsearch> sh\r\n\r\n# 设置超级用户的密码，此用户名密码可以用在logstash、zipkin和kibana web ui的登录上\r\nbin/elasticsearch-reset-password -u elastic\r\n\r\n# 设置kibana用户的密码，此用户专用于kibana容器与elasticsearch容器的交互\r\nbin/elasticsearch-reset-password -u kibana_system\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "ELK 部署",
      "lvl1": "docker-compose.yml",
      "lvl2": "logstash.conf",
      "lvl3": "设置密码"
    },
    "frontmatter": {
      "title": "ELK 部署",
      "date": "2025/04/16",
      "tags": [
        "elasticsearch"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "HAProxy TCP 端口代理",
    "path": "/blogs/yunweishouce/HAProxy-TCPduankoudaili.html",
    "url": "/blogs/yunweishouce/HAProxy-TCPduankoudaili.html",
    "content": "---\r\ntitle: HAProxy TCP 端口代理\r\ndate: 2025/07/02\r\ntags:\r\n - proxy\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n\r\n## docker-compose.yml\r\n```yml\r\nversion: '3.8'\r\nservices: \r\n  haproxy: \r\n    image: haproxy:lts-alpine\r\n    privileged: true\r\n    ports:\r\n      - 1080:1080\r\n      - 3306:3306\r\n    volumes: \r\n      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg\r\n```\r\n\r\n## haproxy.cfg\r\n```properties\r\ndefaults\r\n    mode            tcp\r\n    log             global\r\n    option          tcplog\r\n    option          dontlognull\r\n    option http-server-close\r\n    option          redispatch\r\n    retries         3\r\n    timeout http-request 10s\r\n    timeout queue   1m\r\n    timeout connect 10s\r\n    timeout client  1m\r\n    timeout server  1m\r\n    timeout http-keep-alive 10s\r\n    timeout check   10s\r\n    maxconn         3000\r\nfrontend    mysql\r\n    bind        0.0.0.0:3306\r\n    mode        tcp\r\n    log         global\r\n    default_backend mysql_server\r\nbackend     mysql_server\r\n    balance roundrobin\r\n    server capital_mysql qbh.jiangxicheng.xyz:3306 check inter 5s rise 2 fall 3\r\nlisten stats\r\n    mode    http\r\n    bind    0.0.0.0:1080\r\n    stats   enable\r\n    stats   hide-version\r\n    stats uri /haproxyamdin?stats\r\n    stats realm Haproxy\\ Statistics\r\n    stats auth admin:admin\r\n    stats admin if TRUE\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "HAProxy TCP 端口代理",
      "lvl1": "docker-compose.yml",
      "lvl2": "haproxy.cfg"
    },
    "frontmatter": {
      "title": "HAProxy TCP 端口代理",
      "date": "2025/07/02",
      "tags": [
        "proxy"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "hexo 下载内部文件",
    "path": "/blogs/yunweishouce/hexo-xiazainabuwenjian.html",
    "url": "/blogs/yunweishouce/hexo-xiazainabuwenjian.html",
    "content": "---\r\ntitle: hexo 下载内部文件\r\ndate: 2025/07/02\r\ntags:\r\n - hexo\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n1. `_config.yml` 文件内修改属性 `post_asset_folder: true`\r\n2. 在 `source` 文件夹内创建下载目录 `download`\r\n3. 下载链接：`[xxxxxx](/download/xxxxxx)`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "hexo 下载内部文件"
    },
    "frontmatter": {
      "title": "hexo 下载内部文件",
      "date": "2025/07/02",
      "tags": [
        "hexo"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Jumpserver 部署",
    "path": "/blogs/yunweishouce/Jumpserverbushu.html",
    "url": "/blogs/yunweishouce/Jumpserverbushu.html",
    "content": "---\r\ntitle: Jumpserver 部署\r\ndate: 2025/06/16\r\ntags:\r\n - Jumpserver\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## docker compose\r\n\r\n```yml\r\nservices:\r\n  jumpserver: \r\n    image: jumpserver/jms_all\r\n    restart: unless-stopped\r\n    user: root\r\n    privileged: true\r\n    ports:\r\n      - \"10880:80\"\r\n    environment:\r\n      SECRET_KEY: \"uuid\"\r\n      BOOTSTRAP_TOKEN: \"uuid\"\r\n      LOG_LEVEL: \"ERROR\"\r\n      DB_ENGINE: mysql\r\n      DB_HOST: \"\"\r\n      DB_PORT: \"3306\"\r\n      DB_USER: \"root\"\r\n      DB_PASSWORD: \"\"\r\n      DB_NAME: \"jumpserver\"\r\n      REDIS_HOST: \"\"\r\n      REDIS_PORT: \"\"\r\n      REDIS_PASSWORD: \"\"\r\n      DOMAINS: host:port\r\n    volumes:\r\n      - /mnt/nexus3/jumpserver:/opt/jumpserver/data\r\n```\r\n\r\n:::tip\r\n- [Docker Hub - Jumpserver/jms_all](https://hub.docker.com/r/jumpserver/jms_all)\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Jumpserver 部署",
      "lvl1": "docker compose"
    },
    "frontmatter": {
      "title": "Jumpserver 部署",
      "date": "2025/06/16",
      "tags": [
        "Jumpserver"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 关闭 iptables 防火墙",
    "path": "/blogs/yunweishouce/Linuxguanbiiptablesfanghuoqiang.html",
    "url": "/blogs/yunweishouce/Linuxguanbiiptablesfanghuoqiang.html",
    "content": "---\r\ntitle: Linux 关闭 iptables 防火墙\r\ndate: 2025/03/11\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 允许所有流量\r\n\r\n```shell\r\niptables -P FORWARD ACCEPT \r\niptables -P OUTPUT ACCEPT \r\niptables -P INPUT ACCEPT\r\niptables -F \r\n```\r\n\r\n::: warning\r\n该方式会在重启后失效\r\n:::\r\n\r\n## 自动生效\r\n\r\n```shell\r\napt install iptables-persistent\r\n\r\nnetfilter-persistent save\r\n\r\n# 重启后验证\r\niptables -L -v\r\n```\r\n\r\n::: tip\r\n适用于 Debian/Ubuntu 系统\r\n:::\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 关闭 iptables 防火墙",
      "lvl1": "允许所有流量",
      "lvl2": "自动生效"
    },
    "frontmatter": {
      "title": "Linux 关闭 iptables 防火墙",
      "date": "2025/03/11",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 开启 BBR",
    "path": "/blogs/yunweishouce/LinuxkaiqiBBR.html",
    "url": "/blogs/yunweishouce/LinuxkaiqiBBR.html",
    "content": "---\r\ntitle: Linux 开启 BBR\r\ndate: 2025/03/05\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 开启 BBR\r\n\r\n```bash\r\necho \"net.core.default_qdisc=fq\" >> /etc/sysctl.conf\r\necho \"net.ipv4.tcp_congestion_control=bbr\" >> /etc/sysctl.conf\r\n\r\n# 生效\r\nsysctl -p\r\n\r\n# 查看内核是否已开启BBR\r\nsysctl net.ipv4.tcp_available_congestion_control\r\n\r\n# 查看BBR是否启动\r\nlsmod | grep bbr\r\n```\r\n\r\n::: warning 内核版本\r\n1. Linux 内核版本 4.9 以上才可以开启\r\n2. 查看版本是否符合要求：`uname -r` \r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 开启 BBR",
      "lvl1": "开启 BBR"
    },
    "frontmatter": {
      "title": "Linux 开启 BBR",
      "date": "2025/03/05",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Linux 添加 Swap 交换空间",
    "path": "/blogs/yunweishouce/LinuxtianjiaSwapjiaohuankongjian.html",
    "url": "/blogs/yunweishouce/LinuxtianjiaSwapjiaohuankongjian.html",
    "content": "---\r\ntitle: Linux 添加 Swap 交换空间\r\ndate: 2025/03/07\r\ntags:\r\n - Linux\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 添加交换空间\r\n\r\n```bash\r\nmkdir /swap\r\n\r\n# 创建交换空间文件\r\nfallocate -l 2G /swap/swapfile1\r\n# 或者使用 dd 命令\r\ndd if=/dev/zero of=/swap/swapfile1 bs=1024 count=2097152\r\n\r\n# 启用并挂载交换空间\r\nchmod 600 /swap/swapfile1\r\nmkswap /swap/swapfile1\r\nswapon /swap/swapfile1\r\necho \"/swap/swapfile1 swap swap defaults 0 0\" | sudo tee -a /etc/fstab\r\n\r\n# 查看是否挂载成功\r\nswapon --show\r\nfree -h\r\n```\r\n\r\n## 删除交换空间\r\n```bash\r\n# 卸载交换空间\r\nswapoff -v /swap/swapfile1\r\n\r\n# 删除挂载交换空间的配置\r\nvi /etc/fstab\r\nrm /swap/swapfile1\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Linux 添加 Swap 交换空间",
      "lvl1": "添加交换空间",
      "lvl2": "删除交换空间"
    },
    "frontmatter": {
      "title": "Linux 添加 Swap 交换空间",
      "date": "2025/03/07",
      "tags": [
        "Linux"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MySQL 僵尸锁",
    "path": "/blogs/yunweishouce/MySQLjiangshisuo.html",
    "url": "/blogs/yunweishouce/MySQLjiangshisuo.html",
    "content": "---\r\ntitle: MySQL 僵尸锁\r\ndate: 2025/05/10\r\ntags:\r\n - MySQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 僵尸锁\r\n\r\n```sql\r\nSELECT * FROM performance_schema.data_locks;\r\n```\r\n\r\n存在锁，而查不到\r\n\r\n```sql\r\nSELECT\r\n    THREAD_ID,\r\n    PROCESSLIST_ID,\r\n    NAME,\r\n    TYPE\r\nFROM performance_schema.threads\r\nWHERE THREAD_ID IN (5468414, 5468475);\r\n```\r\n\r\n是一个假死的长事务导致的   \r\n \r\n```sql\r\nselect * from information_schema.INNODB_TRX;\r\n```\r\n\r\n但是查不到这个事务的线程id  \r\n \r\n```sql\r\nSELECT\r\n    trx_id,\r\n    trx_state,\r\n    trx_mysql_thread_id,\r\n    trx_started,\r\n    trx_query\r\nFROM information_schema.INNODB_TRX\r\nWHERE trx_id = 65772512;\r\n```\r\n\r\n也无法回滚事务\r\n\r\n```sql\r\nXA RECOVER;\r\nXA ROLLBACK '10.0.6.112.tm17458036649580053510.0.6.112.tm238';\r\n```\r\n\r\n## 回滚事务\r\n\r\n:::info\r\n根据16进制xid中不同的位数，直接回滚那个造成僵尸锁的事务\r\n:::\r\n\r\n```sql\r\nXA RECOVER CONVERT XID;\r\nXA ROLLBACK X'31302E302E362E3131322E746D313734353830333636343935383030353335', X'31302E302E362E3131322E746D323338', 1096044365;\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MySQL 僵尸锁",
      "lvl1": "僵尸锁",
      "lvl2": "回滚事务"
    },
    "frontmatter": {
      "title": "MySQL 僵尸锁",
      "date": "2025/05/10",
      "tags": [
        "MySQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
    "path": "/blogs/yunweishouce/MYSQLzengliangbinlogdenixianghuifangzhibinlog2sql.html",
    "url": "/blogs/yunweishouce/MYSQLzengliangbinlogdenixianghuifangzhibinlog2sql.html",
    "content": "---\r\ntitle: MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】\r\ndate: 2025/06/28\r\ntags:\r\n - MYSQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 下载工具 `binlog2sql`: `git clone https://github.com/danfengcao/binlog2sql.git`\r\n2. 初始化依赖环境\r\n3. 校验 mysql binlog 功能：其他实例的binlog在本地实例中的应用\r\n4. 生成逆向sql：兼容性问题（字符集问题）\r\n:::\r\n\r\n## binlog2sql\r\n\r\n```shell\r\n# 下载\r\ngit clone https://github.com/danfengcao/binlog2sql.git\r\n# 依赖环境（conda 为例）\r\nconda create -n binlog2sql_env python=3.9 -y\r\nconda activate binlog2sql_env\r\n\r\npip install -r requirements.txt\r\npip install mysqlclient\r\npip install pymysql\r\npip install requests\r\npip install python-dateutil\r\n\r\n# 验证\r\ncd .\\binlog2sql\\\r\npython binlog2sql.py --help\r\n```\r\n\r\n## binlog\r\n:::warning\r\n- 如果你的binlog文件来自其他实例，记得提前把binlog文件放入mysql的数据文件夹下（`/var/lib/mysql`），并修改`mysql-bin.index`文件\r\n- 查看binlog：`SHOW BINARY LOGS;`\r\n- 查看数据库字符集：`SHOW CREATE DATABASE matcheasy_new;`\r\n- 查看数据库表字符集：`SHOW FULL COLUMNS FROM matcheasy_new.i_resume;`\r\n:::\r\n\r\n以本地环境（docker mysql）为例（把线上实例的binlog放在本地实例上回放测试）\r\n\r\n```yml\r\nservices:\r\n  mysql:\r\n    image: mysql:8.0\r\n    environment:\r\n      MYSQL_ROOT_PASSWORD: password\r\n      MYSQL_USER: root_user\r\n      MYSQL_PASSWORD: password\r\n    ports:\r\n      - \"33306:3306\"\r\n    command:\r\n      --default-authentication-plugin=mysql_native_password\r\n      --character-set-server=utf8mb4\r\n      --collation-server=utf8mb4_unicode_ci\r\n      --binlog-format=ROW\r\n      --server-id=1\r\n      --log-bin=mysql-bin\r\n      --local-infile=1\r\n      --log-bin-trust-function-creators=1\r\n      --gtid-mode=ON\r\n      --enforce-gtid-consistency=ON\r\n    volumes:\r\n      - ./mysql_data:/var/lib/mysql\r\n```\r\n\r\n```sql\r\n-- 启动实例后给用户赋权\r\nGRANT ALL PRIVILEGES ON *.* TO 'root_user'@'%';\r\nFLUSH PRIVILEGES;\r\n```\r\n\r\n:::tip\r\n- 基础数据准备参考：[MYSQL数据导出导入](./MYSQL数据导出导入.md)\r\n- mysql版本以8.0为例，binlog以开启gtid为例\r\n- 源实例字符集以 utf8mb3 为例（注意我的docker compose文件中字符集指定的是 utf8mb4 ，因为它和 utf8mb3 可能会有兼容性问题，且本工具对 utf8mb3 也有兼容性问题，方便进行演示，实际场景中请保证两实例字符集一致）\r\n:::\r\n\r\n## 生成逆向sql\r\n\r\n:::info\r\n- 本工具可以直接连线上的mysql，包括阿里云什么的，就不用折腾两个实例了，这里只是对这种特殊需求的演示\r\n:::\r\n\r\n```shell\r\npython ..\\binlog2sql\\binlog2sql.py \\\r\n    --start-file=mysql-bin.001030 \\\r\n    --stop-file=mysql-bin.001039 \\\r\n    --host=127.0.0.1 --port=33306 \\\r\n    --user=root_user \\\r\n    --password='password' \\\r\n    --database=test_database \\\r\n    --flashback \\\r\n        > rollback.sql\r\n```\r\n\r\n:::danger utf8mb3字符集兼容性问题报错\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 150, in <module>\r\n    binlog2sql.process_binlog()\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 105, in process_binlog\r\n    for row in binlog_event.rows:\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 428, in rows\r\n    self._fetch_rows()\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 423, in _fetch_rows\r\n    self.__rows.append(self._fetch_one_row())\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 476, in _fetch_one_row\r\n    row[\"values\"] = self._read_column_data(self.columns_present_bitmap)\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 132, in _read_column_data\r\n    values[name] = self.__read_string(1, column)\r\n  File \"C:\\Users\\xiche\\anaconda3\\envs\\binlog2sql_env\\lib\\site-packages\\pymysqlreplication\\row_event.py\", line 220, in __read_string\r\n    string = string.decode(charset_to_encoding(column.character_set_name))\r\nLookupError: unknown encoding: utf8mb3\r\n```\r\n\r\n解决方案：因为本工具引用的pymysql版本太老，无法识别utf8mb3，所以需要手动修改pymysql包下的`charset.py`\r\n```py\r\ndef charset_to_encoding(name):\r\n    \"\"\"Convert MySQL's charset name to Python's codec name\"\"\"\r\n    if name == 'utf8mb4':\r\n        return 'utf8'\r\n    if name == 'utf8mb3':\r\n        return 'utf8'\r\n    return name\r\n```\r\n:::\r\n\r\n:::danger 字符解码报错\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 150, in <module>\r\n    binlog2sql.process_binlog()\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 121, in process_binlog\r\n    self.print_rollback_sql(filename=tmp_file)\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql.py\", line 129, in print_rollback_sql\r\n    for line in reversed_lines(f_tmp):\r\n  File \"E:\\DB-BACK\\binlog2sql\\binlog2sql\\binlog2sql\\binlog2sql_util.py\", line 249, in reversed_lines\r\n    block = block.decode(\"utf-8\")\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x83 in position 0: invalid start byte\r\n```\r\n\r\n解决方案：因为两实例字符集不同，或实例修改字符集导致的历史数据问题，总之解析binlog时发现存在无法解析的字符编码，所以需要手动修改工具中的解码逻辑，修改`binlog2sql_util.py`文件，这样非法字符就会被`�`代替，等回放完需要去sql文件中手动修改非法字符\r\n```py\r\nblock = block.decode(\"utf-8\")\r\n# 改为\r\nblock = block.decode(\"utf-8\", errors=\"replace\")\r\n```\r\n- 字符编码的报错没有好的办法彻底避免\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
      "lvl1": "binlog2sql",
      "lvl2": "binlog",
      "lvl3": "生成逆向sql"
    },
    "frontmatter": {
      "title": "MYSQL 增量 binlog 的逆向回放【danfengcao/binlog2sql】",
      "date": "2025/06/28",
      "tags": [
        "MYSQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "MYSQL 数据导出导入",
    "path": "/blogs/yunweishouce/MYSQLshujudaochudaoru.html",
    "url": "/blogs/yunweishouce/MYSQLshujudaochudaoru.html",
    "content": "---\r\ntitle: MYSQL 数据导出导入\r\ndate: 2025/03/05\r\ntags:\r\n - MYSQL\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip\r\n1. 安装 mysqlsh\r\n2. 导出数据\r\n3. 导入数据（需要开启性能模式）\r\n:::\r\n\r\n## 安装 mysqlsh\r\n\r\n```shell\r\nwinget install Oracle.MySQLShell\r\nmysqlsh\r\n```\r\n\r\n## 导出\r\n\r\n```js\r\n\\connect username@host\r\n\\js\r\nutil.dumpTables(\"asktrue_exam\", [\"project_exam_student_result\"], \"E:\\\\DB\\\\asktrue\")\r\nutil.dumpSchemas([\"staffcloud_crm\", \"staffcloud_oa\"], \"E:\\\\DB\\\\staffcloud\");\r\n\r\n// 移除 definer，比如创建该库的用户名\r\nutil.dumpSchemas([\"staffcloud_crm\", \"staffcloud_oa\"], \"E:\\\\DB\\\\staffcloud\", {compatibility:[\"strip_definers\"]});\r\n```\r\n\r\n## 导入\r\n\r\n```js\r\n\\connect username@host\r\n\\js\r\nutil.loadDump(\"E:\\\\DB\\\\asktrue\\\\project_exam_student_result\", {threads: 4});\r\n\r\n// 指定导入另一个 schema\r\nutil.loadDump(\"E:\\\\DB-BACK\\\\matcheasy_new_gray_20250630_0100_2\", {schema: \"matcheasy_new\"})\r\n```\r\n\r\n::: info 需要开启性能模式\r\n开启性能模式：`performance_schema=ON`\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "MYSQL 数据导出导入",
      "lvl1": "安装 mysqlsh",
      "lvl2": "导出",
      "lvl3": "导入"
    },
    "frontmatter": {
      "title": "MYSQL 数据导出导入",
      "date": "2025/03/05",
      "tags": [
        "MYSQL"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
    "path": "/blogs/yunweishouce/prometheusjiagrafanajichengcadvisorhenode-exportershixianjiankongwulijihedockerrongqidexingnenzhibiao.html",
    "url": "/blogs/yunweishouce/prometheusjiagrafanajichengcadvisorhenode-exportershixianjiankongwulijihedockerrongqidexingnenzhibiao.html",
    "content": "---\r\ntitle: prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标\r\ndate: 2025/04/29\r\ntags:\r\n - prometheus\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 部署采集器\r\n\r\n:::tip\r\n- node-exporter 采集物理机指标\r\n- cadvisor 采集各个 Docker 容器的指标\r\n:::\r\n\r\n```yml\r\nservices:\r\n  node-exporter:\r\n    image: prom/node-exporter:latest\r\n    deploy:\r\n      mode: global\r\n      restart_policy:\r\n        condition: any\r\n    ports:\r\n      - 9100:9100\r\n    pid: host\r\n    volumes:\r\n      - /:/host:ro,rslave\r\n    command:\r\n      - --path.rootfs=/host\r\n    labels:\r\n      - \"monitoring=enabled\"\r\n\r\n  cadvisor:\r\n    image: cadvisor/cadvisor:latest\r\n    deploy:\r\n      mode: global\r\n      restart_policy:\r\n        condition: any\r\n    ports: \r\n      - 8080:8080\r\n    volumes:\r\n      - /:/rootfs:ro\r\n      - /var/run:/var/run:rw\r\n      - /sys:/sys:ro\r\n      - /var/lib/docker/:/var/lib/docker:ro\r\n    labels:\r\n      - \"monitoring=enabled\"\r\n```\r\n\r\n## 自动更新采集端点\r\n\r\n:::tip\r\n- 需要整理所有的端点供 prometheus 采集信息\r\n- 保存到 file_sd 文件夹下的 json 文件中，这样 prometheus 就可以自动解析了\r\n:::\r\n\r\n```bash\r\n#!/bin/bash\r\n\r\nEXPORTER_PORTS=(9100 8080)\r\nPROM_FILE_SD_DIR=\"/etc/prometheus/file_sd\"\r\nmkdir -p $PROM_FILE_SD_DIR\r\n\r\n# 只选 Ready 状态节点\r\nNODES=$(docker node ls --format '{{.Hostname}} {{.Status}}' | awk '$2 == \"Ready\" {print $1}')\r\n\r\nfor PORT in \"${EXPORTER_PORTS[@]}\"; do\r\n  JSON_FILE=\"$PROM_FILE_SD_DIR/exporter_${PORT}.json\"\r\n  echo \"[\" > $JSON_FILE\r\n  SEP=\"\"\r\n  for HOST in $NODES; do\r\n    IP=$(docker node inspect \"$HOST\" --format '{{ index .Spec.Labels \"exporter_ip\" }}')\r\n    if [[ -n \"$IP\" ]]; then\r\n      echo \"${SEP}{\\\"targets\\\":[\\\"$IP:$PORT\\\"],\\\"labels\\\":{\\\"node\\\":\\\"$HOST\\\"}}\" >> $JSON_FILE\r\n      SEP=\",\"\r\n    fi\r\n  done\r\n  echo \"]\" >> $JSON_FILE\r\ndone\r\n```\r\n\r\n## prometheus\r\n\r\n```yml\r\n# prometheus.yml\r\n\r\nglobal:\r\n  scrape_interval: 15s\r\n\r\nscrape_configs:\r\n  - job_name: 'node-exporter'\r\n    file_sd_configs:\r\n      - files:\r\n          - /etc/prometheus/file_sd/exporter_9100.json\r\n\r\n  - job_name: 'cadvisor'\r\n    file_sd_configs:\r\n      - files:\r\n          - /etc/prometheus/file_sd/exporter_8080.json\r\n```\r\n\r\n```yml\r\nservices:\r\n  prometheus:\r\n    image: prom/prometheus:latest\r\n    container_name: prometheus\r\n    restart: always\r\n    volumes:\r\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro\r\n      - /etc/prometheus/file_sd:/etc/prometheus/file_sd:ro\r\n    ports:\r\n      - \"9090:9090\"\r\n    command:\r\n      - \"--config.file=/etc/prometheus/prometheus.yml\"\r\n      - \"--web.enable-lifecycle\"\r\n```\r\n\r\n## grafana\r\n\r\n:::tip\r\n- node-exporter 模板：11074、1860、405\r\n- cadvisor 模板：14282\r\n:::\r\n\r\n```yml\r\nservices:\r\n  grafana:\r\n    image: grafana/grafana-oss:latest\r\n    container_name: grafana\r\n    user: root\r\n    ports:\r\n      - \"9300:3000\"\r\n    volumes:\r\n      - ./data/grafana_data:/var/lib/grafana\r\n    environment:\r\n      - GF_SECURITY_ADMIN_USER=admin\r\n      - GF_SECURITY_ADMIN_PASSWORD=admin\r\n    restart: always\r\n```\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
      "lvl1": "部署采集器",
      "lvl2": "自动更新采集端点",
      "lvl3": "prometheus",
      "lvl4": "grafana"
    },
    "frontmatter": {
      "title": "prometheus 加 grafana 集成 cadvisor 和 node-exporter 实现监控物理机和 docker 容器的性能指标",
      "date": "2025/04/29",
      "tags": [
        "prometheus"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 SpringBootAdmin",
    "path": "/blogs/yunweishouce/SpringBootjichengSpringBootAdmin.html",
    "url": "/blogs/yunweishouce/SpringBootjichengSpringBootAdmin.html",
    "content": "---\r\ntitle: SpringBoot 集成 SpringBootAdmin\r\ndate: 2025/05/15\r\ntags:\r\n - SpringBoot\r\n - SpringBootAdmin\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 部署 SpringBootAdminServer\r\n2. 集成 SpringBootAdminClient\r\n3. 按不同环境修改 SpringBootAdminClient 注册的实例名称\r\n:::\r\n\r\n## 部署 SpringBootAdminServer\r\n\r\n```java\r\n@EnableAdminServer\r\n@SpringBootApplication\r\npublic class AdminServerApplication {\r\n    public static void main(String[] args) {\r\n        SpringApplication.run(AdminServerApplication.class, args);\r\n    }\r\n}\r\n```\r\n\r\n:::info\r\n- 开启 `httpBasic` 来允许 `curl` 使用用户名密码的方式访问 `/actuator`\r\n:::\r\n\r\n```java\r\n@Configuration\r\n@EnableWebSecurity\r\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\r\n    @Override\r\n    protected void configure(HttpSecurity http) throws Exception {\r\n        http\r\n                .authorizeRequests()\r\n                .anyRequest().authenticated()\r\n                .and()\r\n                .formLogin()\r\n                .and()\r\n                .httpBasic()\r\n                .and()\r\n                .logout()\r\n                .and()\r\n                .csrf().disable();\r\n    }\r\n}\r\n```\r\n\r\n:::info\r\n- 可以集成注册中心（如 Nacos）实现服务的自动发现\r\n- SpringBootAdmin2 可以通过 `ignored-services` 属性忽略注册中心的某些服务\r\n- SpringBootAdmin3 可以通过 `metadata-filter` 属性通过元数据来选择注册中心中的某些服务\r\n:::\r\n\r\n```yml\r\nserver:\r\n  port: 8111\r\n\r\nspring:\r\n  application:\r\n    name: SPRING-BOOT-ADMIN-SERVER\r\n  security:\r\n    user:\r\n      name: admin\r\n      password: password\r\n  cloud:\r\n    nacos:\r\n      server-addr: nacos-server-addr\r\n      discovery:\r\n        username: nacos\r\n        password: password\r\n        group: DEFAULT_GROUP\r\n        namespace: public\r\n  boot:\r\n    admin:\r\n      discovery:\r\n        ignored-services: shlink,snowflake\r\n      client:\r\n        url: http://localhost:${server.port}\r\n        username: ${spring.security.user.name}\r\n        password: ${spring.security.user.password}\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            environment: ${spring.profiles.active}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n\r\nmanagement:\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: '*'\r\n      base-path: /actuator\r\n  endpoint:\r\n    health:\r\n      show-details: always\r\n    shutdown:\r\n      enabled: true\r\n```\r\n\r\n```xml\r\n    <parent>\r\n        <groupId>org.springframework.boot</groupId>\r\n        <artifactId>spring-boot-starter-parent</artifactId>\r\n        <version>2.7.9</version>\r\n        <relativePath/>\r\n    </parent>\r\n\r\n   <dependencies>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-server</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-server-ui</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-client</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.alibaba.cloud</groupId>\r\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-actuator</artifactId>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-security</artifactId>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n## 集成 SpringBootAdminClient\r\n\r\n:::info\r\n- 通过 `spring.boot.admin.client.instance.metadata` 来自定义要注册的元数据\r\n- 通过 `spring.boot.admin.client.instance.metadata.user` 来定义访问 `/actuator` 所需的用户名密码\r\n- 通过 `spring.boot.admin.client.username` 来定义 SpringBootAdminServer 所需的用户名\r\n- 通过 `spring.boot.admin.client.password` 来定义 SpringBootAdminServer 所需的密码\r\n:::\r\n\r\n```yml\r\nspring:\r\n  boot:\r\n    admin:\r\n      client:\r\n        url: http://asktrue.cn:8111\r\n        username: admin\r\n        password: password\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            application: ${spring.application.name}\r\n            environment: ${spring.profiles.active}\r\n            ip: ${spring.cloud.client.ip-address}\r\n            port: ${server.port}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>de.codecentric</groupId>\r\n            <artifactId>spring-boot-admin-starter-client</artifactId>\r\n            <version>${spring-boot-admin.version}</version>\r\n        </dependency>\r\n```\r\n\r\n## 按不同环境修改 SpringBootAdminClient 注册的实例名称\r\n\r\n:::info\r\n- 只能通过代码修改 `spring.boot.admin.client.instance.name` 属性来修改实例名称\r\n:::error\r\n- 直接在 `application.yml` 中修改 `spring.boot.admin.client.instance.name` 属性是无效的\r\n:::\r\n:::\r\n\r\n```java\r\n@Configuration\r\npublic class SBANameConfig implements ApplicationListener<ApplicationReadyEvent> {\r\n    @Value(\"${spring.application.name}\")\r\n    private String appName;\r\n    @Value(\"${spring.profiles.active:default}\")\r\n    private String active;\r\n\r\n    @PostConstruct\r\n    public void setAdminClientNameProperty() {\r\n        // 设置 System Property 让 SBA client 用自定义 name\r\n        System.setProperty(\"spring.boot.admin.client.instance.name\", appName + \"-[\" + active + \"]\");\r\n    }\r\n    @Override\r\n    public void onApplicationEvent(ApplicationReadyEvent event) {\r\n        // 这里也可以设置，保证启动后仍然有效\r\n        System.setProperty(\"spring.boot.admin.client.instance.name\", appName + \"-[\" + active + \"]\");\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 SpringBootAdmin",
      "lvl1": "部署 SpringBootAdminServer",
      "lvl2": "集成 SpringBootAdminClient",
      "lvl3": "按不同环境修改 SpringBootAdminClient 注册的实例名称"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 SpringBootAdmin",
      "date": "2025/05/15",
      "tags": [
        "SpringBoot",
        "SpringBootAdmin"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
    "path": "/blogs/yunweishouce/SpringBootjichengSpringBootAdminheArthasshixianyuanchengzhenduan.html",
    "url": "/blogs/yunweishouce/SpringBootjichengSpringBootAdminheArthasshixianyuanchengzhenduan.html",
    "content": "---\r\ntitle: SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断\r\ndate: 2025/05/15\r\ntags:\r\n - SpringBoot\r\n - SpringBootAdmin\r\n - Arthas\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n:::tip\r\n1. 部署 arthas-tunnel-server\r\n2. SpringBoot 集成 arthas-spring-boot-starter\r\n3. 将 agent-id 注册到 SpringBootAdmin\r\n:::\r\n\r\n## 部署 arthas-tunnel-server\r\n\r\n:::tip\r\n- DockerHub 地址：https://hub.docker.com/repository/docker/jxch/arthas-tunnel-server/general\r\n- GitHub 地址：https://github.com/jxch-docker/docker-build/tree/main/arthas/tunnel\r\n:::\r\n\r\n```yml\r\nservices:\r\n  tunnel-server:\r\n    image: jxch/arthas-tunnel-server:4.0.5\r\n    ports:\r\n      - \"7777:7777\"\r\n      - \"10777:8080\"\r\n    environment:\r\n      - ARTHAS_TOKEN=token\r\n      - PASSWORD=password\r\n```\r\n\r\n## 集成 arthas-spring-boot-starter\r\n\r\n:::info\r\n- tunnelWeb 并非 arthas-spring-boot-starter 提供的字段，我的目的是把这个入口注册到 SpringBootAdminServer，这样就可以在 SBA Server 上直接进入远程诊断了\r\n- tunnelToken 是 arthas-spring-boot-starter 提供的字段，但并没有显示的 Java 属性，这个字段是必填的\r\n- tunnelServer 必须用 ws 地址\r\n:::\r\n\r\n```yml\r\narthas:\r\n  tunnelWeb: http://arthas-tunnel-server-ip-address:10777/\r\n  tunnelServer: ws://arthas-tunnel-server-ip-address:7777/ws\r\n  tunnelToken: ARTHAS_TOKEN\r\n  app-name: ${spring.application.name}\r\n  agent-id: ${spring.application.name}-${spring.cloud.client.ip-address:${server.address:127.0.0.1}}-${server.port}\r\n```\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>com.taobao.arthas</groupId>\r\n            <artifactId>arthas-spring-boot-starter</artifactId>\r\n            <version>4.0.5</version>\r\n        </dependency>\r\n```\r\n\r\n## 集成 SpringBootAdminClient 并注册 agent-id\r\n\r\n:::info\r\n- 参考：[SpringBoot 集成 SpringBootAdmin](./SpringBoot集成SpringBootAdmin.md)\r\n- 把 agent-id 等信息通过元数据注册到 SpringBootAdminServer\r\n- 这样就可以在 SpringBootAdminServer 的 web 面板中直接进入远程诊断了\r\n:::\r\n\r\n```yml\r\nspring:\r\n  boot:\r\n    admin:\r\n      client:\r\n        url: http://asktrue.cn:8111\r\n        username: admin\r\n        password: password\r\n        instance:\r\n          prefer-ip: true\r\n          metadata:\r\n            application: ${spring.application.name}\r\n            environment: ${spring.profiles.active}\r\n            arthas-tunnel-server: ${arthas.tunnelWeb}\r\n            arthas-agent-id: ${arthas.agent-id}\r\n            ip: ${spring.cloud.client.ip-address}\r\n            port: ${server.port}\r\n            user:\r\n              name: ${spring.security.user.name}\r\n              password: ${spring.security.user.password}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
      "lvl1": "部署 arthas-tunnel-server",
      "lvl2": "集成 arthas-spring-boot-starter",
      "lvl3": "集成 SpringBootAdminClient 并注册 agent-id"
    },
    "frontmatter": {
      "title": "SpringBoot 集成 SpringBootAdmin 和 Arthas 实现远程诊断",
      "date": "2025/05/15",
      "tags": [
        "SpringBoot",
        "SpringBootAdmin",
        "Arthas"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "V2fly Shadowsocks 等翻墙服务部署",
    "path": "/blogs/yunweishouce/v2fly_shadowsocksdengfanqiangfuwubushu.html",
    "url": "/blogs/yunweishouce/v2fly_shadowsocksdengfanqiangfuwubushu.html",
    "content": "---\r\ntitle: V2fly Shadowsocks 等翻墙服务部署\r\ndate: 2025/03/08\r\ntags:\r\n - proxy\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: info\r\n替换一下各配置文件中的 uuid 就可以了\r\n:::\r\n\r\n## docker swarm 部署\r\n\r\n```yml\r\nservices:\r\n  shadowsocks: \r\n    image: shadowsocks/shadowsocks-libev \r\n    restart: unless-stopped\r\n    ports: \r\n      - 12346:12346\r\n      - 12346:12346/udp \r\n    configs: \r\n      - source: shadowsocks_config\r\n        target: /etc/shadowsocks-libev/config.json \r\n    environment:\r\n      - DNS_ADDRS=8.8.8.8,8.8.4.4\r\n    command: ss-server -c /etc/shadowsocks-libev/config.json \r\n  v2fly:\r\n    image: v2fly/v2fly-core\r\n    restart: unless-stopped\r\n    ports:\r\n      - 12345:12345\r\n    configs: \r\n      - source: v2fly_config\r\n        target: /etc/v2ray/config.json\r\n    entrypoint: [\"v2ray\", \"run\",  \"-c\", \"/etc/v2ray/config.json\"]\r\n\r\n\r\nconfigs:\r\n  shadowsocks_config:\r\n    file: /root/server/config/shadowsocks/config.json \r\n  v2fly_config:\r\n    file: /root/server/config/v2fly/config.json\r\n```\r\n\r\n## shadowsocks config.json\r\n\r\n```json\r\n{\r\n    \"server\":\"0.0.0.0\",\r\n    \"server_port\":12346,\r\n    \"password\":\"uuid\",\r\n    \"timeout\":3000,\r\n    \"method\":\"aes-256-gcm\",\r\n    \"fast_open\":false,\r\n    \"mode\":\"tcp_and_udp\"\r\n}\r\n\r\n```\r\n\r\n## v2fly config.json\r\n\r\n```json\r\n{\r\n    \"log\": {\r\n        \"access\": \"/var/log/v2ray/access.log\",\r\n        \"error\": \"/var/log/v2ray/error.log\",\r\n        \"loglevel\": \"warning\"\r\n    },\r\n    \"inbound\": {\r\n        \"port\": 12345,\r\n        \"protocol\": \"vmess\",\r\n        \"settings\": {\r\n            \"clients\": [\r\n                {\r\n                    \"id\": \"uuid\",\r\n                    \"level\": 1,\r\n                    \"alterId\": 0\r\n                }\r\n            ]\r\n        }\r\n    },\r\n    \"outbound\": {\r\n        \"protocol\": \"freedom\",\r\n        \"settings\": {}\r\n    },\r\n    \"inboundDetour\": [],\r\n    \"outboundDetour\": [\r\n        {\r\n            \"protocol\": \"blackhole\",\r\n            \"settings\": {},\r\n            \"tag\": \"blocked\"\r\n        }\r\n    ],\r\n    \"routing\": {\r\n        \"strategy\": \"rules\",\r\n        \"settings\": {\r\n            \"rules\": [\r\n                {\r\n                    \"type\": \"field\",\r\n                    \"ip\": [\r\n                        \"0.0.0.0/8\",\r\n                        \"10.0.0.0/8\",\r\n                        \"100.64.0.0/10\",\r\n                        \"127.0.0.0/8\",\r\n                        \"169.254.0.0/16\",\r\n                        \"172.16.0.0/12\",\r\n                        \"192.0.0.0/24\",\r\n                        \"192.0.2.0/24\",\r\n                        \"192.168.0.0/16\",\r\n                        \"198.18.0.0/15\",\r\n                        \"198.51.100.0/24\",\r\n                        \"203.0.113.0/24\",\r\n                        \"::1/128\",\r\n                        \"fc00::/7\",\r\n                        \"fe80::/10\"\r\n                    ],\r\n                    \"outboundTag\": \"blocked\"\r\n                }\r\n            ]\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "V2fly Shadowsocks 等翻墙服务部署",
      "lvl1": "docker swarm 部署",
      "lvl2": "shadowsocks config.json",
      "lvl3": "v2fly config.json"
    },
    "frontmatter": {
      "title": "V2fly Shadowsocks 等翻墙服务部署",
      "date": "2025/03/08",
      "tags": [
        "proxy"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 使用 Diskpart 永久固定 USB 盘符",
    "path": "/blogs/yunweishouce/WINshiyongDiskpartyongjiugudingUSBpanfu.html",
    "url": "/blogs/yunweishouce/WINshiyongDiskpartyongjiugudingUSBpanfu.html",
    "content": "---\r\ntitle: Windows 使用 Diskpart 永久固定 USB 盘符\r\ndate: 2025/03/05\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n::: tip Diskpart\r\n先执行 Diskpart 命令，进入 Diskpart 命令窗\r\n:::\r\n\r\n```powershell\r\n# 列出所有的硬盘\r\nlist volume\r\n\r\n# 选择需要操作的硬盘\r\nselect volume 6\r\n\r\n# 手动设置盘符\r\nassign letter=U\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 使用 Diskpart 永久固定 USB 盘符"
    },
    "frontmatter": {
      "title": "Windows 使用 Diskpart 永久固定 USB 盘符",
      "date": "2025/03/05",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 使用 NSSM 管理 Service",
    "path": "/blogs/yunweishouce/WINshiyongNSSMguanliService.html",
    "url": "/blogs/yunweishouce/WINshiyongNSSMguanliService.html",
    "content": "---\r\ntitle: Windows 使用 NSSM 管理 Service\r\ndate: 2025/06/29\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n- 安装：`winget install NSSM.NSSM`\r\n- 安装服务：`nssm install cloudflared-dns`\r\n  - 在弹出的对话框中\r\n    - Application path 添应用的绝对路径\r\n    - Startup dir 添 `win + r` 输入 `shell:startup` 回车后弹出的文件夹路径\r\n    - Arguments 填应用的启动参数\r\n    - 最后点击 Install service\r\n- 启动服务：`net start cloudflared-dns` 或 `Start-Service cloudflared-dns`\r\n- 检查服务状态： `Get-Service cloudflared-dns`\r\n- 修改服务参数：`nssm edit cloudflared-dns`\r\n- 卸载服务：`nssm remove cloudflared-dns confirm`\r\n\r\n:::info\r\n- 需要以管理员权限运行\r\n:::\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 使用 NSSM 管理 Service"
    },
    "frontmatter": {
      "title": "Windows 使用 NSSM 管理 Service",
      "date": "2025/06/29",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "WIN 安装 ANDROID 安卓子系统",
    "path": "/blogs/yunweishouce/WINanzhuangANDROIDanzhuozixitong.html",
    "url": "/blogs/yunweishouce/WINanzhuangANDROIDanzhuozixitong.html",
    "content": "---\r\ntitle: WIN 安装 ANDROID 安卓子系统\r\ndate: 2025/06/19\r\ntags:\r\n - Windows\r\n - Android\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n1. 打开链接 [https://store.rg-adguard.net/](https://store.rg-adguard.net/)\r\n2. 输入 `https://www.microsoft.com/store/productid/9p3395vx91nr`\r\n3. 选择 `slow`，点击 `√`\r\n4. `MicrosoftCorporationII.WindowsSubsystemForAndroid_1.8.32837.0_neutral_~_8wekyb3d8bbwe.msixbundle`，右键这个链接，复制链接地址，新建标签页，打开这个链接，开始下载\r\n5. 进入管理员模式 PS\r\n6. `Add-AppxPackage \"D:\\xicheng_jiang\\下载\\浏览器\\MicrosoftCorporationII.WindowsSubsystemForAndroid_1.8.32837.0_neutral___8wekyb3d8bbwe.Msixbundle\"`\r\n\r\n\r\n:::danger 安装过程中报错\r\n- 若报错则以同样的方式安装 `Microsoft.UI.Xaml.2.6_2.62112.3002.0_x64__8wekyb3d8bbwe.appx`，然后重试\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "WIN 安装 ANDROID 安卓子系统"
    },
    "frontmatter": {
      "title": "WIN 安装 ANDROID 安卓子系统",
      "date": "2025/06/19",
      "tags": [
        "Windows",
        "Android"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
    "path": "/blogs/yunweishouce/WINshezhiRoutezailianjieVPNdetongshibaochiduihulianwangdezhengchangfangwen.html",
    "url": "/blogs/yunweishouce/WINshezhiRoutezailianjieVPNdetongshibaochiduihulianwangdezhengchangfangwen.html",
    "content": "---\r\ntitle: Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问\r\ndate: 2025/03/08\r\ntags:\r\n - Windows\r\ncategories:\r\n - 运维手册\r\n---\r\n\r\n## 操作方法\r\n\r\n1. `win+R` 输入 `ncpa.cpl`，按回车\r\n2. 右键需要操作的 VPN 设备，点击`属性`\r\n3. 点击`网络`选项卡，双击 `TCP/IPv4`，点击`高级`\r\n4. 取消勾选：`在远程网络上使用默认网关`\r\n5. 连接VPN\r\n6. 管理员模式打开 `powershell` 或 `cmd`\r\n7. 输入命令 `ipconfig /all` 回车，查看需要操作的VPN（如PPP连接）的IP地址，如`192.168.33.19`\r\n8. 添加永久静态路由：`route add 172.16.0.0 mask 255.255.0.0  192.168.33.19 -p` \r\n   - 将 `172.16.0.0` 网段，子网掩码为 `255.255.0.0` 的所有流量通过 `192.168.33.19` 接口访问，而 `192.168.33.19` 正是该VPN的接口\r\n\r\n::: info\r\n该方法的原理是，仅让特定网段的流量走VPN，其他流量依然走本地默认路由\r\n:::\r\n\r\n## Powershell 脚本\r\n\r\n```powershell\r\n# auto-vpn-route.ps1\r\n\r\nparam([String]$vpn, [String]$ip, [String]$mask)\r\n\r\n$vpn_ipv4 = (Get-NetIPAddress | Where-Object {$_.InterfaceAlias -eq $vpn}).IPAddress\r\n\r\nWrite-Host \"vpn: $vpn; vpn-ipv4: $vpn_ipv4\"\r\nIf([String]::IsNullOrEmpty($vpn_ipv4)) {\r\n    Write-Warning \"请连接 VPN：$vpn\"\r\n} Else {\r\n    Write-Host \"route delete $ip\" -ForegroundColor DarkGray\r\n    route delete $ip\r\n    Write-Host \"route add $ip mask $mask $vpn_ipv4\" -ForegroundColor DarkGray\r\n    route add $ip mask $mask $vpn_ipv4\r\n\r\n    If([String]::IsNullOrEmpty((route print | Select-String -Pattern \"\\s0.0.0.0\" | Select-String $vpn_ipv4))) {\r\n        Write-Host \"操作完成！可使用 route print | select-string $ip 查询路由表是否修改。\"\r\n    } Else {\r\n        Write-Host \"route delete $ip\" -ForegroundColor DarkGray\r\n        route delete $ip\r\n        Write-Warning \"请去控制面板关闭 $vpn 网卡的默认网关功能\" \r\n        Write-Warning \"参见：ncpa.cpl -> $vpn -> 属性 -> 网络 -> (TCP/IPv4) -> 高级 -> 在远程网络上使用默认网关\" \r\n        Write-Warning \"重新连接 $vpn\"\r\n    }\r\n}\r\n```\r\n\r\n```powershell\r\n.\\auto-vpn-route.ps1 -vpn 云开发 -ip 172.0.0.0 -mask 255.0.0.0\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
      "lvl1": "操作方法",
      "lvl2": "Powershell 脚本"
    },
    "frontmatter": {
      "title": "Windows 设置 Route 在连接 VPN 的同时保持对互联网的正常访问",
      "date": "2025/03/08",
      "tags": [
        "Windows"
      ],
      "categories": [
        "运维手册"
      ]
    },
    "type": "content"
  },
  {
    "title": "JAVA 架构师学习笔记",
    "path": "/docs/architect/architect.html",
    "url": "/docs/architect/architect.html",
    "content": "---\r\ntitle: JAVA 架构师学习笔记\r\ndate: 2025/03/04\r\n---\r\n\r\n## 学习路径\r\n\r\n- 并发编程\r\n- 设计模式\r\n- JAVA反射、流式编程、编码规范\r\n- Spring、SpringBoot（核心启动流程、常见扩展点）\r\n- SpringCloud（微服务、分布式）\r\n- MySQL、MybatisPlus\r\n- 中间件（Redis、Sharding-Sphere、Zookeeper、RabbitMQ、Kafka、RocketMQ、Dubbo）\r\n- 网络编程（Netty）\r\n- JVM（内存模型、垃圾回收、GraalVM）\r\n- 性能调优（数据库、JVM、Tomcat）\r\n- MonoDB、ElasticSearch\r\n- clickhouse、Neo4j\r\n- Docker+K8S\r\n- 架构设计（DDD）\r\n- webflux\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JAVA 架构师学习笔记",
      "lvl1": "学习路径"
    },
    "frontmatter": {
      "title": "JAVA 架构师学习笔记",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "读书笔记",
    "path": "/docs/book/book.html",
    "url": "/docs/book/book.html",
    "content": "---\r\ntitle: 读书笔记\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "读书笔记"
    },
    "frontmatter": {
      "title": "读书笔记",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "日记",
    "path": "/docs/diary/diary.html",
    "url": "/docs/diary/diary.html",
    "content": "---\r\ntitle: 日记\r\npassword: b593bf97f44387eb6fdc629acef2d138\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "日记"
    },
    "frontmatter": {
      "title": "日记",
      "password": "b593bf97f44387eb6fdc629acef2d138",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "计算机技术栈",
    "path": "/docs/it/it.html",
    "url": "/docs/it/it.html",
    "content": "---\r\ntitle: 计算机技术栈\r\ndate: 2025/03/08\r\n---\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "计算机技术栈"
    },
    "frontmatter": {
      "title": "计算机技术栈",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "感谢打赏",
    "path": "/docs/others/donate.html",
    "url": "/docs/others/donate.html",
    "content": "---\r\ntitle: 感谢打赏\r\ndate: 2025/03/05\r\n---\r\n\r\n<div style=\"display: flex; justify-content: space-around; flex-wrap: wrap;\">\r\n    <img src=\"@source/docs/others/static/收款码-支付宝.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n    <img src=\"@source/docs/others/static/收款码-微信.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n    <img src=\"@source/docs/others/static/收款码-QQ.jpg\" alt=\"描述\" width=\"300\" height=\"200\">\r\n</div>\r\n\r\n::: info \r\n加入群聊一起交流哦！如有错误的地方，欢迎指正！\r\n\r\n<ul>\r\n    <li><a target=\"_blank\" href=\"http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=_8OK2fsmwKYXliSoqszUCHZ_RnMmcZsm&authKey=KEju9D76HcqTr3vuFLbdkamaqpGVYcvfo%2F%2BlLd04GucOwH0XnMZjeg0a0WUJ7OwQ&noverify=0&group_code=961215331\">架构师：961215331</a></li>\r\n    <li><a target=\"_blank\" href=\"http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=1CRaLYPuesGlWXEPQmqwmi2UsTgXebSz&authKey=EReo0mUHRG9%2FGdYsRLClzizP%2BcRIzQCVIIHjfMLUmX%2FpoV4RIoAnQBktkimpKqdD&noverify=0&group_code=966469984\">操盘手：966469984</a></li>\r\n</ul>\r\n:::\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "感谢打赏"
    },
    "frontmatter": {
      "title": "感谢打赏",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "诗集",
    "path": "/docs/poetry/poetry.html",
    "url": "/docs/poetry/poetry.html",
    "content": "---\r\ntitle: 诗集\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "诗集"
    },
    "frontmatter": {
      "title": "诗集",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "操盘手学习笔记",
    "path": "/docs/trader/trader.html",
    "url": "/docs/trader/trader.html",
    "content": "---\r\ntitle: 操盘手学习笔记\r\ndate: 2025/03/05\r\n---\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "操盘手学习笔记"
    },
    "frontmatter": {
      "title": "操盘手学习笔记",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "交易笔记",
    "path": "/docs/trading_journal/trading_journal.html",
    "url": "/docs/trading_journal/trading_journal.html",
    "content": "---\r\ntitle: 交易笔记\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "交易笔记"
    },
    "frontmatter": {
      "title": "交易笔记",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-1",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-1.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-1.html",
    "content": "---\r\ntitle: 格言联璧-名句-1\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n> \r\n> <font color=\"orange\">静坐常思己过，闲谈莫论人非</font><br>\r\n> 怒是猛虎，欲是深渊<br>\r\n> <font color=\"orange\">鱼离水则身枯，心离书则神索</font><br>\r\n> <font color=\"orange\">修己以清心为要，涉世以慎言为先</font><br>\r\n> 谦，美德也，过谦者怀诈。默，懿行也，过默者藏奸<br>\r\n> <font color=\"orange\">天欲祸人，先以微福骄之；天欲福人，先以微祸儆之</font><br>\r\n> 日日行不怕千万里，常常做不怕千万事<br>\r\n> 对失意人，莫谈得意事。处得意日，莫忘失意时<br>\r\n> <font color=\"orange\">以情恕人，以理律己</font><br>\r\n> <font color=\"orange\">恶莫大于纵己之欲，祸莫大于言人之非</font><br>\r\n> 此生不学一可惜，此日闲过二可惜，此身一败三可惜<br>\r\n> 人之谤我也，与其能辩，不如能容；人之侮我也，与其能防，不如能化<br>\r\n> <font color=\"orange\">提得起，放得下，算得到，做得完，看得破，撇得开</font><br>\r\n> <font color=\"orange\">是非窝里，人用口，我用耳；热闹场中，人向前，我落后</font><br>\r\n> <font color=\"orange\">事有机缘，不先不后，刚刚凑巧。命若蹭蹬，走来走去，步步踏空</font><br>\r\n> 胆欲大，心欲小；智欲圆，行欲方<br>\r\n> <font color=\"orange\">事当快意时须转，言到快意时须住</font><br>\r\n> 不自重者取辱，不自畏者招祸，不自满者受益，不自是者博闻<br>\r\n> 读书即未成名，究竟人高品雅。修德不期获报，自然梦稳心安<br>\r\n> 以恕己之心恕人，则全交。以责人之心责己，则寡过<br>\r\n> 世人以七尺为性命，君子以性命为七尺<br>\r\n> 在古人之后议古人之失，则易；处古人之位为古人之事，则难<br>\r\n> 读未见书，如得良友；见已读书，如逢故人<br>\r\n> 事不可做尽，言不可道尽，势不可倚尽，福不可享尽<br>\r\n> <font color=\"orange\">不可吃尽，不可穿尽，不可说尽；又要洞得，又要做得，又要耐得</font><br>\r\n> <font color=\"orange\">有才而性缓，定属大才。有智而气和，斯为大智</font><br>\r\n> 何思何虑，居心当如止水；勿取勿忘，为学当如流水<br>\r\n> 案上不可多书，心中不可少书<br>\r\n> 辱人以不堪，必反辱；伤人以已甚，必反伤<br>\r\n> 无事时埋藏着许多小人，多事时识破了许多君子<br>\r\n> 不自反者，看不出一身病痛；不耐烦者，做不成一件事业<br>\r\n> 无心者公，无我者明<br>\r\n> 论人当节取其长，曲谅其短；做事必先审其害，后计其利<br>\r\n> 人好刚，我以柔胜之；人用术，我以诚感之；人使气，我以理屈之<br>\r\n> 盛喜中勿许人物，盛怒中勿答人书<br>\r\n> 不可不存时时可死之心，不可不行步步求生之事<br>\r\n> 见事贵乎理明，处事贵乎心公<br>\r\n> 气忌盛，心忌满，才忌露<br>\r\n> <font color=\"orange\">一念疏忽，是错起头。一念决裂，是错到底</font><br>\r\n> <font color=\"orange\">龙吟虎啸，凤翥鸾翔，大丈夫之气象</font><br>\r\n> <font color=\"orange\">缓事宜急干，敏则有功；急事宜缓办，忙则多错</font><br>\r\n> 直道事人，虚衷御物<br>\r\n> 小人乐闻君子之过，君子耻闻小人之恶<br>\r\n> <font color=\"orange\">不近人情，举足尽是危机；不体物情，一生俱成梦境</font><br>\r\n> <font color=\"orange\">心慎杂欲，则有余灵；目慎杂观，则有余明</font><br>\r\n> 眼界要阔，遍历名山大川；度量要宏，熟读五经诸史<br>\r\n> 步步占先者，必有人以挤之。事事争胜者，必有人以挫之<br>\r\n> <font color=\"orange\">顽石之中良玉隐焉，寒灰之中星火寓焉</font><br>\r\n> <font color=\"orange\">下手处是自强不息，成就处是至诚无息</font><br>\r\n> <font color=\"orange\">自责之外，无胜人之术。自强之外，无上人之术</font><br>\r\n>\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-1"
    },
    "frontmatter": {
      "title": "格言联璧-名句-1",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-2",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-2.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-2.html",
    "content": "---\r\ntitle: 格言联璧-名句-2\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 穷寇不可追也，遁辞不可攻也，贫民不可威也<br>\r\n> 见人不是，诸恶之根，见己不是，万善之门<br>\r\n> 热闹荣华之境，一过辄生凄凉。清真冷淡之为，历久愈有意味<br>\r\n> 古今来许多世家，无非积德。天地间第一人品，还是读书<br>\r\n> 善用威者不轻怒，善用恩者不妄施<br>\r\n> 事到手，且莫急，便要缓缓想；想到时，切莫缓，便要急急行<br>\r\n> 静以修身，俭以养德。入则笃行，出则友贤<br>\r\n> 作本色人，说根心话，干近情事<br>\r\n> <font color=\"orange\">知足常足，终身不辱；知止常止，终身不耻</font><br>\r\n> 怒如火，不遏则燎原；欲如水，不遏则滔天<br>\r\n> 不让古人，是谓有志；不让今人，是谓无量<br>\r\n> 读书为身上之用，而人以为纸上之用<br>\r\n> 执法如山，守身如玉，爱民如子，去蠹如仇<br>\r\n> 小人专望受人恩，受过辄忘；君子不轻受人恩，受则必报<br>\r\n> 书有未曾经我读，事无不可对人言<br>\r\n> 至乐无如读书，至要莫如教子<br>\r\n> <font color=\"orange\">福莫大于无祸，祸莫大于邀福</font><br>\r\n> 大智兴邦，不过集众思；大愚误国，只为好自用<br>\r\n> <font color=\"orange\">任难任之事，要有力而无气；处难处之人，要有知而无言</font><br>\r\n> 待小人宜宽，防小人宜严<br>\r\n> 无欲之谓圣，寡欲之谓贤，多欲之谓凡，徇欲之谓狂<br>\r\n> <font color=\"orange\">律己宜带秋气，处世须带春风</font><br>\r\n> 有真才者，必不矜才。有实学者，必不夸学<br>\r\n> 天下之势，以渐而成；天下之事，以积而居<br>\r\n> <font color=\"orange\">强不知以为知，此乃大愚；本无事而生事，是谓薄福</font><br>\r\n> 处逆境心，须用开拓法。处顺境心，要用收敛法<br>\r\n> 物忌全胜，事忌全美，人忌全盛<br>\r\n> 一时劝人以言，百世劝人以书<br>\r\n> <font color=\"orange\">有作用者，器宇定是不凡。有智慧者，才情决然不露</font><br>\r\n> 以虚养心，以德养身，以仁养天下万物，以道养天下万世<br>\r\n> <font color=\"orange\">心不欲杂，杂则神荡而不收；心不欲劳，劳则神疲而不入</font><br>\r\n> 对愁人勿乐，对哭人勿笑，对失意人勿矜<br>\r\n> 寡欲故静，有主则虚<br>\r\n> 必有容，德乃大；必有忍，事乃济<br>\r\n> 聪明者，戒太察。刚强者，戒太暴。温良者，戒无断<br>\r\n> 喜来时一检点，怒来时一检点，怠惰时一检点，放肆时一检点<br>\r\n> <font color=\"orange\">毋以小嫌疏至戚，毋以新怨忘旧恩</font><br>\r\n> 倚势欺人，势尽而为人欺；恃财侮人，财散而受人侮<br>\r\n> 彼之理是，我之理非，我让之；彼之理非，我之理是，我容之<br>\r\n> <font color=\"orange\">大着肚皮容物，立定脚跟做人</font><br>\r\n> <font color=\"orange\">闻恶不可遽怒，恐为谗人泄忿；闻善不可就亲，恐引奸人进身</font><br>\r\n> 炎凉之态，富贵其于贫贱；嫉妒之心，骨肉其于外人<br>\r\n> <font color=\"orange\">待人三自反，处世两如何</font><br>\r\n> 涵养冲虚，便是身世学问。省除烦恼，何等心性安和<br>\r\n> <font color=\"orange\">公生明，诚生明，从容生明</font><br>\r\n> 居安虑危，处治思乱<br>\r\n> 丈夫之高华，只在于道德气节。鄙夫之炫耀，但求诸服饰起居<br>\r\n> 古之君子病其无能也，学之；今之君子耻其无能也，讳之<br>\r\n> 身在天地后，心在天地前；身在万物中，心在万物上<br>\r\n> <font color=\"orange\">世事让三分，天空地阔。心田培一点，子种孙收</font><br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-2"
    },
    "frontmatter": {
      "title": "格言联璧-名句-2",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-3",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-3.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-3.html",
    "content": "---\r\ntitle: 格言联璧-名句-3\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> <font color=\"orange\">处事须留余地，责善切戒尽言</font><br>\r\n> 以耐事了天下之多事，以无心息天下之争心<br>\r\n> 读书贵能疑，疑乃可以启信。读书在有渐，渐乃克底有成<br>\r\n> 只是心不放肆，便无过差。只是心不怠忽，便无逸志<br>\r\n> 临事须替别人想，论人先将自己想<br>\r\n> <font color=\"orange\">以镜自照见形容，以心自照见吉凶</font><br>\r\n> 人性中不曾缺一物，人性上不可添一物<br>\r\n> 看书求理，须令自家胸中点头。与人谈理，须令人家胸中点头<br>\r\n> <font color=\"orange\">不为过三字，昧却多少良心；没奈何三字，抹却多少体面</font><br>\r\n> 静能制动，沈能制浮。宽能制褊，缓能制急<br>\r\n> 观天地生物气象，学圣贤克己工夫<br>\r\n> 贫贱是苦境，能善处者自乐；富贵是乐境，不善处者更苦<br>\r\n> 谈人之善，泽于膏沐；暴人之恶，痛于戈矛<br>\r\n> 人未己知，不可急求其知；人未己合，不可急与之合<br>\r\n> 勿施小惠伤大体，毋借公道遂私情<br>\r\n> 心志要苦，意趣要乐。气度要宏，言动要谨<br>\r\n> 勤能补拙，俭以养廉<br>\r\n> 尽前行者地步窄，向后看者眼界宽<br>\r\n> 阿谀取容，男子耻为妾妇之道。本真不凿，大人不失赤子之心<br>\r\n> 穷达有命，吉凶见人<br>\r\n> 省费医贫，恬退医躁，独卧医淫，随缘医愁，读书医俗<br>\r\n> 以鲜花视美色，则孽障自消；以流水听弦歌，则性灵何害<br>\r\n> 当厄之施甘于时雨，伤心之语毒于阴冰<br>\r\n> 能容小人是大人，能培薄德是厚德<br>\r\n> <font color=\"orange\">居处必先精勤，乃能闲暇。凡事务求停妥，然后逍遥</font><br>\r\n> <font color=\"orange\">毋毁众人之名，以成一己之善。毋没天下之理，以护一己之过</font><br>\r\n> <font color=\"orange\">实处着脚，稳处下手</font><br>\r\n> 兄弟争财，父遗不尽不止；妻妾争宠，夫命不死不休<br>\r\n> 盖世功劳，当不得一个“矜”字。弥天罪恶，当不得一个“悔”字<br>\r\n> 古之学者得一善言，附于其身；今之学者得一善言，务以悦人<br>\r\n> 万理澄彻，则一心愈精而愈谨。一心凝聚，则万理愈通而愈流<br>\r\n> 语言间尽可积德，妻子间亦是修身<br>\r\n> 吉凶祸福，是天主张。毁誉予夺，是人主张。主身行己，是我主张<br>\r\n> 位尊身危，财多命殆<br>\r\n> <font color=\"orange\">天下无不是的父母，世间最难得者兄弟</font><br>\r\n> 读书者不贱，力田者不饥。积德者不倾，择交者不败<br>\r\n> 天德只是个无我，王道只是个爱人<br>\r\n> <font color=\"orange\">真圣贤决非迂腐，真豪杰断不粗疏</font><br>\r\n> 防欲如挽逆水之舟，才歇手便下流。力行如缘无枝之树，才住脚便下坠<br>\r\n> 以仁义存心，以勤俭作家，以忍让接物<br>\r\n> <font color=\"orange\">恩怕先益后损，威怕先松后紧</font><br>\r\n> 无事时戒一“偷”字，有事时戒一“乱”字<br>\r\n> 律身惟廉为宜，处世以退为尚<br>\r\n> 俭则约，约则百善俱兴；侈则肆，肆则百恶俱纵<br>\r\n> <font color=\"orange\">欲理会七尺，先理会方寸；欲理会六合，先理会一腔</font><br>\r\n> 径路窄处，留一步与人行；滋味浓处，减三分让人嗜<br>\r\n> 飘风不可以调宫商，巧妇不可以主中馈，词章之士不可以治国家<br>\r\n> <font color=\"orange\">人褊急，我受之以宽宏；人险仄，我待之以坦荡</font><br>\r\n> 工于论人者，察己常阔疏；狃于讦直者，发言多弊病<br>\r\n> <font color=\"orange\">不蹈无人之室，不入有事之门，不处藏物之所</font><br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-3"
    },
    "frontmatter": {
      "title": "格言联璧-名句-3",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-4",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-4.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-4.html",
    "content": "---\r\ntitle: 格言联璧-名句-4\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 敬守此心，则心定；敛抑其气，则气平<br>\r\n> 富以能施为德，贫以无求为德，贵以下人为德，贱以忘势为德<br>\r\n> <font color=\"orange\">要得富贵福泽，天主张由不得我。要做贤人君子，我主张由不得天</font><br>\r\n> <font color=\"orange\">爱惜精神，留他日担当宇宙。蹉跎岁月，尽此身污秽乾坤</font><br>\r\n> 为善最乐，读书便佳<br>\r\n> <font color=\"orange\">富贵家不肯从宽，必遭横祸；聪明人不肯学厚，必殀天年</font><br>\r\n> <font color=\"orange\">海阔从鱼跃，天空任鸟飞</font><br>\r\n> 事以典故为据，故当博洽，不然臆说杜撰也<br>\r\n> 敬为千圣授受真源，慎乃百年提撕紧钥<br>\r\n> 祸到休愁，也要会救；福来休喜，也要会受<br>\r\n> 庙堂之上，以养正气为先；海宇之内，以养元气为本<br>\r\n> <font color=\"orange\">凡为外所胜者，皆内不足；凡为邪所夺者，皆正不足</font><br>\r\n> 只一事不留心，便有一事不得其理；只一物不留心，便有一物不得其所<br>\r\n> 古之从仕者养人，今之从仕者养己<br>\r\n> 未用兵时，全要虚心用人；既用兵时，全要实心活人<br>\r\n> <font color=\"orange\">治家严家乃和，居乡恕乡乃睦</font><br>\r\n> <font color=\"orange\">直不犯祸，和不害义</font><br>\r\n> 困辱非忧，取困辱为忧。荣利非乐，忘荣利为乐<br>\r\n> 接人要和中有介，处事要精中有果，认理要正中有道通<br>\r\n> 意粗性躁，一事无成。心平气和，千祥骈集<br>\r\n> <font color=\"orange\">喜闻人过，不若喜闻己过；乐道己善，何如乐道人善</font><br>\r\n> <font color=\"orange\">在事者，当置身利害之外；建言者，当设身利害之中</font><br>\r\n> 人属寒微，要思矜礼他，着不得一毫傲睨的气象<br>\r\n> 果决人似忙，心中常有余闲。因循人似闲，人中常有余忙<br>\r\n> 俗语近于市，纤语近于娼，诨语近于优<br>\r\n> <font color=\"orange\">岂能尽如人意，但求不愧我心</font><br>\r\n> 能改过，则天地不怒。能安分，则鬼神无权<br>\r\n> 居官先厚民风，处事先求大体<br>\r\n> 事属暖昧，要思回护他，着不得一点攻讦的念头<br>\r\n> 名誉自屈辱中彰，德量自隐忍中大<br>\r\n> <font color=\"orange\">荆棘满野，而望收嘉禾者愚；私念满胸，而欲求福应者悖</font><br>\r\n> 心术不可得罪于天地，言行要留好样与儿孙<br>\r\n> 肆傲者纳侮，诲过者长恶，贪利者害己，纵欲者戕生<br>\r\n> <font color=\"orange\">作恶事须防鬼神知，干好事莫怕旁人笑</font><br>\r\n> 作德日休，是谓福地；居易俟命，是谓洞天<br>\r\n> 藏书可以邀友，积德可以邀天<br>\r\n> <font color=\"orange\">于福作罪，其罪非轻；于苦作福，其福最大</font><br>\r\n> 洁己方能不失己，爱民所重在亲民<br>\r\n> 供人欣赏，侪风月于烟花，是曰亵天<br>\r\n> <font color=\"orange\">宇宙内事，乃己分内事；己分内事，乃宇宙内事</font><br>\r\n> 舍事功更无学问。求性道不外文章<br>\r\n> 事事难上难，举足常虞失坠；件件想一想，浑身都是过差<br>\r\n> 怒宜实力消融，过要细心检点<br>\r\n> 经济出自学问，经济方有本源；心性见之事功，心性方为圆满<br>\r\n> 逞我机锋，借诗书以戏谑，是名侮圣<br>\r\n> 罪莫大于亵天，恶莫大于无耻；苛刻心术之恶，过莫大于深险<br>\r\n> 衣垢不湔，器缺不补，对人犹有惭色<br>\r\n> <font color=\"orange\">盛者衰之始，福者祸之基</font><br>\r\n> 国家立法，不可不严。有司行法，不可不恕<br>\r\n> \r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-4"
    },
    "frontmatter": {
      "title": "格言联璧-名句-4",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "格言联璧-名句-5",
    "path": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-5.html",
    "url": "/blogs/dushubiji/geyanlianbi/geyanlianbi-mingju-5.html",
    "content": "---\r\ntitle: 格言联璧-名句-5\r\ndate: 2025/07/01\r\ntags:\r\n - 摘抄\r\ncategories:\r\n - 读书笔记\r\n---\r\n\r\n>\r\n> 古之名望相近则相得，今之名望相近则相妒<br>\r\n> 孝莫辞劳，转眼便为人父母；善因望报，回头但看尔儿孙<br>\r\n> 理欲交争，肺腑成为吴越。物我一体，参商终是兄弟<br>\r\n> 政令之所重者人才，国家之所重者元气<br>\r\n> 父母所欲为者，我继述之；父母所重念者，我亲厚之<br>\r\n> 兄弟和其中自乐，子孙贤此外何求<br>\r\n> 造物所忌，曰刻曰巧；万类相感，以诚以忠<br>\r\n> 入瑶树琼林中皆宝，有谦德仁心者为祥<br>\r\n> 行垢不湔，德缺不补，对天岂无愧心<br>\r\n> 内不欺己，外不欺人<br>\r\n> 何思何虑，居心当如止水；勿取勿忘，为学当如流水<br>\r\n> 存养宜冲粹，近春温；省察宜谨严，近秋肃<br>\r\n> 惩忿如摧山，窒欲如填壑；惩忿如救火，窒欲如防水<br>\r\n> 奢者富不足，俭者贫有余。奢者心常贫，贫者心常富<br>\r\n> 蚕茧蛛丝，蚁封蚓结，儿女子之经营<br>\r\n> 慎言动于妻子仆隶之间，检身人于食息起居之际<br>\r\n> 宽厚者，毋使人有所恃；精明者，不使人有所容<br>\r\n> 富儿因求宦倾赀，污吏以黩货失职<br>\r\n> 问消息于蓍龟，疑团空结；祈福祉于奥灶，奢想徒劳<br>\r\n> 圣贤学问是一套，行王道必本天德；后世学问是两截，不修己只管治人<br>\r\n> 理以心得为精，故当沈潜，不然耳边口头尔<br>\r\n> <font color=\"orange\">信不足则多言</font><br>\r\n> <font color=\"orange\">立党羽，不如昭信义</font><br>\r\n> 孝子百世之宗，仁人天下之命<br>\r\n> 圣人敛福，君子考祥；作德日休，为善最乐<br>\r\n> 听断之官，成心必不可有；任事之官，成算必不可无<br>\r\n> 做大官底是一样家数，做好人底是一样家数<br>\r\n> 知足常乐，能忍自安<br>\r\n> 休诿罪于气化，一切责之人事。休过望于世间，一切求之我身<br>\r\n> 亲兄弟析箸，璧合翻作瓜分。士大夫爱钱，书香化为铜臭<br>\r\n> <font color=\"orange\">一能胜千，君子不可无此小心。吾何畏彼，丈夫不可无此大志</font><br>\r\n> 安莫安于知足，危莫危于多言<br>\r\n> 人之心胸，多欲则窄，寡欲则宽<br>\r\n> <font color=\"orange\">惟有主，则天地万物自我而立；必无私，斯上下四旁咸得其平</font><br>\r\n> 茹素虽佛氏教也，好生非上天意乎<br>\r\n> 志之所趋，无远勿届，穷山距海，不能限也<br>\r\n> 对痴人莫说梦话，防所误也；见短人莫说矮话，避所忌也<br>\r\n> 有违言为信，践言为非信者<br>\r\n> 情爱过义，子孙之灾也<br>\r\n> 勤俭治家之本，忠孝齐家之本，谨慎保家之本，诗书起家之本，积善传家之本<br>\r\n> 饱肥甘衣轻暖，不知节者损福<br>\r\n> 广积聚骄富贵，不知止者杀身<br>\r\n> <font color=\"orange\">戒久睡，久睡倦神</font><br>\r\n> 慨夏畦之劳劳，秋毫无补；悯冬烘之贸贸，春恩广覃<br>\r\n> 四海和平之福，只是随缘。一生牵惹之劳，总因好事<br>\r\n> 口不妄言，君子所以存诚<br>\r\n> 志之所向，无坚不入，锐兵固甲，不能御也<br>\r\n> 天下无不可化之人，但恐诚心未至；天下无不可为之事，只怕立志不坚<br>\r\n> ",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "格言联璧-名句-5"
    },
    "frontmatter": {
      "title": "格言联璧-名句-5",
      "date": "2025/07/01",
      "tags": [
        "摘抄"
      ],
      "categories": [
        "读书笔记"
      ]
    },
    "type": "content"
  },
  {
    "title": "JAVA并发-设计模式",
    "path": "/docs/architect/concurrent/JAVAbingfa-shejimoshi.html",
    "url": "/docs/architect/concurrent/JAVAbingfa-shejimoshi.html",
    "content": "---\r\ntitle: JAVA并发-设计模式\r\ndate: 2025/04/22\r\n---\r\n\r\n- 终止线程的设计模式\r\n\t- Two-phase Termination（两阶段终止）模式：终止标志位\r\n- 避免共享的设计模式\r\n\t- Immutability模式：只读\r\n\t- Copy-on-Write模式：写时复制\r\n\t- Thread-Specific Storage 模式：线程本地存储 ThreadLocal\r\n- 多线程版本的 if 模式\r\n\t- Guarded Suspension 模式（Guarded Wait 模式、Spin Lock 模式）：一个线程需要等待另外的线程完成后继续下一步操作\r\n\t- Balking 模式：一个线程发现另一个线程已经做了某一件相同的事，那么本线程就无需再做了，直接结束返回\r\n- 多线程分工模式\r\n\t- Thread-Per-Message 模式：为每个任务分配一个独立的线程\r\n\t- Worker Thread 模式：线程池\r\n\t- 生产者-消费者模式：核心是一个任务队列\r\n\t\t- 过饱问题：生产者生产的速度大于消费者消费的速度\r\n\t\t\t- 消费者每天能处理的量比生产者生产的少：消费者加机器\r\n\t\t\t- 消费者每天能处理的量比生产者生产的多：适当的加大队列\r\n\t\t\t- 系统高峰期生产者速度太快：生产者限流\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JAVA并发-设计模式"
    },
    "frontmatter": {
      "title": "JAVA并发-设计模式",
      "date": "2025/04/22"
    },
    "type": "content"
  },
  {
    "title": "JVM-内存模型",
    "path": "/docs/architect/jvm/JVM-nacunmoxing.html",
    "url": "/docs/architect/jvm/JVM-nacunmoxing.html",
    "content": "---\r\ntitle: JVM-内存模型\r\ndate: 2025/03/04\r\n---\r\n\r\n::: tip 介绍\r\n1. JVM 内存模型\r\n2. JVM 内存核心参数\r\n3. 存调优案例\r\n:::\r\n\r\n## JVM 内存模型\r\n\r\n![JVM 内存模型](static/JVM-内存模型-内存模型.png)\r\n\r\n## JVM 内存核心参数\r\n\r\n![JVM 核心参数](static/JVM-内存模型-核心参数.png)\r\n\r\n- 关于元空间的JVM参数有两个：`-XX:MetaspaceSize=N` 和 `-XX:MaxMetaspaceSize=N`\r\n\t- `-XX:MaxMetaspaceSize` ： 设置元空间最大值， 默认是 -1， 即不限制， 或者说只受限于本地内存大小\r\n\t- `-XX:MetaspaceSize`： 指定元空间触发Fullgc的初始阈值(元空间无固定初始大小)， 以字节为单位，默认是21M，达到该值就会触发full gc进行类型卸载\r\n\t\t- 同时收集器会对该值进行调整： 如果释放了大量的空间， 就适当降低该值； 如果释放了很少的空间， 那么在不超过 `-XX:MaxMetaspaceSize`（如果设置了的话） 的情况下， 适当提高该值\r\n\t\t- 这个跟早期jdk版本的 `-XX:PermSize` 参数意思不一样，`-XX:PermSize` 代表永久代的初始容量\r\n\t- 由于调整元空间的大小需要Full GC，这是非常昂贵的操作，如果应用在启动的时候发生大量Full GC，通常都是由于永久代或元空间发生了大小调整，基于这种情况，一般建议在JVM参数中将 MetaspaceSize 和 MaxMetaspaceSize 设置成一样的值，并设置得比初始值要大，对于 8G 物理内存的机器来说，一般我会将这两个值都设置为 256M\r\n- `-Xss` 设置越小，说明一个线程栈里能分配的栈帧就越少，但是对 JVM 整体来说能开启的线程数会更多\r\n- 尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收\r\n\r\n## 内存调优案例\r\n\r\n![JVM 内存调优案例](static/JVM-内存模型-案例.png)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JVM-内存模型",
      "lvl1": "JVM 内存模型",
      "lvl2": "JVM 内存核心参数",
      "lvl3": "内存调优案例"
    },
    "frontmatter": {
      "title": "JVM-内存模型",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "JVM-常量池",
    "path": "/docs/architect/jvm/JVM-changliangchi.html",
    "url": "/docs/architect/jvm/JVM-changliangchi.html",
    "content": "---\r\ntitle: JVM-常量池\r\ndate: 2025/03/04\r\n---\r\n\r\n::: tip 介绍\r\n1. Class 常量池与运行时常量池\r\n2. 字符串常量池\r\n3. 八种基本类型的包装类和对象池\r\n:::\r\n\r\n## Class 常量池与运行时常量池\r\n\r\n- Class 常量池与运行时常量池（`javap -v Xxx.class` -> Constant pool）：常量池中主要存放字面量和符号引用\r\n\t- Class常量池可以理解为是Class文件中的资源仓库\r\n\t\t- Class文件中除了包含类的版本、字段、方法、接口等描述信息外， 还有一项信息就是常量池(constant pool table)，用于存放编译期生成的各种字面量(Literal)和符号引用(Symbolic References)\r\n\t- 字面量：就是指由字母、数字等构成的字符串或者数值常量\r\n\t\t- 字面量只可以右值出现，所谓右值是指等号右边的值，如：int a=1 这里的a为左值，1为右值\r\n\t- 符号引用：是编译原理中的概念，是相对于直接引用来说的\r\n\t\t- 主要包括了三类常量：类和接口的全限定名；字段的名称和描述符；方法的名称和描述符\r\n\t- 运行时常量池：这些常量池现在是静态信息，只有到运行时被加载到内存后，这些符号才有对应的内存地址信息，这些常量池一旦被装入内存就变成运行时常量池\r\n\t\t- 例如，compute()这个符号引用在运行时就会被转变为compute()方法具体代码在内存中的 地址，主要通过对象头里的类型指针去转换直接引用\r\n\r\n## 字符串常量池\r\n- 字符串常量池\r\n\t- 设计思想\r\n\t\t- 字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价，作为最基础的数据类型，大量频繁的创建字符串，极大程度地影响程序的性能\r\n\t\t- JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化\r\n\t\t\t- 为字符串开辟一个字符串常量池，类似于缓存区\r\n\t\t\t- 创建字符串常量时，首先查询字符串常量池是否存在该字符串\r\n\t\t\t- 存在该字符串，返回引用实例，不存在，实例化该字符串并放入池中\r\n\t- 三种字符串操作\r\n\t\t- 直接赋值字符串（指向常量池中的引用）：`String s = \"jxch\";`\r\n\t\t\t- 这种方式创建的字符串对象，只会在常量池中\r\n\t\t\t- 创建对象s的时候，JVM会先去常量池中通过 equals(key) 方法，判断是否有相同的对象\r\n\t\t\t\t- 如果有，则直接返回该对象在常量池中的引用\r\n\t\t\t\t- 如果没有，则会在常量池中创建一个新对象，再返回引用\r\n\t\t- `String s = new String(\"jxch\");` （指向内存中的对象引用）\r\n\t\t\t- 这种方式会保证字符串常量池和堆中都有这个对象，没有就创建，最后返回堆内存中的对象引用\r\n\t\t\t- 先检查字符串常量池中是否存在字符串\r\n\t\t\t\t- 不存在，先在字符串常量池里创建一个字符串对象；再去内存中创建一个字符串对象\r\n\t\t\t\t- 存在的话，就直接去堆内存中创建一个字符串对象\r\n\t\t\t- 最后，将内存中的引用返回\r\n\t\t- `intern` 方法是一个 native 的方法\r\n\t\t\t- 如果池已经包含一个等于此String对象的字符串（equals(oject)），则返回池中的字符串\r\n\t\t\t- 否则，将intern返回的引用指向当前字符串\r\n\t\t\t\t- 在 JDK 1.7 (及以上版本) 中，由于字符串池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象（字符串不存在时不再需要重新创建实例，可以直接指向堆上的实例）\r\n\t\t\t\t- jdk1.6版本需要将字符串复制到字符串常量池里\r\n\t- 常量池的位置\r\n\t\t- Jdk1.6及之前： 有永久代, 运行时常量池在永久代，运行时常量池包含字符串常量池\r\n\t\t- Jdk1.7：有永久代，但已经逐步“去永久代”，字符串常量池从永久代里的运行时常量池分离到堆里\r\n\t\t- Jdk1.8及之后： 无永久代，运行时常量池在元空间，字符串常量池里依然在堆里\r\n\t- 设计原理：类似 HashTable ，本质上是字符串对象的引用\r\n\r\n## 八种基本类型的包装类和对象池\r\n- 八种基本类型的包装类和对象池\r\n\t- java中基本类型的包装类的大部分都实现了常量池技术 (严格来说应该叫对象池，在堆上)\r\n\t- Byte,Short,Integer,Long,Character,Boolean （另外两种浮点数类型的包装类则没有实现对象池）\r\n\t- Byte,Short,Integer,Long,Character这5种整型的包装类也只是在对应值小于等于127时才可使用对象池\r\n\t\t- 即对象不负责创建和管理大于127的这些类的对象\r\n\t\t- 一般这种比较小的数用到的概率相对较大\r\n\r\n\r\n## 字符串常量池示例\r\n\r\n```java\r\nString s1 = new String(\"he\") + new String(\"llo\");\r\nString s2 = s1.intern();\r\n \r\nSystem.out.println(s1 == s2);\r\n// 在 JDK 1.6 下输出是 false，创建了 6 个对象\r\n// 在 JDK 1.7 及以上的版本输出是 true，创建了 5 个对象 \r\n// 当然我们这里没有考虑GC，但这些对象确实存在或存在过\r\n```\r\n\r\n![字符串常量池-JDK1.7+](static/JVM-常量池-字符串常量池-JDK1.7+.png)\r\n\r\n\r\n![字符串常量池-JDK1.6](static/JVM-常量池-字符串常量池-JDK1.6.png)\r\n\r\n```java\r\nString s0=\"zhuge\"; \r\nString s1=\"zhuge\"; \r\nString s2=\"zhu\" + \"ge\";\r\nSystem.out.println( s0==s1 ); //true \r\nSystem.out.println( s0==s2 ); //true\r\n\r\nString s0=\"zhuge\";\r\nString s1=new String(\"zhuge\");\r\nString s2=\"zhu\" + new String(\"ge\");\r\nSystem.out.println( s0==s1 ); // false \r\nSystem.out.println( s0==s2 )； // false \r\nSystem.out.println( s1==s2 ); // false\r\n\r\nString a = \"a1\";\r\nString b = \"a\" + 1;\r\nSystem.out.println(a == b); // true\r\nString a = \"atrue\";\r\nString b = \"a\" + \"true\";\r\nSystem.out.println(a == b); // true\r\nString a = \"a3.4\";\r\nString b = \"a\" + 3.4;\r\nSystem.out.println(a == b); // true\r\n\r\nString a = \"ab\"; \r\nString bb = \"b\"; \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // false 由于在字符串的\"+\"连接中，有字符串引用存在，而引用的值在程序编译期是无法确定的\r\n\r\nString a = \"ab\";\r\nfinal String bb = \"b\"; \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // true 对于final修饰的变量，它在编译时被解析为常量值的一个本地拷贝存储到自己的常量池中或嵌入到它的字节码流中\r\n\r\nprivate static String getBB() { return \"b\"; }\r\nString a = \"ab\";\r\nfinal String bb = getBB(); \r\nString b = \"a\" + bb;\r\nSystem.out.println(a == b); // false JVM对于字符串引用bb，它的值在编译期无法确定，只能在程序运行期调用方法后，将方法的返回值和\"a\"来动态连接并分配地址为b\r\n\r\nString str1 = new StringBuilder(\"ja\").append(\"va\").toString();\r\nSystem.out.println(str1 == str1.intern()); //false java是关键字，在JVM初始化的相关类里肯定早就放进字符串常量池了\r\n```\r\n\r\n::: info 注意\r\nString是不可变的\r\n:::\r\n\r\n```java\r\nString s = \"a\" + \"b\" + \"c\"; //就等价于String s = \"abc\";\r\nString a = \"a\";\r\nString b = \"b\";\r\nString c = \"c\";\r\nString s1 = a + b + c;\r\n\r\n// `s1` 这个就不一样了，可以通过观察其 `JVM` 指令码发现 `s1` 的 `+` 操作会变成如下操作\r\nStringBuilder temp = new StringBuilder(); \r\ntemp.append(a).append(b).append(c);\r\nString s = temp.toString();\r\n```\r\n\r\n## 包装类对象池示例\r\n\r\n```java\r\n //5种整形的包装类Byte,Short,Integer,Long,Character的对象，\r\n //在值小于127时可以使用对象池\r\n Integer i1 = 127; //这种调用底层实际是执行的Integer.valueOf(127)，里面用到了IntegerCache对象池 \r\n Integer i2 = 127;\r\n System.out.println(i1 == i2);//输出true\r\n \r\n //值大于127时，不会从对象池中取对象\r\n Integer i3 = 128;\r\n Integer i4 = 128;\r\n System.out.println(i3 == i4);//输出false\r\n \r\n //用new关键词新生成对象不会使用对象池\r\n Integer i5 = new Integer(127);\r\n Integer i6 = new Integer(127);\r\n System.out.println(i5 == i6);//输出false\r\n \r\n //Boolean类也实现了对象池技术\r\n Boolean bool1 = true;\r\n Boolean bool2 = true;\r\n System.out.println(bool1 == bool2);//输出true\r\n \r\n //浮点类型的包装类没有实现对象池技术\r\n Double d1 = 1.0;\r\n Double d2 = 1.0;\r\n System.out.println(d1 == d2);//输出false\r\n```\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "JVM-常量池",
      "lvl1": "Class 常量池与运行时常量池",
      "lvl2": "字符串常量池",
      "lvl3": "八种基本类型的包装类和对象池",
      "lvl4": "字符串常量池示例",
      "lvl5": "包装类对象池示例"
    },
    "frontmatter": {
      "title": "JVM-常量池",
      "date": "2025/03/04"
    },
    "type": "content"
  },
  {
    "title": "1.生态",
    "path": "/docs/architect/hadoop/Hadoop-1.shengtai.html",
    "url": "/docs/architect/hadoop/Hadoop-1.shengtai.html",
    "content": "---\r\ntitle: 1.生态\r\ndate: 2025/07/01\r\n---\r\n\r\n## Hadoop 背景\r\n\r\n其实最先被这些问题困惑的并不是电商，而是 google，他需面对的挑战一点也不会比电商小\r\n* 大量的网页怎么存储\r\n* 面对的数据和计算难题\r\n\r\n2003，2004 年 Google\r\n* GFS\r\n* MapReduce\r\n\r\n为了解决上面的两大难题，google 提出了自己的简介方案，当然这解决方案是闭源的，另外\r\n还提出了两篇论文，为大量数据的存储与计算问题提供了思路。\r\n\r\n---\r\n\r\n## Hadoop 生态\r\n[Hadoop 是 apache 下面的一套开源软件平台](http://hadoop.apache.org/)\r\n\r\nHadoop 的功能：利用服务器的集群，根据用户的业务逻辑对海里信息进行处理（存储与计算）\r\nHadoop 的核心组件:\r\n* HDFS(分布式文件系统)\r\n* MAPREDUCE(分布式运行系统)\r\n* YARN(运算资源调度系统)\r\n以上就是 hadoop 最核心的部分，可是随着时间的推移，hadoop 已经不只是这些技术了，它慢慢进化成了一个生态圈\r\n\r\n![Hadoop 生态](static/生态.png)\r\n\r\n---\r\n\r\n## Hadoop 起源\r\n* Hadoop 最初是由 Apache Lucene 项目的创始人 Doug Cutting 开发的文本搜索库。Hadoop 源自始于 2002 年的 Apache Nutch 项目——一个开源的网络搜索引擎并且也是 Lucene 项目的一部分\r\n* 2004 年 Nutch 项目也模仿 GFS 开发了自己的分布式文件系统 NDFS（Nutch Distributed File System），也就是 HDFS 的前身\r\n* 2005 年，Nutch 开源实现了谷歌的 MapReduce\r\n* 2006 年 2 月，Nutch 中的 NDFS 和 MapReduce 开始独立出来，成为 Lucene 项目的一个子项目，称为 Hadoop，同时，Doug Cutting 加盟雅虎\r\n* 2008 年 1 月，HADOOP 成为 Apache 顶级项目，迎来了它的快速发展期。\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "1.生态",
      "lvl1": "Hadoop 背景",
      "lvl2": "Hadoop 生态",
      "lvl3": "Hadoop 起源"
    },
    "frontmatter": {
      "title": "1.生态",
      "date": "2025/07/01"
    },
    "type": "content"
  },
  {
    "title": "10. YARN 资源调度器",
    "path": "/docs/architect/hadoop/Hadoop-10-YARNziyuandiaoduqi.html",
    "url": "/docs/architect/hadoop/Hadoop-10-YARNziyuandiaoduqi.html",
    "content": "---\r\ntitle: 10. YARN 资源调度器\r\ndate: 2025/07/02\r\n---\r\n\r\n配置 ([官方文档](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml)):\r\n`yarn.resourcemanager.scheduler.class` 默认: `org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler`\r\n\r\n---\r\n\r\n![YARN 资源调度器](static/YARN-QUEUE.png)\r\n\r\n1. FIFO 队列缺点: 大任务会耗时太长会导致小任务得不到及时的执行\r\n2. 分为大小任务两个队列，小任务在大任务执行时也能得到及时执行\r\n    * 缺点：如果只有大任务或只有小任务，会浪费掉一部分内存资源维护另一个用不到的队列\r\n    * Apache Hadoop 原生默认的队列类型\r\n3. 公平队列：在大任务执行过程中，如果加入了小任务，那么大任务会让出部分资源给小任务执行\r\n    * 缺点：小任务需要等待大任务让出资源，得不到及时执行\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "10. YARN 资源调度器"
    },
    "frontmatter": {
      "title": "10. YARN 资源调度器",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "11.优化",
    "path": "/docs/architect/hadoop/Hadoop-11-youhua.html",
    "url": "/docs/architect/hadoop/Hadoop-11-youhua.html",
    "content": "---\r\ntitle: 11.优化\r\ndate: 2025/07/02\r\n---\r\n\r\n## 参数调优\r\n**以下参数是在用户自己的 mr 应用程序中配置就可以生效**\r\n1. `mapreduce.map.memory.mb`: 一个 Map Task 可使用的资源上限（单位:MB），默认为 1024。如果 Map Task 实际使用的资源量超过该值，则会被强制杀死。\r\n2. `mapreduce.reduce.memory.mb`: 一个 Reduce Task 可使用的资源上限（单位:MB），默认为 1024。如果 Reduce Task 实际使用的资源量超过该值，则会被强制杀死。\r\n3. `mapreduce.map.cpu.vcores`: 每个 Map task 可使用的最多 cpu core 数目, 默认值: 1\r\n4. `mapreduce.reduce.cpu.vcores`: 每个 Reduce task 可使用的最多 cpu core 数目, 默认值: 1\r\n5. `mapreduce.map.java.opts`: Map Task 的 JVM 参数，你可以在此配置默认的 java heap size 等参数, e.g. \"-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc\" （@taskid@ 会被 Hadoop 框架自动换为相应的 taskid）, 默认值: \"\"\r\n6. `mapreduce.reduce.java.opts`: Reduce Task 的 JVM 参数，你可以在此配置默认的 java heap size 等参数, e.g. \"-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc\", 默认值: \"\"\r\n\r\n**应该在 yarn 启动之前就配置在服务器的配置文件中才能生效**\r\n1. `yarn.scheduler.minimum-allocation-mb`: 1024 给应用程序 container 分配的最小内存\r\n2. `yarn.scheduler.maximum-allocation-mb`: 8192 给应用程序 container 分配的最大内存\r\n3. `yarn.scheduler.minimum-allocation-vcores`: 1 最小核数\r\n4. `yarn.scheduler.maximum-allocation-vcores`: 32 最大核数\r\n5. `yarn.nodemanager.resource.memory-mb`: 8192 nodemanager resource 内存大小\r\n\r\n**shuffle 性能优化的关键参数，应在 yarn 启动之前就配置好**\r\n1. `mapreduce.task.io.sort.mb`: 100  shuffle 的环形缓冲区大小，默认 100m\r\n2. `mapreduce.map.sort.spill.percent`: 0.8  环形缓冲区溢出的阈值，默认 80%\r\n\r\n**可靠性相关**\r\n1. `mapreduce.map.speculative`: 是否为 Map Task 打开推测执行机制，默认为 false \r\n2. `mapreduce.reduce.speculative`: 是否为 Reduce Task 打开推测执行机制，默认为 false\r\n3. `mapreduce.job.user.classpath.first` & `mapreduce.task.classpath.user.precedence`：当同一个 class 同时出现在用户 jar 包和 hadoop jar 中时，优先使用哪个 jar 包中的 class，默认为 false，表示优先使用 hadoop jar 中的 class\r\n4. `mapreduce.input.fileinputformat.split.minsize`: FileInputFormat 做切片时的最小切片大小，\r\n5. `mapreduce.input.fileinputformat.split.maxsize`: FileInputFormat 做切片时的最大切片大小 (切片的默认大小就等于 blocksize，即 134217728)\r\n\r\n推测执行机制就是同时执行两台机器，选最先出结果的机器的结果，杀死另一台机器的任务，防止出现其中一台机器计算速度太慢的情况\r\n\r\n**压缩**\r\n* 如果是 IO 密集形任务，可以考虑开启压缩\r\n\r\n## 代码优化\r\n1. 输出的时候不要频繁创建对象\r\n```java\r\nfor(String word: words) {\r\n    context.write(new Text(word),new IntWritable(1));\r\n}\r\n// 改为\r\nText text = new Text(\"\");\r\nIntWritable count = new IntWritable(1);\r\nfor(String word: words) {\r\n    context.write(text.set(word), count);\r\n}\r\n```\r\n2. 尽量使用Combiner机制，减轻Reduce的压力: `job.setCombinerClass(XXReducer.class);`\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "11.优化",
      "lvl1": "参数调优",
      "lvl2": "代码优化"
    },
    "frontmatter": {
      "title": "11.优化",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "11.1. 数据压缩",
    "path": "/docs/architect/hadoop/Hadoop-11.1.shujuyasuo.html",
    "url": "/docs/architect/hadoop/Hadoop-11.1.shujuyasuo.html",
    "content": "---\r\ntitle: 11.1. 数据压缩\r\ndate: 2025/07/02\r\n---\r\n\r\n## 原则\r\nMapReduce 支持压缩，通过压缩算法对 mapper 或者 reducer 的最终数据结果进行压缩\r\n* 好处：减少了磁盘 io，提高了 MR 获取数据的速度，节省了磁盘空间\r\n* 坏处：压缩需要增加 cpu 的运算负担\r\n\r\n原则:\r\n* 运算密集的 job，少用压缩，尤其是中间数据\r\n* Io 密集的 job，可以用压缩，尤其是最终归档数据\r\n\r\n[官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Data_Compression)\r\n\r\n---\r\n\r\n## Mapper 输出压缩\r\n配置文档:\r\n* `mapreduce.map.output.compress=false`\r\n* `mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec`\r\n\r\n在代码中进行配置:\r\n```java\r\nconf.setBoolean(Job.MAP_OUTPUT_COMPRESS, true);\r\nconf.setClass(Job.MAP_OUTPUT_COMPRESS_CODEC, GzipCodec.class, CompressionCodec.class);\r\n```\r\n\r\n## Reduce 输出压缩\r\n配置文档:\r\n* `mapreduce.output.fileoutputformat.compress=false `\r\n* `mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec `\r\n* `mapreduce.output.fileoutputformat.compress.type=RECORD`\r\n\r\n在代码中进行配置:\r\n```java\r\nJob job = Job.getInstance(conf);\r\nFileOutputFormat.setCompressOutput(job, true);\r\nFileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);\r\n```\r\n\r\n---\r\n\r\n![支持的压缩类型](static/Compression.jpg)\r\n\r\n不建议使用配置文档的方式，不灵活，可以使用代码进行配置\r\n[配置文件官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "11.1. 数据压缩",
      "lvl1": "原则",
      "lvl2": "Mapper 输出压缩",
      "lvl3": "Reduce 输出压缩"
    },
    "frontmatter": {
      "title": "11.1. 数据压缩",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12. Hive 特点",
    "path": "/docs/architect/hadoop/Hadoop-12-Hive-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-12-Hive-tedian.html",
    "content": "---\r\ntitle: 12. Hive 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n\r\n## Hive 简介\r\nHive 是属于 Hadoop 的数据仓库工具，可以让使用者将结构化数据映射成一张张数据库的表，让用户能通过 SQL 来查询数据。用户出 SQL 命令给 hive，<font color=\"orange\">hive 把 SQL 语句转换成 MapReduce 查询分析存储在 hdfs 上的数据</font>。\r\n\r\n优点:\r\n* 直接使用 MapReuce 实现复杂查询比较复杂，而 Hive 提供 SQL 的语法，提高了开发的便捷程度\r\n* 直接使用 SQL 查询，减少了人员的学习成本，哪怕是数据库操作人员能很快上手\r\n* HIVE 提供很好的扩展性，方便用户增加功能\r\n\r\n## Hive 与传统数据库对比\r\n![Hive 与传统数据库对比](static/Hive-SQL-Compare.png)\r\n\r\n* **查询语言**: 由于 SQL 被广泛的应用在数据仓库中，因此，专门针对 Hive 的特性设计了类 SQL 的查询语言 HQL。熟悉 SQL 开发的开发者可以很方便的使用 Hive 进行开发。\r\n* **数据存储位置**: Hive 是建立在 Hadoop 之上的，所有 Hive 的数据都是存储在 HDFS 中的。而数据库则可以将数据保存在块设备或者本地文件系统中。\r\n* **数据格式**: Hive 中没有定义专门的数据格式，数据格式可以由用户指定，用户定义数据格式需要指定三个属性：**列分隔符**（通常为空格、”\\t”、”\\x001″）、**行分隔符**（”\\n”）以及**读取文件数据的方法**（Hive 中默认有三个文件格式 `TextFile`，`SequenceFile` 以及 `RCFile`）。由于在加载数据的过程中，不需要从用户数据格式到 Hive 定义的数据格式的转换，因此，**Hive 在加载的过程中不会对数据本身进行任何修改**，而只是将数据内容复制或者移动到相应的 HDFS 目录中。而在数据库中，不同的数据库有不同的存储引擎，定义了自己的数据格式。所有数据都会按照一定的组织存储，因此，数据库加载数据的过程会比较耗时。\r\n* **数据更新**: 由于 Hive 是针对数据仓库应用设计的，而数据仓库的内容是**读多写少**的。因此，**Hive 中不支持对数据的改写和添加**，所有的数据都是在加载的时候中确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO ... VALUES 添加数据，使用 UPDATE ... SET 修改数据。\r\n* **索引**: 之前已经说过，Hive 在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些 Key 建立索引。Hive 要访问数据中满足条件的特定值时，需要**暴力扫描整个数据**，因此访问延迟较高。由于 `MapReduce` 的引入， Hive 可以**并行访问数据**，因此即使没有索引，**对于大数据量的访问，Hive 仍然可以体现出优势**。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了 **Hive 不适合在线数据查询**。\r\n* **执行**: Hive 中大多数查询的执行是通过 Hadoop 提供的 `MapReduce` 来实现的（类似 select * from tbl 的查询不需要 MapReduce）。而数据库通常有自己的执行引擎。\r\n* **执行延迟**: 之前提到，Hive 在查询数据的时候，**由于没有索引，需要扫描整个表，因此延迟较高**。另外一个导致 Hive 执行延迟高的因素是 MapReduce 框架。由于 **MapReduce 本身具有较高的延迟**，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，**当数据规模大到超过数据库的处理能力的时候，Hive 的并行计算显然能体现出优势**。\r\n* **可扩展性**: 由于 Hive 是建立在 Hadoop 之上的，因此 **Hive 的可扩展性是和 Hadoop 的可扩展性是一致的**。而数据库由于 ACID 语义的严格限制，扩展行非常有限。目前最先进的并行数据库 Oracle 在理论上的扩展能力也只有 100 台左右。\r\n* **数据规模**: 由于 Hive 建立在集群上并可以利用 MapReduce 进行并行计算，因此可以支持**很大规模的数据**；对应的，数据库可以支持的数据规模较小。\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12. Hive 特点",
      "lvl1": "Hive 简介",
      "lvl2": "Hive 与传统数据库对比"
    },
    "frontmatter": {
      "title": "12. Hive 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.1. Hive 窗口函数",
    "path": "/docs/architect/hadoop/Hadoop-12.1.Hivechuangkouhanshu.html",
    "url": "/docs/architect/hadoop/Hadoop-12.1.Hivechuangkouhanshu.html",
    "content": "---\r\ntitle: 12.1. Hive 窗口函数\r\ndate: 2025/07/02\r\n---\r\n\r\n```sql\r\nCREATE TABLE window_demo(cookieid STRING, createtime STRING, pv INT)\r\nROW FORMAT DELIMITED\r\nFIELDS TERMINATED BY ',';\r\n\r\nload data local inpath '/testdata/window' into table window_demo;\r\n```\r\n\r\n## SUM\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime) AS pv1, -- 默认为从起点到当前行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS pv2, --从起点到当前行，结果同 pv1\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN 3 PRECEDING AND CURRENT ROW) AS pv3, --当前行+往前 3 行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING) AS pv4, --当前行+往前 3 行+往后 1 行\r\nSUM(pv) OVER(PARTITION BY cookieid ORDER BY createtime \r\nROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS pv5 --当前行+往后所有行\r\nFROM test1;\r\n```\r\n\r\n* 如果不指定 `ROWS BETWEEN`, 默认统计窗口为从起点到当前行\r\n* 如果不指定 `ORDER BY`, 不仅分区内没有排序, 则将分组内所有值累加\r\n* `max()` 函数无论有没有 `order by` 都是计算整个分区的最大值\r\n\r\n关键是理解 `ROWS BETWEEN` 含义, 也叫做 window 子句：\r\n* `PRECEDING`：往前\r\n* `FOLLOWING`：往后\r\n* `CURRENT ROW`：当前行\r\n* `UNBOUNDED`：无边界\r\n* `UNBOUNDED PRECEDING`：表示从最前面的起点开始 \r\n* `UNBOUNDED FOLLOWING`：表示到最后面的终点\r\n\r\n## NTILE\r\n`NTILE(n)`，用于将分组数据按照顺序切分成 n 片，返回当前切片值，`NTILE` 不支持 `ROWS BETWEEN`\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nNTILE(2) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile1, --分组内将数据分成 2 片\r\nNTILE(3) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile2, --分组内将数据分成 3 片\r\nNTILE(4) OVER(PARTITION BY cookieid ORDER BY createtime) AS ntile3 --将所有数据分成 4 片\r\nFROM window_demo;\r\n```\r\n\r\n## ROW_NUMBER\r\n`ROW_NUMBER()` 从 1 开始，按照顺序，生成分组内记录的序列\r\n`ROW_NUMBER()` 的应用场景非常多，比如获取分组内排序第一的记录\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY pv desc) AS rn\r\nFROM window_demo;\r\n```\r\n\r\n## RANK DENSE_RANK\r\n`RANK()` 生成数据项在分组中的排名，排名相等会在名次中留下空位\r\n`DENSE_RANK()` 生成数据项在分组中的排名，排名相等会在名次中不会留下空位\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nRANK() OVER(PARTITION BY cookieid ORDER BY pv desc) AS rank1, \r\nDENSE_RANK() OVER(PARTITION BY cookieid ORDER BY pv desc) AS d_rank2, \r\nROW_NUMBER() OVER(PARTITION BY cookieid ORDER BY pv DESC) AS rn3\r\nFROM window_demo\r\n```\r\n\r\n## CUME_DIST\r\n`cume_dist` 返回 小于等于 当前值的行数/分组内总行数\r\n\r\n```sql\r\nSELECT cookieid,createtime,pv, \r\nround(CUME_DIST() OVER(ORDER BY pv),2) AS cd1, \r\nround(CUME_DIST() OVER(PARTITION BY cookieid ORDER BY pv),2) AS cd2\r\nFROM window_demo;\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.1. Hive 窗口函数",
      "lvl1": "SUM",
      "lvl2": "NTILE",
      "lvl3": "ROW_NUMBER",
      "lvl4": "RANK DENSE_RANK",
      "lvl5": "CUME_DIST"
    },
    "frontmatter": {
      "title": "12.1. Hive 窗口函数",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.2. Hive 常用命令 dd 与 dmll",
    "path": "/docs/architect/hadoop/Hadoop-12.2.Hivechangyongminglingddyudmll.html",
    "url": "/docs/architect/hadoop/Hadoop-12.2.Hivechangyongminglingddyudmll.html",
    "content": "---\r\ntitle: 12.2. Hive 常用命令 dd 与 dmll\r\ndate: 2025/07/02\r\n---\r\n\r\n## 创建表\r\n```sql\r\nCREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name\r\n    [(col_name data_type [COMMENT col_comment], ...)]\r\n    [COMMENT table_comment]\r\n    [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]\r\n    [CLUSTERED BY (col_name, col_name, ...)\r\n    [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]\r\n    [ROW FORMAT row_format]\r\n    [STORED AS file_format]\r\n    [LOCATION hdfs_path]\r\n```\r\n\r\n### 创建内部表\r\n删除表的时候数据也会被删除\r\n\r\n```sql\r\ncreate table if not exists mytable(sid int ,sname string) \r\nrow format delimited\r\nfields terminated by ',' stored as textfile;\r\n\r\nshow tables;\r\n```\r\n\r\n上传数据: `hdfs dfs -put a /user/hive/warehouse/test.db/mytable/`\r\n`select * from mytable`\r\n\r\n### 创建外部表\r\n删除表的时候数据不会被删除\r\n\r\n```sql\r\ncreate external table mytable_ext(sid int ,sname string)\r\nrow format delimited\r\nfields terminated by ',' location '/dbdata'\r\n\r\nshow tables;\r\nselect * from mytable_ext;\r\n```\r\n\r\n### 创建分区表\r\n```sql\r\ncreate table person_p(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited fields\r\nterminated by ','stored as textfile;\r\n\r\nload data local inpath '/testdata/a' into table person_p partition(sex='nan');\r\nload data local inpath '/testdata/a' into table person_p partition(sex='nv');\r\n\r\nshow tables;\r\nselect * from person_p;\r\n```\r\n\r\n### 创建动态分区表\r\n```sql\r\nset hive.exec.dynamic.partition.mode=nonstrict;\r\n\r\ncreate table person_p2(sid int ,sname string) partitioned by(sex string) row format delimited\r\nfields terminated by ','stored as textfile;\r\n\r\ninsert into person_p2 partition(sex) select sid,sname,sex from person_p;\r\n\r\nshow tables;\r\nselect * from person_p2;\r\n```\r\n\r\n## 修改表\r\n```sql\r\nALTER TABLE table_name ADD [IF NOT EXISTS] partition_spec [ LOCATION 'location1' ] partition_spec [ LOCATION 'location2' ] ...\r\npartition_spec:\r\n: PARTITION (partition_col = partition_col_value, partition_col = partiton_col_value, ...)\r\n\r\nALTER TABLE table_name DROP partition_spec, partition_spec,...\r\n```\r\n\r\n### 增加分区\r\n```sql\r\ncreate table person_p3(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited\r\nfields terminated by ','stored as textfile;\r\n\r\nalter table person_p3 add partition(sex='1') partition(sex='2');\r\n\r\nload data local inpath '/testdata/a' into table person_p3 partition(sex='1');\r\nload data local inpath '/testdata/a' into table person_p3 partition(sex='2');\r\n\r\nshow tables;\r\nselect * from person_p3;\r\n```\r\n\r\n### 删除分区\r\n```sql\r\nalter table person_p3 drop partition(sex='2')\r\n```\r\n\r\n###  重命名表\r\n```sql\r\nALTER TABLE person_p3 RENAME TO person_p4;\r\n```\r\n\r\n### 新增列\r\nADD 是代表新增一字段，字段位置在所有列后面(partition 列前)，REPLACE 则是表示替换表中所有字段。\r\n```sql\r\nALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...\r\n```\r\n\r\n```sql\r\ncreate table person_p5(sid int ,sname string) partitioned by(sex string) \r\nrow format delimited\r\nfields terminated by \r\n\r\nAlter table person_p5 add COLUMNS (age int);\r\ndesc person_p5;\r\n\r\nAlter table person_p5 REPLACE COLUMNS (age2 int);\r\ndesc person_p5;\r\n```\r\n\r\n### 修改列\r\n```sql\r\nALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type\r\n[COMMENT col_comment] [FIRST|AFTER column_name]\r\n```\r\n\r\n```sql\r\nalter table person_p5 change column age2 age2 string;\r\n\r\ndesc person_p5;\r\n```\r\n\r\n## 显示命令\r\n```sql\r\nshow tablese;\r\nshow databasese;\r\nshow partitions table_namee;\r\nshow functionse;\r\ndesc extended table_name;\r\ndesc formatted table_name;\r\n```\r\n\r\n## Load 操作\r\n```sql\r\nLOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO\r\nTABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]\r\n```\r\n\r\n## Insert\r\n```sql\r\nINSERT INTO TABLE VALUES(XX,YY,ZZ);\r\n\r\nINSERT OVERWRITE [INTO] TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)]\r\nselect_statement1 \r\n```\r\n\r\n## SELECT\r\n```sql\r\nSELECT [ALL | DISTINCT] select_expr, select_expr, ... FROM table_reference\r\n[WHERE where_condition]\r\n[GROUP BY col_list [HAVING condition]]\r\n[CLUSTER BY col_list\r\n| [DISTRIBUTE BY col_list] [SORT BY| ORDER BY col_list]\r\n]\r\n[LIMIT number]\r\n```\r\n\r\n1. `order by` 会对输入做全局排序，因此只有一个 reducer，会导致当输入规模较大时，需要较长的计算时间。\r\n2. `sort by` 不是全局排序，其在数据进入 reducer 前完成排序。因此，如果用 `sort by` 进行排序，并且设置 `mapred.reduce.tasks>1`，则 `sort by` 只保证每个 reducer 的输出有序，**不保证全局有序**。\r\n3. `distribute by`(字段) 根据指定的字段将数据分到不同的 reducer，且分发算法是 **hash 散列**。\r\n4. `Cluster by`(字段) 除了具有 `Distribute by` 的功能外，还会对该字段进行**排序**。\r\n\r\n因此，如果分桶和 sort 字段是同一个时，此时，`cluster by = distribute by + sort by`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.2. Hive 常用命令 dd 与 dmll",
      "lvl1": "创建表",
      "lvl2": "修改表",
      "lvl3": "显示命令",
      "lvl4": "Load 操作",
      "lvl5": "Insert",
      "lvl6": "SELECT"
    },
    "frontmatter": {
      "title": "12.2. Hive 常用命令 dd 与 dmll",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.3. Hive 分桶",
    "path": "/docs/architect/hadoop/Hadoop-12.3.Hivefentong.html",
    "url": "/docs/architect/hadoop/Hadoop-12.3.Hivefentong.html",
    "content": "---\r\ntitle: 12.3. Hive 分桶\r\ndate: 2025/07/02\r\n---\r\n\r\n## 创建桶表\r\n```sql\r\nset hive.enforce.bucketing=true;\r\nset mapreduce.job.reduces=4;\r\n\r\ndrop table person_buck;\r\n\r\ncreate table person_buck(sid int ,sname string)\r\npartitioned by(sex string)\r\nclustered by(sid)\r\nsorted by(sid DESC)\r\ninto 4 buckets\r\nrow format delimited\r\nfields terminated by ',';\r\n\r\ninsert into person_buck partition(sex) select sid,sname,sex from person_p;\r\n```\r\n\r\n## 桶表抽样查询\r\n```sql\r\nselect * from table_name tablesample(bucket X out of Y on field);\r\n\r\nselect * from person_buck tablesample(bucket 1 out of 2 on sid);\r\n```\r\n\r\n* X 表示从哪个桶中开始抽取\r\n* Y 表示相隔多少个桶再次抽取\r\n    * Y 必须为分桶数量的倍数或者因子，比如分桶数为 6，Y 为 6，则表示只从桶中抽取 1 个 bucket 的数据；若 Y 为 3，则表示从桶中抽取 6/3 (2)个 bucket 的数据\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.3. Hive 分桶",
      "lvl1": "创建桶表",
      "lvl2": "桶表抽样查询"
    },
    "frontmatter": {
      "title": "12.3. Hive 分桶",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
    "path": "/docs/architect/hadoop/Hadoop-12.4.HiveDemodaxiaoxiezhuanhuanUDFzidingyihanshu.html",
    "url": "/docs/architect/hadoop/Hadoop-12.4.HiveDemodaxiaoxiezhuanhuanUDFzidingyihanshu.html",
    "content": "---\r\ntitle: 12.4. Hive Demo 大小写转换 UDF 自定义函数\r\ndate: 2025/07/02\r\n---\r\n\r\n## pom.xml\r\n```xml\r\n<dependency>\r\n    <groupId>org.apache.hive</groupId>\r\n    <artifactId>hive-exec</artifactId>\r\n</dependency>\r\n```\r\n\r\n## Lower.java\r\n```java\r\npublic final class Lower extends UDF {\r\n    public Text evaluate(final Text s){\r\n        if(s==null){return null;}\r\n        return new Text(s.toString().toLowerCase());\r\n    }\r\n}\r\n```\r\n\r\n## 测试\r\n将代码打成 jar 包上传到服务器\r\n\r\n```sql\r\nadd JAR /path/to/udf.jar\r\n\r\ncreate temporary function tolowercase as 'cn.enjoy.hive.Lower'\r\n\r\nselect tolowercase(\"AAA\");\r\nselect sid,tolowercase(sname),sex from person_p;\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
      "lvl1": "pom.xml",
      "lvl2": "Lower.java",
      "lvl3": "测试"
    },
    "frontmatter": {
      "title": "12.4. Hive Demo 大小写转换 UDF 自定义函数",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.5.1. Hive 不支援 10 验证类型",
    "path": "/docs/architect/hadoop/Hadoop-12.5.1.Hivebuzhiyuan10yanzhengleixing.html",
    "url": "/docs/architect/hadoop/Hadoop-12.5.1.Hivebuzhiyuan10yanzhengleixing.html",
    "content": "---\r\ntitle: 12.5.1. Hive 不支援 10 验证类型\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger\r\n- 报错：PSQLException: 不支援 10 验证类型。请核对您已经组态 pg_hba.conf 文件包含客户端的IP位址或网路区段，以及驱动程序所支援的验证架构模式已被支援\r\n:::\r\n\r\n原因：驱动不兼容（需要更新驱动版本）\r\n\r\n1. 去官网或者使用Maven下载新的驱动jar包\r\n2. 添加到 hive/lib 目录中\r\n3. 将目录中旧的驱动jar包移出 hive/lib 目录\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.5.1. Hive 不支援 10 验证类型"
    },
    "frontmatter": {
      "title": "12.5.1. Hive 不支援 10 验证类型",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "12.5.2. Hive WstxParsingException",
    "path": "/docs/architect/hadoop/Hadoop-12.5.2.HiveWstxParsingException.html",
    "url": "/docs/architect/hadoop/Hadoop-12.5.2.HiveWstxParsingException.html",
    "content": "---\r\ntitle: 12.5.2. Hive WstxParsingException\r\ndate: 2025/07/02\r\n---\r\n\r\n:::danger\r\n- Hive-WstxParsingException: Illegal character entity: expansion character\r\n:::\r\n\r\n`hive-site.xml` 文件第 3215 行左右有一个特殊字符 (`&#8;`)，删掉它:\r\n\r\n```xml\r\n214      <description>\r\n3215       Ensures commands with OVERWRITE (such as INSERT OVERWRITE) acquire Exclusive      locks for&#8;transactional tables.  This ensures that inserts (w/o overwrite) runni     ng concurrently\r\n3216       are not hidden by the INSERT OVERWRITE.\r\n3217     </description>\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "12.5.2. Hive WstxParsingException"
    },
    "frontmatter": {
      "title": "12.5.2. Hive WstxParsingException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13. HBase 特点",
    "path": "/docs/architect/hadoop/Hadoop-13-HBase-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-13-HBase-tedian.html",
    "content": "---\r\ntitle: 13. HBase 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n## HBase 列式数据库简介\r\nHBase 是一个开源的非关系型分布式数据库（NoSql） 原型是 Google 的 BigTable 论文，受到了该论文思想的启发，目前作为Hadoop 的子项目来开发维护。它介于 nosql 和 RDBMS 之间，仅能通过主键(row key)和主键的 range 来检索数据，可通过 hive 支持来实现多表 join 等复杂操作。\r\n\r\n## HBase 特点\r\n\r\n* **海量存储**: Hbase 适合存储 PB 级别的海量数据，在 PB 级别的数据以及采用廉价 PC 存储的情况下，能在几十到百毫秒内返回数据。这与 Hbase 的极易扩展性息息相关。正式因为 Hbase 良好的扩展性，才为海量数据的存储提供了便利。\r\n* **列式存储**: 这里的列式存储其实说的是列族（ColumnFamily）存储，Hbase 是根据列族来存储数据的。列族下面可以有非常多的列，列族在创建表的时候就必须指定。\r\n* **极易扩展**: Hbase 的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer）的扩展，一个是基于存储的扩展（HDFS）。通过横向添加RegionSever 的机器，进行水平扩展，提升 Hbase 上层的处理能力，提升 Hbsae 服务更多 Region 的能力。\r\n* **高并发**: 由于目前大部分使用 Hbase 的架构，都是采用的廉价 PC，因此单个 IO 的延迟其实并不小，一般在几十到上百 ms 之间。这里说的高并发，主要是在并发的情况下，Hbase 的单个 IO 延迟下降并不多。能获得高并发、低延迟的服务。\r\n* **稀疏**: 稀疏主要是针对 Hbase 列的灵活性，在列族中，你可以指定任意多的列，在列数据为空的情况下，是不会占用存储空间的。\r\n\r\n适用场景:\r\n* 持久化存储大量数据（TB、PB）\r\n* 对扩展伸缩性有要求\r\n* 需要良好的随机读写性能\r\n* 简单的业务 KV 查询(不支持复杂的查询比如表关联等)\r\n* 能够同时处理结构化和非结构化的数据\r\n* 订单流水、交易记录、需要记录历史版本的数据等\r\n\r\n不适用场景:\r\n* 几千、几百万那种还不如使用 RDBMS\r\n* 需要类型列\r\n* 需要跨行事务，目前 HBase 只支持单行事务\r\n* SQL 查询\r\n\r\n## HBase 数据模型\r\n<table>\r\n    <tr>\r\n        <th>Row Key</th>\r\n        <th>Time Stamp</th>\r\n        <th>CF1</th>\r\n        <th>CF2</th>\r\n        <th>CF3</th>\r\n    </tr>\r\n    <tr>\r\n        <td rowspan=\"3\">rk00001</td>\r\n        <td>t1</td>\r\n        <td></td>\r\n        <td>CF2:q1=val1</td>\r\n        <td>CF3:q2=val2</td>\r\n    </tr>\r\n    <tr>\r\n        <td>t2</td>\r\n        <td></td>\r\n        <td></td>\r\n        <td></td>\r\n    </tr>\r\n    <tr>\r\n        <td>t3</td>\r\n        <td>CF1:q3=val3</td>\r\n        <td></td>\r\n        <td></td>\r\n    </tr>\r\n</table>\r\n\r\n* ROW KEY\r\n    * 决定一行数据\r\n    * 按照字典顺序排序的\r\n    * ROW KEY 只能存储 64k 的字节数据\r\n* Column Family 列族 & qualifier 列\r\n    * HBase 表中的每个列都归属于某个列族，列族必须作为表模式(schema)定义的一部分预先给出。`create 'test', 'course'`\r\n    * 列名以列族作为前缀， 每个“列族”都可以有多个列成员(column) ； 如 `course:math`,`course:english`, 新的列族成员（列）可以随后按需、动态加入；\r\n    * 权限控制、存储以及调优都是在列族层面进行的；\r\n    * HBase 把同一列族里面的数据存储在同一目录下，由几个文件保存\r\n* Timestamp 时间戳\r\n    * 在HBase 每个 cell 存储单元对同一份数据有多个版本，根据唯一的时间戳来区分每个版本之间的差异，不同版本的数据按照时间倒序排序，最新的数据版本排在最前面\r\n    * 时间戳的类型是 64 位整型\r\n    * 时间戳可以由HBase(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间\r\n    * 时间戳也可以由客户显式赋值\r\n* Cell 单元格\r\n    * 由行和列的坐标交叉决定\r\n    * 单元格是有版本的\r\n    * 单元格的内容是未解析的字节数组\r\n    * 由`{rowkey，column(=<family> +<qualifier>)，version}`唯一确定的单元\r\n    * Cell 中的数据是没有类型的，全部是二进制字节码形式存储\r\n\r\n## HBase 架构\r\n![HBase 架构](static/HBase.png)\r\n\r\n* **Client**: 包含了访问 Hbase 的接口，另外 Client 还维护了对应的 cache 来加速 HBase 的访问，比如 cache 的.META.元数据的信息\r\n* **Zookeeper**: HBase 通过 Zookeeper 来做 master 的高可用、RegionServer 的监控、元数据的入口以及集群配置的维护等工作\r\n    * 通过 Zoopkeeper 来保证集群中只有1个 master 在运行，如果 master 异常，会通过竞争机制\r\n    * 产生新的 master 提供服务\r\n    * 通过 Zoopkeeper 来监控 RegionServer 的状态，当 RegionSevrer 有异常的时候，通过回调的形式通知 Master RegionServer 上下线的信息\r\n    * 通过 Zoopkeeper 存储元数据的统一入口地址\r\n* **HMaster**: \r\n    * 为 RegionServer 分配 Region\r\n    * 维护整个集群的负载均衡\r\n    * 维护集群的元数据信息\r\n    * 发现失效的 Region，并将失效的 Region 分配到正常的 RegionServer 上\r\n    * 当 RegionSever 失效的时候，协调对应 Hlog 的拆分\r\n* **HregionServer**: 直接对接用户的读写请求，是真正的“干活”的节点\r\n    * 管理 master 为其分配的 Region\r\n    * 处理来自客户端的读写请求\r\n    * 负责和底层 HDFS 的交互，存储数据到 HDFS\r\n    * 负责 Region 变大以后的拆分\r\n    * 负责 Storefile 的合并工作\r\n* **HDFS**: 为 Hbase 提供最终的底层数据存储服务，同时为 HBase 提供高可用（Hlog 存储在 HDFS）的支持\r\n    * 提供元数据和表数据的底层分布式存储服务\r\n    * 数据多副本，保证的高可靠和高可用性\r\n\r\n## HBase 中的角色\r\n\r\n* **HMaster**\r\n    * 监控 RegionServer\r\n    * 处理 RegionServer 故障转移\r\n    * 处理元数据的变更\r\n    * 处理 region 的分配或转移\r\n    * 在空闲时间进行数据的负载均衡\r\n    * 通过 Zookeeper 发布自己的位置给客户端\r\n* **RegionServer**\r\n    * 负责存储 HBase 的实际数据\r\n    * 处理分配给它的 Region\r\n    * 刷新缓存到 HDFS\r\n    * 维护 Hlog\r\n    * 执行压缩\r\n    * 负责处理 Region 分片\r\n* **Write-Ahead logs (WAL)**\r\n    * HBase 的修改记录，当对 HBase 读写数据的时候，数据不是直接写进磁盘，它会在内存中保留一段时间（时间以及数据量阈值可以设定）。但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入内存中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。\r\n* **Region**\r\n    * Hbase 表的分片，HBase 表会根据 RowKey 值被切分成不同的 region 存储在 RegionServer 中，在一个 RegionServer 中可以有多个不同的 region\r\n* **Store**\r\n    * HFile 存储在 Store 中，一个 Store 对应 HBase 表中的一个列族(列簇， ColumnFamily)\r\n* **MemStore**\r\n    * 顾名思义，就是内存存储，位于内存中，用来保存当前的数据操作，所以当数据保存在 WAL 中之后，RegsionServer 会在内存中存储键值对\r\n* **HFile**\r\n    * 这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。StoreFile 是以 HFile 的形式存储在 HDFS 的\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13. HBase 特点",
      "lvl1": "HBase 列式数据库简介",
      "lvl2": "HBase 特点",
      "lvl3": "HBase 数据模型",
      "lvl4": "HBase 架构",
      "lvl5": "HBase 中的角色"
    },
    "frontmatter": {
      "title": "13. HBase 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.1. HBase 常用命令",
    "path": "/docs/architect/hadoop/Hadoop-13.1.HBasechangyongmingling.html",
    "url": "/docs/architect/hadoop/Hadoop-13.1.HBasechangyongmingling.html",
    "content": "---\r\ntitle: 13.1. HBase 常用命令\r\ndate: 2025/07/02\r\n---\r\n\r\n`hbase shell` 进入shell\r\n`help` 命令查看帮助文档\r\n`list` 命令查看数据库中的表\r\n\r\n## 创建表\r\n创建 person 表，包含 info, data 两个列族\r\n然后查看表结构\r\n```sql\r\ncreate 'person', 'info', 'data'\r\ndescribe 'person'\r\n```\r\n\r\n## 插入数据\r\n```sql\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加name 列标示符，值为zhangsan\r\nput 'person', 'rk0001', 'info:name', 'zhangsan'\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加gender 列标示符，值为female\r\nput 'person', 'rk0001', 'info:gender', 'female'\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族info 中添加age 列标示符，值为20\r\nput 'person', 'rk0001', 'info:age', 20\r\n\r\n-- 向person 表中插入信息，row key 为rk0001，列族data 中添加pic 列标示符，值为picture\r\nput 'person', 'rk0001', 'data:pic', 'picture'\r\n```\r\n\r\n## 查询数据\r\n`get` 适用于获取单个记录或少量记录的场景，`scan` 适用于获取大量记录的场景\r\n```sql\r\n-- 获取person 表中row key 为rk0001 的所有信息\r\nget 'person', 'rk0001'\r\n\r\n-- 获取person 表中row key 为rk0001，info 列族的所有信息\r\nget 'person', 'rk0001', 'info'\r\n\r\n-- 获取person 表中row key 为rk0001，info 列族的name、age 列标示符的信息\r\nget 'person', 'rk0001', 'info:name', 'info:age'\r\n\r\n-- 获取person 表中row key 为rk0001，info、data 列族的信息\r\nget 'person', 'rk0001', 'info', 'data'\r\n\r\nget 'person', 'rk0001', {COLUMN => ['info', 'data']}\r\nget 'person', 'rk0001', {COLUMN => ['info:name', 'data:pic']}\r\n\r\n-- 获取person 表中row key 为rk0001，列族为info，版本号最新5 个的信息\r\nget 'person', 'rk0001', {COLUMN => 'info', VERSIONS => 5}\r\n\r\nget 'person', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5}\r\nget 'person', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5, TIMERANGE => [1567491377530,1567491377590]}\r\n\r\n-- 获取person 表中row key 为rk0001，cell 的值为zhangsan 的信息\r\nget 'person', 'rk0001', {FILTER => \"ValueFilter(=, 'binary:zhangsan')\"}\r\n\r\n-- 获取person 表中row key 为rk0001，列标示符中含有a 的信息\r\nget 'person', 'rk0001', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\r\n\r\nput 'person', 'rk0002', 'info:name', 'fanbingbing'\r\nput 'person', 'rk0002', 'info:gender', 'female'\r\nput 'person', 'rk0002', 'info:nationality', '中国'\r\nget 'person', 'rk0002', {FILTER => \"ValueFilter(=, 'binary:中国')\"}\r\n\r\n-- 查询person 表中的所有信息\r\nscan 'person'\r\n\r\n-- 查询person 表中列族为info 的信息\r\nscan 'person', {COLUMNS => 'info'}\r\n\r\n-- 查询person 表中列族为info 和data 的信息\r\nscan 'person', {COLUMNS => ['info', 'data']}\r\nscan 'person', {COLUMNS => ['info:name', 'data:pic']}\r\n\r\n-- 查询person 表中列族为info、列标示符为name 的信息\r\nscan 'person', {COLUMNS => 'info:name'}\r\n\r\n-- 查询person 表中列族为info、列标示符为name 的信息,并且版本最新的5 个\r\nscan 'person', {COLUMNS => 'info:name', VERSIONS => 5}\r\n\r\n-- 查询person 表中列族为info 和data 且列标示符中含有a 字符的信息\r\nscan 'person', {COLUMNS => ['info', 'data'], FILTER => \"(QualifierFilter(=,'substring:a'))\"}\r\n\r\n-- 查询person 表中列族为info，rk 范围是[rk0001, rk0003)的数据\r\nscan 'person', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}\r\n\r\n-- 查询person 表中row key 以rk 字符开头的\r\nscan 'person',{FILTER=>\"PrefixFilter('rk')\"}\r\n\r\n-- 查询person 表中指定范围的数据\r\nscan 'person', {TIMERANGE => [1392368783980, 1392380169184]}\r\n```\r\n\r\n## 删除数据\r\n```sql\r\n-- 删除person 表row key 为rk0001，列标示符为info:name 的数据\r\ndelete 'person', 'rk0001', 'info:name'\r\n\r\n-- 删除person 表row key 为rk0001，列标示符为info:name，timestamp 为1392383705316 的数据\r\ndelete 'person', 'rk0001', 'info:name', 1392383705316\r\n\r\n-- 清空person 表中的数据\r\ntruncate 'person'\r\n```\r\n\r\n## 修改表结构\r\n```sql\r\n-- 首先停用person 表\r\ndisable 'person'\r\n\r\n-- 添加两个列族f1 和f2\r\nalter 'person', NAME => 'f1'\r\nalter 'person', NAME => 'f2'\r\n\r\n-- 删除一个列族\r\nalter 'person', NAME => 'f1', METHOD => 'delete'\r\nalter 'person', 'delete' => 'f1'\r\n\r\n-- 添加列族f1 同时删除列族f2\r\nalter 'person', {NAME => 'f1'}, {NAME => 'f2', METHOD => 'delete'}\r\n\r\n-- 将person 表的f1 列族版本号改为5\r\nalter 'person', NAME => 'info', VERSIONS => 5\r\n\r\n-- 启用表\r\nenable 'person'\r\n```\r\n\r\n## 删除表\r\n```sql\r\ndisable 'person'\r\ndrop 'person'\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.1. HBase 常用命令",
      "lvl1": "创建表",
      "lvl2": "插入数据",
      "lvl3": "查询数据",
      "lvl4": "删除数据",
      "lvl5": "修改表结构",
      "lvl6": "删除表"
    },
    "frontmatter": {
      "title": "13.1. HBase 常用命令",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.2. HBase 优化",
    "path": "/docs/architect/hadoop/Hadoop-13.2.HBaseyouhua.html",
    "url": "/docs/architect/hadoop/Hadoop-13.2.HBaseyouhua.html",
    "content": "---\r\ntitle: 13.2. HBase 优化\r\ndate: 2025/07/02\r\n---\r\n\r\n* [13.3. HBase 设计优化 rowkey](./Hadoop-13.3.HBase设计优化rowkey.md)\r\n* 代码优化\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setInMemory(true)` 将表放到 RegionServer 的缓存中，**保证在读取的时候被 cache 命中**\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setMaxVersions(int maxVersions)` **设置表中数据的最大版本**，如果只需要保存最新版本的数据，那么可以设置 `setMaxVersions(1)`\r\n    * 创建表的时候，可以通过 `HColumnDescriptor.setTimeToLive(int timeToLive)` **设置表中数据的存储生命期，过期数据将自动被删除**，例如如果只需要存储最近两天的数据，那么可以设置 `setTimeToLive(2 * 24 * 60 * 60)`\r\n* `hdfs-site.xml`: **HDFS 副本数的调整**\r\n    * `dfs.replication`: 如果数据量巨大，且不是非常之重要，可以调整为2~3，如果数据非常之重要，可以调整为3~5\r\n    * `dfs.datanode.max.transfer.threads`: HBase 一般都会同一时间操作大量的文件，根据集群的数量和规模以及数据动作，设置为 4096 或者更高。默认值：4096\r\n* `mapred-site.xml`: **优化数据的写入效率, 减少写入时间 (压缩)**\r\n    * `mapreduce.map.output.compress`: 修改为 `true`\r\n    * `mapreduce.map.output.compress.codec`: 修改为 `org.apache.hadoop.io.compress.GzipCodec` 或者其他压缩方式\r\n* `hbase-site.xml`\r\n    * `hbase.regionserver.handler.count`: 默认值为 30，用于指定 **RPC 监听的数量**，可以根据客户端的请求数进行调整，读写请求较多时，增加此值\r\n    * `hbase.hregion.max.filesize`: 默认值10737418240(10GB)，如果需要运行 HBase 的 MR 任务，可以减小此值，因为**一个 region 对应一个 map 任务**，如果单个 region 过大，会导致 map 任务执行时间过长。该值的意思就是，如果 HFile 的大小达到这个数值，则这个 region 会被切分为两个 Hfile\r\n    * `hbase.client.write.buffer`: 用于指定 HBase 客户端缓存，**增大该值可以减少 RPC 调用次数，但是会消耗更多内存**。一般我们需要设定一定的缓存大小，以达到减少 RPC 次数的目的\r\n    * `hbase.client.scanner.caching`: 用于指定 `scan.next` 方法**获取的默认行数，值越大，消耗内存越大**\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.2. HBase 优化"
    },
    "frontmatter": {
      "title": "13.2. HBase 优化",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.3. HBase 设计优化 rowkey",
    "path": "/docs/architect/hadoop/Hadoop-13.3.HBaseshejiyouhuarowkey.html",
    "url": "/docs/architect/hadoop/Hadoop-13.3.HBaseshejiyouhuarowkey.html",
    "content": "---\r\ntitle: 13.3. HBase 设计优化 rowkey\r\ndate: 2025/07/02\r\n---\r\n\r\n## 性能上考虑\r\n一条数据的唯一标识就是 rowkey，而这行数据最终存储到哪一个分区里面，取决于分区({% post_link architect/Hadoop/HBase-预分区 %})，如果从性能上考虑 rowkey 优化，应该考虑的是让数据均匀的分布在所有的 region 中，**防止数据的倾斜**。\r\n\r\n设计方案:\r\n1. 使用**随机数**, **hash** 等\r\n2. **字符串反转** 10001, 10002 反转成为 10001, 20001\r\n3. **拼接字符串** XX0001 -> 1000XX0001\r\n\r\n## 业务上考虑\r\n\r\n### 列族数目\r\n一个列族和一个 Store 对于，如果经常需要跨列族查询，对应就是需要从多个 Store 中取数据，这样对性能开销挺大，建议**创建表的时候不要太多列族，一般 2-3 个为主**。**基本信息**放到一个列族，**扩展信息**放到一个列族，如果还有另外的**不常用的附件信息**放到第三个列族。\r\n\r\n### 行键设置\r\n\r\n**根据查询要求设置 key**:\r\n* 手机号-日期: \r\n    * `18229955555-20190919`\r\n    * `18229955555-20190920`\r\n* 日期-姓名缩写-类别: 姓名缩写长度需要保持一致 (填充和截断)\r\n    * `20150230-lisi-category`\r\n    * `20150230-zs__-category`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.3. HBase 设计优化 rowkey",
      "lvl1": "性能上考虑",
      "lvl2": "业务上考虑"
    },
    "frontmatter": {
      "title": "13.3. HBase 设计优化 rowkey",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.4. HBase 预分区",
    "path": "/docs/architect/hadoop/Hadoop-13.4.HBaseyufenqu.html",
    "url": "/docs/architect/hadoop/Hadoop-13.4.HBaseyufenqu.html",
    "content": "---\r\ntitle: 13.4. HBase 预分区\r\ndate: 2025/07/02\r\n---\r\n\r\n在默认情况下，在使用 hbase 创建表的时候会自动创建一个 region 分区，所有 hbase 的客户端的数据都写到这个 region 分区里面，一直到 region 足够大的时候才进行切分。每一个 region 维护着 startRow 与 endRowKey，如果加入的数据符合某个 region 维护的 rowKey范围，则该数据交给这个 region 维护, 根据这个特性，我们可以根据以后要插入 hbase 的数据进行一个预估，**将数据大致估算好，提前进行分区，用于提升 hbase 的性能**。\r\n\r\n可以在 `http://hadoop01:16010/`(主节点) 查看分区情况\r\n\r\n## 预分区\r\n* 手动预分区: `create 'p1','info','partition1',SPLITS => ['1000','2000','3000','4000']`\r\n* 16进制分区: `create 'p2','info','partition2',{NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'}`\r\n* 代码分区: 创建表的时候指定分区\r\n    ```java\r\n    public class SplitReginTest {\r\n        private Configuration conf = null;\r\n        private Connection conn = null;\r\n\r\n        @Before\r\n        public void init() throws Exception {\r\n            conf = HBaseConfiguration.create();\r\n            conf.set(\"hbase.zookeeper.quorum\",\"hadoop01:2181,hadoop02:2182,hadoop03:2183\");\r\n            conn = ConnectionFactory.createConnection(conf);\r\n        }\r\n\r\n        @Test\r\n        public void testCreateTable() throws Exception {\r\n            Admin admin = conn.getAdmin();\r\n\r\n            HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(\"split_p\"));\r\n            HColumnDescriptor hcd1 = new HColumnDescriptor(\"base_info\");\r\n            htd.addFamily(hcd1);\r\n\r\n            byte[][] splitKeys = new byte[4][];\r\n            splitKeys[0] = Bytes.toBytes(\"1000\");\r\n            splitKeys[1] = Bytes.toBytes(\"2000\");\r\n            splitKeys[2] = Bytes.toBytes(\"3000\");\r\n            splitKeys[3] = Bytes.toBytes(\"4000\");\r\n\r\n            admin.createTable(htd,splitKeys);\r\n\r\n            admin.close();\r\n            conn.close();\r\n        }\r\n    }\r\n    ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.4. HBase 预分区",
      "lvl1": "预分区"
    },
    "frontmatter": {
      "title": "13.4. HBase 预分区",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.5.1. HBase Demo Java API 常用操作",
    "path": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "url": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "content": "---\r\ntitle: 13.5.1. HBase Demo Java API 常用操作\r\ndate: 2025/07/02\r\n---\r\n\r\n## pom.xml\r\n\r\n```xml\r\n        <dependency>\r\n            <groupId>org.apache.hbase</groupId>\r\n            <artifactId>hbase-server</artifactId>\r\n            <version>2.5.4</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hbase</groupId>\r\n            <artifactId>hbase-client</artifactId>\r\n            <version>2.5.4</version>\r\n        </dependency>\r\n```\r\n\r\n## 获得连接\r\n```java\r\nprivate Configuration conf = null;\r\nprivate Connection conn = null;\r\n\r\n    @Before\r\n    public void init() throws Exception {\r\n        conf = HBaseConfiguration.create();\r\n        conf.set(\"hbase.zookeeper.quorum\", \"hadoop01:2181,hadoop02:2182,hadoop03:2183\");\r\n        conn = ConnectionFactory.createConnection(conf);\r\n    }\r\n```\r\n\r\n## 建表\r\n```java\r\n    @Test\r\n    public void testCreateTable() throws Exception {\r\n        // 获取一个表管理器\r\n        Admin admin = conn.getAdmin();\r\n\r\n        // 构造一个表描述器，并指定表名\r\n        HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 构造一个列族描述器，并指定列族名\r\n        HColumnDescriptor hcd1 = new HColumnDescriptor(\"base_info\");\r\n        // 构造第二个列族描述器，并指定列族名\r\n        HColumnDescriptor hcd2 = new HColumnDescriptor(\"extra_info\");\r\n\r\n        // 将列族描述器添加到表描述器中\r\n        htd.addFamily(hcd1).addFamily(hcd2);\r\n        admin.createTable(htd);\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 删除表\r\n```java\r\n    @Test\r\n    public void testDrop() throws Exception {\r\n        Admin admin = conn.getAdmin();\r\n\r\n        admin.disableTable(TableName.valueOf(\"t_person_info\"));\r\n        admin.deleteTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 修改表结构\r\n```java\r\n    @Test\r\n    public void testModify() throws Exception {\r\n        Admin admin = conn.getAdmin();\r\n\r\n        // 修改已有的ColumnFamily\r\n        HTableDescriptor table = admin.getTableDescriptor(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 添加新的ColumnFamily\r\n        table.addFamily(new HColumnDescriptor(\"other_info\"));\r\n        admin.modifyTable(TableName.valueOf(\"t_person_info\"), table);\r\n\r\n        admin.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 插入/修改数据\r\n```java\r\n    @Test\r\n    public void testPut() throws Exception {\r\n        Table table = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        ArrayList<Put> puts = new ArrayList<Put>();\r\n        // 构建一个put 对象（kv），指定其行键\r\n        Put put01 = new Put(Bytes.toBytes(\"user001\"));\r\n        put01.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhangsan\"));\r\n        Put put02 = new Put(\"user001\".getBytes());\r\n        put02.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"password\"),Bytes.toBytes(\"123456\"));\r\n        Put put03 = new Put(\"user002\".getBytes());\r\n        put03.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"lisi\"));\r\n        put03.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put04 = new Put(\"zhang_sh_01\".getBytes());\r\n        put04.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang01\"));\r\n        put04.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put05 = new Put(\"zhang_sh_02\".getBytes());\r\n        put05.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang02\"));\r\n        put05.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put06 = new Put(\"liu_sh_01\".getBytes());\r\n        put06.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"liu01\"));\r\n        put06.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put07 = new Put(\"zhang_bj_01\".getBytes());\r\n        put07.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang03\"));\r\n        put07.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n        Put put08 = new Put(\"zhang_bj_01\".getBytes());\r\n        put08.addColumn(Bytes.toBytes(\"base_info\"), Bytes.toBytes(\"username\"),Bytes.toBytes(\"zhang04\"));\r\n        put08.addColumn(Bytes.toBytes(\"extra_info\"), Bytes.toBytes(\"married\"),Bytes.toBytes(\"false\"));\r\n\r\n        puts.add(put01);\r\n        puts.add(put02);\r\n        puts.add(put03);\r\n        puts.add(put04);\r\n        puts.add(put05);\r\n        puts.add(put06);\r\n        puts.add(put07);\r\n        puts.add(put08);\r\n        table.put(puts);\r\n\r\n        table.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## get 查询\r\n```java\r\n    @Test\r\n    public void testGet() throws Exception {\r\n        Table table = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n\r\n        // 构造一个get 查询参数对象，指定要get 的是哪一行\r\n        Get get = new Get(\"user001\".getBytes());\r\n        Result result = table.get(get);\r\n\r\n        CellScanner cellScanner = result.cellScanner();\r\n        while (cellScanner.advance()) {\r\n            Cell current = cellScanner.current();\r\n            byte[] familyArray = current.getFamilyArray();\r\n            byte[] qualifierArray = current.getQualifierArray();\r\n            byte[] valueArray = current.getValueArray();\r\n            System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n            System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n            System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n        }\r\n\r\n        table.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## 删除表中数据\r\n```java\r\n    @Test\r\n    public void testDel() throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.5.1. HBase Demo Java API 常用操作",
      "lvl1": "pom.xml",
      "lvl2": "获得连接",
      "lvl3": "建表",
      "lvl4": "删除表",
      "lvl5": "修改表结构",
      "lvl6": "插入/修改数据",
      "lvl7": "get 查询",
      "lvl8": "删除表中数据",
      "lvl9": "scan 查询",
      "lvl10": "过滤查询"
    },
    "frontmatter": {
      "title": "13.5.1. HBase Demo Java API 常用操作",
      "date": "2025/07/02"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 2
  },
  {
    "title": "13.5.1. HBase Demo Java API 常用操作",
    "path": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "url": "/docs/architect/hadoop/Hadoop-13.5.1.HBaseDemoJavaAPIchangyongcaozuo.html",
    "content": "(\"t_person_info\"));\r\n\r\n        Delete delete = new Delete(\"user001\".getBytes());\r\n        delete.addColumn(\"base_info\".getBytes(), \"password\".getBytes());\r\n\r\n        t_person_info.delete(delete);\r\n\r\n        t_person_info.close();\r\n        conn.close();\r\n    }\r\n```\r\n\r\n## scan 查询\r\n```java\r\n    @Test\r\n    public void testScan() throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n        Scan scan = new Scan(Bytes.toBytes(\"liu_sh_01\"), Bytes.toBytes(\"zhang_bj_01\" + \"\\000\"));\r\n        ResultScanner scanner = t_person_info.getScanner(scan);\r\n        Iterator<Result> iter = scanner.iterator();\r\n        while (iter.hasNext()) {\r\n            Result result = iter.next();\r\n            CellScanner cellScanner = result.cellScanner();\r\n            while (cellScanner.advance()) {\r\n                Cell current = cellScanner.current();\r\n                byte[] familyArray = current.getFamilyArray();\r\n                byte[] valueArray = current.getValueArray();\r\n                byte[] qualifierArray = current.getQualifierArray();\r\n                byte[] rowArray = current.getRowArray();\r\n                System.out.println(new String(rowArray, current.getRowOffset(),current.getRowLength()));\r\n                System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n                System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n                System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n            }\r\n            System.out.println(\"-----------------------\");\r\n        }\r\n    }\r\n```\r\n\r\n## 过滤查询\r\n```java\r\n    @Test\r\n    public void testFilter() throws Exception {\r\n        // 针对行键的前缀过滤器\r\n        Filter pf = new PrefixFilter(Bytes.toBytes(\"liu\"));\r\n        testScan(pf);\r\n\r\n        // 行过滤器\r\n        RowFilter rf1 = new RowFilter(CompareOp.LESS, new BinaryComparator(Bytes.toBytes(\"user002\")));\r\n        RowFilter rf2 = new RowFilter(CompareOp.EQUAL, new SubstringComparator(\"00\"));\r\n        testScan(rf1);\r\n        System.out.println(\"**********\");\r\n        testScan(rf2);\r\n\r\n        // 针对指定一个列的 value 来过滤\r\n        SingleColumnValueFilter scvf = new SingleColumnValueFilter(\"base_info\".getBytes(),\"password\".getBytes(), CompareOp.EQUAL, \"123456\".getBytes());\r\n        scvf.setFilterIfMissing(true); // 如果指定的列缺失，则也过滤掉\r\n        testScan(scvf);\r\n\r\n        ByteArrayComparable comparator1 = new RegexStringComparator(\"^zhang\");\r\n        ByteArrayComparable comparator2 = new SubstringComparator(\"ang\");\r\n        SingleColumnValueFilter scvf = new SingleColumnValueFilter(\"base_info\".getBytes(),\r\n        \"username\".getBytes(), CompareOp.EQUAL, comparator2);\r\n        testScan(scvf);\r\n\r\n        // 针对列族名的过滤器返回结果中只会包含满足条件的列族中的数据\r\n        FamilyFilter ff1 = new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(\"inf\")));\r\n        FamilyFilter ff2 = new FamilyFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"base\")));\r\n        testScan(ff1);\r\n\r\n        // 针对列名的过滤器返回结果中只会包含满足条件的列的数据\r\n        QualifierFilter qf = new QualifierFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(\"password\")));\r\n        QualifierFilter qf2 = new QualifierFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"us\")));\r\n        testScan(qf);\r\n\r\n        // 跟 SingleColumnValueFilter 结果不同，只返回符合条件的该column\r\n        ColumnPrefixFilter cf = new ColumnPrefixFilter(\"passw\".getBytes());\r\n        testScan(cf);\r\n\r\n        byte[][] prefixes = new byte[][]{ Bytes.toBytes(\"username\"),Bytes.toBytes(\"password\") };\r\n        MultipleColumnPrefixFilter mcf = new MultipleColumnPrefixFilter(prefixes);\r\n        testScan(mcf);\r\n\r\n        FamilyFilter ff2 = new FamilyFilter(CompareOp.EQUAL, new BinaryPrefixComparator(Bytes.toBytes(\"base\")));\r\n        ColumnPrefixFilter cf = new ColumnPrefixFilter(\"passw\".getBytes());\r\n        FilterList filterList = new FilterList(Operator.MUST_PASS_ALL);\r\n        filterList.addFilter(ff2);\r\n        filterList.addFilter(cf);\r\n        testScan(filterList);\r\n    }\r\n```\r\n\r\n```java\r\n    private void testScan(Filter filter) throws Exception {\r\n        Table t_person_info = conn.getTable(TableName.valueOf(\"t_person_info\"));\r\n        Scan scan = new Scan();\r\n        scan.setFilter(filter);\r\n        ResultScanner scanner = t_person_info.getScanner(scan);\r\n        Iterator<Result> iter = scanner.iterator();\r\n        while (iter.hasNext()) {\r\n            Result result = iter.next();\r\n            CellScanner cellScanner = result.cellScanner();\r\n            while (cellScanner.advance()) {\r\n                Cell current = cellScanner.current();\r\n                byte[] familyArray = current.getFamilyArray();\r\n                byte[] valueArray = current.getValueArray();\r\n                byte[] qualifierArray = current.getQualifierArray();\r\n                byte[] rowArray = current.getRowArray();\r\n                System.out.println(new String(rowArray, current.getRowOffset(),current.getRowLength()));\r\n                System.out.print(new String(familyArray, current.getFamilyOffset(),current.getFamilyLength()));\r\n                System.out.print(\":\" + new String(qualifierArray, current.getQualifierOffset(),current.getQualifierLength()));\r\n                System.out.println(\" \" + new String(valueArray, current.getValueOffset(),current.getValueLength()));\r\n            }\r\n            System.out.println(\"-----------------------\");\r\n        }\r\n    }\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.5.1. HBase Demo Java API 常用操作",
      "lvl1": "pom.xml",
      "lvl2": "获得连接",
      "lvl3": "建表",
      "lvl4": "删除表",
      "lvl5": "修改表结构",
      "lvl6": "插入/修改数据",
      "lvl7": "get 查询",
      "lvl8": "删除表中数据",
      "lvl9": "scan 查询",
      "lvl10": "过滤查询"
    },
    "frontmatter": {
      "title": "13.5.1. HBase Demo Java API 常用操作",
      "date": "2025/07/02"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 2
  },
  {
    "title": "13.6.1. HBase ServerNotRunningYetException",
    "path": "/docs/architect/hadoop/Hadoop-13.6.1.HBaseServerNotRunningYetException.html",
    "url": "/docs/architect/hadoop/Hadoop-13.6.1.HBaseServerNotRunningYetException.html",
    "content": "---\r\ntitle: 13.6.1. HBase ServerNotRunningYetException\r\ndate: 2025/07/02\r\n---\r\n\r\n:::denger ServerNotRunningYetException\r\n- HBase ServerNotRunningYetException: Server is not running yet\r\n:::\r\n\r\n`hbase-site.xml` 中添加:\r\n```xml\r\n  <property>\r\n    <name>hbase.wal.provider</name>\r\n    <value>filesystem</value>\r\n  </property>\r\n```\r\n\r\n重启 HBase 即可\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.6.1. HBase ServerNotRunningYetException"
    },
    "frontmatter": {
      "title": "13.6.1. HBase ServerNotRunningYetException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "13.6.2. HBase No Hbase Master Found",
    "path": "/docs/architect/hadoop/Hadoop-13.6.2.HBaseNoHbaseMasterFound.html",
    "url": "/docs/architect/hadoop/Hadoop-13.6.2.HBaseNoHbaseMasterFound.html",
    "content": "---\r\ntitle: 13.6.2. HBase No Hbase Master Found\r\ndate: 2025/07/02\r\n---\r\n\r\n:::denger\r\n- HBase-stop-hbase.sh: no hbase master found\r\n:::\r\n\r\n1. `hbase-env.sh` 中添加: `export HBASE_PID_DIR=/var/hbase/pids`\r\n2. `jps` 查看 hbase 相关的 pid, 然后 `kill -9` 结束进程\r\n3. `start-hbase.sh` 启动 hbase\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "13.6.2. HBase No Hbase Master Found"
    },
    "frontmatter": {
      "title": "13.6.2. HBase No Hbase Master Found",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14. Sqoop 特点",
    "path": "/docs/architect/hadoop/Hadoop-14-Sqoop-tedian.html",
    "url": "/docs/architect/hadoop/Hadoop-14-Sqoop-tedian.html",
    "content": "---\r\ntitle: 14. Sqoop 特点\r\ndate: 2025/07/02\r\n---\r\n\r\n## Sqoop 简介\r\nSqoop 是 apache 旗下的工具，用于实现结构型数据（如关系数据库）和 Hadoop 之间进行数据迁移的工具, 可以讲关系型数据库中的数据导入到 Hadoop 的 HDFS 中，同样也完全可以把 HDFS 的数据导入到关系型数据库里面\r\n* 导入数据：MySQL, Oracle 导入数据到 Hadoop 的 HDFS, HIVE, HBASE 等数据存储系统\r\n* 导出数据：从 Hadoop 的文件系统中导出数据到关系数据库\r\n\r\n![Sqoop](static/sqoop.png)\r\n\r\n## Sqoop 原理\r\nSqoop 把导入或导出命令翻译成 `mapreduce` 代码来实现, 在翻译出的 `mapreduce` 中，其实只是对 `inputformat` 和 `outputformat` 进行了定制\r\n\r\n---\r\n\r\n<font color=\"red\">该项目已于 2021-06 终止, 并移入 Apache Attic</font>\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14. Sqoop 特点",
      "lvl1": "Sqoop 简介",
      "lvl2": "Sqoop 原理"
    },
    "frontmatter": {
      "title": "14. Sqoop 特点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.1. Sqoop 导入数据到 HBase",
    "path": "/docs/architect/hadoop/Hadoop-14.1.SqoopdaorushujudaoHBase.html",
    "url": "/docs/architect/hadoop/Hadoop-14.1.SqoopdaorushujudaoHBase.html",
    "content": "---\r\ntitle: 14.1. Sqoop 导入数据到 HBase\r\ndate: 2025/07/02\r\n---\r\n\r\n1. 创建 HBase 表: `create 'hbase_person','info'`\r\n2. 导入数据到 HBase\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --columns \"pid,name,sex\" \\\r\n        --column-family \"info\" \\\r\n        --hbase-create-table \\\r\n        --hbase-row-key \"pid\" \\\r\n        --hbase-table \"hbase_person\" \\\r\n        --num-mappers 1 \\\r\n        --split-by pid\r\n    ```\r\n3. `scan 'hbase_person'`\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.1. Sqoop 导入数据到 HBase"
    },
    "frontmatter": {
      "title": "14.1. Sqoop 导入数据到 HBase",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.2. Sqoop Hive 与 Mysql 互导",
    "path": "/docs/architect/hadoop/Hadoop-14.2.SqoopHiveyuMysqlhudao.html",
    "url": "/docs/architect/hadoop/Hadoop-14.2.SqoopHiveyuMysqlhudao.html",
    "content": "---\r\ntitle: 14.2. Sqoop Hive 与 Mysql 互导\r\ndate: 2025/07/02\r\n---\r\n\r\n* 导入数据到 HIVE\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --num-mappers 1 \\\r\n        --hive-import \\\r\n        --fields-terminated-by \",\" \\\r\n        --hive-overwrite \\\r\n        --hive-table person_hive\r\n    ```\r\n* hive/hdfs 导入数据到 mysql\r\n    ```bash\r\n    sqoop export \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person2 \\\r\n        --export-dir /user/hive/warehouse/person_hive \\\r\n        --m 1\r\n    ```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.2. Sqoop Hive 与 Mysql 互导"
    },
    "frontmatter": {
      "title": "14.2. Sqoop Hive 与 Mysql 互导",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "14.3. Sqoop Mysql 导入 HDFS",
    "path": "/docs/architect/hadoop/Hadoop-14.3.SqoopMysqldaoruHDFS.html",
    "url": "/docs/architect/hadoop/Hadoop-14.3.SqoopMysqldaoruHDFS.html",
    "content": "---\r\ntitle: 14.3. Sqoop Mysql 导入 HDFS\r\ndate: 2025/07/02\r\n---\r\n\r\n1. Mysql 测试数据\r\n    ```sql\r\n    create database sqooptest;\r\n    Use sqooptest\r\n    create table person(pid int primary key auto_increment, name varchar(20), sex varchar(20));\r\n    insert into person(name, sex) values('james', 'Male');\r\n    insert into person(name, sex) values('lison', 'Female');\r\n    ```\r\n2. 全量导入\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --table person \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\"\r\n\r\n    hadoop fs -cat /user/person/part-m-00000\r\n    ```\r\n3. 带查询条件导入: `$CONDITIONS` 不能省略, 要链接 sqoop 默认的条件\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\" \\\r\n        --query 'select name,sex from person where pid <=1 and $CONDITIONS;'\r\n\r\n    hadoop fs -cat /user/person/part-m-00000\r\n    ```\r\n4. 导入特定列\r\n    ```bash\r\n    sqoop import \\\r\n        --connect jdbc:mysql://192.168.244.100:3306/sqooptest \\\r\n        --username root \\\r\n        --password root1234% \\\r\n        --target-dir /user/person \\\r\n        --delete-target-dir \\\r\n        --num-mappers 1 \\\r\n        --fields-terminated-by \",\" \\\r\n        --columns pid,sex \\\r\n        --table person\r\n    ```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "14.3. Sqoop Mysql 导入 HDFS"
    },
    "frontmatter": {
      "title": "14.3. Sqoop Mysql 导入 HDFS",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.1. Demo 单词统计",
    "path": "/docs/architect/hadoop/Hadoop-15.1.Demodancitongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.1.Demodancitongji.html",
    "content": "---\r\ntitle: 15.1. Demo 单词统计\r\ndate: 2025/07/02\r\n---\r\n\r\n导入 `hadoop` 和 `hadoop.mapreduce` 包下的类\r\n\r\n## WCMapper.java\r\n```java\r\n// 泛型分别是：输入的键值类型; 输出的键值类型 \r\npublic class WCMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\r\n\r\n    @Override\r\n    protected void map(LongWritable key, @NotNull Text value, Context context) throws IOException, InterruptedException {\r\n        String line = value.toString();\r\n        String[] words = line.split(\" \");\r\n        for (String word : words) {\r\n            context.write(new Text(word), new IntWritable(1));\r\n        }\r\n    }\r\n\r\n}\r\n```\r\n\r\n## WCReducer.java\r\n```java\r\n// 泛型分别是：输入的键值类型; 输出的键值类型 \r\npublic class WCReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\r\n\r\n    @Override\r\n    protected void reduce(Text key, @NotNull Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\r\n        int count = 0;\r\n        for (IntWritable v : values) {\r\n            count += v.get();\r\n        }\r\n        context.write(key, new IntWritable(count));\r\n    }\r\n\r\n}\r\n```\r\n\r\n## WCJob.java\r\n```java\r\npublic class WCJob {\r\n\r\n    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n\r\n        job.setJarByClass(WCJob.class);\r\n\r\n        job.setMapperClass(WCMapper.class);\r\n        job.setReducerClass(WCReducer.class);\r\n        \r\n//        Mapper 输出键值类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n\r\n//        Reducer 输出键值类型\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n\r\n//         前期准备, 在 Hadoop /wc/input 目录中上传进待分析的文件\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\"));\r\n\r\n//        等待执行完并检查是否执行成功\r\n        System.exit(job.waitForCompletion(true)? 0:-1);\r\n    }\r\n\r\n}\r\n```\r\n\r\n## pom.xml\r\n```xml\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-jar-plugin</artifactId>\r\n                <version>3.3.0</version>\r\n                <configuration>\r\n                    <archive>\r\n                        <manifest>\r\n                            <addClasspath>true</addClasspath>\r\n                            <classpathPrefix>lib/</classpathPrefix>\r\n                            <mainClass>org.jxch.study.hadoop.mr.wc.WCJob</mainClass>\r\n                        </manifest>\r\n                    </archive>\r\n                </configuration>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 运行\r\n编译 jar 包: `mvn package -Dmaven.test.skip=true -f pom.xml`\r\n将 jar 包上传到 Hadoop 服务器之后，执行命令: `hadoop jar /home/jxch/study-hadoop-1.0-SNAPSHOT.jar `\r\n\r\n跑完后，检查运行结果:\r\n* `hadoop fs -ls /wc/output`\r\n* `hadoop fs -cat /wc/output/part-r-00000`\r\n\r\n---\r\n\r\n## 依赖包\r\n```xml\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-common</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-hdfs</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-client</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>junit</groupId>\r\n            <artifactId>junit</artifactId>\r\n            <version>4.13.2</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-api</artifactId>\r\n            <version>2.0.7</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-simple</artifactId>\r\n            <version>2.0.7</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.projectlombok</groupId>\r\n            <artifactId>lombok</artifactId>\r\n            <version>1.18.26</version>\r\n            <scope>provided</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.jetbrains</groupId>\r\n            <artifactId>annotations</artifactId>\r\n            <version>RELEASE</version>\r\n            <scope>compile</scope>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.1. Demo 单词统计",
      "lvl1": "WCMapper.java",
      "lvl2": "WCReducer.java",
      "lvl3": "WCJob.java",
      "lvl4": "pom.xml",
      "lvl5": "运行",
      "lvl6": "依赖包"
    },
    "frontmatter": {
      "title": "15.1. Demo 单词统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.2. Demo 单词分组排序统计",
    "path": "/docs/architect/hadoop/Hadoop-15.2.Demodancifenzupaixutongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.2.Demodancifenzupaixutongji.html",
    "content": "---\r\ntitle: 15.2. Demo 单词分组排序统计\r\ndate: 2025/07/02\r\n---\r\n\r\n先进行单词统计: [15.Demo单词统计](./Hadoop-15.Demo单词统计.md)\r\n\r\n## 排序\r\n利用对Mapper输出的Key的自动排序进行排序\r\n\r\n```java\r\npublic class WCSortMapper extends Mapper<LongWritable, Text, DescIntWritable, Text> {\r\n    @Override\r\n    protected void map(LongWritable key, @NotNull Text value, @NotNull Context context) throws IOException, InterruptedException {\r\n        String line = value.toString();\r\n        String[] words = line.split(\"\\t\");\r\n        if (words.length == 2) {\r\n            context.write(new DescIntWritable(Integer.parseInt(words[1])), new Text(words[0]));\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n```java\r\npublic class WCSortReducer extends Reducer<DescIntWritable, Text, Text, IntWritable> {\r\n    @Override\r\n    protected void reduce(DescIntWritable key, @NotNull Iterable<Text> values, Context context) throws IOException, InterruptedException {\r\n        for (Text word : values) {\r\n            context.write(word, key);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n```java\r\npublic class DescIntWritable extends IntWritable {\r\n\r\n    public DescIntWritable() {\r\n    }\r\n\r\n    public DescIntWritable(int value) {\r\n        super(value);\r\n    }\r\n\r\n    @Override\r\n    public int compareTo(IntWritable o) {\r\n        return -super.compareTo(o);\r\n    }\r\n}\r\n```\r\n\r\n## 分组\r\n\r\n```java\r\npublic class WCPartitioner extends Partitioner<DescIntWritable, Text> {\r\n\r\n    @Override\r\n    public int getPartition(DescIntWritable descIntWritable, @NotNull Text text, int numPartitions) {\r\n        return text.toString().contains(\"jxch\") ? 0 : 1;\r\n    }\r\n\r\n}\r\n```\r\n\r\n## Job\r\n先完成单词统计的任务，然后在此基础上进行分组排序\r\n```java\r\npublic class WCSortJob {\r\n    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {\r\n        Job job = Job.getInstance(new Configuration());\r\n\r\n        job.setJarByClass(WCSortJob.class);\r\n\r\n        job.setMapperClass(WCMapper.class);\r\n        job.setReducerClass(WCReducer.class);\r\n\r\n//        Mapper 输出键值类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n\r\n//        Reducer 输出键值类型\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\"));\r\n\r\n//        等待执行完并检查是否执行成功\r\n        if (job.waitForCompletion(true)) {\r\n            Job sortJob = Job.getInstance(new Configuration());\r\n\r\n            sortJob.setJarByClass(WCSortJob.class);\r\n            sortJob.setMapperClass(WCSortMapper.class);\r\n            sortJob.setReducerClass(WCSortReducer.class);\r\n            sortJob.setMapOutputKeyClass(DescIntWritable.class);\r\n            sortJob.setMapOutputValueClass(Text.class);\r\n            sortJob.setOutputKeyClass(Text.class);\r\n            sortJob.setOutputValueClass(IntWritable.class);\r\n            sortJob.setInputFormatClass(TextInputFormat.class);\r\n            sortJob.setOutputFormatClass(TextOutputFormat.class);\r\n            sortJob.setPartitionerClass(WCPartitioner.class);\r\n            sortJob.setNumReduceTasks(2);\r\n\r\n            FileInputFormat.setInputPaths(sortJob, new Path(\"/wc/output\"));\r\n            FileOutputFormat.setOutputPath(sortJob, new Path(\"/wc/output_sort\"));\r\n\r\n            System.exit(sortJob.waitForCompletion(true)? 0:-1);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n## pom.xml\r\n```xml\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-jar-plugin</artifactId>\r\n                <version>3.3.0</version>\r\n                <configuration>\r\n                    <archive>\r\n                        <manifest>\r\n                            <addClasspath>true</addClasspath>\r\n                            <classpathPrefix>lib/</classpathPrefix>\r\n                            <mainClass>org.jxch.study.hadoop.mr.wc.sort.WCSortJob</mainClass>\r\n                        </manifest>\r\n                    </archive>\r\n                </configuration>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n```\r\n\r\n## 运行\r\n编译 jar 包: `mvn package -Dmaven.test.skip=true -f pom.xml`\r\n将 jar 包上传到 Hadoop 服务器之后，执行命令: `hadoop jar /home/jxch/study-hadoop-1.1-SNAPSHOT.jar `\r\n\r\n跑完后，检查运行结果:\r\n* `hadoop fs -ls /wc/output_sort`\r\n* `hadoop fs -cat /wc/output_sort/part-r-00000`\r\n* `hadoop fs -cat /wc/output_sort/part-r-00001`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.2. Demo 单词分组排序统计",
      "lvl1": "排序",
      "lvl2": "分组",
      "lvl3": "Job",
      "lvl4": "pom.xml",
      "lvl5": "运行"
    },
    "frontmatter": {
      "title": "15.2. Demo 单词分组排序统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.3. Demo 倒排索引-文章单词统计",
    "path": "/docs/architect/hadoop/Hadoop-15.3.Demodaopaisuoyin-wenzhangdancitongji.html",
    "url": "/docs/architect/hadoop/Hadoop-15.3.Demodaopaisuoyin-wenzhangdancitongji.html",
    "content": "---\r\ntitle: 15.3. Demo 倒排索引-文章单词统计\r\ndate: 2025/07/02\r\n---\r\n\r\n## 思路 (倒推法)\r\n\r\n第二步:\r\n* Reduce\r\n    * key:单词\r\n    * values[] 文章--次数\r\n* Map \r\n    * key: 单词\r\n    * value: 文章--次数\r\n\r\n第一步:\r\n* Reduce\r\n    * key: 单词--文档位置 \r\n    * value: 单词次数\r\n* Map\r\n    * key: 单词--文档位置 \r\n    * value: 1\r\n\r\n---\r\n\r\n## JAVA 代码\r\n\r\n### IndexStepOne.java\r\n```java\r\npublic class IndexStepOne {\r\n    public static class IndexStepOneMapper extends Mapper<LongWritable, Text, Text, IntWritable>{\r\n        Text k = new Text();\r\n        IntWritable v = new IntWritable(1);\r\n\r\n        @Override\r\n        protected void map(LongWritable key, Text value,Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] words = line.split(\" \");\r\n            FileSplit Split = (FileSplit)context.getInputSplit();\r\n            String filename = Split.getPath().getName();\r\n            //输出 key :单词--文件名 value:1\r\n            for(String word : words){\r\n                k.set(word +\"--\"+ filename);\r\n                context.write(k, v);\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class IndexStepOneReducer extends Reducer<Text, IntWritable, Text, IntWritable>{\r\n        IntWritable v = new IntWritable();\r\n\r\n        @Override\r\n        protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\r\n            int count = 0;\r\n            for(IntWritable value : values){\r\n                count += value.get();\r\n            }\r\n            v.set(count);\r\n            context.write(key, v);\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(IndexStepOne.class);\r\n        job.setMapperClass(IndexStepOneMapper.class);\r\n        job.setReducerClass(IndexStepOneReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(IntWritable.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(IntWritable.class);\r\n        //这里可以进行 combiner 组件的设置\r\n        job.setCombinerClass(IndexStepOneReducer.class);\r\n        job.setInputFormatClass(TextInputFormat.class);\r\n        job.setOutputFormatClass(TextOutputFormat.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:/index/input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:/index/output-1\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n### IndexStepTwo.java\r\n```java\r\npublic class IndexStepTwo {\r\n    public static class IndexStepTwoMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        Text k = new Text();\r\n        Text v = new Text();\r\n        \r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] fields = line.split(\"\\t\");\r\n            String word_file = fields[0];\r\n            String count = fields[1];\r\n            String[] split = word_file.split(\"--\");\r\n            String word = split[0];\r\n            String file = split[1];\r\n            k.set(word);\r\n            v.set(file+\"--\"+count);\r\n            context.write(k, v);\r\n        }\r\n    }\r\n\r\n    public static class IndexStepTwoReducer extends Reducer<Text, Text, Text, Text>{\r\n        Text v = new Text();\r\n\r\n        @Override\r\n        protected void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for (Text value : values) {\r\n                sBuffer.append(value.toString()).append(\" \");\r\n            }\r\n            v.set(sBuffer.toString());\r\n            context.write(key, v);\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(IndexStepTwo.class);\r\n        //告诉程序，我们的程序所用的 mapper 类和 reducer 类是什么\r\n        job.setMapperClass(IndexStepTwoMapper.class);\r\n        job.setReducerClass(IndexStepTwoReducer.class);\r\n        //告诉框架，我们程序输出的数据类型\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        //这里可以进行 combiner 组件的设置\r\n        job.setCombinerClass(IndexStepTwoReducer.class);\r\n        //告诉框架，我们要处理的数据文件在那个路劲下\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:/index/output-1\"));\r\n        //告诉框架，我们的处理结果要输出到什么地方\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:/index/output-2\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.3. Demo 倒排索引-文章单词统计",
      "lvl1": "思路 (倒推法)",
      "lvl2": "JAVA 代码"
    },
    "frontmatter": {
      "title": "15.3. Demo 倒排索引-文章单词统计",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.4. Demo 共同好友",
    "path": "/docs/architect/hadoop/Hadoop-15.4.Demogongtonghaoyou.html",
    "url": "/docs/architect/hadoop/Hadoop-15.4.Demogongtonghaoyou.html",
    "content": "---\r\ntitle: 15.4. Demo 共同好友\r\ndate: 2025/07/02\r\n---\r\n\r\n## 思路\r\n原数据:\r\n```text\r\nA:B,C,D,F,E,O\r\nB:A,C,E,K\r\nC:F,A,D,I\r\nD:A,E,F,L\r\nE:B,C,D,M,L\r\nF:A,s,C,D,E,O,M\r\nG:A,C,D,E,F\r\nH:A,C,D,E,O\r\nI:A,O\r\nJ:B,O\r\nK:A,C,D\r\nL:D,E,F\r\nM:E,F,G\r\nO:A,H,I,J\r\n```\r\n\r\n1. 先找出一个用户是哪些用户的共同好友（比如 C 是哪些用户的共同好友，以上题目中的 C 是用户 A,B,E,F,G,H,K 的共同好友，所以 AB 的共同好友为 C，AE 的共同好友为 C，以此类推。。。）\r\n2. 经过第一步推算，得到 AE 的 共同好友还有 D，最后将 AE 的共同好友合并得到 C,D，这只是举个例子，他们的共同好友还有很多，即将两两用户作为 key，好友作为 value，以此类推，因此需要写两个 mapreduce\r\n\r\n## JAVA 代码\r\n### FriendsStepOne.java\r\n```java\r\npublic class FriendsStepOne {\r\n    public static class FriendsStepOneMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] splits = line.split(\":\");\r\n            String person = splits[0];\r\n            String[] friends = splits[1].split(\",\");\r\n            for(String fString :friends){\r\n                context.write(new Text(fString), new Text(person));\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class FriendsStepOneReducer extends Reducer<Text, Text, Text, Text>{\r\n        @Override\r\n        protected void reduce(Text friend, Iterable<Text> persons, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for(Text pText :persons){\r\n                sBuffer.append(pText).append(\"-\");\r\n            }\r\n            context.write(friend, new Text(sBuffer.toString()));\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(FriendsStepOne.class);\r\n        job.setMapperClass(FriendsStepOneMapper.class);\r\n        job.setReducerClass(FriendsStepOneReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:\\\\friends\\\\input\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:\\\\friends\\\\output-1\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n\r\n### FriendsStepTwo.java\r\n```java\r\npublic class FriendsStepTwo {\r\n    public static class FriendsStepTwoMapper extends Mapper<LongWritable, Text, Text, Text>{\r\n        @Override\r\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n            String line = value.toString();\r\n            String[] splits = line.split(\"\\t\");\r\n            String friend = splits[0];\r\n            String[] persons = splits[1].split(\"-\");\r\n            Arrays.sort(persons);\r\n            for (int i = 0; i < persons.length-1; i++) {\r\n                for (int j = i+1; j < persons.length; j++) {\r\n                    context.write(new Text(persons[i]+\"-\"+persons[j]), new Text(friend));\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    public static class FriendsStepTwoReducer extends Reducer<Text, Text, Text, Text>{\r\n        @Override\r\n        protected void reduce(Text person_pair, Iterable<Text> friends, Context context) throws IOException, InterruptedException {\r\n            StringBuffer sBuffer = new StringBuffer();\r\n            for(Text fText : friends){\r\n                sBuffer.append(fText).append(\" \");\r\n            }\r\n            context.write(person_pair, new Text(sBuffer.toString()));\r\n        }\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(FriendsStepTwo.class);\r\n        job.setMapperClass(FriendsStepTwoMapper.class);\r\n        job.setReducerClass(FriendsStepTwoReducer.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setOutputKeyClass(Text.class);\r\n        job.setOutputValueClass(Text.class);\r\n        FileInputFormat.setInputPaths(job, new Path(\"D:\\\\friends\\\\output-1\"));\r\n        FileOutputFormat.setOutputPath(job, new Path(\"D:\\\\friends\\\\output-2\"));\r\n        boolean res = job.waitForCompletion(true);\r\n        System.exit(res?0:1);\r\n    }\r\n}\r\n```\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.4. Demo 共同好友",
      "lvl1": "思路",
      "lvl2": "JAVA 代码"
    },
    "frontmatter": {
      "title": "15.4. Demo 共同好友",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.5. Demo 自定义 InputFileFormat",
    "path": "/docs/architect/hadoop/Hadoop-15.5.DemozidingyiInputFileFormat.html",
    "url": "/docs/architect/hadoop/Hadoop-15.5.DemozidingyiInputFileFormat.html",
    "content": "---\r\ntitle: 15.5. Demo 自定义 InputFileFormat\r\ndate: 2025/07/02\r\n---\r\n\r\n以 excel 的文件举例\r\n\r\n## pom.xml\r\n```xml\r\n<dependency>\r\n    <groupId>net.sourceforge.jexcelapi</groupId>\r\n    <artifactId>jxl</artifactId>\r\n    <version>2.6.12</version>\r\n</dependency>\r\n```\r\n\r\n## ExcelInputFormat.java\r\n```java\r\npublic class ExcelFileInputFormat extends FileInputFormat<IntWritable,Text> {\r\n    @Override\r\n    protected boolean isSplitable(JobContext context, Path filename) {\r\n        return false;\r\n    }\r\n    public RecordReader<IntWritable, Text> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {\r\n        return new ExcelRecordReader();\r\n    }\r\n}\r\n```\r\n\r\n## ExcelRecordReader.java\r\n```java\r\npublic class ExcelRecordReader extends RecordReader<IntWritable,Text> {\r\n    private int rows;\r\n    private int current = -1;\r\n    private Sheet sheet;\r\n    private Workbook workbook;\r\n    \r\n    @Override\r\n    public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {\r\n        FileSplit filesplit = (FileSplit) split;\r\n        Configuration conf= context.getConfiguration();\r\n        Path filePath =filesplit.getPath();\r\n        FileSystem fs=filePath.getFileSystem(conf);\r\n        FSDataInputStream inputStream = fs.open(filePath);\r\n        try {\r\n            workbook = Workbook.getWorkbook(inputStream);\r\n            sheet = workbook.getSheets()[0];\r\n            rows = sheet.getRows();\r\n        } catch (BiffException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public boolean nextKeyValue() throws IOException, InterruptedException {\r\n        if(current<rows-1) {\r\n            current++;\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n\r\n    @Override\r\n    public IntWritable getCurrentKey() throws IOException, InterruptedException {\r\n        return new IntWritable(current);\r\n    }\r\n\r\n    @Override\r\n    public Text getCurrentValue() throws IOException, InterruptedException {\r\n        StringBuffer sb = new StringBuffer(\"\");\r\n        for(int i=0; i<sheet.getColumns(); i++){\r\n            Cell cell = sheet.getCell(i, current);\r\n            sb.append(cell.getContents() + \" \");\r\n        }\r\n        return new Text(sb.toString());\r\n    }\r\n\r\n    @Override\r\n    public float getProgress() throws IOException, InterruptedException {\r\n        return current/rows;\r\n    }\r\n\r\n    @Override\r\n    public void close() throws IOException {\r\n        workbook.close();\r\n    }\r\n}\r\n```\r\n\r\n## ExcelMapper.java\r\n```java\r\npublic class ExcelMapper extends Mapper<IntWritable,Text,IntWritable,Text> {\r\n    @Override\r\n    protected void map(IntWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n        super.map(key, value, context);\r\n    }\r\n}\r\n```\r\n\r\n## ExcelJob.java\r\n```java\r\npublic class ExcelJob {\r\n    public static void main(String[] args) throws Exception{\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(ExcelJob.class);\r\n        job.setMapperClass(ExcelMapper.class);\r\n        job.setMapOutputKeyClass(IntWritable.class);\r\n        job.setMapOutputValueClass(Text.class);\r\n        job.setInputFormatClass(ExcelFileInputFormat.class);\r\n        //不需要Reduce\r\n        job.setNumReduceTasks(0);\r\n        //指定文件得读取位置\r\n        FileInputFormat.setInputPaths(job, new Path(\"/wc/excel\"));\r\n        //指定文件得输出位置\r\n        FileOutputFormat.setOutputPath(job, new Path(\"/wc/excelout\"));\r\n\r\n        System.exit(job.waitForCompletion(true) ? 0 : -1);\r\n    }\r\n}\r\n```\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.5. Demo 自定义 InputFileFormat",
      "lvl1": "pom.xml",
      "lvl2": "ExcelInputFormat.java",
      "lvl3": "ExcelRecordReader.java",
      "lvl4": "ExcelMapper.java",
      "lvl5": "ExcelJob.java"
    },
    "frontmatter": {
      "title": "15.5. Demo 自定义 InputFileFormat",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.6. Demo 自定义 OutputFileFormat",
    "path": "/docs/architect/hadoop/Hadoop-15.6.DemozidingyiOutputFileFormat.html",
    "url": "/docs/architect/hadoop/Hadoop-15.6.DemozidingyiOutputFileFormat.html",
    "content": "---\r\ntitle: 15.6. Demo 自定义 OutputFileFormat\r\ndate: 2025/07/02\r\n---\r\n\r\n如果单词是老师人名，放到一个目录，否则放到另外一个目录\r\n\r\n## TeacherOutPutFormat.java\r\n```java\r\npublic class TeacherOutPutFormat extends FileOutputFormat<Text,NullWritable> {\r\n    \r\n    public RecordWriter<Text,NullWritable> getRecordWriter(TaskAttemptContext job) throws IOException, InterruptedException {\r\n        FileSystem fs = FileSystem.get(job.getConfiguration());\r\n        Path teacherPath = new Path(\"/wc/excelteacher/excelteacher.txt\");\r\n        Path otherPath = new Path(\"/wc/excelother/excelother.txt\");\r\n        FSDataOutputStream teacherOut = fs.create(teacherPath);\r\n        FSDataOutputStream otherOut = fs.create(otherPath);\r\n        return new TeacherRecordWriter(teacherOut,otherOut);\r\n    }\r\n\r\n    static class TeacherRecordWriter extends RecordWriter<Text,NullWritable> {\r\n        FSDataOutputStream teacherOut;\r\n        FSDataOutputStream otherOut;\r\n        \r\n        public TeacherRecordWriter(FSDataOutputStream teacherOut, FSDataOutputStream otherOut) {\r\n            this.teacherOut = teacherOut;\r\n            this.otherOut = otherOut;\r\n        }\r\n\r\n        public void write(Text key, NullWritable value) throws IOException, InterruptedException {\r\n            String keyStr = key.toString()+\"\\n\";\r\n            if(keyStr.contains(\":teacher\")){\r\n                String resultKey = keyStr.replace(\":teacher\", \"\");\r\n                teacherOut.write(resultKey.getBytes());\r\n            }else {\r\n                otherOut.write(keyStr.getBytes());\r\n            }\r\n        }\r\n\r\n        public void close(TaskAttemptContext context) throws IOException, InterruptedException {\r\n            if(teacherOut !=null) {\r\n                teacherOut.close();\r\n            }\r\n            if(otherOut !=null) {\r\n                otherOut.close();\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n## ExcelMapper.java\r\n```java\r\npublic class ExcelMapper extends Mapper<IntWritable,Text,Text,NullWritable> {\r\n    private List<String> teachers = null;\r\n    \r\n    @Override\r\n    protected void map(IntWritable key, Text value, Context context) throws IOException, InterruptedException {\r\n        String[] words = value.toString().split(\" \");\r\n        for(String word :words) {\r\n            if(teachers.contains(word)) {\r\n                word = word+\":teacher\";\r\n            }\r\n            context.write(new Text(word),NullWritable.get());\r\n        }\r\n    }\r\n\r\n    @Override\r\n    protected void setup(Context context) throws IOException, InterruptedException {\r\n        teachers = new ArrayList<String>();\r\n        teachers.add(\"deer\");\r\n        teachers.add(\"james\");\r\n        teachers.add(\"peter\");\r\n        teachers.add(\"lison\");\r\n        teachers.add(\"king\");\r\n        teachers.add(\"mark\");\r\n    }\r\n}\r\n```\r\n\r\n## ExcelJob.java\r\n```java\r\npublic class ExcelJob {\r\n    public static void main(String[] args) throws Exception{\r\n        Configuration conf = new Configuration();\r\n        Job job = Job.getInstance(conf);\r\n        job.setJarByClass(ExcelJob.class);\r\n        job.setMapperClass(ExcelMapper.class);\r\n        job.setMapOutputKeyClass(Text.class);\r\n        job.setMapOutputValueClass(NullWritable.class);\r\n        job.setInputFormatClass(ExcelFileInputFormat.class);\r\n        job.setOutputFormatClass(TeacherOutPutFormat.class);\r\n        //不需要Reduce\r\n        job.setNumReduceTasks(0);\r\n        //指定文件得读取位置\r\n        FileInputFormat.setInputPaths(job,new Path(\"D:\\\\wc\\\\excel\"));\r\n        //指定文件得输出位置 还有success文件需要输出 \r\n        FileOutputFormat.setOutputPath(job,new Path(\"D:\\\\wc\\\\excelout\"));\r\n\r\n        System.exit(job.waitForCompletion(true) ? 0 : -1);\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.6. Demo 自定义 OutputFileFormat",
      "lvl1": "TeacherOutPutFormat.java",
      "lvl2": "ExcelMapper.java",
      "lvl3": "ExcelJob.java"
    },
    "frontmatter": {
      "title": "15.6. Demo 自定义 OutputFileFormat",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "15.7. Demo 文件操作 FileSystem",
    "path": "/docs/architect/hadoop/Hadoop-15.7.DemowenjiancaozuoFileSystem.html",
    "url": "/docs/architect/hadoop/Hadoop-15.7.DemowenjiancaozuoFileSystem.html",
    "content": "---\r\ntitle: 15.7. Demo 文件操作 FileSystem \r\ndate: 2025/07/02\r\n---\r\n\r\n\r\n## FSTest.java\r\n```java\r\n/**\r\n * 需要安装Hadoop程序, 并配置环境变量(HADOOP_HOME)\r\n * 不配置也可以使用部分功能\r\n * 配置本地的hosts文件, 对应hadoop01的ip地址\r\n */\r\n@Slf4j\r\npublic class FSTest {\r\n\r\n    public static FileSystem fileSystem;\r\n\r\n\r\n    @Before\r\n    public void init() throws URISyntaxException, IOException, InterruptedException {\r\n        fileSystem = FileSystem.get(new URI(\"hdfs://hadoop01:9000\"), new Configuration(), \"root\");\r\n    }\r\n\r\n    @After\r\n    public void close() throws IOException {\r\n        fileSystem.close();\r\n    }\r\n\r\n    //显示根目录下文件\r\n    @Test\r\n    public void showRootFiles() throws Exception {\r\n        RemoteIterator<LocatedFileStatus> files = fileSystem.listFiles(new Path(\"/\"), false);\r\n        while (files.hasNext()) {\r\n            LocatedFileStatus fileStatus = files.next();\r\n            Path path = fileStatus.getPath();\r\n            String name = path.getName();\r\n            log.info(\"{} -> {}\", path, name);\r\n        }\r\n    }\r\n\r\n    //测试上传文件\r\n    @Test\r\n    public void testCopyFromLocalFile() throws Exception {\r\n        Path src = new Path(\"E:\\\\work\\\\test.txt\");\r\n        Path dst = new Path(\"/\");\r\n        fileSystem.copyFromLocalFile(src, dst);\r\n    }\r\n\r\n    //测试删除文件\r\n    @Test\r\n    public void testDelete() throws Exception {\r\n        Path dst = new Path(\"/test.txt\");\r\n        fileSystem.delete(dst, true);\r\n    }\r\n\r\n    //测试使用流的方式上传\r\n    @Test\r\n    public void testUploadUseStream() throws Exception {\r\n        FileInputStream fis = new FileInputStream(\"E:\\\\work\\\\test.txt\");\r\n        Path path = new Path(\"/test.txt\");\r\n        FSDataOutputStream fos = fileSystem.create(path);\r\n        IOUtils.copy(fis, fos);\r\n    }\r\n\r\n    //测试下载文件\r\n    @Test\r\n    public void testCopyToLocalFile() throws Exception {\r\n//        这种方式只有配置了HADOOP_HOME之后才能使用\r\n//        fileSystem.copyToLocalFile(new Path(\"/test.txt\"), new Path(\"E:\\\\work\\\\test2.txt\"));\r\n\r\n//        使用Java默认的方式 (RawLocalFileSystem)\r\n        fileSystem.copyToLocalFile(false, new Path(\"/test.txt\"), new Path(\"E:\\\\work\\\\test2.txt\"), true);\r\n    }\r\n}\r\n```\r\n\r\n\r\n## pom.xml\r\n```xml\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-common</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-hdfs</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.hadoop</groupId>\r\n            <artifactId>hadoop-client</artifactId>\r\n            <version>3.3.5</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>junit</groupId>\r\n            <artifactId>junit</artifactId>\r\n            <version>4.13.2</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-api</artifactId>\r\n            <version>2.0.7</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-simple</artifactId>\r\n            <version>2.0.7</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.projectlombok</groupId>\r\n            <artifactId>lombok</artifactId>\r\n            <version>1.18.26</version>\r\n            <scope>provided</scope>\r\n        </dependency>\r\n    </dependencies>\r\n```\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "15.7. Demo 文件操作 FileSystem",
      "lvl1": "FSTest.java",
      "lvl2": "pom.xml"
    },
    "frontmatter": {
      "title": "15.7. Demo 文件操作 FileSystem",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "16.1. 启动时没有启动 datanode",
    "path": "/docs/architect/hadoop/Hadoop-16.1.qidongshimeiyouqidongdatanode.html",
    "url": "/docs/architect/hadoop/Hadoop-16.1.qidongshimeiyouqidongdatanode.html",
    "content": "---\r\ntitle: 16.1. 启动时没有启动 datanode\r\ndate: 2025/07/02\r\n---\r\n\r\n原因:\r\n在第一次格式化`dfs`后，启动并使用了`hadoop`，后来又重新执行了格式化命令 `hdfs namenode -format`，这时`namenode`的`clusterID`会重新生成，而`datanode`的`clusterID` 保持不变。\r\n\r\n解决方法:\r\n1. 删除目录，重新格式化\r\n2. 将`name/current`下的`VERSION`中的`clusterID`复制到`data/current`下的`VERSION`中，覆盖掉原来的`clusterID`\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "16.1. 启动时没有启动 datanode"
    },
    "frontmatter": {
      "title": "16.1. 启动时没有启动 datanode",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "16.2. ClassNotFoundException",
    "path": "/docs/architect/hadoop/Hadoop-16.2.ClassNotFoundException.html",
    "url": "/docs/architect/hadoop/Hadoop-16.2.ClassNotFoundException.html",
    "content": "---\r\ntitle: 16.2. ClassNotFoundException\r\ndate: 2025/07/02\r\n---\r\n\r\n1. 输入命令 `hadoop classpath`, 将结果复制下来\r\n2. `mapred-site.xml` 中加入:\r\n```xml\r\n  <property>\r\n     <name>mapreduce.application.classpath</name>\r\n     <value>刚才复制的值</value>\r\n   </property>\r\n```\r\n1. `yarn-site.xml` 中加入:\r\n```xml\r\n  <property>\r\n     <name>yarn.application.classpath</name>\r\n     <value>刚才复制的值</value>\r\n   </property>\r\n\r\n```\r\n4. 重启 hadoop 集群\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "16.2. ClassNotFoundException"
    },
    "frontmatter": {
      "title": "16.2. ClassNotFoundException",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "17.1. 常用命令 fs",
    "path": "/docs/architect/hadoop/Hadoop-17.1.changyongminglingfs.html",
    "url": "/docs/architect/hadoop/Hadoop-17.1.changyongminglingfs.html",
    "content": "---\r\ntitle: 17.1. 常用命令 fs\r\ndate: 2025/07/02\r\n---\r\n\r\n|命令|作用|\r\n|-|-|\r\n|`hadoop fs -help`|帮助命令|\r\n|`hadoop fs -ls /`|显示目录信息|\r\n|`hadoop fs -ls hdfs://hadoop01:9000/`|显示目录信息(使用Nn节点)|\r\n|`hadoop fs -mkdir -p /path1/path2/path3`|创建目录|\r\n|`hadoop fs -moveFromLocal /file/a.txt /path1/path2`|从本地剪切粘贴到hdfs|\r\n|`hadoop fs -appendToFile  b.txt /file/a.txt`|追加文件|\r\n|`hadoop fs -cat /a.txt`|显示文件|\r\n|`hadoop fs -chmod 666 /file/a.txt`|改权限|\r\n|`hadoop fs -chown root:root /file/a.txt`|改组和拥有者|\r\n|`hadoop fs -chgrp group /file/a.txt`|改组|\r\n|`hadoop fs -copyFromLocal ./b.txt /`|拷贝文件到HDFS (上传)|\r\n|`hadoop fs -copyToLocal /b.txt /c.txt`|拷贝HDFS文件到本地 (下载)|\r\n|`hadoop fs -cp /aa.txt /bbb.txt`|复制|\r\n|`hadoop fs -mv /aa.txt /bbb.txt`|移动|\r\n|`hadoop fs -get /aa.txt`|下载|\r\n|`hadoop fs -put aa.txt /file`|上传|\r\n|`hadoop fs -getmerge /file bb.txt`|合并下载某个目录中的多个文件|\r\n|`hadoop fs -rmdir /file1/file2`|删除空目录|\r\n|`hadoop fs -rm -r /d.txt`|删除文件或文件夹|\r\n|`hadoop fs -df -h /`|统计文件系统可用空间|\r\n|`hadoop fs -du -s -h /file`|统计文件夹大小|\r\n|`hadoop fs -count /file`|统计文件夹节点数量|\r\n|`hadoop fs -setrep 3 /aa.txt`|设置副本数量|\r\n|`hdfs dfsadmin -report`|查看集群状态|\r\n\r\n---\r\n[官方文档](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html)\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "17.1. 常用命令 fs"
    },
    "frontmatter": {
      "title": "17.1. 常用命令 fs",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "2.节点",
    "path": "/docs/architect/hadoop/Hadoop-2.jiedian.html",
    "url": "/docs/architect/hadoop/Hadoop-2.jiedian.html",
    "content": "---\r\ntitle: 2.节点\r\ndate: 2025/07/02\r\n---\r\n\r\n* NN: NameNode fdfs 节点的 leader\r\n* DN: DataNode fdfs 的数据节点\r\n* SNN SecondaryNameNode fdfs 节点的镜像复制节点\r\n* RM: resoucemanager yarn 资源管理器的主节点\r\n* NM: nodemanager yarn 资源管理器的从节点\r\n* JN: JournalNode 日志节点\r\n\r\n---\r\n\r\n* ZKFC: DFSZKFailoverController Zookeeper 高可用控制\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2.节点"
    },
    "frontmatter": {
      "title": "2.节点",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "3. HDFS 读写文件流程",
    "path": "/docs/architect/hadoop/Hadoop-3.HDFSduxiewenjianliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-3.HDFSduxiewenjianliucheng.html",
    "content": "---\r\ntitle: 3. HDFS 读写文件流程\r\ndate: 2025/07/02\r\n---\r\n\r\n## HDFS 特点\r\n\r\n1. hdfs 里的文件是分块（block）存储的，默认大小是 128M\r\n2. hdfs 使用统一的抽象目录树管理文件，客户端不需要关心具体的文件分块\r\n    * 例如：hdfs://hadoop01:port/path1/path2/file\r\n3. 抽象目录树以及分块的信息由 namenode 节点管理\r\n4. 具体的 block 存储在每一个节点上，并且每一个 block 可以有多个副本（dfs.replication）\r\n5. Hdfs 适合设计成一次写入多次读取的情况，不支持修改\r\n\r\n## HDFS 写文件流程\r\n\r\n![HDFS 写文件流程](static/HDFS-W.png)\r\n\r\n举例来说，现在要上传一个 hadoop.jar 文件, 200M（按默认得配置应该分成两个 block [128,72]）\r\n对应命令是： `hadoop fs put hadoop.jar /`\r\n\r\n1. 客户端使用 FIleSystem 上传\r\n2. FIleSystem 与 namenode 进行通信，nn 会检查自己维护得目录树，判断当前目录是否存在\r\n3. 当 namenode 正确返回后，客户端再向 namenode 请求上传第一个 block, namenode 确认 datanode 的状态，把健康的 datanode 集合返回给客户端，客户端会根据返回的 datanode 集合挑选一个进行连接\r\n4. 客户端对每一个用于传输的节点都建立 pipeline 管道，并对传输第一个 block 块的数据（每次传输的并不是一整个 block 块，而是一个 packet，默认大小为 64K，64K 的 packet 中每次传输 512b 的数据时（一个 chunk）会进行一次校验）所以你可以把 packet 又理解成 chunk的集合\r\n5. 每个 datenode 写完个 block 后再返回确认信息\r\n6. 所有写完了，关闭输出流\r\n7. 整个完成后最后通知 namdenode 完成数据上传\r\n\r\n\r\n## HDFS 读文件流程\r\n\r\n![HDFS 写文件流程](static/HDFS-R.png)\r\n\r\n`hadoop fs get /hadoop.jar`\r\n\r\n1. client 访问 NameNode，查询元数据信息，获得这个文件的数据块位置列表，返回输入流对象。\r\n2. 就近挑选一台 datanode 服务器，请求建立输入流\r\n3. DataNode 向输入流中中写数据，以 packet 为单位\r\n4. 关闭输入流\r\n\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "3. HDFS 读写文件流程",
      "lvl1": "HDFS 特点",
      "lvl2": "HDFS 写文件流程",
      "lvl3": "HDFS 读文件流程"
    },
    "frontmatter": {
      "title": "3. HDFS 读写文件流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "4.元数据管理 edits fsimage",
    "path": "/docs/architect/hadoop/Hadoop-4.yuanshujuguanli-edits_fsimage.html",
    "url": "/docs/architect/hadoop/Hadoop-4.yuanshujuguanli-edits_fsimage.html",
    "content": "---\r\ntitle: 4.元数据管理 edits fsimage\r\ndate: 2025/07/02\r\n---\r\n\r\n## 元数据的存储形式\r\nhdfs 的读写流程都离不开 namenode，在 namenode 中维护了文件、文件块的信息，这些信息统统称之为元数据\r\n\r\n元数据在 hdfs 中有 3 种存在形式 (<font color=\"red\">内存的数据 = fsimage + edits 文件</font>)\r\n1. 存在内存中，这个最全的元数据\r\n2. fsimage 磁盘元数据镜像文件\r\n3. 最新的操作日志文件\r\n\r\n查看存储结构:\r\n* `cd /soft/data/tmp/dfs/name/current`\r\n* `hdfs oev -i edits_0000000000000001913-0000000000000001959 -o edits.xml`\r\n* `hdfs oiv -i fsimage_0000000000000001972 -p XML -o fsimage.xml`\r\n\r\n## checkpoint\r\n当达到某个条件后，secondary namenode 会把 namenode 上保存的 edits 和最新的 fsimage 下载到本地，并把这些 edits 和 fsimage 进行合并，产生新的 fsimage，这整个过程把他称作 <font color=\"red\">checkpoint</font> ([官方文档](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml))\r\n\r\ncheckpoint 的条件配置 (hdfs-site.xml):\r\n```properties\r\n#检查触发条件是否满足的频率，60 秒\r\ndfs.namenode.checkpoint.check.period=60 \r\n\r\n# 以下两个参数做checkpoint 操作时，代表 secondary namenode 的本地工作目录\r\ndfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary\r\ndfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir} \r\n\r\n#最大重试次数\r\ndfs.namenode.checkpoint.max-retries=3 \r\n#两次 checkpoint 之间的时间间隔 3600 秒\r\ndfs.namenode.checkpoint.period=3600 \r\n#两次 checkpoint 之间最大的操作记录\r\ndfs.namenode.checkpoint.txns=1000000 \r\n```\r\n\r\n## checkpoint 工作机制\r\n\r\n![checkpoint 工作机制](static/checkpoint.png)\r\n\r\n1. SecondaryNameNode 会定时的和 NameNode 通信，请求其停止使用 edits 文件，暂时将新的写操作写到一个新的文件 edits.new 上，这个操作是瞬时完成的，上层的写日志函数完全感觉不到差别\r\n2. econdaryNameNode 通过 HTTP 的 get 方法从 NameNode 上获取到 fsimage 和 edits 文件，SecondaryNameNode 将 fsimage 文件载入内存中，逐一执行 edits 文件中的事务，创建新的合并后的 fsimage 文件，<font color=\"red\">使得内存中的 fsimage 保存最新</font>。\r\n3. SecondaryNameNode 执行完 2 之后，会通过 post 方法将新的 fsimage 文件发送到 NameNode 节点上\r\n4. NameNode 将从 SecondaryNameNode 接收到的新的 fsimage 文件保存为.ckpt 文件\r\n5. NameNode 重新命名 fsimage.ckpt 为 fsimage 替换旧的 fsimage 文件，同时将 edits.new 替换为 edits 文件，<font color=\"red\">通过这个过程 edits 文件就变小了</font>。\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "4.元数据管理 edits fsimage",
      "lvl1": "元数据的存储形式",
      "lvl2": "checkpoint",
      "lvl3": "checkpoint 工作机制"
    },
    "frontmatter": {
      "title": "4.元数据管理 edits fsimage",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "5. mapreduce 工作机制",
    "path": "/docs/architect/hadoop/Hadoop-5.mapreducegongzuojizhi.html",
    "url": "/docs/architect/hadoop/Hadoop-5.mapreducegongzuojizhi.html",
    "content": "---\r\ntitle: 5. mapreduce 工作机制\r\ndate: 2025/07/02\r\n---\r\n\r\n一个完整的 mapreduce 程序在分布式运行时有三类实例进程：\r\n1. MRAppMaster：负责整个程序的过程调度及状态协调\r\n2. MapTask：负责 map 阶段的整个数据处理流程\r\n3. ReduceTask：负责 reduce 阶段的整个数据处理流程\r\n\r\n---\r\n流程:\r\n1. 一个 mr 程序启动的时候，最先启动的是 MRAppMaster，MRAppMaster 启动后根据本次 job 的描述信息，计算出需要的 maptask 实例数量，然后向集群申请机器启动相应数量的 maptask 进程（这里先理解成一个文件一个 maptask）\r\n2. maptask 进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：\r\n    1. 利用客户指定的 inputformat 来获取数据，形成输入 K，V 对\r\n    2. 将输入 KV 对传递给客户定义的 `map()` 方法，做逻辑运算，并将 `map()` 方法输出的 KV 对收集到缓存\r\n    3. 将缓存中的 KV 对按照 K 分区排序后不断溢写到磁盘文件\r\n3. MRAppMaster 监控到所有 maptask 进程任务完成之后，会根据客户指定的参数启动相应数量的 reducetask 进程，并告知 reducetask 进程要处理的数据范围（数据分区）\r\n4. Reducetask 进程启动之后，根据 MRAppMaster 告知的待处理数据所在位置，从若干台 maptask 运行所在机器上获取到若干个 maptask 输出结果文件，并在本地进行重新归并排序，然后按照相同 key 的 KV 为一个组，调用客户定义的 `reduce()` 方法进行逻辑运算，并收集运算输出的结果 KV，然后调用客户指定的 outputformat 将结果数据输出到外部存储\r\n\r\n---\r\n\r\n{% mermaid %}\r\ngraph TD\r\n    M -.->|开启两个MapTask| C1\r\n    M -.->|所有maptask进程完成后<br>开启两个ReduceTask<br>告知数据所在位置| R1\r\n    M(MRAppMaster) --> A(input dir)\r\n    A --> B1([1.txt])\r\n    A --> B2([2.txt])\r\n    B1 --InputFormat<br>TextInputFormat--> C1([MapTask1])\r\n    B2 --InputFormat<br>TextInputFormat--> C2([MapTask2])\r\n    M -.->|开启两个MapTask| C2\r\n    C1 --Mapper.map-->D1([context.write])\r\n    C2 --Mapper.map-->D2([context.write])\r\n    D1 --> E1(内存缓存-环形缓冲区)\r\n    D2 --> E2(内存缓存-环形缓冲区)\r\n    E1 --按照KEY分区排序<br>写入磁盘--> F1(溢出文件1) \r\n    E1 --按照KEY分区排序<br>写入磁盘--> F2(溢出文件2) \r\n    E2 --按照KEY分区排序<br>写入磁盘--> F3(溢出文件3) \r\n    E2 --按照KEY分区排序<br>写入磁盘--> F4(溢出文件4)\r\n    F1 --> H1([Shuffle流程])\r\n    F2 --> H1([Shuffle流程])\r\n    F3 --> H2([Shuffle流程])\r\n    F4 --> H2([Shuffle流程])\r\n    H1 -.-> F5(所有客户机的数据)\r\n    H2 -.-> F5\r\n    F5 --从客户机获取溢出文件<br>key.hashcode%2=0--> R1([ReduceTask1])\r\n    F5 --从客户机获取溢出文件<br>key.hashcode%2=1--> R2([ReduceTask2])\r\n    M -.->|所有maptask进程完成后<br>开启两个ReduceTask<br>告知数据所在位置| R2\r\n    R1 --归并排序分组<br>Reducer.reduce--> G1([context.write])\r\n    R2 --归并排序分组<br>Reducer.reduce--> G2([context.write])\r\n    G1 --OutputFormat<br>TextOutputFormat--> P1(part-r-00000)\r\n    G2 --OutputFormat<br>TextOutputFormat--> P2(part-r-00001)\r\n{% endmermaid %}\r\n\r\n---\r\n\r\n关于Shuffle流程: [6.提交任务流程与Shuffle流程](./Hadoop-6.提交任务流程与Shuffle流程.md)\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "5. mapreduce 工作机制"
    },
    "frontmatter": {
      "title": "5. mapreduce 工作机制",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "6.提交任务流程与 Shuffle 流程",
    "path": "/docs/architect/hadoop/Hadoop-6.tijiaorenwuliuchengyuShuffleliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-6.tijiaorenwuliuchengyuShuffleliucheng.html",
    "content": "---\r\ntitle: 6.提交任务流程与 Shuffle 流程\r\ndate: 2025/07/02\r\n---\r\n\r\n\r\nshuffle 并不是个组件，而是 mr 处理流程中的一个子过程，它过程开始于 maptask 把数据写入环形缓存一直到数据到 reduce 之间的整个过程\r\n\r\n![Shuffle 流程](static/shuffle.png)\r\n\r\n1. maptask 收集我们的 `map()` 方法输出的 kv 对，放到内存缓冲区中\r\n2. 从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件\r\n3. 多个溢出文件会被合并成大的溢出文件\r\n4. <font color=\"orange\">在溢出过程中，及合并 Combine 的过程中，都要调用 partitoner 进行分组和针对 key 进行排序 (compare)</font>\r\n5. reducetask 根据自己的分区号，去各个 maptask 机器上取相应的结果分区数据\r\n6. reducetask 会取到同一个分区的来自不同 maptask 的结果文件，<font color=\"orange\">reducetask 会将这些文件再进行合并（归并排序）</font>\r\n7. 合并成大文件后，shuffle 的过程也就结束了，后面进入 reducetask 的逻辑运算过程（从文件中取出一个个的键值对 group，调用用户自定义的 `reduce()`方法）\r\n8. 缓冲区的大小可以通过参数调整, 参数：`mapreduce.task.io.sort.mb` 默认 100M\r\n\r\n---\r\n[官方文档](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "6.提交任务流程与 Shuffle 流程"
    },
    "frontmatter": {
      "title": "6.提交任务流程与 Shuffle 流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "7.切片逻辑",
    "path": "/docs/architect/hadoop/Hadoop-7-qiepianluoji.html",
    "url": "/docs/architect/hadoop/Hadoop-7-qiepianluoji.html",
    "content": "---\r\ntitle: 7.切片逻辑\r\ndate: 2025/07/02\r\n---\r\n\r\n默认切片的大小与 hdfs 的 block 的 size 相等\r\n切片大小: `Math.max(minSize, Math.min(maxSize, blockSize))`\r\n* `mapreduce.input.fileinputformat.split.minsize` 默认值 `1`\r\n* `mapreduce.input.fileinputformat.split.maxsize` 默认值 `Long.MAX_VALUE`\r\n\r\n切片规则: `剩余长度 / splitsize < 1.1`\r\n\r\n---\r\n\r\n流程:\r\n\r\n{% mermaid %}\r\ngraph TD\r\n    A(input.txt) --> F([FileInputFormat])\r\n    F --> J([Jobsubmit])\r\n    J -.->|剩余/splitsize<1.1| S1([切片1])\r\n    J -.->|剩余/splitsize<1.1| S2([切片2])\r\n    S1 --写入文件--> JS(job.split)\r\n    S2 --写入文件--> JS(job.split)\r\n    JS --MrAppMaster--> M1([MapTask1])\r\n    JS --MrAppMaster--> M2([MapTask2])\r\n{% endmermaid %}\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "7.切片逻辑"
    },
    "frontmatter": {
      "title": "7.切片逻辑",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "8.YARN流程",
    "path": "/docs/architect/hadoop/Hadoop-8-YARNliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-8-YARNliucheng.html",
    "content": "---\r\ntitle: 8.YARN流程\r\ndate: 2025/07/02\r\n---\r\n\r\nYARN 是运算资源调度系统，他只做运算资源的分配和调度，不参与用户程序内部的具体工作，所以 YARN 可以作为一个通用的资源调度平台\r\n\r\n在 Hadoop1.x 的时候其实是没有 YRAN，当初的 MapReduce 由两个组件组成\r\n* Job Tracker: 相当于 RM + MrAppMaster\r\n* Task Tracker: 相当于 NM + Task(MapTask, ReduceTask)\r\n\r\n---\r\n\r\n![YARN 流程](static/YARN.png)\r\n\r\n1. 客户端程序向 ResourceManager 提交应用并请求一个 ApplicationMaster 实例\r\n2. ResourceManager 找到一个可以运行一个 Container 的 NodeManager，并在这个 Container 中启动 ApplicationMaster 实例\r\n3. ApplicationMaster 向 ResourceManager 进行注册 ，注册之后客户端就可以查询 ResourceManager 获得自己 ApplicationMaster 的详细信息 ，以后就可以和自己的 ApplicationMaster 直接交互了（这个时候，客户端主动和 ApplicationMaster 交互，应用先向 ApplicationMaster 发送一个满足自己需求的资源请求）\r\n4. 在平常的操作过程中，ApplicationMaster 根据协议向 ResourceManager 发送资源请求\r\n5. 当 Container 被成功分配后，ApplicationMaster 通过向 NodeManager 发送信息来启动 Container，信息包含了能够让 Container 和 ApplicationMaster 交互所需要的资料\r\n6. 应用程序的代码以 task 形式在启动的 Container 中运行，并把运行的进度、状态等信息通过协议发送给 ApplicationMaster\r\n7. 在应用程序运行期间，提交应用的客户端主动和 ApplicationMaster 交流获得应用的运行状态、进度更新等信息\r\n8. 一旦应用程序执行完成并且所有相关工作也已经完成，ApplicationMaster 向 ResourceManager 取消注册然后关闭，用到所有的 Container 也归还给系统\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "8.YARN流程"
    },
    "frontmatter": {
      "title": "8.YARN流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "9. mapreduce YARN 流程",
    "path": "/docs/architect/hadoop/Hadoop-9-mapreduce-YARNliucheng.html",
    "url": "/docs/architect/hadoop/Hadoop-9-mapreduce-YARNliucheng.html",
    "content": "---\r\ntitle: 9. mapreduce YARN 流程\r\ndate: 2025/07/02\r\n---\r\n\r\n![mapreduce-YARN流程](static/YARN-MR.png)\r\n\r\n1. 应用申请运行RM的JOB\r\n2. RM返回JOBID以及提交资源的目录\r\n3. 应用提交相关文件到资源目录\r\n4. 通知RM, JOB资源提交完毕\r\n5. RM初始任务TASK, 加入调度队列\r\n6. 空闲NM领取任务\r\n7. NM根据任务信息创建Container (并且从资源目录获取JOB资源)\r\n8. 应用发送指令启动NM的MrAppMaster\r\n9. MrAppMaster向RM请求运算节点\r\n10. MrAppMaster向请求回来的运算节点中启动MapTask\r\n11. MrAppMaster向请求回来的运算节点中启动ReduceTask\r\n12. JOB执行完成后, MrAppMaster向RM注销自己\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "9. mapreduce YARN 流程"
    },
    "frontmatter": {
      "title": "9. mapreduce YARN 流程",
      "date": "2025/07/02"
    },
    "type": "content"
  },
  {
    "title": "Redis-持久化",
    "path": "/docs/architect/redis/Redis-chijiuhua.html",
    "url": "/docs/architect/redis/Redis-chijiuhua.html",
    "content": "---\r\ntitle: Redis-持久化\r\ndate: 2025/03/05\r\n---\r\n\r\n::: tip 介绍\r\n1. RDB：dump.rdb （二进制文件）\r\n2. AOF（append-only file）：appendonly.aof（resp协议格式）\r\n3. 混合持久化：RDB+AOF\r\n4. 数据备份策略\r\n:::\r\n\r\n## RDB: dump.rdb\r\n\r\n- RDB：dump.rdb （二进制文件）\r\n\t- 配置文件：`bgsave` 方式\r\n\t\t- `save 60 1000`  关闭RDB只需要将所有的 `save` 保存策略注释掉即可\r\n\t\t\t- 60 秒内有至少有 1000 个键被改动， 则进行一次 RDB 持久化\r\n\t- 命令：覆盖原有 rdb 快照文件\r\n\t\t- `save`：同步\r\n\t\t- `bgsave`：异步，写时复制 - COW机制\r\n\t\t\t- `bgsave` 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据\r\n\t\t\t\t- 在生成子进程执行调用fork函数时会有短暂阻塞\r\n\t\t\t- 如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。然后，`bgsave` 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据\r\n\r\n::: danger 缺点\r\n宕机后，服务器将丢失最近写入、且仍未保存到快照中的数据\r\n:::\r\n\r\n## AOF: appendonly.aof\r\n\r\n- AOF（append-only file）：appendonly.aof（resp协议格式）\r\n\t- 将修改的每一条指令记录进文件appendonly.aof中（先写入os cache，每隔一段时间fsync到磁盘）\r\n\t- 命令：`bgrewriteaof`  （fork出一个子进程去做）\r\n\t- 配置文件\r\n\r\n|配置文件|介绍|\r\n|-|-|\r\n|`appendonly yes`|开启AOF模式|\r\n|`appendfsync always`|每条命令都fsync一次，拉低性能|\r\n|`appendfsync everysec`|每秒fsync一次，推荐，缺点是宕机后会丢失1秒的数据，但可以从数据库恢复|\r\n|`appendfsync no`|让操作系统决定fsync的时机，快但不安全|\r\n|`auto‐aof‐rewrite‐min‐size 64mb`|AOF文件超过64M时，重写AOF文件（整合命令）|\r\n|`auto‐aof‐rewrite‐percentage 100`|自上一次重写后文件大小增长了100%则再次触发重写|\r\n\r\n::: warning 缺点\r\n体积大，恢复慢\r\n:::\r\n\r\n## 混合持久化\r\n\r\n- 混合持久化：RDB+AOF\r\n\t- 配置文件（必须先开启AOF）：`aof‐use‐rdb‐preamble yes`\r\n\t- 将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令（生成RDB过程中产生的命令）存在一起，都写入新的AOF文件\r\n\t- 新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换\r\n\r\n::: info 优点\r\n在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可以完全替代之前的AOF 全量文件重放，因此重启效率大幅得到提升\r\n:::\r\n\r\n![混合持久化](static/Redis-持久化-appendonly.aof.png)\r\n\r\n## 数据备份策略\r\n\r\n- 数据备份策略：\r\n\t1. 写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份\r\n\t2. 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份\r\n\t3. 每次copy备份的时候，删除一些旧备份\r\n\t4. 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Redis-持久化",
      "lvl1": "RDB: dump.rdb",
      "lvl2": "AOF: appendonly.aof",
      "lvl3": "混合持久化",
      "lvl4": "数据备份策略"
    },
    "frontmatter": {
      "title": "Redis-持久化",
      "date": "2025/03/05"
    },
    "type": "content"
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "---\r\ntitle: Zookeeper-特性\r\ndate: 2025/06/16\r\n---\r\n\r\n:::tip\r\n- CP架构\r\n- 常见命令\r\n- 数据结构\r\n- 监听通知机制\r\n- 节点特性\r\n- ACL权限控制\r\n- 集群\r\n- 四字命令\r\n- Leader 选举原理\r\n- 数据同步流程\r\n:::\r\n\r\n---\r\n## CP架构\r\n\r\n- CAP 理论指出对于一个分布式计算系统来说，不可能同时满足以下三点\r\n\t- 一致性：在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性，等同于所有节点访问同一份最新的数据副本。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态\r\n\t- 可用性：每次请求都能获取到正确的响应，但是不保证获取的数据为最新数据\r\n\t- 分区容错性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供服务，除非是整个网络环境都发生了故障\r\n- 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项\r\n\t- P 是必须的，因此只能在 CP 和 AP 中选择，zookeeper 保证的是 CP\r\n- BASE 理论：BASE 是 Basically Available(基本可用)、Soft-state(软状态) 和 Eventually Consistent(最终一致性) 三个短语的缩写\r\n\t- 基本可用：在分布式系统出现故障，允许损失部分可用性（服务降级、页面降级）\r\n\t- 软状态：允许分布式系统出现中间状态。而且中间状态不影响系统的可用性。这里的中间状态是指不同的 data replication（数据备份节点）之间的数据更新可以出现延时的最终一致性\r\n\t- 最终一致性：data replications 经过一段时间达到一致性\r\n- Zookeeper 写入是强一致性，读取是顺序一致性（版本号）\r\n- ZooKeeper本质上是一个分布式的小文件存储系统（Zookeeper=文件系统+监听机制）\r\n\t- 是一个基于观察者模式设计的分布式服务管理框架\r\n\r\n---\r\n## 常见命令\r\n\r\n- ls 查看当前 znode 的子节点 \\[可监听\\]\r\n\t- -w: 监听子节点变化\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t- -R: 表示递归的获取\r\n- create 创建节点\r\n\t- -s : 创建有序节点\r\n\t- -e : 创建临时节点\r\n\t- -c : 创建一个容器节点\r\n\t- \\[-t ttl\\] : 创建一个TTL节点， -t 时间（单位毫秒）\r\n\t- data : 节点的数据，可选，如果不使用时，节点数据就为null\r\n\t- acl : 访问控制\r\n- get 获取节点数据信息\r\n\t-  -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t-  -w: 监听节点变化\r\n- set 设置节点数据\r\n\t- -s: 表示节点为顺序节点\r\n\t- -v: 指定版本号\r\n- getAcl 获取节点的访问控制信息\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n- setAcl 设置节点的访问控制列表\r\n\t- -s: 节点状态信息（时间戳、版本号、数据大小等）\r\n\t- -v: 指定版本号\r\n\t- -R: 递归的设置\r\n- stat 查看节点状态信息\r\n- delete  删除某一节点，只能删除无子节点的节点\r\n\t- -v: 表示节点版本号\r\n- deleteall 递归的删除某一节点及其子节点\r\n- setquota 对节点增加限制\r\n\t- -n: 表示子节点的最大个数\r\n\t- -b: 数据值的最大长度，-1表示无限制\r\n\r\n---\r\n## 数据结构\r\n\r\n- ZooKeeper的数据模型是层次模型，层次模型常见于文件系统。层次模型和key-value模型是两种主流的数据模型。ZooKeeper使用文件系统模型主要基于以下两点考虑\r\n\t- 文件系统的树形结构便于表达数据之间的层次关系\r\n\t- 文件系统的树形结构便于为不同的应用分配独立的命名空间 ( namespace ) \r\n- ZooKeeper的层次模型称作Data Tree，Data Tree的每个节点叫作Znode\r\n\t- 每一个 ZNode 默认能够存储 1MB 的数据\r\n\t- 每个 ZNode 都可以通过其路径唯一标识\r\n\t- 每个节点都有一个版本(version)，版本从0开始计数\r\n\t- ![Zookeeper 节点](static/Zookeeper-特性-节点.png)\r\n- 节点分类\r\n\t- 持久节点 (PERSISTENT): 这样的znode在创建之后即使发生ZooKeeper集群宕机或者client宕机也不会丢失\r\n\t- 临时节点 (EPHEMERAL ): client宕机或者client在指定的timeout时间内没有给ZooKeeper集群发消息，这样的znode就会消失\r\n\t- 持久顺序节点 (PERSISTENT_SEQUENTIAL): znode除了具备持久性znode的特点之外，名字具备顺序性\r\n\t- 临时顺序节点 (EPHEMERAL_SEQUENTIAL): znode除了具备临时性znode的特点之外，名字具备顺序性\r\n\t- Container节点 (3.5.3版本新增)：Container容器节点，当容器中没有任何子节点，该容器节点会被zk定期删除（定时任务默认60s 检查一次)\r\n\t\t- 和持久节点的区别是 ZK 服务端启动后，会有一个单独的线程去扫描，所有的容器节点，当发现容器节点的子节点数量为 0 时，会自动删除该节点\r\n\t\t- 可以用于 leader 或者锁的场景中\r\n\t- TTL节点:  带过期时间节点，默认禁用\r\n\t\t- 在zoo.cfg中添加 `extendedTypesEnabled=true `开启\r\n\t\t- ttl 不能用于临时节点\r\n- 节点状态信息\r\n\t- cZxid ：Znode创建的事务id\r\n\t- ctime：节点创建时的时间戳\r\n\t- mZxid ：Znode被修改的事务id，即每次对znode的修改都会更新mZxid\r\n\t\t- 对于zk来说，每次的变化都会产生一个唯一的事务id，zxid（ZooKeeper Transaction Id）\r\n\t\t- 通过zxid，可以确定更新操作的先后顺序\r\n\t\t- 如果zxid1小于zxid2，说明zxid1操作先于zxid2发生\r\n\t\t- zxid对于整个zk都是唯一的，即使操作的是不同的znode\r\n\t- pZxid: 表示该节点的子节点列表最后一次修改的事务ID\r\n\t\t- 只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid\r\n\t\t\t- 添加子节点或删除子节点就会影响子节点列表\r\n\t\t\t- 但是修改子节点的数据内容则不影响该ID\r\n\t- mtime：节点最新一次更新发生时的时间戳\r\n\t- cversion ：子节点的版本号\r\n\t\t- 当znode",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 1,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "的子节点有变化时，cversion 的值就会增加1\r\n\t- dataVersion：数据版本号\r\n\t\t- 每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据）\r\n\t\t- 可有效避免了数据更新时出现的先后顺序问题\r\n\t- ephemeralOwner\r\n\t\t- 如果该节点为临时节点, ephemeralOwner值表示与该节点绑定的session id\r\n\t\t\t- 在client和server通信之前,首先需要建立连接,该连接称为session\r\n\t\t\t- 连接建立后,如果发生连接超时、授权失败,或者显式关闭连接,连接便处于closed状态, 此时session结束\r\n\t\t- 如果不是, ephemeralOwner值为0 (持久节点)\r\n\t- dataLength： 数据的长度\r\n\t- numChildren：子节点的数量（只统计直接子节点的数量）\r\n\r\n---\r\n## 监听通知机制\r\n\r\n- watcher 机制\r\n\t- 一个Watch事件是一个一次性的触发器\r\n\t\t- 当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们\r\n\t- Zookeeper采用了 Watcher机制实现数据的发布订阅功能\r\n\t\t- 多个订阅者可同时监听某一特定主题对象，当该主题对象的自身状态发生变化时例如节点内容改变、节点下的子节点列表改变等，会实时、主动通知所有订阅者\r\n\t- watcher机制事件上与观察者模式类似，也可看作是一种观察者模式在分布式场景下的实现方式\r\n- watcher 的过程\r\n\t- 客户端向服务端注册watcher\r\n\t- 服务端事件发生触发watcher\r\n\t- 客户端回调watcher得到触发事件情况\r\n- Zookeeper中的watch机制，必须客户端先去服务端注册监听，这样事件发送才会触发监听，通知给客户端\r\n- 支持的事件类型\r\n\t- None: 连接建立事件\r\n\t- NodeCreated： 节点创建 \r\n\t- NodeDeleted： 节点删除 \r\n\t- NodeDataChanged：节点数据变化\r\n\t- NodeChildrenChanged：子节点列表变化 \r\n\t- DataWatchRemoved：节点监听被移除 \r\n\t- ChildWatchRemoved：子节点监听被移除\r\n- 特性\r\n\t- 一次性触发：watcher是一次性的，一旦被触发就会移除，再次使用时需要重新注册\r\n\t- 客户端顺序回调：watcher回调是顺序串行执行的，只有回调后客户端才能看到最新的数据状态。一个watcher回调逻辑不应该太多，以免影响别的watcher执行\r\n\t- 轻量级：WatchEvent是最小的通信单位，结构上只包含通知状态、事件类型和节点路径，并不会告诉数据节点变化前后的具体内容\r\n\t- 时效性：watcher只有在当前session彻底失效时才会无效，若在session有效期内快速重连成功，则watcher依然存在，仍可接收到通知\r\n- 使用场景\r\n\t- master-worker 机制\r\n\t- 基于版本号的条件更新\r\n\t\t- ![Zookeeper 更新](static/Zookeeper-特性-更新.png)\r\n\r\n---\r\n## 节点特性\r\n\r\n- 同一级节点 key 名称是唯一的\r\n- 创建节点时，必须要带上全路径\r\n- session 关闭，临时节点清除\r\n- 自动创建顺序节点\r\n- watch 机制，监听节点变化\r\n\t- 监听事件被单次触发后，事件就失效了\r\n- 永久性 Watch（`addWatch [‐m mode] path`）：是Zookeeper 3.6.0版本新增的功能\r\n\t- 在被触发之后，仍然保留，可以继续监听ZNode上的变更\r\n\t- 针对指定节点添加事件监听，支持两种模式\r\n\t\t- PERSISTENT，持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件\r\n\t\t- PERSISTENT_RECURSIVE，持久化递归订阅，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件\r\n- delete 命令只能一层一层删除\r\n- deleteall 命令递归删除\r\n- 应用场景：适用于存储和协同相关的关键数据，不适合用于大数据量存储\r\n\t- 注册中心 \r\n\t- 数据发布/订阅（常用于实现配置中心） \r\n\t\t- 数据量小的KV\r\n\t\t- 数据内容在运行时会发生动态变化\r\n\t\t- 集群机器共享，配置一致\r\n\t\t- 推拉结合\r\n\t\t\t- 服务端会推给注册了监控节点的客户端 Watcher 事件通知\r\n\t\t\t- 客户端获得通知后，然后主动到服务端拉取最新的数据\r\n\t- 统一集群管理\r\n\t- 负载均衡\r\n\t- 命名服务\r\n\t- 分布式协调/通知\r\n\t- 集群管理\r\n\t- Master选举\r\n\t- 分布式锁\r\n\t- 分布式队列\r\n\r\n---\r\n## ACL权限控制\r\n\r\n- zookeeper 的 ACL（Access Control List，访问控制表）权限可以针对节点设置相关读写等权限\r\n- zookeeper 的 acl 通过 `[scheme:id:permissions]` 来构成权限列表\r\n\t- scheme：授权的模式，代表采用的某种权限机制\r\n\t\t- 包括 world、auth、digest、ip、super 几种\r\n\t- id：授权对象，代表允许访问的用户\r\n\t\t- 如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段\r\n\t\t- 而如果使用 Digest 或 Super 方式，则对应于一个用户名\r\n\t\t- 如果是 World 模式，是授权系统中所有的用户\r\n\t- permissions：授权的权限，权限组合字符串，由 cdrwa 组成，其中每个字母代表支持不同权限\r\n\t\t- 创建权限 create(c)、删除权限 delete(d)、读权限 read(r)、写权限 write(w)、管理权限admin(a)。\r\n\r\n| 模式     | 描述                                        |\r\n| ------ | ----------------------------------------- |\r\n| world  | 授权对象只有一个anyone，代表登录到服务器的所有客户端都能对该节点执行某种权限 |\r\n| ip     | 对连接的客户端使用IP地址认证方式进行认证                     |\r\n| auth   | 使用以添加认证的用户进行认证                            |\r\n| digest | 使用用户:密码方式验证                               |\r\n\r\n| 权限类型   | ACL简写 | 描述              |\r\n| ------ | ----- | --------------- |\r\n| read   | r     | 读取节点及显示子节点列表的权限 |\r\n| write  | w     | 设置节点数据的权限       |\r\n| create | c     | 创建子节点的权限        |\r\n| delete | d     | 删除子节点的权限        |\r\n| admin  | a     | 设置该节点ACL权限的权限   |\r\n\r\n| 授权命令    |",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 2,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": " 用法                   | 描述             |\r\n| ------- | -------------------- | -------------- |\r\n| getAcl  | getAcl path          | 读取节点的ACL       |\r\n| setAcl  | setAcl path acl      | 设置节点的ACL       |\r\n| create  | create path data acl | 创建节点时设置ACL     |\r\n| addAuth | addAuth scheme auth  | 添加认证用户，类似于登录操作 |\r\n- setAcl\r\n\t- `set Acl /name world:anyone:cdwa`\r\n- auth授权模式\r\n\t- 创建用户 `addauth digest fox:123456`\r\n\t- `setAcl /name auth:fox:123456:cdrwa`\r\n\t- 密码加密\r\n\t\t- `echo -n fox:123456 | openssl dgst -binary -sha1 | openssl base64`\r\n\t\t- `setAcl /name auth:fox:ZsWwgmtnTnx1usRF1voHFJAYGQU=:cdrwa`\r\n- digest授权模式\r\n\t- `setAcl /tuling/fox digest:fox:ZsWwgmtnTnx1usRF1voHFJAYGQU=:cdrwa`\r\n- IP授权模式\r\n\t- `setAcl /node-ip ip:192.168.109.128:cdwra`\r\n\t- `create /node-ip data ip:192.168.109.128:cdwra`\r\n\t\t- 多个指定IP可以通过逗号分隔\r\n\t\t\t- `setAcl /node-ip ip:IP1:rw,ip:IP2:a`\r\n- Super 超级管理员模式\r\n\t- 这是一种特殊的Digest模式， 在Super模式下超级管理员用户可以对Zookeeper上的节点进行任何的操作\r\n\t- 需要在启动脚本上通过添加JVM 参数开启\r\n\t\t- `-Dzookeeper.DigestAuthenticationProvider.superDigest=admin:<base64encoded(SHA1(123456))`\r\n\r\n---\r\n## 集群\r\n\r\n- 集群角色\r\n\t- Leader： 领导者\r\n\t\t- 事务请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性\r\n\t\t- 集群内部各个服务器的调度者\r\n\t\t- 对于create、setData、delete等有写操作的请求，则要统一转发给leader处理，leader需要决定编号、执行操作，这个过程称为事务\r\n\t- Follower：跟随者\r\n\t\t- 处理客户端非事务（读操作）请求（可以直接响应）\r\n\t\t- 转发事务请求给 Leader\r\n\t\t- 参与集群 Leader 选举投票\r\n\t- Observer：观察者\r\n\t\t- 对于非事务请求可以独立处理（读操作）\r\n\t\t- 对于事务性请求会转发给 leader 处理\r\n\t\t- Observer 节点接收来自 leader 的 inform 信息，更新自己的本地存储\r\n\t\t- 不参与提交和选举投票\r\n\t\t- 在不影响集群事务处理能力的前提下提升集群的非事务处理能力\r\n\t\t- Observer 应用场景\r\n\t\t\t- 提升集群的读性能\r\n\t\t\t- 跨数据中心部署\r\n\t\t\t\t- 比如需要部署一个北京和香港两地都可以使用的zookeeper集群服务，并且要求北京和香港客户的读请求延迟都很低。解决方案就是把香港的节点都设置为observer\r\n- 集群架构\r\n\t- ![Zookeeper 集群](static/Zookeeper-特性-集群.png)\r\n\t- leader节点可以处理读写请求\r\n\t- follower只可以处理读请求\r\n\t- follower在接到写请求时会把写请求转发给leader来处理\r\n- Zookeeper数据一致性保证\r\n\t- 全局可线性化 (Linearizable) 写入：先到达leader的写请求会被先处理，leader决定写请求的执行顺序\r\n\t- 客户端FIFO顺序：来自给定客户端的请求按照发送顺序执行\r\n- 集群搭建\r\n\t- 修改zoo.cfg配置，添加server节点配置：`server.A=B:C:D`\r\n\t\t- `dataDir=/data/zookeeper`\r\n\t\t- `server.1=192.168.65.156:2888:3888`\r\n\t\t- A 是一个数字，表示这个是第几号服务器\r\n\t\t\t- 集群模式下配置一个文件 myid，这个文件在 dataDir 目录下，这个文件里面有一个数据 就是 A 的值，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个server\r\n\t\t- B 是这个服务器的地址\r\n\t\t- C 是这个服务器Follower与集群中的Leader服务器交换信息的端口\r\n\t\t- D 是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader\r\n\t\t\t- 而这个端口就是用来执行选举时服务器相互通信的端口\r\n\t- 创建 myid 文件，配置服务器编号\r\n\t- 启动 zookeeper server 集群 `bin/zkServer.sh start`\r\n\r\n---\r\n## 四字命令\r\n\r\n- zookeeper 支持某些特定的四字命令与其交互，用户获取 zookeeper 服务的当前状态及相关信息\r\n\t- 用户在客户端可以通过 telenet 或者 nc（netcat） 向 zookeeper 提交相应的命令\r\n- 开启四字命令\r\n\t- 在 zoo.cfg 文件里加入配置项让这些指令放行\r\n\t\t- `4lw.commands.whitelist=*`\r\n\t- 在 zk 的启动脚本 zkServer.sh 中新增放行指令（添加ＶＭ环境变量）\r\n\t\t- `ZOOMAIN=\"-Dzookeeper.4lw.commands.whitelist=* ${ZOOMAIN}\"`\r\n- `echo [command] | nc [ip] [port]`\r\n\t- stat 命令用于查看 zk 的状态信息\r\n\t\t- `echo stat | nc 192.168.65.156 2181`\r\n\r\n| 四字命令 | 功能描述                                                                        |\r\n| ---- | --------------------------------------------------------------------------- |\r\n| conf | 3.3.0版本引入的。打印出服务相关配置的详细信息。                                                  |\r\n| cons | 3.3.0版本引入的。列出所有连接到这台服务器的客户端全部连接/会话详细信息。包括\"接受/发送\"的包数量、会话id、操作延迟、最后的操作执行等等信息。 |\r\n| crst | 3.3.0版本引入的。重置所有连接的连接和会话统计信息。                                                |\r\n| dump | 列出那些比较重要的会话和临时节点。这个命令只能在leader节点上有用。                                        |\r\n| envi | 打印出服务环境的详细信息。                                                               |\r\n| reqs | 列出未经处理的请求                                                                   |\r\n| ruok | 测试服务是否处于正确状态。如果确实如此，那么服务返回\"imok\"，否则不做任何相应。                                  |\r\n| stat | 输出关于性能和连接的客户端的列表。                                                           |\r\n| srst | 重置服务器的统计。                                                                   |\r\n| srvr | 3.3.0版本引入的。列出连接服务器的详细信息                                                     |\r\n| wchs | 3.3.0版本引入的。列出服务器watch的",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 3,
    "contentParts": 4
  },
  {
    "title": "Zookeeper-特性",
    "path": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "url": "/docs/architect/zookeeper/Zookeeper-texing.html",
    "content": "详细信息。                                                 |\r\n| wchc | 3.3.0版本引入的。通过session列出服务器watch的详细信息，它的输出是一个与watch相关的会话的列表。                  |\r\n| wchp | 3.3.0版本引入的。通过路径列出服务器watch的详细信息。它输出一个与session相关的路径。                          |\r\n| mntr | 3.4.0版本引入的。输出可用于检测集群健康状态的变量列表                                               |\r\n\r\n---\r\n## Leader 选举原理\r\n\r\n- zookeeper 的 leader 选举存在两个阶段\r\n\t- 一个是服务器启动时 leader 选举\r\n\t- 另一个是运行过程中 leader 服务器宕机\r\n- 重要的参数\r\n\t- 服务器 ID(myid)：编号越大在选举算法中权重越大\r\n\t- 事务 ID(zxid)：值越大说明数据越新，权重越大\r\n\t- 逻辑时钟(epoch-logicalclock)：同一轮投票过程中的逻辑时钟值是相同的，每投完一次值会增加\r\n- 选举状态\r\n\t- LOOKING: 竞选状态\r\n\t- FOLLOWING: 随从状态，同步 leader 状态，参与投票 \r\n\t- OBSERVING: 观察状态，同步 leader 状态，不参与投票 \r\n\t- LEADING: 领导者状态\r\n- 服务器启动时的 leader 选举\r\n\t- 每个节点启动的时候都 LOOKING 观望状态，接下来就开始进行选举主流程\r\n\t\t- 第一台服务器 server1启动时，无法进行 leader 选举\r\n\t\t- 当第二台服务器 server2 启动时，两台机器可以相互通信，进入 leader 选举过程\r\n\t- ![Zookeeper 选举](static/Zookeeper-特性-选举.png)\r\n\t\t1. 每台 server 发出一个投票\r\n\t\t\t1. 由于是初始情况，server1 和 server2 都将自己作为 leader 服务器进行投票\r\n\t\t\t2. 每次投票包含所推举的服务器myid、zxid、epoch，使用（myid，zxid）表示\r\n\t\t\t3. 此时 server1 投票为（1,0），server2 投票为（2,0），然后将各自投票发送给集群中其他机器\r\n\t\t2. 接收来自各个服务器的投票\r\n\t\t\t1. 集群中的每个服务器收到投票后，首先判断该投票的有效性\r\n\t\t\t2. 如检查是否是本轮投票（epoch）、是否来自 LOOKING 状态的服务器\r\n\t\t3. 分别处理投票\r\n\t\t\t1. 针对每一次投票，服务器都需要将其他服务器的投票和自己的投票进行对比\r\n\t\t\t\t1. 优先比较 epoch\r\n\t\t\t\t2. 检查 zxid，zxid 比较大的服务器优先作为 leader\r\n\t\t\t\t3. 如果 zxid 相同，那么就比较 myid，myid 较大的服务器作为 leader 服务器\r\n\t\t4. 统计投票\r\n\t\t\t1. 每次投票后，服务器统计投票信息，判断是否有过半机器接收到相同的投票信息\r\n\t\t\t2. server1、server2 都统计出集群中有两台机器接受了（2,0）的投票信息，此时已经选出了 server2 为 leader 节点\r\n\t\t5. 改变服务器状态\r\n\t\t\t1. 一旦确定了 leader，每个服务器响应更新自己的状态\r\n\t\t\t2. 如果是 follower，那么就变更为 FOLLOWING，如果是 Leader，变更为 LEADING\r\n\t\t\t3. 此时 server3继续启动，直接加入变更自己为 FOLLOWING\r\n- 运行过程中的 leader 选举：当集群中 leader 服务器出现宕机或者不可用情况时，整个集群无法对外提供服务，进入新一轮的 leader 选举\r\n\t1. 变更状态：leader 挂后，其他非 Oberver服务器将自身服务器状态变更为 LOOKING\r\n\t2. 每个 server 发出一个投票：在运行期间，每个服务器上 zxid 可能不同\r\n\t3. 处理投票：规则同启动过程\r\n\t4. 统计投票：与启动过程相同\r\n\t5. 改变服务器状态：与启动过程相同\r\n\r\n---\r\n## 数据同步流程\r\n\r\n- 在 Zookeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性\r\n- ZAB 协议分为两部分：消息广播；崩溃恢复\r\n- 消息广播\r\n\t- ![Zookeeper 事务](static/Zookeeper-特性-事务.png)\r\n\t- Zookeeper 使用单一的主进程 Leader 来接收和处理客户端所有事务请求\r\n\t- 并采用 ZAB 协议的原子广播协议，将事务请求以 Proposal 提议广播到所有 Follower 节点\r\n\t- 当集群中有过半的Follower 服务器进行正确的 ACK 反馈\r\n\t\t- 那么Leader就会再次向所有的 Follower 服务器发送commit 消息，将此次提案进行提交\r\n\t- 这个过程可以简称为 2pc 事务提交\r\n\t- 注意 Observer 节点只负责同步 Leader 数据，不参与 2PC 数据同步过程\r\n- 崩溃恢复\r\n\t- 在正常情况消息下广播能运行良好，但是一旦 Leader 服务器出现崩溃，或者由于网络原理导致 Leader 服务器失去了与过半 Follower 的通信，那么就会进入崩溃恢复模式\r\n\t- 需要选举出一个新的 Leader 服务器\r\n\t- 在这个过程中可能会出现两种数据不一致性的隐患，需要 ZAB 协议的特性进行避免\r\n\t\t- Leader 服务器将消息 commit 发出后，立即崩溃\r\n\t\t- Leader 服务器刚提出 proposal 后，立即崩溃\r\n\t- ZAB 协议的恢复模式使用了以下策略\r\n\t\t- 选举 zxid 最大的节点作为新的 leader\r\n\t\t- 新 leader 将事务日志中尚未提交的消息进行处理\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "Zookeeper-特性",
      "lvl1": "CP架构",
      "lvl2": "常见命令",
      "lvl3": "数据结构",
      "lvl4": "监听通知机制",
      "lvl5": "节点特性",
      "lvl6": "ACL权限控制",
      "lvl7": "集群",
      "lvl8": "四字命令",
      "lvl9": "Leader 选举原理",
      "lvl10": "数据同步流程"
    },
    "frontmatter": {
      "title": "Zookeeper-特性",
      "date": "2025/06/16"
    },
    "type": "content",
    "contentPart": 4,
    "contentParts": 4
  },
  {
    "title": "2025-03",
    "path": "/docs/diary/2025/2025-03.html",
    "url": "/docs/diary/2025/2025-03.html",
    "content": "---\r\ntitle: 2025-03\r\npassword: b593bf97f44387eb6fdc629acef2d138\r\ndate: 2025/03/08\r\n---\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## 2025-03-08\r\n\r\n- 优化博客站点\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "2025-03",
      "lvl1": "2025-03-08"
    },
    "frontmatter": {
      "title": "2025-03",
      "password": "b593bf97f44387eb6fdc629acef2d138",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "边缘填充算法",
    "path": "/docs/it/jisuanjituxingxue/bianyuantianchongsuanfa.html",
    "url": "/docs/it/jisuanjituxingxue/bianyuantianchongsuanfa.html",
    "content": "---\r\ntitle: 边缘填充算法\r\ndate: 2025/03/08\r\n---\r\n\r\n## 填充原理\r\n边缘填充算法是先求出多边形的每条边与扫描线的交点，然后**将交点右侧的所有像素颜色全部取为补色（或反色**）。按任意顺序处理完多边形的所有边后，就完成了多边形的填充任务。边缘填充算法利用了图像处理中的求“补”或求“反”的概念，对于黑白图像，求补就是把RGB(1,1,1)（白色）的像素置为RGB(0,0,0)（黑色），反之亦然；对于彩色图像，求补就是将背景色置为填充色，反之亦然。求补的一条基本性质是**一个像素求补两次就恢复为原色**。**如果多边形内部的像素被求补偶数次，保持原色，如果被求补奇数次，显示填充色。**\r\n\r\n## 填充过程\r\n假定边的顺序为E0、E1、E2、E3、E4、E5和E6。这里，边的顺序并不影响填充结果，只是方便编写循环结构而已。\r\n\r\n\r\n![边缘填充算法](static/边缘填充算法.png)\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "边缘填充算法",
      "lvl1": "填充原理",
      "lvl2": "填充过程"
    },
    "frontmatter": {
      "title": "边缘填充算法",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "期权交易策略",
    "path": "/docs/trader/options/qiquanjiaoyicelue.html",
    "url": "/docs/trader/options/qiquanjiaoyicelue.html",
    "content": "---\r\ntitle: 期权交易策略\r\ndate: 2025/03/06\r\n---\r\n\r\n## 单向策略\r\n\r\n::: tip\r\n|评估|Long Call|Long Put|Short Call|Short Put|\r\n|-|-|-|-|-|\r\n|预期|上涨|下跌|微涨/不变|微跌/不变/有买入意愿|\r\n|场景|看涨|看跌|赚权利金|赚权利金/低价买入|\r\n|权利|按行权价买入|按行权价卖出|-|-|\r\n|义务|-|-|按行权价卖出|按行权价买入|\r\n|成本|权利金|权利金|保证金|保证金|\r\n|收益|涨幅 - 权利金|跌幅 - 权利金|权利金 - (市价 - 行权价)|权利金 - (行权价 - 市价)|\r\n|亏损|损失权利金|损失权利金|越涨越亏|越跌越亏 （最低为0）|\r\n|风险|风险低；收益无限|风险低；收益高|风险无限；收益低|风险高；收益低|\r\n\r\n::: danger\r\n1. 卖方的最大成本取决于市场的波动性，虽然表格中用“保证金”表示，但实际计算中，卖方承担的亏损可能远超保证金。\r\n:::\r\n\r\n\r\n- 买入看涨期权：Long Call\r\n  - 预期：标的资产价格将上涨\r\n  - 权利：买方有权利在期权到期时按行权价买入标的资产，但没有义务。\r\n  - 成本：买方需要支付权利金。\r\n  - 收益：潜在收益是无限的（标的资产价格上涨越多，收益越大）。\r\n  - 风险：风险有限，最大损失是支付的权利金。\r\n- 买入看跌期权：Long Put\r\n  - 预期：标的资产价格将下跌\r\n  - 权利：买方有权利在期权到期时按行权价卖出标的资产，但没有义务。\r\n  - 成本：买方需要支付权利金。\r\n  - 收益：潜在收益有限，但标的资产价格跌得越多，收益越大（最低价格为0）。\r\n  - 风险：风险有限，最大损失是支付的权利金。\r\n- 卖出看涨期权：Short Call\r\n  - 预期：标的资产价格不会上涨太多或保持不变\r\n  - 义务：卖方有义务按行权价卖出标的资产给买方（如果买方行权）。\r\n  - 收益：收益有限，最大收益是收到的权利金。\r\n  - 风险：风险无限（标的资产价格上涨越多，卖方亏损越大）。\r\n- 卖出看跌期权：Short Put\r\n  - 预期：标的资产价格不会大幅下跌或保持不变\r\n  - 义务：卖方有义务按行权价买入标的资产（如果买方行权）。\r\n  - 收益：收益有限，最大收益是收到的权利金。\r\n  - 风险：风险很高（标的资产价格下跌越多，卖方亏损越大，但跌幅有限，最低为0）。\r\n\r\n\r\n## 价差策略\r\n\r\n::: tip\r\n|评估|Bull Spread|Bear Spread|\r\n|-|-|-|\r\n|预期|温和上涨|温和下跌|\r\n|场景|在看涨市场中降低成本|在看跌市场中降低成本|\r\n|收益|行权价差 - 净权利金|行权价差 - 净权利金|\r\n|成本|净权利金|净权利金|\r\n|亏损|净权利金|净权利金|\r\n|风险|风险低；收益低|风险低；收益低|\r\n|构成|买入较低行权价的看涨期权 <br/> 卖出较高行权价的看涨期权|买入较高行权价的看跌期权 <br/> 卖出较低行权价的看跌期权|\r\n\r\n::: info\r\n1. 如果标的价格超出价格区间以外，那么期权的权利与义务会互相抵消，所以限制了最大收益，同时也限制了最大亏损\r\n2. Bull Spread 和 Bear Spread 都是低风险、低收益的策略，适合温和的市场走势，而非剧烈波动\r\n:::\r\n\r\n- 牛市价差：Bull Spread\r\n  - 预期：适用于看涨市场，收益和风险都有限\r\n  - 构成：\r\n    - 买入较低行权价的看涨期权（成本较高）\r\n    - 卖出较高行权价的看涨期权（获得权利金）\r\n  - 收益风险：\r\n    - 最大收益：两行权价差 - 净支出\r\n    - 最大亏损：净支出（买入权利金 - 卖出权利金）\r\n- 熊市价差：Bear Spread\r\n  - 预期：适用于看跌市场，收益和风险都有限\r\n  - 构成：\r\n    - 买入较高行权价的看跌期权（成本较高）\r\n    - 卖出较低行权价的看跌期权（获得权利金）\r\n  - 收益风险：\r\n    - 最大收益：两行权价差 - 净支出\r\n    - 最大亏损：净支出（买入权利金 - 卖出权利金）\r\n\r\n\r\n### 跨式策略\r\n\r\n::: tip\r\n|评估|Long Straddle|Long Strangle|Short Straddle|Short Strangle|\r\n|-|-|-|-|-|\r\n|预期|大幅波动|大幅波动|||\r\n|场景|重大事件前|重大事件前|||\r\n|收益|波幅 - 净权利金|波幅 - 净权利金|||\r\n|成本|净权利金|净权利金|||\r\n|亏损|净权利金|净权利金|||\r\n|风险|风险低；收益高|风险低；收益高；成本低|||\r\n|构成|买入相同行权价的看涨期权 <br/> 买入相同行权价的看跌期权|买入较高行权价的看涨期权 <br/> 买入较低行权价的看跌期权|||\r\n:::\r\n\r\n\r\n\r\n\r\n### 复杂价差策略\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "期权交易策略",
      "lvl1": "单向策略",
      "lvl2": "价差策略"
    },
    "frontmatter": {
      "title": "期权交易策略",
      "date": "2025/03/06"
    },
    "type": "content"
  },
  {
    "title": "期权交易策略收益图表",
    "path": "/docs/trader/options/qiquanjiaoyicelueshouyitubiao.html",
    "url": "/docs/trader/options/qiquanjiaoyicelueshouyitubiao.html",
    "content": "---\r\ntitle: 期权交易策略收益图表\r\ndate: 2025/03/08\r\n---\r\n\r\n<iframe src=\"/html/OptionsStrategy.html\" style=\"width:100%; height: 1000px\"></iframe>\r\n\r\n<a href=\"/html/OptionsStrategy.html\" target=\"_blank\">全屏展示</a>\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "期权交易策略收益图表"
    },
    "frontmatter": {
      "title": "期权交易策略收益图表",
      "date": "2025/03/08"
    },
    "type": "content"
  },
  {
    "title": "实盘日记 - 2025 年",
    "path": "/docs/trading_journal/diary/2025.html",
    "url": "/docs/trading_journal/diary/2025.html",
    "content": "---\r\ntitle: 实盘日记 - 2025 年\r\ndate: 2025/03/19\r\n---\r\n\r\n## 2025/3/19 TQQQ CALL\r\n\r\n:::info\r\n- 策略类型：看涨期权（短期反弹博弈）\r\n- 期权类型：买入TQQQ Call期权\r\n- 行权价：61-62美元附近\r\n- 到期日：2-4周\r\n- 仓位：500美元以内\r\n- 止盈目标：EMA20（68美元附近）\r\n- 止损位：57美元以下\r\n\r\n|情境|股价目标|期权预估价值|盈亏金额|盈亏百分比|\r\n|-|-|-|-|-|\r\n|止盈|68美元|约6.2美元|盈利740美元|+148%|\t\t\t\t\r\n|止损|57美元|约0.8美元|亏损340美元|-68%|\r\n\r\n盈亏比大于2，属于较好的盈亏比\r\n:::\r\n\r\n预计收益计算（止盈情境）：假设未来1-2周内TQQQ上涨到EMA20附近（约68美元）\r\n- 行权价：62美元\r\n- 股价上涨到：68美元\r\n- 期权的内在价值 = 股票价格 – 行权价格 = 68 – 62 = 6美元\r\n- 期权买入成本：2.5美元/张\r\n- 期权到期时预估的价值：6美元（内在价值）+ 0.2美元左右的时间价值估计（由于临近到期，时间价值不多）= 约6.2美元\r\n- 每张期权盈利 = 6.2美元 - 2.5美元 = 3.7美元\r\n- 2张期权总盈利 = 3.7美元 × 2张 × 100股 = 740美元\r\n\r\n止盈情境下的收益率：\r\n- 总盈利 = 740美元\r\n- 总成本 = 500美元\r\n- 净利润 = 740美元\r\n- 盈利比例 = (740 ÷ 500) × 100% = 148%\r\n\r\n预计亏损计算（止损情境）：假设未来几天内TQQQ下跌到57美元以下\r\n- 行权价：62美元（看涨期权）\r\n- 跌破支撑位到57美元甚至更低，此时期权变为深度价外，价值快速缩水。\r\n- 假设跌破57美元时，看涨期权的价值大幅缩水到0.8美元左右（甚至更低），此时及时止损：\r\n- 每张期权亏损 = 买入成本 - 期权剩余价值 = 2.5美元 - 0.8美元 = 1.7美元\r\n- 2张期权总亏损 = 1.7美元 × 2张 × 100股 = 340美元\r\n\r\n止损情境下的亏损率：\r\n- 总亏损 = 340美元\r\n- 总成本 = 500美元\r\n- 亏损比例 = (340 ÷ 500) × 100% = 68%\r\n\r\n盈亏比评估：盈亏比大于2，属于较好的盈亏比\r\n- 盈利情境预期盈利 = 740美元\r\n- 亏损情境预期亏损 = 340美元\r\n- 盈亏比 = 740 ÷ 340 ≈ 2.18\r\n\r\n\r\n\r\n",
    "lang": "zh-CN",
    "hierarchy": {
      "lvl0": "实盘日记 - 2025 年",
      "lvl1": "2025/3/19 TQQQ CALL"
    },
    "frontmatter": {
      "title": "实盘日记 - 2025 年",
      "date": "2025/03/19"
    },
    "type": "content"
  }
]